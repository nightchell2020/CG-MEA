{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Networks\n",
    "\n",
    "- Three-way SoftMax or Multi-BCE classifier of normal, non-vascular MCI, and non-vascular dementia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import datetime\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "from IPython.display import clear_output\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import wandb\n",
    "\n",
    "# custom package\n",
    "from utils.eeg_dataset import *\n",
    "from models import *\n",
    "from utils.train_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook name\n",
    "def get_notebook_name():\n",
    "    import ipynbname\n",
    "    return ipynbname.name()\n",
    "nb_fname = get_notebook_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other settings\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # cleaner text\n",
    "\n",
    "plt.style.use('default') \n",
    "# ['Solarize_Light2', '_classic_test_patch', 'bmh', 'classic', 'dark_background', 'fast', \n",
    "#  'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn', 'seaborn-bright', 'seaborn-colorblind', \n",
    "#  'seaborn-dark', 'seaborn-dark-palette', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', \n",
    "#  'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', \n",
    "#  'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'tableau-colorblind10']\n",
    "\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams[\"font.family\"] = 'NanumGothic' # for Hangul in Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Set up the Dataset and the PyTorch Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_data = {}\n",
    "cfg_data['dataset'] = 'CAUHS'\n",
    "cfg_data['vascular'] = 'X'\n",
    "cfg_data['segment'] = 'no' # 'train', 'all', 'no'\n",
    "cfg_data['seed'] = 0\n",
    "cfg_data['crop_length'] = 200 * 10 # 10 seconds\n",
    "cfg_data['input_norm'] = 'dataset' # 'datatset', 'datapoint', 'no'\n",
    "cfg_data['EKG'] = 'O'\n",
    "cfg_data['photic'] = 'X'\n",
    "cfg_data['awgn'] = 1e-1\n",
    "cfg_data['awgn_age'] = 1e-1\n",
    "cfg_data['minibatch'] = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data file path\n",
    "data_path = r'dataset/02_Curated_Data/'\n",
    "meta_path = os.path.join(data_path, 'metadata_debug.json')\n",
    "\n",
    "with open(meta_path, 'r') as json_file:\n",
    "    metadata = json.load(json_file)\n",
    "\n",
    "# pprint.pprint(metadata[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter the Data According to the Target Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider only non-vascular symptoms\n",
    "if cfg_data['vascular'] == 'X': \n",
    "    diagnosis_filter = [\n",
    "        # Normal\n",
    "        {'type': 'Normal',\n",
    "         'include': ['normal'], \n",
    "         'exclude': []},\n",
    "        # Non-vascular MCI\n",
    "        {'type': 'Non-vascular MCI',\n",
    "         'include': ['mci'], \n",
    "         'exclude': ['mci_vascular']},\n",
    "        # Non-vascular dementia\n",
    "        {'type': 'Non-vascular dementia',\n",
    "         'include': ['dementia'], \n",
    "         'exclude': ['vd']},\n",
    "    ]\n",
    "# consider all cases\n",
    "elif cfg_data['vascular'] == 'O':\n",
    "    diagnosis_filter = [\n",
    "        # Normal\n",
    "        {'type': 'Normal',\n",
    "         'include': ['normal'], \n",
    "         'exclude': []},\n",
    "        # Non-vascular MCI\n",
    "        {'type': 'Non-vascular MCI',\n",
    "         'include': ['mci'], \n",
    "         'exclude': []},\n",
    "        # Non-vascular dementia\n",
    "        {'type': 'Non-vascular dementia',\n",
    "         'include': ['dementia'], \n",
    "         'exclude': []},\n",
    "    ]\n",
    "else:\n",
    "    raise ValueError(f\"cfg_data['vascular'] have to be set to one of ['O', 'X']\")\n",
    "\n",
    "    \n",
    "class_label_to_type = [d_f['type'] for d_f in diagnosis_filter]\n",
    "print('class_label_to_type:', class_label_to_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_class_label(label):\n",
    "    for c, f in enumerate(diagnosis_filter):\n",
    "        inc = set(f['include']) & set(label) == set(f['include'])\n",
    "        # inc = len(set(f['include']) & set(label)) > 0        \n",
    "        exc = len(set(f['exclude']) & set(label)) == 0\n",
    "        if  inc and exc:\n",
    "            return (c, f['type'])\n",
    "    return (-1, 'The others')\n",
    "\n",
    "\n",
    "splitted_metadata = [[] for i in diagnosis_filter]\n",
    "\n",
    "for m in metadata:\n",
    "    c, n = generate_class_label(m['label'])\n",
    "    if c >= 0:\n",
    "        m['class_type'] = n\n",
    "        m['class_label'] = c\n",
    "        splitted_metadata[c].append(m)\n",
    "        \n",
    "for i, split in enumerate(splitted_metadata):\n",
    "    if len(split) == 0:\n",
    "        print(f'(Warning) Split group {i} has no data.')\n",
    "    else:\n",
    "        print(f'- There are {len(split):} data belonging to {split[0][\"class_type\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the filtered dataset and shuffle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "random.seed(cfg_data['seed'])\n",
    "\n",
    "# Train : Val : Test = 8 : 1 : 1\n",
    "ratio1 = 0.8\n",
    "ratio2 = 0.1\n",
    "\n",
    "metadata_train = []\n",
    "metadata_val = []\n",
    "metadata_test = []\n",
    "\n",
    "for split in splitted_metadata:\n",
    "    random.shuffle(split)\n",
    "    \n",
    "    n1 = round(len(split) * ratio1)\n",
    "    n2 = n1 + round(len(split) * ratio2)\n",
    "\n",
    "    metadata_train.extend(split[:n1])\n",
    "    metadata_val.extend(split[n1:n2])\n",
    "    metadata_test.extend(split[n2:])\n",
    "\n",
    "random.shuffle(metadata_train)\n",
    "random.shuffle(metadata_val)\n",
    "random.shuffle(metadata_test)\n",
    "\n",
    "print('Train data size\\t\\t:', len(metadata_train))\n",
    "print('Validation data size\\t:', len(metadata_val))\n",
    "print('Test data size\\t\\t:', len(metadata_test))\n",
    "\n",
    "print('\\n', '--- Recheck ---', '\\n')\n",
    "train_class_nums = np.zeros((len(class_label_to_type)), dtype=np.int32)\n",
    "for m in metadata_train:\n",
    "    train_class_nums[m['class_label']] += 1\n",
    "\n",
    "val_class_nums = np.zeros((len(class_label_to_type)), dtype=np.int32)\n",
    "for m in metadata_val:\n",
    "    val_class_nums[m['class_label']] += 1\n",
    "\n",
    "test_class_nums = np.zeros((len(class_label_to_type)), dtype=np.int32)\n",
    "for m in metadata_test:\n",
    "    test_class_nums[m['class_label']] += 1\n",
    "\n",
    "print('Train data label distribution\\t:', train_class_nums, train_class_nums.sum())\n",
    "print('Val data label distribution\\t:', val_class_nums, val_class_nums.sum())\n",
    "print('Test data label distribution\\t:', test_class_nums, test_class_nums.sum())\n",
    "\n",
    "# random seed\n",
    "random.seed()\n",
    "\n",
    "# print([m['serial']  for m in metadata_train[:15]])\n",
    "# print([m['serial']  for m in metadata_val[:15]])\n",
    "# print([m['serial']  for m in metadata_test[:15]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compose the dataset transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = []\n",
    "for m in metadata_train:\n",
    "    ages.append(m['age'])\n",
    "\n",
    "ages = np.array(ages)\n",
    "age_mean = np.mean(ages)\n",
    "age_std = np.std(ages)\n",
    "\n",
    "print('Age mean and standard deviation:')\n",
    "print(age_mean, age_std)\n",
    "\n",
    "cfg_data['age_mean'] = age_mean\n",
    "cfg_data['age_std'] = age_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_train = [EEGRandomCrop(crop_length=cfg_data['crop_length']), \n",
    "                  EEGNormalizeAge(mean=cfg_data['age_mean'], std=cfg_data['age_std'])]\n",
    "composed_test = [EEGRandomCrop(crop_length=cfg_data['crop_length']), \n",
    "                 EEGNormalizeAge(mean=cfg_data['age_mean'], std=cfg_data['age_std'])]\n",
    "longer_composed_test = [EEGRandomCrop(crop_length=cfg_data['crop_length'] * 10), \n",
    "                        EEGNormalizeAge(mean=cfg_data['age_mean'], std=cfg_data['age_std'])]\n",
    "\n",
    "if cfg_data['awgn_age'] is None or cfg_data['awgn_age'] <= 1e-12:\n",
    "    pass\n",
    "elif cfg_data['awgn_age'] > 0.0:\n",
    "    composed_train += [EEGAddGaussianNoiseAge(mean=0.0, std=cfg_data['awgn_age'])]\n",
    "else:\n",
    "    raise ValueError(f\"cfg_data['awgn'] have to be None or a positive floating point number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg_data['input_norm'] == 'dataset':\n",
    "    # composed = transforms.Compose([EEGRandomCrop(crop_length=cfg_data['crop_length'])])\n",
    "    # train_dataset = EEGDataset(data_path, metadata_train, composed)\n",
    "\n",
    "    # signal_means = []\n",
    "    # signal_stds = []\n",
    "\n",
    "    # for i in range(10):\n",
    "    #     for d in train_dataset:\n",
    "    #         signal_means.append(d['signal'].mean(axis=1, keepdims=True))\n",
    "    #         signal_stds.append(d['signal'].std(axis=1, keepdims=True))\n",
    "\n",
    "    # signal_mean = np.mean(np.array(signal_means), axis=0)\n",
    "    # signal_std = np.mean(np.array(signal_stds), axis=0)\n",
    "\n",
    "    # print('Mean and standard deviation for signal:')\n",
    "    # print(signal_means, '\\n\\n', signal_stds)\n",
    "\n",
    "    # SPEED-UP\n",
    "    signal_mean = np.array([[ 0.1127599 ], [ 0.06298441], [-0.02522413], [ 0.00508518], \n",
    "                             [ 0.12026667], [-0.19987741], [-0.00516898], [ 0.00239212], \n",
    "                             [-0.02861219], [-0.02973673], [-0.02515898], [-0.00060568], \n",
    "                             [ 0.04921601], [-0.00562142], [-0.04888308], [-0.0438447 ], \n",
    "                             [ 0.07532331], [-0.01890181], [-0.044876  ], [-0.00365138], [-0.01564376]])\n",
    "    signal_std = np.array([[46.09896  ], [20.50783  ], [11.196733 ], [11.236944 ], [15.070532 ], \n",
    "                            [47.664406 ], [19.32747  ], [10.106162 ], [11.314243 ], [15.065008 ],\n",
    "                            [20.478817 ], [13.86243  ], [13.2378435], [21.554531 ], [16.875841 ],\n",
    "                            [13.989367 ], [19.789454 ], [10.839711 ], [11.179158 ], [94.12114  ], [65.64865  ]])\n",
    "    \n",
    "    cfg_data['signal_mean'] = signal_mean\n",
    "    cfg_data['signal_std'] = signal_std\n",
    "    \n",
    "    composed_train += [EEGNormalizeMeanStd(mean=cfg_data['signal_mean'], \n",
    "                                           std=cfg_data['signal_std'])]\n",
    "    composed_test += [EEGNormalizeMeanStd(mean=cfg_data['signal_mean'], \n",
    "                                          std=cfg_data['signal_std'])]\n",
    "    longer_composed_test += [EEGNormalizeMeanStd(mean=cfg_data['signal_mean'], \n",
    "                                                 std=cfg_data['signal_std'])]\n",
    "    \n",
    "elif cfg_data['input_norm'] == 'datapoint':\n",
    "    composed_train += [EEGNormalizePerSignal()]\n",
    "    composed_test += [EEGNormalizePerSignal()]\n",
    "    longer_composed_test += [EEGNormalizePerSignal()]\n",
    "elif cfg_data['input_norm'] == 'no':\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError(f\"cfg_data['input_norm'] have to be set to one of ['dataset', 'datapoint', 'no']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg_data['EKG'] == 'O':\n",
    "    pass\n",
    "elif cfg_data['EKG'] == 'X':\n",
    "    composed_train += [EEGDropEKGChannel()]\n",
    "    composed_test += [EEGDropEKGChannel()]\n",
    "    longer_composed_test += [EEGDropEKGChannel()]\n",
    "else:\n",
    "    raise ValueError(f\"cfg_data['EKG'] have to be set to one of ['O', 'X']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg_data['photic'] == 'O':\n",
    "    pass\n",
    "elif cfg_data['photic'] == 'X':\n",
    "    composed_train += [EEGDropPhoticChannel()]\n",
    "    composed_test += [EEGDropPhoticChannel()]\n",
    "    longer_composed_test += [EEGDropPhoticChannel()]\n",
    "else:\n",
    "    raise ValueError(f\"cfg_data['photic'] have to be set to one of ['O', 'X']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg_data['awgn'] is None or cfg_data['awgn'] <= 1e-12:\n",
    "    pass\n",
    "elif cfg_data['awgn'] > 0.0:\n",
    "    composed_train += [EEGAddGaussianNoise(mean=0.0, std=cfg_data['awgn'])]\n",
    "else:\n",
    "    raise ValueError(f\"cfg_data['awgn'] have to be None or a positive floating point number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_train += [EEGToTensor()]\n",
    "composed_test += [EEGToTensor()]\n",
    "longer_composed_test += [EEGToTensor()]\n",
    "\n",
    "composed_train = transforms.Compose(composed_train)\n",
    "composed_test = transforms.Compose(composed_test)\n",
    "longer_composed_test = transforms.Compose(longer_composed_test)\n",
    "\n",
    "print('composed_train:', composed_train)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "print('composed_test:', composed_test)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "print('longer_composed_test:', longer_composed_test)\n",
    "print('\\n' + '-' * 100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrap the splitted data using PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EEGDataset(data_path, metadata_train, composed_train)\n",
    "val_dataset = EEGDataset(data_path, metadata_val, composed_test)\n",
    "test_dataset = EEGDataset(data_path, metadata_test, composed_test)\n",
    "longer_test_dataset = EEGDataset(data_path, metadata_test, longer_composed_test)\n",
    "\n",
    "print(train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0])\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "print(val_dataset[0]['signal'].shape)\n",
    "print(val_dataset[0])\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "print(test_dataset[0]['signal'].shape)\n",
    "print(test_dataset[0])\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "print(longer_test_dataset[0]['signal'].shape)\n",
    "print(longer_test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train, validation, test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == 'cuda':\n",
    "    num_workers = 0 # A number other than 0 causes an error\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=cfg_data['minibatch'], \n",
    "                          shuffle=True, \n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers, \n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                        batch_size=cfg_data['minibatch'], \n",
    "                        shuffle=False, \n",
    "                        drop_last=False,\n",
    "                        num_workers=num_workers, \n",
    "                        pin_memory=pin_memory,\n",
    "                        collate_fn=eeg_collate_fn)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         batch_size=cfg_data['minibatch'], \n",
    "                         shuffle=False, \n",
    "                         drop_last=False,\n",
    "                         num_workers=num_workers, \n",
    "                         pin_memory=pin_memory,\n",
    "                         collate_fn=eeg_collate_fn)\n",
    "\n",
    "longer_test_loader = DataLoader(longer_test_dataset, \n",
    "                                batch_size=cfg_data['minibatch'] // 2, # memory capacity\n",
    "                                shuffle=False, \n",
    "                                drop_last=False,\n",
    "                                num_workers=num_workers, \n",
    "                                pin_memory=pin_memory,\n",
    "                                collate_fn=eeg_collate_fn)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    sample_batched['signal'].to(device)\n",
    "    sample_batched['age'].to(device)\n",
    "    sample_batched['class_label'].to(device)\n",
    "    \n",
    "    print(i_batch, \n",
    "          sample_batched['signal'].shape, \n",
    "          sample_batched['age'].shape, \n",
    "          sample_batched['class_label'].shape, \n",
    "          len(sample_batched['metadata']))\n",
    "    \n",
    "    if i_batch > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Define Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def calculate_final_shape(model):\n",
    "    x = torch.zeros_like(sample_batched['signal']).to(device)\n",
    "    model(x, age=sample_batched['age'].to(device))\n",
    "    return model.get_final_shape()\n",
    "\n",
    "\n",
    "def visualize_network_tensorboard(model, name):\n",
    "    # default `log_dir` is \"runs\" - we'll be more specific here\n",
    "    writer = SummaryWriter('runs/' + nb_fname + '_' + name)\n",
    "\n",
    "    for batch_i, sample_batched in enumerate(train_loader):\n",
    "        # pull up the batch data\n",
    "        x = sample_batched['signal'].to(device)\n",
    "        age = sample_batched['age'].to(device)\n",
    "        target = sample_batched['class_label'].to(device)\n",
    "\n",
    "        # apply model on whole batch directly on device\n",
    "        writer.add_graph(model, (x, age))\n",
    "        output = model(x, age, print_shape=True)\n",
    "        break\n",
    "        \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_common_model = {'in_channels': train_dataset[0]['signal'].shape[0], \n",
    "                    'out_dims': len(class_label_to_type)}\n",
    "model_pool = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D Tiny CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-Tiny-CNN'\n",
    "cfg_model['generator'] = TinyCNN1D\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M7 model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-M7'\n",
    "cfg_model['generator'] = M7\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 256\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M7 model (conv-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-M7'\n",
    "cfg_model['generator'] = M7\n",
    "cfg_model['use_age'] = 'conv'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 256\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M7 model (no-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-M7'\n",
    "cfg_model['generator'] = M7\n",
    "cfg_model['use_age'] = None\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 256\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNet model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-29'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNet model (conv-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-29'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'conv'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNet model (no-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-29'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = None\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deeper 1D ResNet model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-53'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deeper 1D ResNet model (conv-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-53'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'conv'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shallower 1D ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-21'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BasicBlock1D\n",
    "cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tiny 1D ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-13'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BasicBlock1D\n",
    "cfg_model['conv_layers'] = [1, 1, 1, 1]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Dilated 1D ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-Multi-Dilated-ResNet-53'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = MultiBottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 32\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNeXt-53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNeXt-53'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['groups'] = 32\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNeXt-103'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [3, 4, 23, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['groups'] = 32\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNet-20 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '2D-ResNet-20' # resnet-18 + two more fc layer\n",
    "cfg_model['generator'] = ResNet2D\n",
    "cfg_model['block'] = BasicBlock2D\n",
    "cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['n_fft'] = 100\n",
    "cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNet-52 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '2D-ResNet-52' # resnet-50 + two more fc layer\n",
    "cfg_model['generator'] = ResNet2D\n",
    "cfg_model['block'] = Bottleneck2D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['n_fft'] = 100\n",
    "cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN-Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-CNN-Transformer'\n",
    "# cfg_model['generator'] = CNNTransformer\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 256\n",
    "# cfg_model['n_encoders'] = 4\n",
    "# cfg_model['n_heads'] = 4\n",
    "# cfg_model['dropout'] = 0.2\n",
    "# cfg_model['LR'] = 1e-3\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# cfg_model['num_params'] = count_parameters(model)\n",
    "# cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "# print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "# print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# # tensorboard visualization\n",
    "# # visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "# del model\n",
    "# model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize the loaded models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cfg_model in model_pool:\n",
    "    pprint.pp(cfg_model, width=150)\n",
    "    print('\\n' + '-' * 100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training configurations\n",
    "cfg_train = {}\n",
    "cfg_train['iterations'] = 100000\n",
    "cfg_train['history_interval'] = cfg_train['iterations'] // 500\n",
    "cfg_train['lr_decay_step'] = round(cfg_train['iterations'] * 0.8)\n",
    "cfg_train['lr_decay_gamma'] = 0.1\n",
    "cfg_train['weight_decay'] = 1e-2\n",
    "cfg_train['mixup'] = 0.0 # 0 for no usage\n",
    "cfg_train['criterion'] = 'cross-entropy' # 'cross-entropy', 'multi-bce'\n",
    "cfg_train['tr_ms'] = train_multistep if cfg_train.get('mixup', 0) < 1e-12 else train_mixup_multistep\n",
    "cfg_train['device'] = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cfg_model in model_pool:\n",
    "    if cfg_model[\"LR\"] is None:\n",
    "        print(f'{cfg_model[\"model\"]} LR searching..')\n",
    "        model = cfg_model['generator'](**cfg_model).to(device)\n",
    "        model.train()\n",
    "        \n",
    "        record = learning_rate_search(model, train_loader, \n",
    "                                      min_log_lr=-4.5, max_log_lr=-3.0, \n",
    "                                      trials=100, config=cfg_train, steps=100)\n",
    "        best_log_lr = record[np.argmax(np.array([v for lr, v in record]))][0]\n",
    "        \n",
    "        cfg_model['LR'] = 10 ** best_log_lr\n",
    "        cfg_model['lr_search'] = record\n",
    "        \n",
    "        print(f'best lr {cfg_model[\"LR\"]:.5e} / log_lr {best_log_lr}')\n",
    "    else:\n",
    "        print(f'{cfg_model[\"model\"]}: {cfg_model[\"LR\"]:.5e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "save_temporary = False\n",
    "draw_result = True\n",
    "\n",
    "# progress bar\n",
    "pbar = tqdm(total=len(model_pool) * cfg_train['iterations'])\n",
    "\n",
    "# train process on model_pool\n",
    "for cfg_model in model_pool:\n",
    "    print('*'*120)\n",
    "    print(f'{\"*\"*30}{cfg_model[\"model\"] + \" train starts\":^60}{\"*\"*30}')\n",
    "    print('*'*120)\n",
    "    \n",
    "    # wandb initialization\n",
    "    config = {}\n",
    "    config.update(cfg_data)\n",
    "    config.update(cfg_train)\n",
    "    config.update(cfg_model)\n",
    "    \n",
    "    # generate model and its trainer\n",
    "    model = config['generator'](**config).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), \n",
    "                            lr=config['LR'], \n",
    "                            weight_decay=config['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, \n",
    "                                          step_size=config['lr_decay_step'], \n",
    "                                          gamma=config['lr_decay_gamma'])\n",
    "    \n",
    "    wandb_run = wandb.init(project=\"eeg-analysis\", \n",
    "                           entity=\"ipis-mjkim\", \n",
    "                           reinit=True,\n",
    "                           save_code=True, \n",
    "                           notes=nb_fname,\n",
    "                           config=config)\n",
    "    wandb.run.name = wandb.run.id\n",
    "    \n",
    "    save_path = f'checkpoint_temp/{wandb.run.name}/'\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    with wandb_run:\n",
    "        wandb.watch(model, log='all', \n",
    "                    log_freq=config['history_interval'], \n",
    "                    log_graph=True)\n",
    "        \n",
    "        # train and validation routine\n",
    "        best_val_acc = 0\n",
    "        for i in range(0, config[\"iterations\"], config[\"history_interval\"]):\n",
    "            # train 'history_interval' steps\n",
    "            loss, train_acc = config['tr_ms'](model, train_loader, optimizer, scheduler, \n",
    "                                              config, config[\"history_interval\"])\n",
    "            \n",
    "            # validation\n",
    "            val_acc, _, _, _, _ = check_accuracy(model, val_loader, config, repeat=10)\n",
    "            \n",
    "            if best_val_acc < val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_model_state = deepcopy(model.state_dict())                \n",
    "                if save_model and save_temporary:\n",
    "                    path = os.path.join(save_path, f'{config[\"model\"]}')\n",
    "                    torch.save(best_model_state, path)                    \n",
    "                \n",
    "            # log\n",
    "            wandb.log({'Loss': loss, \n",
    "                       'Train Accuracy': train_acc, \n",
    "                       'Validation Accuracy': val_acc}, step=i)\n",
    "            pbar.update(config['history_interval'])\n",
    "\n",
    "        # calculate the test accuracies for best and last models\n",
    "        last_model_state = deepcopy(model.state_dict())\n",
    "        last_test_result = check_accuracy(model, test_loader, config, repeat=30)\n",
    "        last_test_acc = last_test_result[0]\n",
    "        \n",
    "        model.load_state_dict(best_model_state)\n",
    "        best_test_result = check_accuracy(model, test_loader, config, repeat=30)\n",
    "        best_test_acc = best_test_result[0]\n",
    " \n",
    "        if last_test_acc < best_test_acc:\n",
    "            model_state = best_model_state\n",
    "            test_result = best_test_result\n",
    "        else:\n",
    "            model_state = last_model_state\n",
    "            test_result = last_test_result\n",
    "            \n",
    "        model.load_state_dict(model_state)\n",
    "        test_acc, test_confusion, test_debug, score, target = test_result\n",
    "        \n",
    "        # calculate the test accuracies for final model on much longer sequence\n",
    "        last_test_result = check_accuracy(model, longer_test_loader, config, repeat=30)\n",
    "        longer_test_acc = last_test_result[0]\n",
    "        \n",
    "        # save the model\n",
    "        if save_model:\n",
    "            path = os.path.join(save_path, f'{config[\"model\"]}')\n",
    "            torch.save(model_state, path)\n",
    "            \n",
    "        # leave the message\n",
    "        wandb.log({'Test Accuracy': test_acc,\n",
    "                   '(Best / Last) Test Accuracy': ('Best' if last_test_acc < best_test_acc else 'Last', \n",
    "                                                   round(best_test_acc, 2), round(last_test_acc, 2)),\n",
    "                   'Confusion Matrix (Array)': test_confusion,\n",
    "                   'Test Accuracy (Longer)': longer_test_acc, \n",
    "                   'Test Debug Table/Serial': test_debug[0], \n",
    "                   'Test Debug Table/EDF': test_debug[1], \n",
    "                   'Test Debug Table/Pred': test_debug[2], \n",
    "                   'Test Debug Table/GT': test_debug[3]})\n",
    "        \n",
    "        if 'lr_search' in config:\n",
    "            draw_learning_rate_record(config['lr_search'], use_wandb=True)\n",
    "            \n",
    "        \n",
    "        if draw_result:\n",
    "            draw_roc_curve(score, target, class_label_to_type, use_wandb=True)\n",
    "            draw_confusion(test_confusion, class_label_to_type, use_wandb=True)\n",
    "            draw_debug_table(test_debug, use_wandb=True)\n",
    "            wandb.log({\"Confusion Matrix\": wandb.plot.confusion_matrix(y_true=target, \n",
    "                                                                              preds=score.argmax(axis=-1), \n",
    "                                                                              class_names=class_label_to_type)})\n",
    "            wandb.log({\"ROC Curve\": wandb.plot.roc_curve(target, score, labels=class_label_to_type)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
