{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and DataLoader\n",
    "\n",
    "This notebook loads the `CAUEEG` dataset, tests some useful preprocessing, and makes up the PyTorch DataLoader instances for the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_dataset import *\n",
    "from datasets.caueeg_script import *\n",
    "from datasets.pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.11.0+cu113\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data file path\n",
    "data_path = r'local/dataset/02_Curated_Data_220412/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Load the CAUEEG dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the whole CAUEEG data as a PyTorch dataset instance without considering the target task (no train/val/test sets and no class label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_name': 'CAUEEG dataset',\n",
      " 'signal_header': ['Fp1-AVG', 'F3-AVG', 'C3-AVG', 'P3-AVG', 'O1-AVG', 'Fp2-AVG', 'F4-AVG', 'C4-AVG', 'P4-AVG', 'O2-AVG', 'F7-AVG', 'T3-AVG', 'T5-AVG', 'F8-AVG', 'T4-AVG', 'T6-AVG', 'FZ-AVG', 'CZ-AVG', 'PZ-AVG', 'EKG', 'Photic']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 78,\n",
      " 'serial': '00001',\n",
      " 'signal': array([[  0., -11., -13., ...,   0.,   0.,   0.],\n",
      "       [ 29.,  33.,  34., ...,   0.,   0.,   0.],\n",
      "       [ -3.,  -6.,  -3., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ -4.,  -2.,   1., ...,   0.,   0.,   0.],\n",
      "       [112.,  67.,  76., ...,   0.,   0.,   0.],\n",
      "       [ -1.,  -1.,  -1., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 56,\n",
      " 'serial': '00002',\n",
      " 'signal': array([[  39.,   58.,   72., ...,    0.,    0.,    0.],\n",
      "       [   4.,   12.,   13., ...,    0.,    0.,    0.],\n",
      "       [   1.,   -2.,   -3., ...,    0.,    0.,    0.],\n",
      "       ...,\n",
      "       [   2.,    1.,    1., ...,    0.,    0.,    0.],\n",
      "       [ -22., -173., -175., ...,    0.,    0.,    0.],\n",
      "       [   2.,    0.,    0., ...,    0.,    0.,    0.]]),\n",
      " 'symptom': ['normal', 'smi']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         load_event=False, \n",
    "                                                         file_format='edf',\n",
    "                                                         transform=None)\n",
    "\n",
    "pprint.pprint(config_data, width=250)\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(full_eeg_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(full_eeg_dataset[1])\n",
    "print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the CAUEEG task1 datasets as the PyTorch dataset instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_label_to_name': ['Normal', 'MCI', 'Dementia'],\n",
      " 'class_name_to_label': {'Dementia': 2, 'MCI': 1, 'Normal': 0},\n",
      " 'task_description': 'Classification of [Normal], [MCI], and [Dementia] '\n",
      "                     'symptoms.',\n",
      " 'task_name': 'CAUEEG-task1 benchmark'}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 81,\n",
      " 'class_label': 2,\n",
      " 'class_name': 'Dementia',\n",
      " 'serial': '01222',\n",
      " 'signal': array([[  1.,   1.,  -1., ...,   0.,   0.,   0.],\n",
      "       [-24., -14., -14., ...,   0.,   0.,   0.],\n",
      "       [ -6.,  -5.,  -6., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ -1.,   6.,   6., ...,   0.,   0.,   0.],\n",
      "       [-42., -62., -59., ...,   0.,   0.,   0.],\n",
      "       [  0.,   0.,  -1., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['dementia', 'ad', 'load']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 74,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00857',\n",
      " 'signal': array([[118.,  91.,  91., ...,   0.,   0.,   0.],\n",
      "       [ 27.,  16.,  16., ...,   0.,   0.,   0.],\n",
      "       [  9.,   6.,   4., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ -8.,  -3.,  -3., ...,   0.,   0.,   0.],\n",
      "       [179., 347., 327., ...,   0.,   0.,   0.],\n",
      "       [ -1.,  -1.,   0., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['normal', 'smi']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 77,\n",
      " 'class_label': 1,\n",
      " 'class_name': 'MCI',\n",
      " 'serial': '01255',\n",
      " 'signal': array([[-14.,  22.,  27., ...,   0.,   0.,   0.],\n",
      "       [-22., -17., -19., ...,   0.,   0.,   0.],\n",
      "       [  1.,   4.,   4., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ 10.,   8.,   5., ...,   0.,   0.,   0.],\n",
      "       [-30., -23.,  -4., ...,   0.,   0.,   0.],\n",
      "       [  1.,   1.,  -2., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_ef']}\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf', \n",
    "                                                                                  transform=None)\n",
    "pprint.pprint(config_data)\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(train_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(val_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the CAUEEG task2 datasets as the PyTorch dataset instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_label_to_name': ['Normal', 'Abnormal'],\n",
      " 'class_name_to_label': {'Abnormal': 1, 'Normal': 0},\n",
      " 'task_description': 'Classification of [Normal] and [Abnormal] symptoms',\n",
      " 'task_name': 'CAUEEG-task2 benchmark'}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 66,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00085',\n",
      " 'signal': array([[ 39.,  87.,  85., ...,   0.,   0.,   0.],\n",
      "       [ 17.,  64.,  67., ...,   0.,   0.,   0.],\n",
      "       [ -1.,   9.,  12., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ 10.,   3.,   3., ...,   0.,   0.,   0.],\n",
      "       [ 30.,  46., -30., ...,   0.,   0.,   0.],\n",
      "       [  2.,   2.,   1., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 79,\n",
      " 'class_label': 1,\n",
      " 'class_name': 'Abnormal',\n",
      " 'serial': '01203',\n",
      " 'signal': array([[117., 165., 163., ...,   0.,   0.,   0.],\n",
      "       [ 38.,  58.,  56., ...,   0.,   0.,   0.],\n",
      "       [  1.,  -3.,  -2., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ 16.,  22.,  19., ...,   0.,   0.,   0.],\n",
      "       [ 69.,  48., -15., ...,   0.,   0.,   0.],\n",
      "       [ -1.,  -1.,   0., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_ef']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 59,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00560',\n",
      " 'signal': array([[  9.,   8.,   1., ...,   0.,   0.,   0.],\n",
      "       [ 24.,  24.,  21., ...,   0.,   0.,   0.],\n",
      "       [  4.,  12.,  12., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ 10.,  13.,  15., ...,   0.,   0.,   0.],\n",
      "       [ -9., -17., -10., ...,   0.,   0.,   0.],\n",
      "       [  0.,  -3.,  -3., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['normal', 'cb_normal']}\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf', \n",
    "                                                                                  transform=None)\n",
    "pprint.pprint(config_data)\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(train_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(val_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 81,\n",
      " 'class_label': 2,\n",
      " 'class_name': 'Dementia',\n",
      " 'event': [[0, 'Start Recording'],\n",
      "           [0, 'New Montage - Montage 002'],\n",
      "           [13926, 'Eyes Open'],\n",
      "           [14562, 'Eyes Closed'],\n",
      "           [16000, 'Paused'],\n",
      "           [18000, 'Recording Resumed'],\n",
      "           [20984, 'Eyes Open'],\n",
      "           [21898, 'Eyes Closed'],\n",
      "           [23258, 'Eyes Open'],\n",
      "           [23866, 'Eyes Closed'],\n",
      "           [38064, 'Eyes Open'],\n",
      "           [53800, 'Paused'],\n",
      "           [55600, 'Recording Resumed'],\n",
      "           [62090, 'artifact'],\n",
      "           [62800, 'Paused'],\n",
      "           [64600, 'Recording Resumed'],\n",
      "           [66332, 'Move'],\n",
      "           [70290, 'Move'],\n",
      "           [71122, 'Move'],\n",
      "           [73030, 'Move'],\n",
      "           [73762, 'Move'],\n",
      "           [74600, 'Paused'],\n",
      "           [86600, 'Recording Resumed'],\n",
      "           [88970, 'swallowing'],\n",
      "           [90020, 'Eyes Closed'],\n",
      "           [91490, 'Eyes Open'],\n",
      "           [92708, 'Eyes Closed'],\n",
      "           [95124, 'Eyes Open'],\n",
      "           [95822, 'Eyes Closed'],\n",
      "           [96238, 'Photic On - 3.0 Hz'],\n",
      "           [96740, 'Eyes Open'],\n",
      "           [97496, 'Eyes Closed'],\n",
      "           [98254, 'Photic Off'],\n",
      "           [100312, 'Photic On - 6.0 Hz'],\n",
      "           [101024, 'Eyes Open'],\n",
      "           [101654, 'Eyes Closed'],\n",
      "           [102328, 'Photic Off'],\n",
      "           [104344, 'Photic On - 9.0 Hz'],\n",
      "           [106359, 'Photic Off'],\n",
      "           [106904, 'Eyes Open'],\n",
      "           [108038, 'Eyes Closed'],\n",
      "           [108418, 'Photic On - 12.0 Hz'],\n",
      "           [110433, 'Photic Off'],\n",
      "           [112576, 'Photic On - 15.0 Hz'],\n",
      "           [114508, 'Photic Off'],\n",
      "           [114842, 'Eyes Open'],\n",
      "           [116311, 'Eyes Closed'],\n",
      "           [116524, 'Photic On - 18.0 Hz'],\n",
      "           [118582, 'Photic Off'],\n",
      "           [120598, 'Photic On - 21.0 Hz'],\n",
      "           [122614, 'Photic Off'],\n",
      "           [122990, 'Eyes Open'],\n",
      "           [124292, 'Eyes Closed'],\n",
      "           [124672, 'Photic On - 24.0 Hz'],\n",
      "           [126688, 'Photic Off'],\n",
      "           [128746, 'Photic On - 27.0 Hz'],\n",
      "           [130761, 'Photic Off'],\n",
      "           [131390, 'Eyes Open'],\n",
      "           [132566, 'Eyes Closed'],\n",
      "           [132778, 'Photic On - 30.0 Hz'],\n",
      "           [134794, 'Photic Off'],\n",
      "           [139622, 'Eyes Open'],\n",
      "           [141096, 'Eyes Closed'],\n",
      "           [142530, 'eye blinking'],\n",
      "           [153528, 'Eyes Open'],\n",
      "           [155964, 'Eyes Closed'],\n",
      "           [163692, 'Eyes Open'],\n",
      "           [165834, 'Eyes Closed'],\n",
      "           [174200, 'Paused']],\n",
      " 'serial': '01222',\n",
      " 'signal': array([[  1.,   1.,  -1., ...,   0.,   0.,   0.],\n",
      "       [-24., -14., -14., ...,   0.,   0.,   0.],\n",
      "       [ -6.,  -5.,  -6., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ -1.,   6.,   6., ...,   0.,   0.,   0.],\n",
      "       [-42., -62., -59., ...,   0.,   0.,   0.],\n",
      "       [  0.,   0.,  -1., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['dementia', 'ad', 'load']}\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=True, \n",
    "                                                                                  file_format='edf', \n",
    "                                                                                  transform=None)\n",
    "pprint.pprint(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Format: `EDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'signal': array([[ 39.,  87.,  85., ...,   0.,   0.,   0.],\n",
      "       [ 17.,  64.,  67., ...,   0.,   0.,   0.],\n",
      "       [ -1.,   9.,  12., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ 10.,   3.,   3., ...,   0.,   0.,   0.],\n",
      "       [ 30.,  46., -30., ...,   0.,   0.,   0.],\n",
      "       [  2.,   2.,   1., ...,   0.,   0.,   0.]]), 'serial': '00085', 'age': 66, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "{'signal': array([[  45.,   -7.,   -9., ...,    0.,    0.,    0.],\n",
      "       [   1.,   -2.,  -11., ...,    0.,    0.,    0.],\n",
      "       [   2.,   -6.,   -5., ...,    0.,    0.,    0.],\n",
      "       ...,\n",
      "       [  -4.,    2.,    4., ...,    0.,    0.,    0.],\n",
      "       [ -71., -115.,  -98., ...,    0.,    0.,    0.],\n",
      "       [   0.,    0.,   -1., ...,    0.,    0.,    0.]]), 'serial': '00790', 'age': 59, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "CPU times: total: 188 ms\n",
      "Wall time: 188 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf', \n",
    "                                                                                  transform=None)\n",
    "\n",
    "print(train_dataset[0])\n",
    "print(train_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Format: `PyArrow Feather`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'signal': array([[ 39,  87,  85, ..., -52, -49, -45],\n",
      "       [ 17,  64,  67, ..., -62, -58, -56],\n",
      "       [ -1,   9,  12, ...,  -8,  -7,  -6],\n",
      "       ...,\n",
      "       [ 10,   3,   3, ...,  -1,   0,   2],\n",
      "       [ 30,  46, -30, ...,  -6, -17, -15],\n",
      "       [  2,   2,   1, ...,   1,   0,   0]]), 'serial': '00085', 'age': 66, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "{'signal': array([[  45,   -7,   -9, ...,   15,   18,   16],\n",
      "       [   1,   -2,  -11, ...,  -15,  -14,  -14],\n",
      "       [   2,   -6,   -5, ...,   12,   10,   11],\n",
      "       ...,\n",
      "       [  -4,    2,    4, ...,   -2,   -1,   -1],\n",
      "       [ -71, -115,  -98, ...,    3,    5,   -2],\n",
      "       [   0,    0,   -1, ...,    1,   -1,    0]]), 'serial': '00790', 'age': 59, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "CPU times: total: 109 ms\n",
      "Wall time: 17 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather', \n",
    "                                                                                  transform=None)\n",
    "\n",
    "print(train_dataset[0])\n",
    "print(train_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Format: `NumPy Memmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'signal': memmap([[ 39,  87,  85, ..., -52, -49, -45],\n",
      "        [ 17,  64,  67, ..., -62, -58, -56],\n",
      "        [ -1,   9,  12, ...,  -8,  -7,  -6],\n",
      "        ...,\n",
      "        [ 10,   3,   3, ...,  -1,   0,   2],\n",
      "        [ 30,  46, -30, ...,  -6, -17, -15],\n",
      "        [  2,   2,   1, ...,   1,   0,   0]]), 'serial': '00085', 'age': 66, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "{'signal': memmap([[  45,   -7,   -9, ...,   15,   18,   16],\n",
      "        [   1,   -2,  -11, ...,  -15,  -14,  -14],\n",
      "        [   2,   -6,   -5, ...,   12,   10,   11],\n",
      "        ...,\n",
      "        [  -4,    2,    4, ...,   -2,   -1,   -1],\n",
      "        [ -71, -115,  -98, ...,    3,    5,   -2],\n",
      "        [   0,    0,   -1, ...,    1,   -1,    0]]), 'serial': '00790', 'age': 59, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap', \n",
    "                                                                                  transform=None)\n",
    "\n",
    "print(train_dataset[0])\n",
    "print(train_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PyTorch Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Drop channel(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1-AVG', 'F3-AVG', 'C3-AVG', 'P3-AVG', 'O1-AVG', 'Fp2-AVG', 'F4-AVG', 'C4-AVG', 'P4-AVG', 'O2-AVG', 'F7-AVG', 'T3-AVG', 'T5-AVG', 'F8-AVG', 'T4-AVG', 'T6-AVG', 'FZ-AVG', 'CZ-AVG', 'PZ-AVG', 'EKG', 'Photic']\n",
      "channel_ekg:  19\n",
      "channel_photic:  20\n"
     ]
    }
   ],
   "source": [
    "anno_path = os.path.join(data_path, 'annotation.json')\n",
    "with open(anno_path, 'r') as json_file:\n",
    "    annotation = json.load(json_file)\n",
    "signal_headers = annotation['signal_header']\n",
    "del annotation\n",
    "print(signal_headers)\n",
    "\n",
    "channel_ekg = signal_headers.index('EKG')\n",
    "print('channel_ekg: ', channel_ekg)\n",
    "\n",
    "channel_photic = signal_headers.index('Photic')\n",
    "print('channel_photic: ', channel_photic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: (21, 156600)\n",
      "[[  1   1  -1 ...   2   3   3]\n",
      " [-24 -14 -14 ... -12  -9  -8]\n",
      " [ -6  -5  -6 ...  -3  -1  -1]\n",
      " ...\n",
      " [ -1   6   6 ...  -1  -2  -2]\n",
      " [-42 -62 -59 ... -12 -14 -16]\n",
      " [  0   0  -1 ...  -1   0   0]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "after: (20, 156600)\n",
      "[[  1   1  -1 ...   2   3   3]\n",
      " [-24 -14 -14 ... -12  -9  -8]\n",
      " [ -6  -5  -6 ...  -3  -1  -1]\n",
      " ...\n",
      " [ 14  22  23 ...  -5  -4  -3]\n",
      " [ -1   6   6 ...  -1  -2  -2]\n",
      " [  0   0  -1 ...  -1   0   0]]\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather', \n",
    "                                                                                  transform=None)\n",
    "print('before:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather', \n",
    "                                                                                  transform=EegDropChannels(channel_ekg))\n",
    "print('after:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: (21, 156600)\n",
      "[[  1   1  -1 ...   2   3   3]\n",
      " [-24 -14 -14 ... -12  -9  -8]\n",
      " [ -6  -5  -6 ...  -3  -1  -1]\n",
      " ...\n",
      " [ -1   6   6 ...  -1  -2  -2]\n",
      " [-42 -62 -59 ... -12 -14 -16]\n",
      " [  0   0  -1 ...  -1   0   0]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "after: (20, 156600)\n",
      "[[  1   1  -1 ...   2   3   3]\n",
      " [-24 -14 -14 ... -12  -9  -8]\n",
      " [ -6  -5  -6 ...  -3  -1  -1]\n",
      " ...\n",
      " [ 14  22  23 ...  -5  -4  -3]\n",
      " [ -1   6   6 ...  -1  -2  -2]\n",
      " [-42 -62 -59 ... -12 -14 -16]]\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=None)\n",
    "print('before:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=EegDropChannels(channel_photic))\n",
    "print('after:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: (21, 156600)\n",
      "[[  1   1  -1 ...   2   3   3]\n",
      " [-24 -14 -14 ... -12  -9  -8]\n",
      " [ -6  -5  -6 ...  -3  -1  -1]\n",
      " ...\n",
      " [ -1   6   6 ...  -1  -2  -2]\n",
      " [-42 -62 -59 ... -12 -14 -16]\n",
      " [  0   0  -1 ...  -1   0   0]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "after: (19, 156600)\n",
      "[[  1   1  -1 ...   2   3   3]\n",
      " [-24 -14 -14 ... -12  -9  -8]\n",
      " [ -6  -5  -6 ...  -3  -1  -1]\n",
      " ...\n",
      " [  9  18  19 ...  -3  -2  -1]\n",
      " [ 14  22  23 ...  -5  -4  -3]\n",
      " [ -1   6   6 ...  -1  -2  -2]]\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=None)\n",
    "print('before:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=EegDropChannels([channel_ekg, channel_photic]))\n",
    "print('after:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 66,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00085',\n",
      " 'signal': array([[-61, -60, -60, ..., -45, -46, -45],\n",
      "       [ 17,  17,  18, ...,  -4,  -6,  -6],\n",
      "       [  0,   1,   2, ...,   6,   6,   7],\n",
      "       ...,\n",
      "       [ -2,   0,   0, ...,   8,   9,   7],\n",
      "       [ -6,  -2,   7, ...,  -8,   1,   5],\n",
      "       [  0,   0,   0, ...,   2,   0,  -1]]),\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      ">>> signal shape: (21, 100)\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 66,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00085',\n",
      " 'signal': array([[-46, -48, -54, ...,  -2,  -3,  -2],\n",
      "       [ -1,  -1,  -4, ..., -37, -38, -39],\n",
      "       [-11, -10, -11, ...,   0,  -1,  -2],\n",
      "       ...,\n",
      "       [  8,   8,  11, ...,   8,   7,   8],\n",
      "       [  8,   4,   5, ...,   4,  -7,  -3],\n",
      "       [  0,   1,   2, ...,   0,   0,  -1]]),\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      ">>> signal shape: (21, 100)\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = EegRandomCrop(crop_length=100)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path,\n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "for i in range(2):\n",
    "    d = train_dataset[0]\n",
    "    pprint.pprint(d)\n",
    "    print()\n",
    "    print('>>> signal shape:', d['signal'].shape)\n",
    "    print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Random crop with multiple cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 66,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00085',\n",
      " 'signal': [array([[ 47,  48,  48, ...,  12,  12,  12],\n",
      "       [ 54,  55,  56, ...,  21,  19,  19],\n",
      "       [  6,   6,   7, ...,   8,   6,   4],\n",
      "       ...,\n",
      "       [-19, -18, -17, ...,  -1,  -2,  -4],\n",
      "       [ -9,   0,   5, ...,  -5,   6,   5],\n",
      "       [ -1,  -1,  -1, ...,  -1,   0,  -1]]),\n",
      "            array([[ 24,  24,  26, ...,  17,  15,  15],\n",
      "       [ 22,  22,  24, ..., -27, -27, -26],\n",
      "       [  1,   0,   1, ...,   3,   5,   7],\n",
      "       ...,\n",
      "       [  3,   1,   0, ...,   7,   9,   9],\n",
      "       [  4,   6,  -5, ...,   8,   4,  -5],\n",
      "       [  0,   0,   1, ...,   0,   0,   0]])],\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      ">>> signal shape: [(21, 200), (21, 200)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 66,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00085',\n",
      " 'signal': [array([[  6,   7,   7, ..., -15, -14, -14],\n",
      "       [ 78,  79,  81, ...,  62,  63,  61],\n",
      "       [ -2,  -2,  -1, ...,  -8,  -8,  -9],\n",
      "       ...,\n",
      "       [ -9,  -8,  -6, ..., -12, -11,  -9],\n",
      "       [ -6,   6,   5, ...,  -1,   8,   1],\n",
      "       [  0,   0,   0, ...,   1,   3,   0]]),\n",
      "            array([[-29, -28, -27, ..., -33, -33, -34],\n",
      "       [-55, -54, -51, ...,  -7,  -8, -11],\n",
      "       [  3,   1,   3, ...,  10,  10,  10],\n",
      "       ...,\n",
      "       [ 10,   9,   9, ...,   6,   7,   8],\n",
      "       [  0,  -9,   2, ...,  -3,  -4,   6],\n",
      "       [  1,   2,   0, ...,   2,   0,   0]])],\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      ">>> signal shape: [(21, 200), (21, 200)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = EegRandomCrop(crop_length=200, multiple=2)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "for i in range(2):\n",
    "    d = train_dataset[0]\n",
    "    pprint.pprint(d)\n",
    "    print()\n",
    "    print('>>> signal shape:', [signal.shape for signal in d['signal']])\n",
    "    print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random crop with multiple cropping and latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 66,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00085',\n",
      " 'signal': [array([[-14, -15, -17, ...,  23,  22,  20],\n",
      "       [ 17,  17,  17, ...,  16,  15,  13],\n",
      "       [-13, -14, -14, ...,  -8,  -7,  -8],\n",
      "       ...,\n",
      "       [  5,   4,   5, ...,   4,   3,   4],\n",
      "       [  9,  -5,  -8, ...,   9,  -5,  -1],\n",
      "       [  1,   0,   1, ...,   0,   1,   1]]),\n",
      "            array([[ -6,  -6, -10, ..., -21, -25, -26],\n",
      "       [ -2,  -1,  -4, ..., -14, -13, -11],\n",
      "       [ 14,  16,  17, ...,   5,   5,   3],\n",
      "       ...,\n",
      "       [  1,   0,   0, ...,   0,   1,   1],\n",
      "       [-10,  -2,  11, ...,  -9,   2,   8],\n",
      "       [  0,   1,   3, ...,   0,   1,   3]]),\n",
      "            array([[ 72,  70,  69, ..., -13, -16, -20],\n",
      "       [-19, -21, -23, ..., -49, -50, -51],\n",
      "       [  9,   6,   5, ..., -26, -26, -26],\n",
      "       ...,\n",
      "       [ -1,  -3,  -6, ...,   2,   1,   0],\n",
      "       [ -3,   6,   0, ...,  -1,   4,  -6],\n",
      "       [  1,   1,   0, ...,   0,   0,  -1]])],\n",
      " 'start_point': [60409, 76085, 115349],\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      ">>> signal shape: [(21, 300), (21, 300), (21, 300)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 66,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00085',\n",
      " 'signal': [array([[ 44,  43,  41, ...,   4,   4,   6],\n",
      "       [ 53,  54,  53, ...,  -9, -10,  -4],\n",
      "       [ -3,  -3,  -2, ..., -22, -22, -22],\n",
      "       ...,\n",
      "       [ -6,  -7,  -7, ...,  11,  10,   8],\n",
      "       [-10,   0,   5, ...,  -5,   6,   1],\n",
      "       [  0,   2,   4, ...,   0,   2,   4]]),\n",
      "            array([[  0,   0,  -1, ...,  24,  22,  21],\n",
      "       [-30, -28, -28, ..., -12, -10, -10],\n",
      "       [ -2,   1,   4, ..., -13, -12, -10],\n",
      "       ...,\n",
      "       [ -2,   2,   4, ...,  -4,  -4,  -2],\n",
      "       [  0,   6,  -4, ...,   2,   2,  -9],\n",
      "       [  3,   1,  -1, ...,   3,   0,  -1]]),\n",
      "            array([[ 27,  31,  31, ..., -87, -86, -84],\n",
      "       [-53, -52, -54, ...,  -6,  -2,   0],\n",
      "       [  8,   7,   7, ...,  -8,  -8,  -6],\n",
      "       ...,\n",
      "       [  8,   5,   4, ..., -13, -13, -16],\n",
      "       [  3,  -2,   5, ..., -12,  -5,   5],\n",
      "       [  0,   0,   0, ...,  -1,   0,   0]])],\n",
      " 'start_point': [72509, 95653, 69675],\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      ">>> signal shape: [(21, 300), (21, 300), (21, 300)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = EegRandomCrop(crop_length=300, multiple=3, latency=50000, return_timing=True)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "for i in range(2): \n",
    "    d = train_dataset[0]\n",
    "    pprint.pprint(d)\n",
    "    print()\n",
    "    print('>>> signal shape:', [signal.shape for signal in d['signal']])\n",
    "    print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Max Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 81,\n",
      " 'class_label': 2,\n",
      " 'class_name': 'Dementia',\n",
      " 'serial': '01222',\n",
      " 'signal': [array([[114, 111, 106, ...,  85,  75,  73],\n",
      "       [ 19,  18,  14, ...,  13,  10,   8],\n",
      "       [  3,   5,   4, ...,  -8,  -7,  -6],\n",
      "       ...,\n",
      "       [-19, -18, -20, ..., -22, -21, -20],\n",
      "       [  2,   0,  -2, ..., -14, -10,  -4],\n",
      "       [  0,  -2,  -2, ...,   0,   0,  -3]]),\n",
      "            array([[  8,  21,  36, ...,  13,  36,  54],\n",
      "       [-14, -13, -11, ...,   5,   8,  11],\n",
      "       [  7,   5,   5, ...,   7,   5,   5],\n",
      "       ...,\n",
      "       [ -7,  -8, -10, ..., -17, -18, -19],\n",
      "       [ 32,  31,  27, ...,   3,   1,  -1],\n",
      "       [ -2,   0,   0, ...,  -3,  -3,   0]]),\n",
      "            array([[ 21,  36,  57, ...,  36,  54,  67],\n",
      "       [-13, -11,  -5, ...,   8,  11,  14],\n",
      "       [  5,   5,   6, ...,   5,   5,   4],\n",
      "       ...,\n",
      "       [ -8, -10, -12, ..., -18, -19, -19],\n",
      "       [ 31,  27,  27, ...,   1,  -1,  -5],\n",
      "       [  0,   0,   2, ...,  -3,   0,   0]])],\n",
      " 'start_point': [50021, 50005, 50006],\n",
      " 'symptom': ['dementia', 'ad', 'load']}\n",
      "\n",
      ">>> signal shape: [(21, 200), (21, 200), (21, 200)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 81,\n",
      " 'class_label': 2,\n",
      " 'class_name': 'Dementia',\n",
      " 'serial': '01222',\n",
      " 'signal': [array([[ 42,  34,  24, ...,  29,  24,  21],\n",
      "       [ -1,  -2,  -5, ...,  -2,  -5,  -8],\n",
      "       [  8,  10,  10, ...,  -3,  -6,  -6],\n",
      "       ...,\n",
      "       [-15, -16, -17, ..., -17, -15, -12],\n",
      "       [  5,   0,  -6, ...,  -6, -12, -12],\n",
      "       [  1,   1,  -2, ...,  -1,   1,   1]]),\n",
      "            array([[-66, -68, -73, ..., -45, -46, -46],\n",
      "       [-20, -21, -23, ..., -22, -26, -27],\n",
      "       [ 11,  11,  11, ...,   0,  -2,   0],\n",
      "       ...,\n",
      "       [ -4,  -4,  -2, ...,  -3,  -3,  -3],\n",
      "       [-21, -16, -14, ...,   2,   5,  -6],\n",
      "       [  0,   1,   1, ...,   2,   0,   1]]),\n",
      "            array([[-67, -68, -64, ..., -33, -34, -40],\n",
      "       [-21, -20, -18, ..., -18, -17, -20],\n",
      "       [ 13,  14,  16, ...,   3,   4,   3],\n",
      "       ...,\n",
      "       [ -9, -10,  -9, ...,  -4,  -5,  -4],\n",
      "       [-20, -17, -11, ...,   6,   8,   4],\n",
      "       [ -2,  -2,   0, ...,   1,  -3,  -3]])],\n",
      " 'start_point': [50029, 50073, 50067],\n",
      " 'symptom': ['dementia', 'ad', 'load']}\n",
      "\n",
      ">>> signal shape: [(21, 200), (21, 200), (21, 200)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegLimitMaxLength(50300), \n",
    "    EegRandomCrop(crop_length=200, multiple=3, latency=50000, return_timing=True)\n",
    "])\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "for i in range(2):\n",
    "    d = train_dataset[0]\n",
    "    pprint.pprint(d)\n",
    "    print()\n",
    "    print('>>> signal shape:', [signal.shape for signal in d['signal']])\n",
    "    print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "{'age': 78,\n",
      " 'serial': '00001',\n",
      " 'signal': array([[  0, -11, -13, ...,  18,  21,  22],\n",
      "       [ 29,  33,  34, ...,  -7,  -4,  -4],\n",
      "       [ -3,  -6,  -3, ...,  -1,   1,   2],\n",
      "       ...,\n",
      "       [ -4,  -2,   1, ...,   0,  -1,  -1],\n",
      "       [112,  67,  76, ..., -13, -15, -11],\n",
      "       [ -1,  -1,  -1, ...,  -1,  -1,  -1]]),\n",
      " 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf']}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "After:\n",
      "{'age': tensor(78.),\n",
      " 'serial': '00001',\n",
      " 'signal': tensor([[  0., -11., -13.,  ...,  18.,  21.,  22.],\n",
      "        [ 29.,  33.,  34.,  ...,  -7.,  -4.,  -4.],\n",
      "        [ -3.,  -6.,  -3.,  ...,  -1.,   1.,   2.],\n",
      "        ...,\n",
      "        [ -4.,  -2.,   1.,  ...,   0.,  -1.,  -1.],\n",
      "        [112.,  67.,  76.,  ..., -13., -15., -11.],\n",
      "        [ -1.,  -1.,  -1.,  ...,  -1.,  -1.,  -1.]]),\n",
      " 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf']}\n"
     ]
    }
   ],
   "source": [
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         load_event=False, \n",
    "                                                         file_format='feather',\n",
    "                                                         transform=None)\n",
    "print('Before:')\n",
    "pprint.pprint(full_eeg_dataset[0])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "\n",
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         load_event=False, \n",
    "                                                         file_format='feather',\n",
    "                                                         transform=EegToTensor())\n",
    "print('After:')\n",
    "pprint.pprint(full_eeg_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compose the above all in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': tensor(81.),\n",
      " 'class_label': tensor(2),\n",
      " 'class_name': 'Dementia',\n",
      " 'serial': '01222',\n",
      " 'signal': [tensor([[ 14.,  15.,  15.,  ...,  22.,  21.,  19.],\n",
      "        [ -8.,  -8.,  -9.,  ...,  -1.,  -2.,  -3.],\n",
      "        [ -6.,  -8., -10.,  ...,  -3.,  -3.,  -4.],\n",
      "        ...,\n",
      "        [ 11.,  11.,  10.,  ...,  10.,  10.,   8.],\n",
      "        [ 13.,  13.,  13.,  ...,  -3.,  -2.,  -2.],\n",
      "        [-12., -18., -20.,  ..., -51., -45., -40.]]),\n",
      "            tensor([[ 67.,  67.,  64.,  ..., -13., -14., -15.],\n",
      "        [  9.,  10.,   9.,  ...,  -7.,  -4.,  -4.],\n",
      "        [-21., -18., -18.,  ...,  -3.,  -2.,  -2.],\n",
      "        ...,\n",
      "        [ -5.,  -3.,  -2.,  ...,   0.,   2.,   3.],\n",
      "        [  2.,   1.,   1.,  ...,  -3.,  -2.,   0.],\n",
      "        [  9.,  25.,  45.,  ...,  -9.,  -9.,  -5.]]),\n",
      "            tensor([[-17., -20., -24.,  ...,   4.,   0.,  -1.],\n",
      "        [ -8.,  -9.,  -9.,  ...,  11.,   9.,  10.],\n",
      "        [  9.,  10.,  11.,  ...,  13.,  11.,  13.],\n",
      "        ...,\n",
      "        [  4.,   4.,   5.,  ...,  -6.,  -6.,  -5.],\n",
      "        [  4.,   3.,   4.,  ...,  -2.,  -1.,   0.],\n",
      "        [ 62.,  64.,  60.,  ...,   8.,   8.,   0.]]),\n",
      "            tensor([[  14.,   14.,   12.,  ...,   12.,   12.,   13.],\n",
      "        [   6.,    6.,    7.,  ...,   15.,   14.,   14.],\n",
      "        [ -54.,  -52.,  -52.,  ...,  -27.,  -27.,  -26.],\n",
      "        ...,\n",
      "        [  14.,   14.,   16.,  ...,    6.,    6.,    7.],\n",
      "        [   2.,    3.,    2.,  ...,   -6.,   -5.,   -3.],\n",
      "        [-306., -331., -358.,  ...,  -12.,  -14.,  -10.]])],\n",
      " 'symptom': ['dementia', 'ad', 'load']}\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegLimitMaxLength(max_length=200*60*10),  # 10m\n",
    "    EegRandomCrop(crop_length=200*10, multiple=4, latency=200*10),  # crop: 10s, latency: 10s\n",
    "    EegToTensor()\n",
    "])\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "pprint.pprint(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == 'cuda':\n",
    "    num_workers = 0  # A number other than 0 causes an error\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': tensor([55., 55., 60., 60., 76., 76., 90., 90.]),\n",
      " 'serial': ['01289',\n",
      "            '01289',\n",
      "            '01141',\n",
      "            '01141',\n",
      "            '00724',\n",
      "            '00724',\n",
      "            '00581',\n",
      "            '00581'],\n",
      " 'signal': tensor([[[ -7.,  -8., -13.,  ...,  -3.,  -3.,  -3.],\n",
      "         [  2.,  -1.,  -6.,  ...,   1.,   2.,   2.],\n",
      "         [  3.,   2.,   2.,  ...,  -1.,   0.,   0.],\n",
      "         ...,\n",
      "         [ -4.,  -6.,  -7.,  ...,   3.,   3.,   4.],\n",
      "         [  0.,  -1.,  -2.,  ...,   5.,   7.,   7.],\n",
      "         [-11., -18., -24.,  ...,   4.,   7.,   9.]],\n",
      "\n",
      "        [[ 62.,  61.,  56.,  ...,  -7.,  -5.,  -2.],\n",
      "         [ 21.,  20.,  23.,  ..., -12.,  -9.,  -4.],\n",
      "         [  2.,  -1.,  -5.,  ...,   2.,   3.,   3.],\n",
      "         ...,\n",
      "         [ 23.,  22.,  22.,  ...,   0.,  -1.,  -3.],\n",
      "         [ -6.,  -6.,  -6.,  ...,  -3.,  -2.,  -2.],\n",
      "         [ 36.,  31.,  26.,  ...,  23.,  40.,  20.]],\n",
      "\n",
      "        [[ 18.,  24.,  28.,  ..., -47., -42., -38.],\n",
      "         [ -4.,   0.,   1.,  ..., -11.,  -8.,  -9.],\n",
      "         [ -5.,  -4.,  -3.,  ...,   6.,   6.,   3.],\n",
      "         ...,\n",
      "         [  8.,   8.,   6.,  ...,  -1.,   0.,   2.],\n",
      "         [ -2.,   1.,   5.,  ...,  -4.,  -4.,  -5.],\n",
      "         [ -2.,   5.,  -4.,  ...,   4.,  -5., -10.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  2.,   4.,   4.,  ...,  -8.,  -5.,  -4.],\n",
      "         [ 13.,  13.,  12.,  ...,   0.,   3.,   7.],\n",
      "         [  4.,   2.,   1.,  ...,   3.,   5.,   7.],\n",
      "         ...,\n",
      "         [ -1.,  -2.,  -4.,  ...,  -1.,   1.,   3.],\n",
      "         [  9.,   6.,   5.,  ...,   2.,   1.,   0.],\n",
      "         [ 23.,  31.,  37.,  ..., -16., -65., -83.]],\n",
      "\n",
      "        [[ 14.,  18.,  18.,  ...,  37.,  36.,  29.],\n",
      "         [  3.,  10.,  13.,  ...,  18.,  20.,  22.],\n",
      "         [  2.,   5.,   5.,  ...,   1.,   4.,   6.],\n",
      "         ...,\n",
      "         [  0.,   3.,   5.,  ..., -14., -14., -12.],\n",
      "         [-16., -17., -17.,  ...,   4.,   2.,   2.],\n",
      "         [ 59.,  56.,  62.,  ...,  95., 105., 105.]],\n",
      "\n",
      "        [[-13.,  -4.,  -3.,  ...,  21.,  19.,  16.],\n",
      "         [  0.,   3.,   2.,  ...,  -4.,  -4.,  -3.],\n",
      "         [ -6.,  -5.,  -4.,  ...,  11.,  10.,   9.],\n",
      "         ...,\n",
      "         [-14., -14., -13.,  ...,   8.,   8.,   6.],\n",
      "         [ -6.,  -7.,  -7.,  ...,   3.,   2.,  -1.],\n",
      "         [  1.,  44.,  74.,  ...,  45.,  44.,  43.]]]),\n",
      " 'symptom': [['dementia', 'ad', 'eoad'],\n",
      "             ['dementia', 'ad', 'eoad'],\n",
      "             ['normal', 'cb_normal'],\n",
      "             ['normal', 'cb_normal'],\n",
      "             ['mci', 'mci_amnestic'],\n",
      "             ['mci', 'mci_amnestic'],\n",
      "             ['dementia', 'ad', 'load'],\n",
      "             ['dementia', 'ad', 'load']]}\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegLimitMaxLength(max_length=200*60*10),  # 10m\n",
    "    EegRandomCrop(crop_length=200*10, multiple=2, latency=200*10),  # crop: 10s, latency: 10s\n",
    "    EegToTensor()\n",
    "])\n",
    "\n",
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         load_event=False, \n",
    "                                                         file_format='feather',\n",
    "                                                         transform=transform)\n",
    "\n",
    "full_loader = DataLoader(full_eeg_dataset,\n",
    "                         batch_size=4,\n",
    "                         shuffle=True,\n",
    "                         drop_last=True,\n",
    "                         num_workers=num_workers,\n",
    "                         pin_memory=pin_memory,\n",
    "                         collate_fn=eeg_collate_fn)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(full_loader):\n",
    "    pprint.pprint(sample_batched)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': tensor([39., 39., 77., 77., 86., 86., 73., 73., 82., 82., 84., 84., 85., 85.,\n",
      "        85., 85.]),\n",
      " 'class_label': tensor([0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2]),\n",
      " 'class_name': ['Normal', 'Normal', 'MCI', 'MCI', 'MCI', 'MCI', 'MCI', 'MCI', 'Dementia', 'Dementia', 'MCI', 'MCI', 'Dementia', 'Dementia', 'Dementia', 'Dementia'],\n",
      " 'serial': ['01031', '01031', '00303', '00303', '01242', '01242', '01347', '01347', '01181', '01181', '01243', '01243', '00292', '00292', '00252', '00252'],\n",
      " 'signal': tensor([[[ 44.,  40.,  47.,  ..., -38., -36., -34.],\n",
      "         [ 25.,  26.,  33.,  ..., -26., -29., -28.],\n",
      "         [ 19.,  23.,  24.,  ..., -13., -14., -12.],\n",
      "         ...,\n",
      "         [ -4.,  -2.,  -1.,  ...,  -1.,   0.,   1.],\n",
      "         [  1.,   2.,   2.,  ...,   3.,   5.,   5.],\n",
      "         [  1.,  -1., -10.,  ...,  -9.,   3.,  -4.]],\n",
      "\n",
      "        [[-28., -30., -23.,  ...,  -1.,  -5., -14.],\n",
      "         [-12., -16., -13.,  ..., -10., -11., -11.],\n",
      "         [  1.,   2.,   1.,  ...,   4.,   4.,   6.],\n",
      "         ...,\n",
      "         [ -5.,  -5.,  -6.,  ...,   4.,   5.,   6.],\n",
      "         [  9.,   9.,   9.,  ...,  -3.,  -1.,   2.],\n",
      "         [-12.,  -8.,   1.,  ...,  -6.,  -2.,   5.]],\n",
      "\n",
      "        [[ -5.,  -3.,  -1.,  ...,   9.,  22.,  25.],\n",
      "         [ -3.,   3.,   8.,  ...,  -4.,  -4.,  -3.],\n",
      "         [ -1.,  -1.,  -1.,  ...,   6.,   5.,   6.],\n",
      "         ...,\n",
      "         [-16., -12., -11.,  ...,   0.,   0.,  -1.],\n",
      "         [ -5.,  -2.,  -2.,  ...,  -3.,  -1.,   1.],\n",
      "         [  3.,  26.,  40.,  ..., 165., 264., 271.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -6.,  -3.,   0.,  ...,   5.,   4.,  -2.],\n",
      "         [ -1.,   5.,   6.,  ...,  -7., -10., -13.],\n",
      "         [ 17.,  17.,  16.,  ...,   7.,   7.,   5.],\n",
      "         ...,\n",
      "         [ -3.,  -3.,  -6.,  ...,  -3.,   0.,   3.],\n",
      "         [-13., -16., -18.,  ...,   6.,   8.,  12.],\n",
      "         [-23., -13., -22.,  ..., -16.,  -6.,  -9.]],\n",
      "\n",
      "        [[-51., -50., -53.,  ...,  58.,  44.,  25.],\n",
      "         [-12., -12., -12.,  ...,   5.,   0.,  -7.],\n",
      "         [  5.,   8.,  11.,  ...,  21.,  18.,  15.],\n",
      "         ...,\n",
      "         [ 13.,  17.,  20.,  ...,  16.,  17.,  20.],\n",
      "         [ 28.,  33.,  39.,  ...,  25.,  28.,  32.],\n",
      "         [ -8., -13., -24.,  ...,  -8., -15., -17.]],\n",
      "\n",
      "        [[-20.,   3.,  30.,  ...,   6.,  -6., -11.],\n",
      "         [-35., -25., -13.,  ...,  31.,  29.,  29.],\n",
      "         [  5.,  -1.,   6.,  ...,   1.,   2.,   2.],\n",
      "         ...,\n",
      "         [ 24.,  22.,  17.,  ..., -42., -41., -40.],\n",
      "         [ 26.,  24.,  26.,  ..., -20., -20., -20.],\n",
      "         [133., 122., 114.,  ...,  -3.,  -9.,  -5.]]]),\n",
      " 'symptom': [['normal', 'cb_normal'],\n",
      "             ['normal', 'cb_normal'],\n",
      "             ['mci', 'mci_amnestic', 'mci_amnestic_rf'],\n",
      "             ['mci', 'mci_amnestic', 'mci_amnestic_rf'],\n",
      "             ['mci', 'mci_amnestic', 'mci_amnestic_rf'],\n",
      "             ['mci', 'mci_amnestic', 'mci_amnestic_rf'],\n",
      "             ['mci', 'mci_amnestic', 'mci_amnestic_ef'],\n",
      "             ['mci', 'mci_amnestic', 'mci_amnestic_ef'],\n",
      "             ['dementia', 'ad', 'load'],\n",
      "             ['dementia', 'ad', 'load'],\n",
      "             ['mci', 'mci_amnestic', 'mci_amnestic_rf'],\n",
      "             ['mci', 'mci_amnestic', 'mci_amnestic_rf'],\n",
      "             ['dementia', 'ad', 'load'],\n",
      "             ['dementia', 'ad', 'load'],\n",
      "             ['dementia', 'vd', 'sivd'],\n",
      "             ['dementia', 'vd', 'sivd']]}\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegLimitMaxLength(max_length=200*60*10),  # 10m\n",
    "    EegRandomCrop(crop_length=200*10, multiple=2, latency=200*10),  # crop: 10s, latency: 10s\n",
    "    EegToTensor()\n",
    "])\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=8,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    pprint.pprint(sample_batched, width=250)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Preprocessing steps run by the PyTorch Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegLimitMaxLength(max_length=200*60*10),  # 10m\n",
    "    EegRandomCrop(crop_length=200*10, multiple=2, latency=200*10),  # crop: 10s, latency: 10s\n",
    "    EegToTensor()\n",
    "])\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=2,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To GPU device if it is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      ")\n",
      "- Before -\n",
      "{'age': tensor([72., 72., 85., 85.]),\n",
      " 'class_label': tensor([0, 0, 1, 1]),\n",
      " 'class_name': ['Normal', 'Normal', 'Abnormal', 'Abnormal'],\n",
      " 'serial': ['00696', '00696', '00657', '00657'],\n",
      " 'signal': tensor([[[ -56.,  -55.,  -60.,  ...,   16.,   16.,   15.],\n",
      "         [   1.,    3.,   13.,  ...,   28.,   30.,   31.],\n",
      "         [  25.,   30.,   20.,  ...,   -4.,    0.,    4.],\n",
      "         ...,\n",
      "         [  18.,   17.,   18.,  ...,   -8.,   -7.,   -6.],\n",
      "         [  11.,   15.,   15.,  ...,  -13.,  -11.,   -7.],\n",
      "         [  18.,   20.,   17.,  ...,  -76.,  -83.,  -87.]],\n",
      "\n",
      "        [[  77.,   78.,   76.,  ...,   10.,   13.,   12.],\n",
      "         [  -1.,    2.,    9.,  ...,   12.,   16.,   20.],\n",
      "         [ -11.,   -9.,   -5.,  ...,   -5.,   -4.,   -4.],\n",
      "         ...,\n",
      "         [  -4.,   -3.,   -3.,  ...,   10.,    9.,   10.],\n",
      "         [   4.,   -1.,   -4.,  ...,    8.,    6.,    3.],\n",
      "         [-122., -126., -137.,  ...,   78.,   34.,  -17.]],\n",
      "\n",
      "        [[  -1.,   -6.,  -16.,  ...,  -65.,  -52.,  -47.],\n",
      "         [  -4.,   -4.,   -6.,  ...,   11.,    6.,    9.],\n",
      "         [  -4.,   -7.,  -10.,  ...,    5.,    4.,    3.],\n",
      "         ...,\n",
      "         [  -6.,   -3.,    1.,  ...,    5.,    8.,    8.],\n",
      "         [  -1.,   -2.,    0.,  ...,    9.,    6.,    3.],\n",
      "         [  -2.,   13.,    9.,  ...,  102.,   93.,   82.]],\n",
      "\n",
      "        [[   8.,    3.,   -1.,  ...,   -4.,   -6.,   -5.],\n",
      "         [  -4.,   -7.,   -2.,  ...,   -8.,   -8.,   -2.],\n",
      "         [  -1.,   -2.,   -3.,  ...,    7.,   10.,   10.],\n",
      "         ...,\n",
      "         [  -4.,   -4.,   -4.,  ...,    4.,    8.,   11.],\n",
      "         [   1.,    1.,   -2.,  ...,    4.,    2.,   -1.],\n",
      "         [  51.,   41.,   33.,  ...,   73.,   64.,   66.]]]),\n",
      " 'symptom': [['normal', 'smi'],\n",
      "             ['normal', 'smi'],\n",
      "             ['mci', 'mci_amnestic'],\n",
      "             ['mci', 'mci_amnestic']]}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "{'age': tensor([72., 72., 85., 85.], device='cuda:0'),\n",
      " 'class_label': tensor([0, 0, 1, 1], device='cuda:0'),\n",
      " 'class_name': ['Normal', 'Normal', 'Abnormal', 'Abnormal'],\n",
      " 'serial': ['00696', '00696', '00657', '00657'],\n",
      " 'signal': tensor([[[ -56.,  -55.,  -60.,  ...,   16.,   16.,   15.],\n",
      "         [   1.,    3.,   13.,  ...,   28.,   30.,   31.],\n",
      "         [  25.,   30.,   20.,  ...,   -4.,    0.,    4.],\n",
      "         ...,\n",
      "         [  18.,   17.,   18.,  ...,   -8.,   -7.,   -6.],\n",
      "         [  11.,   15.,   15.,  ...,  -13.,  -11.,   -7.],\n",
      "         [  18.,   20.,   17.,  ...,  -76.,  -83.,  -87.]],\n",
      "\n",
      "        [[  77.,   78.,   76.,  ...,   10.,   13.,   12.],\n",
      "         [  -1.,    2.,    9.,  ...,   12.,   16.,   20.],\n",
      "         [ -11.,   -9.,   -5.,  ...,   -5.,   -4.,   -4.],\n",
      "         ...,\n",
      "         [  -4.,   -3.,   -3.,  ...,   10.,    9.,   10.],\n",
      "         [   4.,   -1.,   -4.,  ...,    8.,    6.,    3.],\n",
      "         [-122., -126., -137.,  ...,   78.,   34.,  -17.]],\n",
      "\n",
      "        [[  -1.,   -6.,  -16.,  ...,  -65.,  -52.,  -47.],\n",
      "         [  -4.,   -4.,   -6.,  ...,   11.,    6.,    9.],\n",
      "         [  -4.,   -7.,  -10.,  ...,    5.,    4.,    3.],\n",
      "         ...,\n",
      "         [  -6.,   -3.,    1.,  ...,    5.,    8.,    8.],\n",
      "         [  -1.,   -2.,    0.,  ...,    9.,    6.,    3.],\n",
      "         [  -2.,   13.,    9.,  ...,  102.,   93.,   82.]],\n",
      "\n",
      "        [[   8.,    3.,   -1.,  ...,   -4.,   -6.,   -5.],\n",
      "         [  -4.,   -7.,   -2.,  ...,   -8.,   -8.,   -2.],\n",
      "         [  -1.,   -2.,   -3.,  ...,    7.,   10.,   10.],\n",
      "         ...,\n",
      "         [  -4.,   -4.,   -4.,  ...,    4.,    8.,   11.],\n",
      "         [   1.,    1.,   -2.,  ...,    4.,    2.,   -1.],\n",
      "         [  51.,   41.,   33.,  ...,   73.,   64.,   66.]]], device='cuda:0'),\n",
      " 'symptom': [['normal', 'smi'],\n",
      "             ['normal', 'smi'],\n",
      "             ['mci', 'mci_amnestic'],\n",
      "             ['mci', 'mci_amnestic']]}\n"
     ]
    }
   ],
   "source": [
    "print('device:', device)\n",
    "print()\n",
    "\n",
    "preprocess_train = transforms.Compose([EegToDevice(device=device)])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    pprint.pprint(sample_batched)\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    pprint.pprint(sample_batched)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization per signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizePerSignal(eps=1e-08)\n",
      ")\n",
      "- Before -\n",
      "Mean: tensor([[ 3.6975,  1.7315,  0.2125, -0.9015,  1.4420,  0.8715,  0.4200, -0.7245,\n",
      "         -0.5970, -0.3370, -0.6790,  0.8970, -0.9285, -0.8055, -0.9575, -1.5605,\n",
      "          3.5805, -0.2895, -0.5280, -1.5705],\n",
      "        [12.0375,  4.4140,  1.2955, -0.2610, -1.2930,  5.5185, -0.1050, -2.3265,\n",
      "         -1.5660, -0.9565,  4.7895,  2.9220, -0.6145, -4.6300, -1.4195, -1.9960,\n",
      "          3.2125, -0.5285, -0.9555,  0.0365],\n",
      "        [ 0.3860,  0.4420,  0.2560,  0.0980, -0.3285,  0.4215,  0.9185,  0.1725,\n",
      "          0.1980, -0.1870, -0.4770,  0.2625,  0.1625, -1.2885, -0.2020, -0.4685,\n",
      "          0.2830, -0.1530,  0.5610,  0.5525],\n",
      "        [-1.4555, -1.2505,  0.7580,  0.5830,  1.2935, -0.1330, -3.2185,  0.0795,\n",
      "          0.2380,  0.5530, -0.7655,  0.3045,  0.7995,  1.1770,  0.4395,  0.1050,\n",
      "          0.6425,  0.6660, -0.7175,  0.2405]])\n",
      "\n",
      "Std: tensor([[ 40.0912,  17.8688,   6.4726,   6.1523,   9.1699,  36.4166,  16.7591,\n",
      "          13.8960,   6.7042,   7.8145,  18.9336,   9.9984,   7.7691,  26.4063,\n",
      "          17.1767,   9.3030,  19.8179,   5.1189,   5.4377, 190.8173],\n",
      "        [ 51.3388,  20.7134,   6.6161,   6.3657,  12.0358,  46.4001,  17.6409,\n",
      "          14.4819,   7.2087,   9.0870,  20.4092,   8.6237,   8.5161,  25.8172,\n",
      "          18.3217,  10.5754,  21.2587,   5.2335,   5.8590, 192.0760],\n",
      "        [  7.7316,  10.8401,   4.4124,   5.1003,   8.6990,  10.5966,   8.1617,\n",
      "           6.5906,   8.5623,   8.9792,   7.9923,   4.5771,   5.8154,   9.3540,\n",
      "           4.3211,   6.0803,   6.4174,   6.4942,   5.7740, 138.5375],\n",
      "        [ 14.4073,   8.2532,   5.0948,   6.1596,  13.4903,  10.7870,  12.5514,\n",
      "           5.6370,   7.8022,   9.1654,   8.5911,   4.7378,   7.8417,   9.4384,\n",
      "           4.9515,   7.0458,   8.3825,   7.6226,   5.1882, 141.1637]])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "Mean: tensor([[-1.5259e-08,  0.0000e+00,  4.7684e-09, -1.9073e-08,  2.6703e-08,\n",
      "         -1.5259e-08,  5.7220e-09, -1.9073e-09,  0.0000e+00,  0.0000e+00,\n",
      "          1.5259e-08,  0.0000e+00,  0.0000e+00, -7.6294e-09,  7.6294e-09,\n",
      "          1.1444e-08,  1.1444e-08,  1.1444e-08,  7.6294e-09, -9.5367e-09],\n",
      "        [ 2.8610e-09, -4.7684e-09,  2.3842e-08,  9.5367e-10, -2.8610e-09,\n",
      "         -1.6212e-08, -1.6212e-08, -5.2452e-09, -6.6757e-09, -3.8147e-09,\n",
      "          1.6212e-08, -1.9073e-09,  9.5367e-09,  1.9073e-08,  6.6757e-09,\n",
      "         -3.8147e-09,  9.5367e-10,  0.0000e+00,  3.8147e-09,  7.6294e-09],\n",
      "        [ 9.5367e-09,  0.0000e+00, -1.4305e-09, -3.8147e-09, -2.3842e-09,\n",
      "         -7.6294e-09, -5.7220e-09,  6.6757e-09,  0.0000e+00,  7.6294e-09,\n",
      "          9.5367e-09,  1.1444e-08,  0.0000e+00,  5.7220e-09,  3.8147e-09,\n",
      "          1.0490e-08,  1.0014e-08, -5.0068e-09,  1.7166e-08, -3.8147e-09],\n",
      "        [-5.3644e-09, -2.5749e-08,  5.7220e-09, -9.0599e-09,  2.5272e-08,\n",
      "          0.0000e+00,  7.6294e-09, -1.8120e-08,  5.7220e-09, -9.5367e-09,\n",
      "          0.0000e+00, -3.8147e-09,  2.1935e-08, -4.2915e-09,  1.8120e-08,\n",
      "          8.5831e-09,  4.7684e-09, -7.6294e-09,  3.8147e-09,  0.0000e+00]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Std: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizePerSignal()\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal normalization using the specified mean and std values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and standard deviation for signal:\n",
      "tensor([[[-0.1357],\n",
      "         [-0.2511],\n",
      "         [ 0.0018],\n",
      "         [ 0.0711],\n",
      "         [-0.0479],\n",
      "         [-0.2520],\n",
      "         [-0.2120],\n",
      "         [ 0.0005],\n",
      "         [-0.0007],\n",
      "         [-0.0591],\n",
      "         [ 0.1582],\n",
      "         [ 0.3231],\n",
      "         [ 0.0052],\n",
      "         [-0.0274],\n",
      "         [ 0.1218],\n",
      "         [ 0.0294],\n",
      "         [-0.0802],\n",
      "         [-0.0193],\n",
      "         [-0.0197],\n",
      "         [-0.0166]]])\n",
      "-\n",
      "tensor([[[46.2526],\n",
      "         [20.3984],\n",
      "         [11.6559],\n",
      "         [11.7465],\n",
      "         [15.2970],\n",
      "         [50.3807],\n",
      "         [20.2444],\n",
      "         [10.7235],\n",
      "         [11.5641],\n",
      "         [15.6016],\n",
      "         [20.7594],\n",
      "         [15.2747],\n",
      "         [13.4793],\n",
      "         [21.4928],\n",
      "         [16.8901],\n",
      "         [15.2875],\n",
      "         [19.7100],\n",
      "         [11.2538],\n",
      "         [11.2400],\n",
      "         [98.3843]]])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeMeanStd(mean=tensor([-0.1357, -0.2511,  0.0018,  0.0711, -0.0479, -0.2520, -0.2120,  0.0005,\n",
      "          -0.0007, -0.0591,  0.1582,  0.3231,  0.0052, -0.0274,  0.1218,  0.0294,\n",
      "          -0.0802, -0.0193, -0.0197, -0.0166]),std=tensor([46.2526, 20.3984, 11.6559, 11.7465, 15.2970, 50.3807, 20.2444, 10.7235,\n",
      "          11.5641, 15.6016, 20.7594, 15.2747, 13.4793, 21.4928, 16.8901, 15.2875,\n",
      "          19.7100, 11.2538, 11.2400, 98.3843]),eps=1e-08)\n",
      ")\n",
      "- Before -\n",
      "Mean: tensor([[-1.4455, -0.6675,  0.7025, -0.8485,  0.7380,  1.0435, -5.1960,  0.4310,\n",
      "          0.6010,  0.7430, -1.0965,  0.0975,  0.2910,  3.3830, -2.8760,  0.7970,\n",
      "          1.1430,  1.0740,  0.7320, -0.6630],\n",
      "        [-5.3350,  1.4030,  0.2360, -0.1480, -0.3505, -1.9430,  1.6035, -0.9100,\n",
      "         -0.5080,  0.3110,  2.4955, -0.1295,  0.1750, -0.6790, -1.5515, -0.7565,\n",
      "         -1.1725,  0.0590, -0.0700, -1.7935],\n",
      "        [-5.8020,  0.5875, -1.1810,  0.4635,  1.0030, -2.5830, -4.8090, -1.4820,\n",
      "         -1.0285,  0.8390, -0.5955,  0.1490,  1.5135,  2.5210, -0.7490,  0.0145,\n",
      "          5.2775, -1.2940, -1.2230,  0.2935],\n",
      "        [-1.0425, -3.2330,  0.6855,  0.9485,  0.0355,  2.2360, -0.0210, -0.0765,\n",
      "          1.2205, -0.2690, -1.8080,  0.5170,  0.1730,  2.2180,  0.5155,  0.3360,\n",
      "         -1.4795,  0.0375,  0.2015, -0.0255]])\n",
      "\n",
      "Std: tensor([[ 27.2465,   9.3855,   7.0616,   6.8630,   7.0892,  25.0844,  13.8279,\n",
      "           7.1976,   5.7375,   6.4715,  14.4509,   9.0884,   7.6103,  17.9820,\n",
      "           8.3788,   6.0339,  15.8950,   8.0085,   6.7850, 153.1640],\n",
      "        [ 20.9831,  12.2670,   5.6404,   5.8564,   7.5888,  13.7221,  11.1131,\n",
      "           5.8968,   5.3336,   7.2418,  11.1252,   7.9763,   7.9350,  12.9688,\n",
      "           8.0298,   6.4180,  10.6949,   8.6259,   6.6331, 168.7881],\n",
      "        [ 22.8368,  22.1219,   6.0443,   5.4282,   4.1337,  16.1109,  13.3033,\n",
      "           4.3234,   3.3477,   4.6191,  10.0498,   7.2916,   5.1886,  25.9051,\n",
      "           3.6208,   4.2014,  21.2753,   4.0240,   3.6384, 111.8365],\n",
      "        [ 24.1662,  23.4149,  11.2352,   5.5281,   4.2946,  24.8376,  14.8250,\n",
      "           6.0757,   4.3126,   4.3987,  22.1897,  13.4501,   5.4250,  19.7692,\n",
      "           9.2758,   5.6523,  11.6144,   3.3256,   3.5017, 111.9565]])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "Mean: tensor([[-2.8318e-02, -2.0414e-02,  6.0114e-02, -7.8289e-02,  5.1379e-02,\n",
      "          2.5713e-02, -2.4619e-01,  4.0149e-02,  5.2031e-02,  5.1411e-02,\n",
      "         -6.0441e-02, -1.4772e-02,  2.1203e-02,  1.5868e-01, -1.7749e-01,\n",
      "          5.0213e-02,  6.2060e-02,  9.7145e-02,  6.6879e-02, -6.5706e-03],\n",
      "        [-1.1241e-01,  8.1089e-02,  2.0092e-02, -1.8654e-02, -1.9779e-02,\n",
      "         -3.3565e-02,  8.9681e-02, -8.4903e-02, -4.3869e-02,  2.3721e-02,\n",
      "          1.1259e-01, -2.9633e-02,  1.2597e-02, -3.0319e-02, -9.9072e-02,\n",
      "         -5.1406e-02, -5.5419e-02,  6.9538e-03, -4.4736e-03, -1.8061e-02],\n",
      "        [-1.2251e-01,  4.1111e-02, -1.0148e-01,  3.3404e-02,  6.8703e-02,\n",
      "         -4.6269e-02, -2.2707e-01, -1.3824e-01, -8.8879e-02,  5.7564e-02,\n",
      "         -3.6308e-02, -1.1400e-02,  1.1190e-01,  1.1857e-01, -5.1559e-02,\n",
      "         -9.7240e-04,  2.7183e-01, -1.1327e-01, -1.0705e-01,  3.1515e-03],\n",
      "        [-1.9605e-02, -1.4618e-01,  5.8656e-02,  7.4693e-02,  5.4549e-03,\n",
      "          4.9383e-02,  9.4361e-03, -7.1771e-03,  1.0560e-01, -1.3455e-02,\n",
      "         -9.4715e-02,  1.2692e-02,  1.2448e-02,  1.0447e-01,  2.3307e-02,\n",
      "          2.0058e-02, -7.0995e-02,  5.0433e-03,  1.9681e-02, -9.0923e-05]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Std: tensor([[0.5891, 0.4601, 0.6058, 0.5843, 0.4634, 0.4979, 0.6830, 0.6712, 0.4962,\n",
      "         0.4148, 0.6961, 0.5950, 0.5646, 0.8367, 0.4961, 0.3947, 0.8064, 0.7116,\n",
      "         0.6036, 1.5568],\n",
      "        [0.4537, 0.6014, 0.4839, 0.4986, 0.4961, 0.2724, 0.5489, 0.5499, 0.4612,\n",
      "         0.4642, 0.5359, 0.5222, 0.5887, 0.6034, 0.4754, 0.4198, 0.5426, 0.7665,\n",
      "         0.5901, 1.7156],\n",
      "        [0.4937, 1.0845, 0.5186, 0.4621, 0.2702, 0.3198, 0.6571, 0.4032, 0.2895,\n",
      "         0.2961, 0.4841, 0.4774, 0.3849, 1.2053, 0.2144, 0.2748, 1.0794, 0.3576,\n",
      "         0.3237, 1.1367],\n",
      "        [0.5225, 1.1479, 0.9639, 0.4706, 0.2807, 0.4930, 0.7323, 0.5666, 0.3729,\n",
      "         0.2819, 1.0689, 0.8806, 0.4025, 0.9198, 0.5492, 0.3697, 0.5893, 0.2955,\n",
      "         0.3115, 1.1380]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "signal_mean, signal_std = calculate_signal_statistics(train_loader, repeats=1, verbose=True)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age mean and standard deviation:\n",
      "tensor([70.6025]) tensor([6.3509])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6025]),std=tensor([6.3509]),eps=1e-08)\n",
      ")\n",
      "- Before -\n",
      "tensor([75., 75., 86., 86.])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "tensor([0.6924, 0.6924, 2.4245, 2.4245], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "age_mean, age_std = calculate_age_statistics(train_loader, verbose=True)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    pprint.pprint(sample_batched['age'])\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    pprint.pprint(sample_batched['age'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short time Fourier transform (STFT or spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegSpectrogram(n_fft=200, complex_mode=as_real, stft_kwargs={})\n",
      ")\n",
      "- Before -\n",
      "torch.Size([4, 20, 2000])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "torch.Size([4, 40, 101, 41])\n"
     ]
    }
   ],
   "source": [
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegSpectrogram(n_fft=200, complex_mode='as_real')\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    pprint.pprint(sample_batched['signal'].shape)\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    pprint.pprint(sample_batched['signal'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal normalization after STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegSpectrogram(n_fft=200, complex_mode=as_real, stft_kwargs={})\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegNormalizeMeanStd(mean=tensor([[ 3.6224e+01,  8.1955e-01, -1.3452e-01,  ..., -6.3493e-02,\n",
      "           -5.8977e-02, -8.1556e-02],\n",
      "          [ 2.6344e+01,  3.9039e-01,  5.7765e-02,  ..., -1.2983e-03,\n",
      "            5.7594e-05, -1.2575e-02],\n",
      "          [-4.3636e+00,  8.2101e-02, -2.9571e-02,  ...,  1.6749e-03,\n",
      "            3.5939e-03,  6.1787e-03],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  1.1858e-01,  2.4689e-02,  ...,  1.4142e-04,\n",
      "           -5.3444e-04, -1.3321e-08],\n",
      "          [ 0.0000e+00,  6.1904e-01,  2.7609e-01,  ...,  1.2308e-03,\n",
      "           -1.3162e-04, -1.4377e-08],\n",
      "          [ 0.0000e+00, -6.7974e-01,  7.8550e-02,  ...,  7.2703e-04,\n",
      "           -1.1213e-02, -1.2512e-07]], device='cuda:0'),std=tensor([[7.4391e+03, 1.5245e+03, 7.9377e+02,  ..., 2.9074e+01, 2.9047e+01,\n",
      "           2.9265e+01],\n",
      "          [3.3342e+03, 6.0361e+02, 3.0638e+02,  ..., 1.3517e+01, 1.3471e+01,\n",
      "           1.3847e+01],\n",
      "          [1.8063e+03, 2.8569e+02, 1.5334e+02,  ..., 8.1293e+00, 8.0798e+00,\n",
      "           8.6541e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 4.4521e+02, 2.4143e+02,  ..., 2.7859e+00, 2.8801e+00,\n",
      "           3.2122e-06],\n",
      "          [0.0000e+00, 4.7726e+02, 2.5940e+02,  ..., 2.7937e+00, 2.8887e+00,\n",
      "           3.2063e-06],\n",
      "          [0.0000e+00, 2.1106e+03, 1.9989e+03,  ..., 3.6976e+00, 4.7884e+00,\n",
      "           6.1757e-05]], device='cuda:0'),eps=1e-08)\n",
      ")\n",
      "- Before -\n",
      "Mean: tensor([[[-4.0946e+02,  6.1881e+00, -7.3714e+01,  ...,  1.2091e+00,\n",
      "           1.1573e+00,  1.8537e+00],\n",
      "         [-4.8476e+02, -9.1326e+00, -1.9722e+01,  ...,  6.1410e-01,\n",
      "           6.8854e-01,  4.6342e-01],\n",
      "         [-7.9249e+02,  4.4630e+00, -1.5486e+00,  ..., -1.9335e+00,\n",
      "          -1.9609e+00, -1.0732e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  3.9747e+01,  1.6609e+01,  ...,  8.5157e-03,\n",
      "           6.1926e-02, -2.1561e-06],\n",
      "         [ 0.0000e+00, -5.1738e+01, -3.6601e+01,  ..., -1.1021e-01,\n",
      "          -6.3455e-02, -3.3143e-07],\n",
      "         [ 0.0000e+00, -6.2605e+00, -1.0439e+02,  ..., -7.7921e-02,\n",
      "          -6.1199e-01,  1.1466e-07]],\n",
      "\n",
      "        [[ 1.7700e+02, -8.8728e+00, -3.3033e+00,  ..., -7.7557e-01,\n",
      "          -7.6099e-01, -2.8049e+00],\n",
      "         [ 4.1098e+01, -2.0771e+00,  2.4251e+00,  ...,  3.0167e-01,\n",
      "           2.1156e-01, -7.5609e-01],\n",
      "         [-2.0951e+01, -5.8090e+00,  2.1856e+00,  ...,  8.9075e-01,\n",
      "           6.3782e-01,  1.7317e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -3.2509e+01, -1.5735e+01,  ...,  2.3864e-02,\n",
      "          -7.8961e-02,  1.3075e-06],\n",
      "         [ 0.0000e+00, -4.7235e+01, -2.4332e+01,  ..., -2.1620e-02,\n",
      "          -3.0855e-03,  9.0939e-07],\n",
      "         [ 0.0000e+00, -1.9381e+01,  7.5580e+01,  ...,  2.2639e-02,\n",
      "           2.1217e-01, -5.7230e-06]],\n",
      "\n",
      "        [[ 4.4500e+02, -3.1897e+01, -1.1727e+02,  ..., -2.6400e+00,\n",
      "          -2.7938e+00, -2.0244e+00],\n",
      "         [ 2.9593e+02, -8.1780e+00, -2.1207e+01,  ..., -8.8036e-01,\n",
      "          -7.5297e-01, -2.7561e+00],\n",
      "         [ 2.8276e+02, -5.9543e+00, -1.4302e+00,  ..., -7.0509e-01,\n",
      "          -5.6421e-01, -1.7073e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  5.5271e+00,  2.6883e+00,  ..., -1.1923e-01,\n",
      "          -1.2397e-01,  6.4997e-07],\n",
      "         [ 0.0000e+00,  1.6319e+01,  7.7215e+00,  ...,  3.3535e-02,\n",
      "           8.5741e-02,  1.4275e-06],\n",
      "         [ 0.0000e+00,  1.1136e+02,  6.5516e+01,  ..., -7.9702e-02,\n",
      "          -1.7855e-01,  3.3362e-06]],\n",
      "\n",
      "        [[ 3.1010e+02,  1.5109e+01, -1.8814e+02,  ..., -3.6233e+00,\n",
      "          -3.7641e+00, -7.3170e-01],\n",
      "         [-1.3818e+03,  4.6118e+00, -2.6874e+01,  ..., -1.4888e+00,\n",
      "          -1.7149e+00, -2.3659e+00],\n",
      "         [-7.4780e+01,  4.1978e-01,  1.3953e+00,  ..., -1.5078e+00,\n",
      "          -1.4540e+00, -4.8777e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  4.6662e+00,  1.8015e+00,  ..., -1.1657e-02,\n",
      "           2.3343e-02,  3.2084e-07],\n",
      "         [ 0.0000e+00, -2.2937e+01, -1.1793e+01,  ...,  3.6344e-03,\n",
      "           1.1498e-02, -1.0923e-06],\n",
      "         [ 0.0000e+00,  2.1456e+00,  2.3545e+01,  ...,  1.7128e-01,\n",
      "          -4.2939e-03, -5.8956e-06]]], device='cuda:0')\n",
      "\n",
      "Std: tensor([[[5.0283e+03, 1.9131e+03, 1.6698e+03,  ..., 2.4108e+01,\n",
      "          2.4103e+01, 2.3803e+01],\n",
      "         [3.1088e+03, 7.6404e+02, 4.2837e+02,  ..., 1.3710e+01,\n",
      "          1.3806e+01, 1.5305e+01],\n",
      "         [4.5783e+03, 4.3956e+02, 1.3285e+02,  ..., 1.4879e+01,\n",
      "          1.4628e+01, 1.3538e+01],\n",
      "         ...,\n",
      "         [0.0000e+00, 3.4798e+02, 1.6336e+02,  ..., 2.6128e+00,\n",
      "          2.6732e+00, 2.2904e-06],\n",
      "         [0.0000e+00, 6.4218e+02, 3.0925e+02,  ..., 2.4505e+00,\n",
      "          3.3314e+00, 2.0445e-06],\n",
      "         [0.0000e+00, 3.1627e+03, 2.8739e+03,  ..., 3.8440e+00,\n",
      "          3.9600e+00, 2.3367e-05]],\n",
      "\n",
      "        [[2.8856e+03, 4.0038e+02, 8.5641e+01,  ..., 1.0117e+01,\n",
      "          1.0270e+01, 1.2319e+01],\n",
      "         [2.0106e+03, 2.1829e+02, 9.4588e+01,  ..., 8.2708e+00,\n",
      "          7.9444e+00, 8.6336e+00],\n",
      "         [2.4734e+03, 3.0781e+02, 9.3073e+01,  ..., 1.1290e+01,\n",
      "          1.1477e+01, 1.3046e+01],\n",
      "         ...,\n",
      "         [0.0000e+00, 1.7903e+02, 1.0339e+02,  ..., 2.9221e+00,\n",
      "          2.6723e+00, 3.3016e-06],\n",
      "         [0.0000e+00, 2.6770e+02, 1.3809e+02,  ..., 2.4999e+00,\n",
      "          2.3605e+00, 1.7615e-06],\n",
      "         [0.0000e+00, 4.8034e+03, 2.7454e+03,  ..., 3.3206e+00,\n",
      "          2.8597e+00, 2.6098e-05]],\n",
      "\n",
      "        [[3.1799e+03, 2.7908e+03, 2.4319e+03,  ..., 4.4506e+01,\n",
      "          4.3637e+01, 4.2339e+01],\n",
      "         [1.0680e+03, 5.5853e+02, 3.8228e+02,  ..., 9.8190e+00,\n",
      "          8.8927e+00, 9.5650e+00],\n",
      "         [7.6196e+02, 1.5191e+02, 1.5268e+02,  ..., 5.9657e+00,\n",
      "          5.5002e+00, 4.8265e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 1.9460e+02, 1.4730e+02,  ..., 2.4514e+00,\n",
      "          2.4347e+00, 3.1086e-06],\n",
      "         [0.0000e+00, 1.9971e+02, 1.6942e+02,  ..., 2.9173e+00,\n",
      "          2.8379e+00, 5.4238e-06],\n",
      "         [0.0000e+00, 9.8572e+02, 1.6979e+03,  ..., 2.5179e+00,\n",
      "          2.8501e+00, 4.9934e-05]],\n",
      "\n",
      "        [[5.0958e+03, 3.6649e+03, 3.4048e+03,  ..., 4.6010e+01,\n",
      "          4.5300e+01, 4.5873e+01],\n",
      "         [2.0548e+03, 5.8993e+02, 5.1985e+02,  ..., 9.5727e+00,\n",
      "          9.5605e+00, 9.2810e+00],\n",
      "         [1.7439e+03, 1.5444e+02, 1.1185e+02,  ..., 6.6591e+00,\n",
      "          5.9175e+00, 5.7574e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 2.2893e+02, 1.3081e+02,  ..., 2.6968e+00,\n",
      "          3.1813e+00, 4.5702e-06],\n",
      "         [0.0000e+00, 2.9428e+02, 1.8394e+02,  ..., 2.2134e+00,\n",
      "          2.2802e+00, 6.6652e-06],\n",
      "         [0.0000e+00, 1.0493e+03, 1.5991e+03,  ..., 4.0663e+00,\n",
      "          3.3892e+00, 5.1025e-05]]], device='cuda:0')\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "Mean: tensor([[[-0.0599,  0.0035, -0.0927,  ...,  0.0438,  0.0419,  0.0661],\n",
      "         [-0.1533, -0.0158, -0.0646,  ...,  0.0455,  0.0511,  0.0344],\n",
      "         [-0.4363,  0.0153, -0.0099,  ..., -0.2380, -0.2431, -0.1247],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0890,  0.0687,  ...,  0.0030,  0.0217, -0.6650],\n",
      "         [ 0.0000, -0.1097, -0.1422,  ..., -0.0399, -0.0219, -0.0986],\n",
      "         [ 0.0000, -0.0026, -0.0523,  ..., -0.0213, -0.1255,  0.0039]],\n",
      "\n",
      "        [[ 0.0189, -0.0064, -0.0040,  ..., -0.0245, -0.0242, -0.0931],\n",
      "         [ 0.0044, -0.0041,  0.0077,  ...,  0.0224,  0.0157, -0.0537],\n",
      "         [-0.0092, -0.0206,  0.0144,  ...,  0.1094,  0.0785,  0.1994],\n",
      "         ...,\n",
      "         [ 0.0000, -0.0733, -0.0653,  ...,  0.0085, -0.0272,  0.4099],\n",
      "         [ 0.0000, -0.1003, -0.0949,  ..., -0.0082, -0.0010,  0.2872],\n",
      "         [ 0.0000, -0.0089,  0.0378,  ...,  0.0059,  0.0467, -0.0906]],\n",
      "\n",
      "        [[ 0.0549, -0.0215, -0.1476,  ..., -0.0886, -0.0942, -0.0664],\n",
      "         [ 0.0809, -0.0142, -0.0694,  ..., -0.0650, -0.0559, -0.1981],\n",
      "         [ 0.1590, -0.0211, -0.0091,  ..., -0.0869, -0.0703, -0.0204],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0121,  0.0110,  ..., -0.0428, -0.0429,  0.2059],\n",
      "         [ 0.0000,  0.0329,  0.0287,  ...,  0.0116,  0.0297,  0.4483],\n",
      "         [ 0.0000,  0.0531,  0.0327,  ..., -0.0218, -0.0349,  0.0560]],\n",
      "\n",
      "        [[ 0.0368,  0.0094, -0.2369,  ..., -0.1224, -0.1276, -0.0222],\n",
      "         [-0.4223,  0.0070, -0.0879,  ..., -0.1100, -0.1273, -0.1700],\n",
      "         [-0.0390,  0.0012,  0.0093,  ..., -0.1857, -0.1804, -0.0064],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0102,  0.0074,  ..., -0.0042,  0.0083,  0.1037],\n",
      "         [ 0.0000, -0.0494, -0.0465,  ...,  0.0009,  0.0040, -0.3351],\n",
      "         [ 0.0000,  0.0013,  0.0117,  ...,  0.0461,  0.0014, -0.0934]]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Std: tensor([[[0.6759, 1.2549, 2.1036,  ..., 0.8292, 0.8298, 0.8134],\n",
      "         [0.9324, 1.2658, 1.3982,  ..., 1.0142, 1.0249, 1.1053],\n",
      "         [2.5346, 1.5386, 0.8663,  ..., 1.8303, 1.8104, 1.5643],\n",
      "         ...,\n",
      "         [0.0000, 0.7816, 0.6766,  ..., 0.9379, 0.9282, 0.7108],\n",
      "         [0.0000, 1.3456, 1.1922,  ..., 0.8772, 1.1533, 0.6357],\n",
      "         [0.0000, 1.4985, 1.4377,  ..., 1.0396, 0.8270, 0.3783]],\n",
      "\n",
      "        [[0.3879, 0.2626, 0.1079,  ..., 0.3480, 0.3536, 0.4209],\n",
      "         [0.6030, 0.3616, 0.3087,  ..., 0.6119, 0.5897, 0.6235],\n",
      "         [1.3693, 1.0774, 0.6070,  ..., 1.3888, 1.4204, 1.5075],\n",
      "         ...,\n",
      "         [0.0000, 0.4021, 0.4283,  ..., 1.0489, 0.9279, 1.0247],\n",
      "         [0.0000, 0.5609, 0.5324,  ..., 0.8948, 0.8171, 0.5477],\n",
      "         [0.0000, 2.2758, 1.3734,  ..., 0.8980, 0.5972, 0.4225]],\n",
      "\n",
      "        [[0.4275, 1.8306, 3.0637,  ..., 1.5308, 1.5023, 1.4468],\n",
      "         [0.3203, 0.9253, 1.2477,  ..., 0.7264, 0.6601, 0.6908],\n",
      "         [0.4218, 0.5317, 0.9957,  ..., 0.7338, 0.6807, 0.5577],\n",
      "         ...,\n",
      "         [0.0000, 0.4371, 0.6101,  ..., 0.8800, 0.8454, 0.9648],\n",
      "         [0.0000, 0.4184, 0.6531,  ..., 1.0442, 0.9824, 1.6863],\n",
      "         [0.0000, 0.4670, 0.8494,  ..., 0.6810, 0.5952, 0.8084]],\n",
      "\n",
      "        [[0.6850, 2.4039, 4.2894,  ..., 1.5825, 1.5596, 1.5675],\n",
      "         [0.6163, 0.9773, 1.6968,  ..., 0.7082, 0.7097, 0.6703],\n",
      "         [0.9654, 0.5406, 0.7294,  ..., 0.8192, 0.7324, 0.6653],\n",
      "         ...,\n",
      "         [0.0000, 0.5142, 0.5418,  ..., 0.9680, 1.1046, 1.4184],\n",
      "         [0.0000, 0.6166, 0.7091,  ..., 0.7923, 0.7893, 2.0723],\n",
      "         [0.0000, 0.4972, 0.8000,  ..., 1.0997, 0.7078, 0.8261]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegSpectrogram(n_fft=200, complex_mode='as_real')\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "\n",
    "signal_2d_mean, signal_2d_std = calculate_signal_statistics(train_loader, preprocess_train)\n",
    "\n",
    "preprocess_train2 = transforms.Compose([\n",
    "    EegNormalizeMeanStd(mean=signal_2d_mean, std=signal_2d_std)\n",
    "])\n",
    "preprocess_train2 = torch.nn.Sequential(*preprocess_train2.transforms).to(device)\n",
    "\n",
    "pprint.pprint(preprocess_train)\n",
    "pprint.pprint(preprocess_train2)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    preprocess_train(sample_batched)   \n",
    "    \n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "    \n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    print('- After -')\n",
    "    preprocess_train2(sample_batched)\n",
    "    \n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Speed check without STFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `EDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegLimitMaxLength(max_length=120000)\n",
      "    EegRandomCrop(crop_length=2000, multiple=2, latency=2000, return_timing=False)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6025]),std=tensor([6.3509]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([-0.1357, -0.2511,  0.0018,  0.0711, -0.0479, -0.2520, -0.2120,  0.0005,\n",
      "          -0.0007, -0.0591,  0.1582,  0.3231,  0.0052, -0.0274,  0.1218,  0.0294,\n",
      "          -0.0802, -0.0193, -0.0197, -0.0166]),std=tensor([46.2526, 20.3984, 11.6559, 11.7465, 15.2970, 50.3807, 20.2444, 10.7235,\n",
      "          11.5641, 15.6016, 20.7594, 15.2747, 13.4793, 21.4928, 16.8901, 15.2875,\n",
      "          19.7100, 11.2538, 11.2400, 98.3843]),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 31min 13s\n",
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegLimitMaxLength(max_length=200*60*10),  # 10m\n",
    "    EegRandomCrop(crop_length=200*10, multiple=2, latency=200*10),  # crop: 10s, latency: 10s\n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf',\n",
    "                                                                                  transform=transform)\n",
    " \n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Feather`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegLimitMaxLength(max_length=120000)\n",
      "    EegRandomCrop(crop_length=2000, multiple=2, latency=2000, return_timing=False)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6025]),std=tensor([6.3509]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([-0.1357, -0.2511,  0.0018,  0.0711, -0.0479, -0.2520, -0.2120,  0.0005,\n",
      "          -0.0007, -0.0591,  0.1582,  0.3231,  0.0052, -0.0274,  0.1218,  0.0294,\n",
      "          -0.0802, -0.0193, -0.0197, -0.0166]),std=tensor([46.2526, 20.3984, 11.6559, 11.7465, 15.2970, 50.3807, 20.2444, 10.7235,\n",
      "          11.5641, 15.6016, 20.7594, 15.2747, 13.4793, 21.4928, 16.8901, 15.2875,\n",
      "          19.7100, 11.2538, 11.2400, 98.3843]),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 1min 47s\n",
      "Wall time: 7.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegLimitMaxLength(max_length=200*60*10),  # 10m\n",
    "    EegRandomCrop(crop_length=200*10, multiple=2, latency=200*10),  # crop: 10s, latency: 10s\n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `memmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegLimitMaxLength(max_length=120000)\n",
      "    EegRandomCrop(crop_length=2000, multiple=2, latency=2000, return_timing=False)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6025]),std=tensor([6.3509]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([-0.1357, -0.2511,  0.0018,  0.0711, -0.0479, -0.2520, -0.2120,  0.0005,\n",
      "          -0.0007, -0.0591,  0.1582,  0.3231,  0.0052, -0.0274,  0.1218,  0.0294,\n",
      "          -0.0802, -0.0193, -0.0197, -0.0166]),std=tensor([46.2526, 20.3984, 11.6559, 11.7465, 15.2970, 50.3807, 20.2444, 10.7235,\n",
      "          11.5641, 15.6016, 20.7594, 15.2747, 13.4793, 21.4928, 16.8901, 15.2875,\n",
      "          19.7100, 11.2538, 11.2400, 98.3843]),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 1min 23s\n",
      "Wall time: 7.14 s\n",
      "Compiler : 188 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegLimitMaxLength(max_length=200*60*10),  # 10m\n",
    "    EegRandomCrop(crop_length=200*10, multiple=2, latency=200*10),  # crop: 10s, latency: 10s\n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    " \n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Speed check with STFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `EDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegLimitMaxLength(max_length=120000)\n",
      "    EegRandomCrop(crop_length=2000, multiple=2, latency=2000, return_timing=False)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6025]),std=tensor([6.3509]),eps=1e-08)\n",
      "  (2): EegSpectrogram(n_fft=200, complex_mode=as_real, stft_kwargs={})\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([[ 3.6224e+01,  8.1955e-01, -1.3452e-01,  ..., -6.3493e-02,\n",
      "           -5.8977e-02, -8.1556e-02],\n",
      "          [ 2.6344e+01,  3.9039e-01,  5.7765e-02,  ..., -1.2983e-03,\n",
      "            5.7594e-05, -1.2575e-02],\n",
      "          [-4.3636e+00,  8.2101e-02, -2.9571e-02,  ...,  1.6749e-03,\n",
      "            3.5939e-03,  6.1787e-03],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  1.1858e-01,  2.4689e-02,  ...,  1.4142e-04,\n",
      "           -5.3444e-04, -1.3321e-08],\n",
      "          [ 0.0000e+00,  6.1904e-01,  2.7609e-01,  ...,  1.2308e-03,\n",
      "           -1.3162e-04, -1.4377e-08],\n",
      "          [ 0.0000e+00, -6.7974e-01,  7.8550e-02,  ...,  7.2703e-04,\n",
      "           -1.1213e-02, -1.2512e-07]], device='cuda:0'),std=tensor([[7.4391e+03, 1.5245e+03, 7.9377e+02,  ..., 2.9074e+01, 2.9047e+01,\n",
      "           2.9265e+01],\n",
      "          [3.3342e+03, 6.0361e+02, 3.0638e+02,  ..., 1.3517e+01, 1.3471e+01,\n",
      "           1.3847e+01],\n",
      "          [1.8063e+03, 2.8569e+02, 1.5334e+02,  ..., 8.1293e+00, 8.0798e+00,\n",
      "           8.6541e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 4.4521e+02, 2.4143e+02,  ..., 2.7859e+00, 2.8801e+00,\n",
      "           3.2122e-06],\n",
      "          [0.0000e+00, 4.7726e+02, 2.5940e+02,  ..., 2.7937e+00, 2.8887e+00,\n",
      "           3.2063e-06],\n",
      "          [0.0000e+00, 2.1106e+03, 1.9989e+03,  ..., 3.6976e+00, 4.7884e+00,\n",
      "           6.1757e-05]], device='cuda:0'),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 31min\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegLimitMaxLength(max_length=200*60*10),  # 10m\n",
    "    EegRandomCrop(crop_length=200*10, multiple=2, latency=200*10),  # crop: 10s, latency: 10s\n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf',\n",
    "                                                                                  transform=transform)\n",
    " \n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegSpectrogram(n_fft=200, complex_mode='as_real'),\n",
    "    EegNormalizeMeanStd(mean=signal_2d_mean, std=signal_2d_std),\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Feather`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegLimitMaxLength(max_length=120000)\n",
      "    EegRandomCrop(crop_length=2000, multiple=2, latency=2000, return_timing=False)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6025]),std=tensor([6.3509]),eps=1e-08)\n",
      "  (2): EegSpectrogram(n_fft=200, complex_mode=as_real, stft_kwargs={})\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([[ 3.6224e+01,  8.1955e-01, -1.3452e-01,  ..., -6.3493e-02,\n",
      "           -5.8977e-02, -8.1556e-02],\n",
      "          [ 2.6344e+01,  3.9039e-01,  5.7765e-02,  ..., -1.2983e-03,\n",
      "            5.7594e-05, -1.2575e-02],\n",
      "          [-4.3636e+00,  8.2101e-02, -2.9571e-02,  ...,  1.6749e-03,\n",
      "            3.5939e-03,  6.1787e-03],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  1.1858e-01,  2.4689e-02,  ...,  1.4142e-04,\n",
      "           -5.3444e-04, -1.3321e-08],\n",
      "          [ 0.0000e+00,  6.1904e-01,  2.7609e-01,  ...,  1.2308e-03,\n",
      "           -1.3162e-04, -1.4377e-08],\n",
      "          [ 0.0000e+00, -6.7974e-01,  7.8550e-02,  ...,  7.2703e-04,\n",
      "           -1.1213e-02, -1.2512e-07]], device='cuda:0'),std=tensor([[7.4391e+03, 1.5245e+03, 7.9377e+02,  ..., 2.9074e+01, 2.9047e+01,\n",
      "           2.9265e+01],\n",
      "          [3.3342e+03, 6.0361e+02, 3.0638e+02,  ..., 1.3517e+01, 1.3471e+01,\n",
      "           1.3847e+01],\n",
      "          [1.8063e+03, 2.8569e+02, 1.5334e+02,  ..., 8.1293e+00, 8.0798e+00,\n",
      "           8.6541e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 4.4521e+02, 2.4143e+02,  ..., 2.7859e+00, 2.8801e+00,\n",
      "           3.2122e-06],\n",
      "          [0.0000e+00, 4.7726e+02, 2.5940e+02,  ..., 2.7937e+00, 2.8887e+00,\n",
      "           3.2063e-06],\n",
      "          [0.0000e+00, 2.1106e+03, 1.9989e+03,  ..., 3.6976e+00, 4.7884e+00,\n",
      "           6.1757e-05]], device='cuda:0'),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 1min 48s\n",
      "Wall time: 7.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegLimitMaxLength(max_length=200*60*10),  # 10m\n",
    "    EegRandomCrop(crop_length=200*10, multiple=2, latency=200*10),  # crop: 10s, latency: 10s\n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegSpectrogram(n_fft=200, complex_mode='as_real'),\n",
    "    EegNormalizeMeanStd(mean=signal_2d_mean, std=signal_2d_std),\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `memmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegLimitMaxLength(max_length=120000)\n",
      "    EegRandomCrop(crop_length=2000, multiple=2, latency=2000, return_timing=False)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6025]),std=tensor([6.3509]),eps=1e-08)\n",
      "  (2): EegSpectrogram(n_fft=200, complex_mode=as_real, stft_kwargs={})\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([[ 3.6224e+01,  8.1955e-01, -1.3452e-01,  ..., -6.3493e-02,\n",
      "           -5.8977e-02, -8.1556e-02],\n",
      "          [ 2.6344e+01,  3.9039e-01,  5.7765e-02,  ..., -1.2983e-03,\n",
      "            5.7594e-05, -1.2575e-02],\n",
      "          [-4.3636e+00,  8.2101e-02, -2.9571e-02,  ...,  1.6749e-03,\n",
      "            3.5939e-03,  6.1787e-03],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  1.1858e-01,  2.4689e-02,  ...,  1.4142e-04,\n",
      "           -5.3444e-04, -1.3321e-08],\n",
      "          [ 0.0000e+00,  6.1904e-01,  2.7609e-01,  ...,  1.2308e-03,\n",
      "           -1.3162e-04, -1.4377e-08],\n",
      "          [ 0.0000e+00, -6.7974e-01,  7.8550e-02,  ...,  7.2703e-04,\n",
      "           -1.1213e-02, -1.2512e-07]], device='cuda:0'),std=tensor([[7.4391e+03, 1.5245e+03, 7.9377e+02,  ..., 2.9074e+01, 2.9047e+01,\n",
      "           2.9265e+01],\n",
      "          [3.3342e+03, 6.0361e+02, 3.0638e+02,  ..., 1.3517e+01, 1.3471e+01,\n",
      "           1.3847e+01],\n",
      "          [1.8063e+03, 2.8569e+02, 1.5334e+02,  ..., 8.1293e+00, 8.0798e+00,\n",
      "           8.6541e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 4.4521e+02, 2.4143e+02,  ..., 2.7859e+00, 2.8801e+00,\n",
      "           3.2122e-06],\n",
      "          [0.0000e+00, 4.7726e+02, 2.5940e+02,  ..., 2.7937e+00, 2.8887e+00,\n",
      "           3.2063e-06],\n",
      "          [0.0000e+00, 2.1106e+03, 1.9989e+03,  ..., 3.6976e+00, 4.7884e+00,\n",
      "           6.1757e-05]], device='cuda:0'),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 1min 26s\n",
      "Wall time: 7.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegLimitMaxLength(max_length=200*60*10),  # 10m\n",
    "    EegRandomCrop(crop_length=200*10, multiple=2, latency=200*10),  # crop: 10s, latency: 10s\n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegSpectrogram(n_fft=200, complex_mode='as_real'),\n",
    "    EegNormalizeMeanStd(mean=signal_2d_mean, std=signal_2d_std),\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test on longer sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegLimitMaxLength(max_length=120000)\n",
      "    EegRandomCrop(crop_length=12000, multiple=2, latency=2000, return_timing=False)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeMeanStd(mean=tensor([-0.1357, -0.2511,  0.0018,  0.0711, -0.0479, -0.2520, -0.2120,  0.0005,\n",
      "          -0.0007, -0.0591,  0.1582,  0.3231,  0.0052, -0.0274,  0.1218,  0.0294,\n",
      "          -0.0802, -0.0193, -0.0197, -0.0166]),std=tensor([46.2526, 20.3984, 11.6559, 11.7465, 15.2970, 50.3807, 20.2444, 10.7235,\n",
      "          11.5641, 15.6016, 20.7594, 15.2747, 13.4793, 21.4928, 16.8901, 15.2875,\n",
      "          19.7100, 11.2538, 11.2400, 98.3843]),eps=1e-08)\n",
      "  (2): EegNormalizeAge(mean=tensor([70.6025]),std=tensor([6.3509]),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 1min 19s\n",
      "Wall time: 6.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "longer_transform = transforms.Compose([\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegLimitMaxLength(max_length=200*60*10),  # 10m\n",
    "    EegRandomCrop(crop_length=200*10*6, multiple=2, latency=200*10),  # crop: 1m, latency: 10s\n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(longer_transform)\n",
    "\n",
    "config_data, longer_test_dataset = load_caueeg_task_split(dataset_path=data_path, \n",
    "                                                          task='task2', \n",
    "                                                          split='test',\n",
    "                                                          load_event=False,\n",
    "                                                          file_format='feather', \n",
    "                                                          transform=longer_transform)\n",
    "\n",
    "longer_test_loader = DataLoader(longer_test_dataset,\n",
    "                                batch_size=32,\n",
    "                                shuffle=True,\n",
    "                                drop_last=False,\n",
    "                                num_workers=num_workers,\n",
    "                                pin_memory=pin_memory,\n",
    "                                collate_fn=eeg_collate_fn)\n",
    " \n",
    "preprocess_test = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std),\n",
    "    EegNormalizeAge(mean=age_mean, std=age_std),\n",
    "])\n",
    "preprocess_test = torch.nn.Sequential(*preprocess_test.transforms).to(device)\n",
    "pprint.pprint(preprocess_test)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_test(sample_batched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
