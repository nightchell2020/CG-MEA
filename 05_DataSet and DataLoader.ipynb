{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and DataLoader\n",
    "\n",
    "This notebook loads the `CAUEEG` dataset, tests some useful preprocessing, and makes up the PyTorch DataLoader instances for the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_dataset import *\n",
    "from datasets.caueeg_script import *\n",
    "from datasets.pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.11.0+cu113\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data file path\n",
    "data_path = r'local/dataset/02_Curated_Data_220412/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Load the CAUEEG dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the whole CAUEEG data as a PyTorch dataset instance without considering the target task (no train/val/test sets and no class label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_name': 'CAUEEG dataset',\n",
      " 'signal_header': ['Fp1-AVG', 'F3-AVG', 'C3-AVG', 'P3-AVG', 'O1-AVG', 'Fp2-AVG', 'F4-AVG', 'C4-AVG', 'P4-AVG', 'O2-AVG', 'F7-AVG', 'T3-AVG', 'T5-AVG', 'F8-AVG', 'T4-AVG', 'T6-AVG', 'FZ-AVG', 'CZ-AVG', 'PZ-AVG', 'EKG', 'Photic']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 78,\n",
      " 'serial': '00001',\n",
      " 'signal': array([[  0., -11., -13., ...,   0.,   0.,   0.],\n",
      "       [ 29.,  33.,  34., ...,   0.,   0.,   0.],\n",
      "       [ -3.,  -6.,  -3., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ -4.,  -2.,   1., ...,   0.,   0.,   0.],\n",
      "       [112.,  67.,  76., ...,   0.,   0.,   0.],\n",
      "       [ -1.,  -1.,  -1., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 56,\n",
      " 'serial': '00002',\n",
      " 'signal': array([[  39.,   58.,   72., ...,    0.,    0.,    0.],\n",
      "       [   4.,   12.,   13., ...,    0.,    0.,    0.],\n",
      "       [   1.,   -2.,   -3., ...,    0.,    0.,    0.],\n",
      "       ...,\n",
      "       [   2.,    1.,    1., ...,    0.,    0.,    0.],\n",
      "       [ -22., -173., -175., ...,    0.,    0.,    0.],\n",
      "       [   2.,    0.,    0., ...,    0.,    0.,    0.]]),\n",
      " 'symptom': ['normal', 'smi']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         load_event=False, \n",
    "                                                         file_format='edf',\n",
    "                                                         transform=None)\n",
    "\n",
    "pprint.pprint(config_data, width=250)\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(full_eeg_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(full_eeg_dataset[1])\n",
    "print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the CAUEEG task1 datasets as the PyTorch dataset instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_label_to_name': ['Normal', 'MCI', 'Dementia'],\n",
      " 'class_name_to_label': {'Dementia': 2, 'MCI': 1, 'Normal': 0},\n",
      " 'task_description': 'Classification of [Normal], [MCI], and [Dementia] '\n",
      "                     'symptoms.',\n",
      " 'task_name': 'CAUEEG-task1 benchmark'}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 81,\n",
      " 'class_label': 2,\n",
      " 'class_name': 'Dementia',\n",
      " 'serial': '01222',\n",
      " 'signal': array([[  1.,   1.,  -1., ...,   0.,   0.,   0.],\n",
      "       [-24., -14., -14., ...,   0.,   0.,   0.],\n",
      "       [ -6.,  -5.,  -6., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ -1.,   6.,   6., ...,   0.,   0.,   0.],\n",
      "       [-42., -62., -59., ...,   0.,   0.,   0.],\n",
      "       [  0.,   0.,  -1., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['dementia', 'ad', 'load']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 74,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00857',\n",
      " 'signal': array([[118.,  91.,  91., ...,   0.,   0.,   0.],\n",
      "       [ 27.,  16.,  16., ...,   0.,   0.,   0.],\n",
      "       [  9.,   6.,   4., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ -8.,  -3.,  -3., ...,   0.,   0.,   0.],\n",
      "       [179., 347., 327., ...,   0.,   0.,   0.],\n",
      "       [ -1.,  -1.,   0., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['normal', 'smi']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 77,\n",
      " 'class_label': 1,\n",
      " 'class_name': 'MCI',\n",
      " 'serial': '01255',\n",
      " 'signal': array([[-14.,  22.,  27., ...,   0.,   0.,   0.],\n",
      "       [-22., -17., -19., ...,   0.,   0.,   0.],\n",
      "       [  1.,   4.,   4., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ 10.,   8.,   5., ...,   0.,   0.,   0.],\n",
      "       [-30., -23.,  -4., ...,   0.,   0.,   0.],\n",
      "       [  1.,   1.,  -2., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_ef']}\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf', \n",
    "                                                                                  transform=None)\n",
    "pprint.pprint(config_data)\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(train_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(val_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the CAUEEG task2 datasets as the PyTorch dataset instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_label_to_name': ['Normal', 'Abnormal'],\n",
      " 'class_name_to_label': {'Abnormal': 1, 'Normal': 0},\n",
      " 'task_description': 'Classification of [Normal] and [Abnormal] symptoms',\n",
      " 'task_name': 'CAUEEG-task2 benchmark'}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 66,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00085',\n",
      " 'signal': array([[ 39.,  87.,  85., ...,   0.,   0.,   0.],\n",
      "       [ 17.,  64.,  67., ...,   0.,   0.,   0.],\n",
      "       [ -1.,   9.,  12., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ 10.,   3.,   3., ...,   0.,   0.,   0.],\n",
      "       [ 30.,  46., -30., ...,   0.,   0.,   0.],\n",
      "       [  2.,   2.,   1., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 79,\n",
      " 'class_label': 1,\n",
      " 'class_name': 'Abnormal',\n",
      " 'serial': '01203',\n",
      " 'signal': array([[117., 165., 163., ...,   0.,   0.,   0.],\n",
      "       [ 38.,  58.,  56., ...,   0.,   0.,   0.],\n",
      "       [  1.,  -3.,  -2., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ 16.,  22.,  19., ...,   0.,   0.,   0.],\n",
      "       [ 69.,  48., -15., ...,   0.,   0.,   0.],\n",
      "       [ -1.,  -1.,   0., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_ef']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 59,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00560',\n",
      " 'signal': array([[  9.,   8.,   1., ...,   0.,   0.,   0.],\n",
      "       [ 24.,  24.,  21., ...,   0.,   0.,   0.],\n",
      "       [  4.,  12.,  12., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ 10.,  13.,  15., ...,   0.,   0.,   0.],\n",
      "       [ -9., -17., -10., ...,   0.,   0.,   0.],\n",
      "       [  0.,  -3.,  -3., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['normal', 'cb_normal']}\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf', \n",
    "                                                                                  transform=None)\n",
    "pprint.pprint(config_data)\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(train_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(val_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 81,\n",
      " 'class_label': 2,\n",
      " 'class_name': 'Dementia',\n",
      " 'event': [[0, 'Start Recording'],\n",
      "           [0, 'New Montage - Montage 002'],\n",
      "           [13926, 'Eyes Open'],\n",
      "           [14562, 'Eyes Closed'],\n",
      "           [16000, 'Paused'],\n",
      "           [18000, 'Recording Resumed'],\n",
      "           [20984, 'Eyes Open'],\n",
      "           [21898, 'Eyes Closed'],\n",
      "           [23258, 'Eyes Open'],\n",
      "           [23866, 'Eyes Closed'],\n",
      "           [38064, 'Eyes Open'],\n",
      "           [53800, 'Paused'],\n",
      "           [55600, 'Recording Resumed'],\n",
      "           [62090, 'artifact'],\n",
      "           [62800, 'Paused'],\n",
      "           [64600, 'Recording Resumed'],\n",
      "           [66332, 'Move'],\n",
      "           [70290, 'Move'],\n",
      "           [71122, 'Move'],\n",
      "           [73030, 'Move'],\n",
      "           [73762, 'Move'],\n",
      "           [74600, 'Paused'],\n",
      "           [86600, 'Recording Resumed'],\n",
      "           [88970, 'swallowing'],\n",
      "           [90020, 'Eyes Closed'],\n",
      "           [91490, 'Eyes Open'],\n",
      "           [92708, 'Eyes Closed'],\n",
      "           [95124, 'Eyes Open'],\n",
      "           [95822, 'Eyes Closed'],\n",
      "           [96238, 'Photic On - 3.0 Hz'],\n",
      "           [96740, 'Eyes Open'],\n",
      "           [97496, 'Eyes Closed'],\n",
      "           [98254, 'Photic Off'],\n",
      "           [100312, 'Photic On - 6.0 Hz'],\n",
      "           [101024, 'Eyes Open'],\n",
      "           [101654, 'Eyes Closed'],\n",
      "           [102328, 'Photic Off'],\n",
      "           [104344, 'Photic On - 9.0 Hz'],\n",
      "           [106359, 'Photic Off'],\n",
      "           [106904, 'Eyes Open'],\n",
      "           [108038, 'Eyes Closed'],\n",
      "           [108418, 'Photic On - 12.0 Hz'],\n",
      "           [110433, 'Photic Off'],\n",
      "           [112576, 'Photic On - 15.0 Hz'],\n",
      "           [114508, 'Photic Off'],\n",
      "           [114842, 'Eyes Open'],\n",
      "           [116311, 'Eyes Closed'],\n",
      "           [116524, 'Photic On - 18.0 Hz'],\n",
      "           [118582, 'Photic Off'],\n",
      "           [120598, 'Photic On - 21.0 Hz'],\n",
      "           [122614, 'Photic Off'],\n",
      "           [122990, 'Eyes Open'],\n",
      "           [124292, 'Eyes Closed'],\n",
      "           [124672, 'Photic On - 24.0 Hz'],\n",
      "           [126688, 'Photic Off'],\n",
      "           [128746, 'Photic On - 27.0 Hz'],\n",
      "           [130761, 'Photic Off'],\n",
      "           [131390, 'Eyes Open'],\n",
      "           [132566, 'Eyes Closed'],\n",
      "           [132778, 'Photic On - 30.0 Hz'],\n",
      "           [134794, 'Photic Off'],\n",
      "           [139622, 'Eyes Open'],\n",
      "           [141096, 'Eyes Closed'],\n",
      "           [142530, 'eye blinking'],\n",
      "           [153528, 'Eyes Open'],\n",
      "           [155964, 'Eyes Closed'],\n",
      "           [163692, 'Eyes Open'],\n",
      "           [165834, 'Eyes Closed'],\n",
      "           [174200, 'Paused']],\n",
      " 'serial': '01222',\n",
      " 'signal': array([[  1.,   1.,  -1., ...,   0.,   0.,   0.],\n",
      "       [-24., -14., -14., ...,   0.,   0.,   0.],\n",
      "       [ -6.,  -5.,  -6., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ -1.,   6.,   6., ...,   0.,   0.,   0.],\n",
      "       [-42., -62., -59., ...,   0.,   0.,   0.],\n",
      "       [  0.,   0.,  -1., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['dementia', 'ad', 'load']}\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=True, \n",
    "                                                                                  file_format='edf', \n",
    "                                                                                  transform=None)\n",
    "pprint.pprint(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Format: `EDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'serial': '00085', 'age': 66, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0, 'signal': array([[ 39.,  87.,  85., ...,   0.,   0.,   0.],\n",
      "       [ 17.,  64.,  67., ...,   0.,   0.,   0.],\n",
      "       [ -1.,   9.,  12., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ 10.,   3.,   3., ...,   0.,   0.,   0.],\n",
      "       [ 30.,  46., -30., ...,   0.,   0.,   0.],\n",
      "       [  2.,   2.,   1., ...,   0.,   0.,   0.]])}\n",
      "{'serial': '00790', 'age': 59, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0, 'signal': array([[  45.,   -7.,   -9., ...,    0.,    0.,    0.],\n",
      "       [   1.,   -2.,  -11., ...,    0.,    0.,    0.],\n",
      "       [   2.,   -6.,   -5., ...,    0.,    0.,    0.],\n",
      "       ...,\n",
      "       [  -4.,    2.,    4., ...,    0.,    0.,    0.],\n",
      "       [ -71., -115.,  -98., ...,    0.,    0.,    0.],\n",
      "       [   0.,    0.,   -1., ...,    0.,    0.,    0.]])}\n",
      "CPU times: total: 188 ms\n",
      "Wall time: 189 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf', \n",
    "                                                                                  transform=None)\n",
    "\n",
    "print(train_dataset[0])\n",
    "print(train_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Format: `PyArrow Feather`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'serial': '00085', 'age': 66, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0, 'signal': array([[ 39,  87,  85, ..., -52, -49, -45],\n",
      "       [ 17,  64,  67, ..., -62, -58, -56],\n",
      "       [ -1,   9,  12, ...,  -8,  -7,  -6],\n",
      "       ...,\n",
      "       [ 10,   3,   3, ...,  -1,   0,   2],\n",
      "       [ 30,  46, -30, ...,  -6, -17, -15],\n",
      "       [  2,   2,   1, ...,   1,   0,   0]])}\n",
      "{'serial': '00790', 'age': 59, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0, 'signal': array([[  45,   -7,   -9, ...,   15,   18,   16],\n",
      "       [   1,   -2,  -11, ...,  -15,  -14,  -14],\n",
      "       [   2,   -6,   -5, ...,   12,   10,   11],\n",
      "       ...,\n",
      "       [  -4,    2,    4, ...,   -2,   -1,   -1],\n",
      "       [ -71, -115,  -98, ...,    3,    5,   -2],\n",
      "       [   0,    0,   -1, ...,    1,   -1,    0]])}\n",
      "CPU times: total: 234 ms\n",
      "Wall time: 245 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather', \n",
    "                                                                                  transform=None)\n",
    "\n",
    "print(train_dataset[0])\n",
    "print(train_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Format: `NumPy Memmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'serial': '00085', 'age': 66, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0, 'signal': memmap([[ 39,  87,  85, ..., -52, -49, -45],\n",
      "        [ 17,  64,  67, ..., -62, -58, -56],\n",
      "        [ -1,   9,  12, ...,  -8,  -7,  -6],\n",
      "        ...,\n",
      "        [ 10,   3,   3, ...,  -1,   0,   2],\n",
      "        [ 30,  46, -30, ...,  -6, -17, -15],\n",
      "        [  2,   2,   1, ...,   1,   0,   0]])}\n",
      "{'serial': '00790', 'age': 59, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0, 'signal': memmap([[  45,   -7,   -9, ...,   15,   18,   16],\n",
      "        [   1,   -2,  -11, ...,  -15,  -14,  -14],\n",
      "        [   2,   -6,   -5, ...,   12,   10,   11],\n",
      "        ...,\n",
      "        [  -4,    2,    4, ...,   -2,   -1,   -1],\n",
      "        [ -71, -115,  -98, ...,    3,    5,   -2],\n",
      "        [   0,    0,   -1, ...,    1,   -1,    0]])}\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 3.51 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap', \n",
    "                                                                                  transform=None)\n",
    "\n",
    "print(train_dataset[0])\n",
    "print(train_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PyTorch Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 66,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00085',\n",
      " 'signal': array([[-33, -32, -33, ...,  28,  29,  29],\n",
      "       [-34, -36, -37, ..., -30, -23, -19],\n",
      "       [-12, -10, -10, ..., -11, -11, -10],\n",
      "       ...,\n",
      "       [-11, -11, -10, ...,  -6,  -4,  -2],\n",
      "       [ -5,   8,   4, ...,  -2,   7,  -6],\n",
      "       [ -1,  -1,   0, ...,   0,   0,  -1]]),\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      ">>> signal shape: (21, 100)\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 66,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00085',\n",
      " 'signal': array([[-65, -65, -65, ..., -40, -39, -41],\n",
      "       [ 31,  33,  33, ...,  37,  36,  36],\n",
      "       [ -7,  -6,  -3, ...,  19,  19,  20],\n",
      "       ...,\n",
      "       [-11, -10,  -9, ..., -11,  -9,  -9],\n",
      "       [ -2,   5,  -2, ...,  -1,   6,  -5],\n",
      "       [  0,  -1,   0, ...,   0,  -1,   2]]),\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      ">>> signal shape: (21, 100)\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = EegRandomCrop(crop_length=100)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path,\n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "for i in range(2):\n",
    "    d = train_dataset[0]\n",
    "    pprint.pprint(d)\n",
    "    print()\n",
    "    print('>>> signal shape:', d['signal'].shape)\n",
    "    print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Random crop with multiple cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 66,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00085',\n",
      " 'signal': [array([[ 85,  91,  92, ..., -32, -35, -34],\n",
      "       [-18, -15, -16, ...,   3,   0,   1],\n",
      "       [-16, -16, -15, ..., -16, -16, -15],\n",
      "       ...,\n",
      "       [ -7,  -8,  -8, ...,  16,  16,  15],\n",
      "       [ -5,  -8,   2, ...,  -6,   1,  10],\n",
      "       [  0,   0,   0, ...,  -1,   0,  -1]]),\n",
      "            array([[ 12,  13,  15, ..., -24, -23, -22],\n",
      "       [ -9,  -7,  -7, ..., -58, -56, -55],\n",
      "       [  6,   7,   8, ..., -12, -10,  -7],\n",
      "       ...,\n",
      "       [ 10,   9,   9, ...,  -7,  -6,  -6],\n",
      "       [  8,  -1, -10, ...,  10,  -3,  -2],\n",
      "       [  0,   0,   0, ...,  -1,   0,   1]])],\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      ">>> signal shape: [(21, 200), (21, 200)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 66,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00085',\n",
      " 'signal': [array([[-76, -75, -69, ..., -24, -24, -20],\n",
      "       [  4,   5,   8, ...,  12,  12,  14],\n",
      "       [  6,   5,   6, ...,   7,   4,   4],\n",
      "       ...,\n",
      "       [ 11,   9,   7, ...,   1,   0,   0],\n",
      "       [  6,  -1,  -2, ...,  10,   3,  10],\n",
      "       [  1,   0,   0, ...,   1,   2,   1]]),\n",
      "            array([[-23, -21, -21, ..., -24, -21, -20],\n",
      "       [ 48,  48,  45, ...,   4,   6,   6],\n",
      "       [ -3,  -4,  -5, ..., -22, -22, -20],\n",
      "       ...,\n",
      "       [-12, -11,  -9, ..., -12, -11, -11],\n",
      "       [  5,   3,  -7, ...,   7,   0,  -1],\n",
      "       [  0,   0,   0, ...,   0,   1,   2]])],\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      ">>> signal shape: [(21, 200), (21, 200)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = EegRandomCrop(crop_length=200, multiple=2)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "for i in range(2):\n",
    "    d = train_dataset[0]\n",
    "    pprint.pprint(d)\n",
    "    print()\n",
    "    print('>>> signal shape:', [signal.shape for signal in d['signal']])\n",
    "    print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random crop with multiple cropping and latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 66,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00085',\n",
      " 'signal': [array([[ -9,  -9,  -8, ...,  23,  23,  23],\n",
      "       [-30, -32, -33, ..., -28, -28, -28],\n",
      "       [ -3,  -5,  -7, ...,  -3,  -4,  -5],\n",
      "       ...,\n",
      "       [  0,   0,  -2, ...,   0,   0,  -1],\n",
      "       [  6,  12,  -2, ...,   6,   5,  -8],\n",
      "       [ -3,   1,   1, ...,  -3,   1,   0]]),\n",
      "            array([[-21, -21, -20, ...,  -5,  -5,  -9],\n",
      "       [ 84,  83,  84, ...,  10,   9,   7],\n",
      "       [  8,   8,   9, ...,   7,   6,   5],\n",
      "       ...,\n",
      "       [  8,   6,   6, ...,   2,   1,   2],\n",
      "       [ -1,   7,   1, ...,  -2,   4,  -5],\n",
      "       [ -1,   0,  -1, ...,  -2,  -3,   0]]),\n",
      "            array([[-23, -25, -25, ..., -47, -46, -45],\n",
      "       [  9,   8,   9, ...,  -2,  -2,  -3],\n",
      "       [  5,   7,   8, ...,   9,   9,   7],\n",
      "       ...,\n",
      "       [ -4,  -2,   0, ...,   7,   7,   7],\n",
      "       [ -8,   2,   6, ...,  -7,   4,   3],\n",
      "       [ -4,   0,   1, ...,   0,   1,   2]])],\n",
      " 'start_point': [95773, 69063, 109772],\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      ">>> signal shape: [(21, 300), (21, 300), (21, 300)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 66,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00085',\n",
      " 'signal': [array([[ 24,  24,  24, ..., -26, -28, -31],\n",
      "       [  6,   6,   5, ...,   4,  -1,  -2],\n",
      "       [  6,   8,   9, ..., -12, -15, -16],\n",
      "       ...,\n",
      "       [ -4,  -3,  -2, ...,   6,   6,   6],\n",
      "       [ -6,   3,  -6, ...,   5,   7,  -5],\n",
      "       [  0,  -3,  -4, ...,  -1,  -1,   0]]),\n",
      "            array([[133, 135, 134, ...,  54,  54,  52],\n",
      "       [ 13,  15,  15, ...,   4,  11,  13],\n",
      "       [  9,  10,  10, ...,   7,   7,   8],\n",
      "       ...,\n",
      "       [  1,   0,  -1, ...,  11,  10,   9],\n",
      "       [  2,   6,  -7, ...,   9,   7,  -7],\n",
      "       [  0,   0,   1, ...,   0,   1,   0]]),\n",
      "            array([[23, 24, 27, ...,  4,  3,  3],\n",
      "       [-2, -2,  0, ..., -4, -5, -4],\n",
      "       [ 4,  2,  0, ...,  1,  2,  3],\n",
      "       ...,\n",
      "       [-6, -6, -6, ...,  1,  2,  2],\n",
      "       [-6,  4, -2, ..., -2,  2, -7],\n",
      "       [ 1,  1,  1, ...,  1,  0,  2]])],\n",
      " 'start_point': [111653, 50227, 93226],\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      ">>> signal shape: [(21, 300), (21, 300), (21, 300)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = EegRandomCrop(crop_length=300, multiple=3, latency=50000, return_timing=True)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "for i in range(2): \n",
    "    d = train_dataset[0]\n",
    "    pprint.pprint(d)\n",
    "    print()\n",
    "    print('>>> signal shape:', [signal.shape for signal in d['signal']])\n",
    "    print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Random crop with multiple cropping, latency, and max length limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 81,\n",
      " 'class_label': 2,\n",
      " 'class_name': 'Dementia',\n",
      " 'serial': '01222',\n",
      " 'signal': [array([[-16, -20, -23, ...,  -4,  -6,  -6],\n",
      "       [-13, -14, -13, ..., -15, -15, -15],\n",
      "       [ 14,  12,  11, ...,  -5,  -4,  -2],\n",
      "       ...,\n",
      "       [ -9,  -9,  -8, ..., -11, -10,  -8],\n",
      "       [ -4,  -7,  -6, ..., -15, -13, -10],\n",
      "       [  0,   1,   0, ...,   2,   0,   1]]),\n",
      "            array([[-58, -60, -62, ..., -45, -42, -41],\n",
      "       [-14, -17, -18, ..., -19, -16, -14],\n",
      "       [ 17,  16,  13, ...,   5,   8,   8],\n",
      "       ...,\n",
      "       [ -9, -10, -12, ...,   3,   1,  -2],\n",
      "       [  3,   3,   7, ...,  61,  27,  20],\n",
      "       [ -2,  -2,   0, ...,   1,  -3,  -3]]),\n",
      "            array([[-60, -62, -63, ..., -28, -31, -30],\n",
      "       [-16, -15, -17, ..., -18, -21, -21],\n",
      "       [ 14,  12,  10, ...,  -3,  -6,  -6],\n",
      "       ...,\n",
      "       [  0,   0,  -1, ...,  -2,  -3,  -4],\n",
      "       [-10, -19, -16, ..., -23, -24, -24],\n",
      "       [  2,   0,   1, ...,   2,   2,   0]])],\n",
      " 'start_point': [50037, 50085, 50054],\n",
      " 'symptom': ['dementia', 'ad', 'load']}\n",
      "\n",
      ">>> signal shape: [(21, 200), (21, 200), (21, 200)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 81,\n",
      " 'class_label': 2,\n",
      " 'class_name': 'Dementia',\n",
      " 'serial': '01222',\n",
      " 'signal': [array([[134, 133, 127, ..., 113, 112, 107],\n",
      "       [ 16,  17,  18, ...,  24,  22,  21],\n",
      "       [  6,   8,   6, ...,  -4,  -6,  -5],\n",
      "       ...,\n",
      "       [-22, -22, -21, ..., -21, -22, -23],\n",
      "       [  9,  11,   8, ..., -10, -10, -11],\n",
      "       [  1,   1,   0, ...,   0,   3,   3]]),\n",
      "            array([[-65, -66, -66, ..., -45, -45, -45],\n",
      "       [-20, -20, -20, ..., -20, -19, -22],\n",
      "       [ 13,  11,  11, ...,   3,   3,   0],\n",
      "       ...,\n",
      "       [ -6,  -5,  -4, ...,  -3,  -3,  -3],\n",
      "       [-17, -25, -21, ...,   9,   7,   2],\n",
      "       [  2,   2,   0, ...,   1,   2,   2]]),\n",
      "            array([[-39, -39, -42, ..., -20, -23, -27],\n",
      "       [ -9,  -9, -11, ..., -18, -17, -17],\n",
      "       [ 16,  16,  17, ...,   1,   1,   1],\n",
      "       ...,\n",
      "       [-12, -11, -10, ...,   0,   1,   0],\n",
      "       [ -6, -13, -12, ..., -16, -14, -15],\n",
      "       [  0,   1,   1, ...,   2,   0,   1]])],\n",
      " 'start_point': [50017, 50071, 50046],\n",
      " 'symptom': ['dementia', 'ad', 'load']}\n",
      "\n",
      ">>> signal shape: [(21, 200), (21, 200), (21, 200)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200, \n",
    "                  length_limit=50300,\n",
    "                  multiple=3, \n",
    "                  latency=50000, \n",
    "                  return_timing=True)\n",
    "])\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "for i in range(2):\n",
    "    d = train_dataset[0]\n",
    "    pprint.pprint(d)\n",
    "    print()\n",
    "    print('>>> signal shape:', [signal.shape for signal in d['signal']])\n",
    "    print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Drop channel(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1-AVG', 'F3-AVG', 'C3-AVG', 'P3-AVG', 'O1-AVG', 'Fp2-AVG', 'F4-AVG', 'C4-AVG', 'P4-AVG', 'O2-AVG', 'F7-AVG', 'T3-AVG', 'T5-AVG', 'F8-AVG', 'T4-AVG', 'T6-AVG', 'FZ-AVG', 'CZ-AVG', 'PZ-AVG', 'EKG', 'Photic']\n",
      "channel_ekg:  19\n",
      "channel_photic:  20\n"
     ]
    }
   ],
   "source": [
    "anno_path = os.path.join(data_path, 'annotation.json')\n",
    "with open(anno_path, 'r') as json_file:\n",
    "    annotation = json.load(json_file)\n",
    "signal_headers = annotation['signal_header']\n",
    "del annotation\n",
    "print(signal_headers)\n",
    "\n",
    "channel_ekg = signal_headers.index('EKG')\n",
    "print('channel_ekg: ', channel_ekg)\n",
    "\n",
    "channel_photic = signal_headers.index('Photic')\n",
    "print('channel_photic: ', channel_photic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: (21, 156600)\n",
      "[[  1   1  -1 ...   2   3   3]\n",
      " [-24 -14 -14 ... -12  -9  -8]\n",
      " [ -6  -5  -6 ...  -3  -1  -1]\n",
      " ...\n",
      " [ -1   6   6 ...  -1  -2  -2]\n",
      " [-42 -62 -59 ... -12 -14 -16]\n",
      " [  0   0  -1 ...  -1   0   0]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "after: (20, 156600)\n",
      "[[  1   1  -1 ...   2   3   3]\n",
      " [-24 -14 -14 ... -12  -9  -8]\n",
      " [ -6  -5  -6 ...  -3  -1  -1]\n",
      " ...\n",
      " [ 14  22  23 ...  -5  -4  -3]\n",
      " [ -1   6   6 ...  -1  -2  -2]\n",
      " [  0   0  -1 ...  -1   0   0]]\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather', \n",
    "                                                                                  transform=None)\n",
    "print('before:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather', \n",
    "                                                                                  transform=EegDropChannels(channel_ekg))\n",
    "print('after:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: (21, 156600)\n",
      "[[  1   1  -1 ...   2   3   3]\n",
      " [-24 -14 -14 ... -12  -9  -8]\n",
      " [ -6  -5  -6 ...  -3  -1  -1]\n",
      " ...\n",
      " [ -1   6   6 ...  -1  -2  -2]\n",
      " [-42 -62 -59 ... -12 -14 -16]\n",
      " [  0   0  -1 ...  -1   0   0]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "after: (20, 156600)\n",
      "[[  1   1  -1 ...   2   3   3]\n",
      " [-24 -14 -14 ... -12  -9  -8]\n",
      " [ -6  -5  -6 ...  -3  -1  -1]\n",
      " ...\n",
      " [ 14  22  23 ...  -5  -4  -3]\n",
      " [ -1   6   6 ...  -1  -2  -2]\n",
      " [-42 -62 -59 ... -12 -14 -16]]\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=None)\n",
    "print('before:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=EegDropChannels(channel_photic))\n",
    "print('after:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: (21, 156600)\n",
      "[[  1   1  -1 ...   2   3   3]\n",
      " [-24 -14 -14 ... -12  -9  -8]\n",
      " [ -6  -5  -6 ...  -3  -1  -1]\n",
      " ...\n",
      " [ -1   6   6 ...  -1  -2  -2]\n",
      " [-42 -62 -59 ... -12 -14 -16]\n",
      " [  0   0  -1 ...  -1   0   0]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "after: (19, 156600)\n",
      "[[  1   1  -1 ...   2   3   3]\n",
      " [-24 -14 -14 ... -12  -9  -8]\n",
      " [ -6  -5  -6 ...  -3  -1  -1]\n",
      " ...\n",
      " [  9  18  19 ...  -3  -2  -1]\n",
      " [ 14  22  23 ...  -5  -4  -3]\n",
      " [ -1   6   6 ...  -1  -2  -2]]\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=None)\n",
    "print('before:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=EegDropChannels([channel_ekg, channel_photic]))\n",
    "print('after:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "{'age': 78,\n",
      " 'serial': '00001',\n",
      " 'signal': array([[  0, -11, -13, ...,  18,  21,  22],\n",
      "       [ 29,  33,  34, ...,  -7,  -4,  -4],\n",
      "       [ -3,  -6,  -3, ...,  -1,   1,   2],\n",
      "       ...,\n",
      "       [ -4,  -2,   1, ...,   0,  -1,  -1],\n",
      "       [112,  67,  76, ..., -13, -15, -11],\n",
      "       [ -1,  -1,  -1, ...,  -1,  -1,  -1]]),\n",
      " 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf']}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "After:\n",
      "{'age': tensor(78.),\n",
      " 'serial': '00001',\n",
      " 'signal': tensor([[  0., -11., -13.,  ...,  18.,  21.,  22.],\n",
      "        [ 29.,  33.,  34.,  ...,  -7.,  -4.,  -4.],\n",
      "        [ -3.,  -6.,  -3.,  ...,  -1.,   1.,   2.],\n",
      "        ...,\n",
      "        [ -4.,  -2.,   1.,  ...,   0.,  -1.,  -1.],\n",
      "        [112.,  67.,  76.,  ..., -13., -15., -11.],\n",
      "        [ -1.,  -1.,  -1.,  ...,  -1.,  -1.,  -1.]]),\n",
      " 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf']}\n"
     ]
    }
   ],
   "source": [
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         load_event=False, \n",
    "                                                         file_format='feather',\n",
    "                                                         transform=None)\n",
    "print('Before:')\n",
    "pprint.pprint(full_eeg_dataset[0])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "\n",
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         load_event=False, \n",
    "                                                         file_format='feather',\n",
    "                                                         transform=EegToTensor())\n",
    "print('After:')\n",
    "pprint.pprint(full_eeg_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compose the above all in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': tensor(81.),\n",
      " 'class_label': tensor(2),\n",
      " 'class_name': 'Dementia',\n",
      " 'serial': '01222',\n",
      " 'signal': [tensor([[-59., -59., -55.,  ..., -58., -65., -65.],\n",
      "        [-20., -19., -17.,  ..., -49., -51., -53.],\n",
      "        [  6.,   7.,   9.,  ...,  10.,   8.,   9.],\n",
      "        ...,\n",
      "        [  2.,   3.,   4.,  ...,   7.,   8.,   9.],\n",
      "        [ 16.,  17.,  16.,  ...,  18.,  19.,  20.],\n",
      "        [ 17.,  28.,  20.,  ...,  -5.,  -7.,  -5.]]),\n",
      "            tensor([[ -6.,  -9., -15.,  ..., -44., -47., -49.],\n",
      "        [  2.,   1.,  -1.,  ..., -21., -19., -20.],\n",
      "        [ -8., -10., -12.,  ...,   6.,   7.,   7.],\n",
      "        ...,\n",
      "        [  0.,   2.,   4.,  ...,  -4.,  -2.,   1.],\n",
      "        [  7.,   7.,   7.,  ...,  -6.,  -7.,  -5.],\n",
      "        [  4.,   0.,  -7.,  ...,  -1.,   6.,   9.]]),\n",
      "            tensor([[ 17.,  10.,   9.,  ..., -25., -23., -31.],\n",
      "        [  0.,  -1.,  -1.,  ...,   1.,  -1.,   0.],\n",
      "        [-28., -27., -27.,  ...,  -2.,  -1.,  -3.],\n",
      "        ...,\n",
      "        [  4.,   3.,   2.,  ...,   6.,   4.,   2.],\n",
      "        [ -5.,  -6.,  -6.,  ...,   9.,   8.,   9.],\n",
      "        [ 83.,  73.,  58.,  ...,   1.,  -3.,  -5.]]),\n",
      "            tensor([[-10., -16., -17.,  ...,  11.,  12.,   4.],\n",
      "        [-12., -13., -12.,  ...,  -3.,  -3.,  -4.],\n",
      "        [ -6.,  -1.,  -2.,  ..., -10.,  -9.,  -8.],\n",
      "        ...,\n",
      "        [  1.,   1.,   1.,  ...,  -7.,  -6.,  -6.],\n",
      "        [  1.,   2.,   3.,  ...,  -7.,  -7.,  -7.],\n",
      "        [ 40.,  27.,  26.,  ..., -26., -27., -21.]])],\n",
      " 'symptom': ['dementia', 'ad', 'load']}\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*10,       # crop: 10s\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=4, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "pprint.pprint(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == 'cuda':\n",
    "    num_workers = 0  # A number other than 0 causes an error\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': tensor([69., 69., 69., 69., 55., 55., 76., 76.]),\n",
      " 'serial': ['00399',\n",
      "            '00399',\n",
      "            '00823',\n",
      "            '00823',\n",
      "            '00816',\n",
      "            '00816',\n",
      "            '00940',\n",
      "            '00940'],\n",
      " 'signal': tensor([[[  -1.,    0.,    2.,  ...,    5.,    6.,    8.],\n",
      "         [ -11.,   -9.,   -9.,  ...,    7.,   11.,   14.],\n",
      "         [  12.,   12.,   12.,  ...,    9.,   11.,   14.],\n",
      "         ...,\n",
      "         [  -3.,   -1.,    1.,  ...,   -7.,   -4.,   -1.],\n",
      "         [  -3.,   -3.,   -3.,  ...,   -4.,   -3.,   -3.],\n",
      "         [ 120.,  118.,  115.,  ...,  106.,   99.,   91.]],\n",
      "\n",
      "        [[  25.,   27.,   28.,  ...,  -18.,  -24.,  -25.],\n",
      "         [ -66.,  -65.,  -63.,  ...,  -27.,  -29.,  -29.],\n",
      "         [  10.,   12.,   14.,  ...,   23.,   23.,   24.],\n",
      "         ...,\n",
      "         [   6.,    6.,    7.,  ...,    5.,    6.,    7.],\n",
      "         [   9.,    8.,    7.,  ...,    5.,    5.,    4.],\n",
      "         [  -5.,   -9.,  -10.,  ...,  114.,  116.,  119.]],\n",
      "\n",
      "        [[  13.,   11.,   10.,  ...,  -21.,  -23.,  -23.],\n",
      "         [   0.,    1.,    0.,  ...,   18.,   18.,   19.],\n",
      "         [   8.,   11.,   11.,  ...,    1.,    1.,    3.],\n",
      "         ...,\n",
      "         [   5.,   10.,    9.,  ...,   -9.,   -5.,   -2.],\n",
      "         [  -1.,    2.,    5.,  ...,  -10.,   -9.,   -8.],\n",
      "         [  -5.,   -9.,   -5.,  ...,  -22.,  -26.,  -29.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  12.,   13.,   16.,  ...,   -7.,   -3.,    1.],\n",
      "         [  12.,   12.,   15.,  ...,  -11.,   -7.,   -4.],\n",
      "         [  15.,   14.,   14.,  ...,  -11.,  -10.,   -9.],\n",
      "         ...,\n",
      "         [   7.,    7.,    6.,  ...,   -1.,   -1.,   -1.],\n",
      "         [   6.,    6.,    8.,  ...,    0.,   -3.,   -6.],\n",
      "         [  42.,   11.,  -44.,  ...,   19.,  -23.,   27.]],\n",
      "\n",
      "        [[   7.,    7.,    3.,  ...,   61.,   58.,   55.],\n",
      "         [ -21.,  -23.,  -29.,  ...,   27.,   24.,   22.],\n",
      "         [ -17.,  -18.,  -19.,  ...,   18.,   18.,   17.],\n",
      "         ...,\n",
      "         [  10.,    6.,    1.,  ...,   96.,   94.,   94.],\n",
      "         [   4.,    4.,    5.,  ...,  119.,  120.,  124.],\n",
      "         [ -14.,  -37.,    3.,  ...,   31.,   31.,   60.]],\n",
      "\n",
      "        [[ -43.,  -46.,  -49.,  ...,    7.,    8.,   11.],\n",
      "         [ -35.,  -37.,  -39.,  ...,  -45.,  -44.,  -44.],\n",
      "         [ -32.,  -32.,  -30.,  ...,   38.,   37.,   37.],\n",
      "         ...,\n",
      "         [ -23.,  -23.,  -23.,  ...,  -14.,  -14.,  -12.],\n",
      "         [ -12.,  -11.,   -9.,  ...,  -21.,  -22.,  -22.],\n",
      "         [-315., -263., -282.,  ..., -352., -401., -273.]]]),\n",
      " 'symptom': [['normal', 'smi'],\n",
      "             ['normal', 'smi'],\n",
      "             ['normal', 'smi'],\n",
      "             ['normal', 'smi'],\n",
      "             ['normal', 'cb_normal'],\n",
      "             ['normal', 'cb_normal'],\n",
      "             ['mci', 'mci_amnestic'],\n",
      "             ['mci', 'mci_amnestic']]}\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*10,       # crop: 10s\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=2, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "\n",
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         load_event=False, \n",
    "                                                         file_format='memmap',\n",
    "                                                         transform=transform)\n",
    "\n",
    "full_loader = DataLoader(full_eeg_dataset,\n",
    "                         batch_size=4,\n",
    "                         shuffle=True,\n",
    "                         drop_last=True,\n",
    "                         num_workers=num_workers,\n",
    "                         pin_memory=pin_memory,\n",
    "                         collate_fn=eeg_collate_fn)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(full_loader):\n",
    "    pprint.pprint(sample_batched)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': tensor([77., 77., 93., 93., 68., 68., 59., 59., 84., 84., 78., 78., 64., 64.,\n",
      "        59., 59.]),\n",
      " 'class_label': tensor([0, 0, 2, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
      " 'class_name': ['Normal', 'Normal', 'Dementia', 'Dementia', 'Normal', 'Normal', 'Dementia', 'Dementia', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal', 'Normal'],\n",
      " 'serial': ['00697', '00697', '00928', '00928', '00675', '00675', '01006', '01006', '01013', '01013', '00050', '00050', '01010', '01010', '00864', '00864'],\n",
      " 'signal': tensor([[[-22., -19., -17.,  ...,  21.,  21.,  22.],\n",
      "         [ -5.,  -5.,  -6.,  ..., -11., -10.,  -7.],\n",
      "         [ 13.,  11.,   9.,  ...,   0.,   3.,   6.],\n",
      "         ...,\n",
      "         [ -1.,  -6.,  -9.,  ..., -18., -20., -18.],\n",
      "         [  5.,   1.,  -2.,  ...,   3.,   3.,   3.],\n",
      "         [ -5.,  -1.,   9.,  ..., -12., -20., -15.]],\n",
      "\n",
      "        [[ 30.,  25.,  25.,  ...,   8.,   2.,   5.],\n",
      "         [ 16.,  13.,   9.,  ...,   2.,   3.,   1.],\n",
      "         [  7.,   4.,   2.,  ...,  27.,  23.,  21.],\n",
      "         ...,\n",
      "         [ -6., -10., -13.,  ...,  -2.,  -6., -12.],\n",
      "         [ -6., -10., -11.,  ...,  10.,   7.,   2.],\n",
      "         [  3.,   1.,  19.,  ...,   3.,  26.,  23.]],\n",
      "\n",
      "        [[  0.,   1.,   4.,  ...,   3.,   1.,  -5.],\n",
      "         [ -6., -14., -11.,  ...,  11.,   4.,  -1.],\n",
      "         [  1.,   0.,  -5.,  ...,   1.,   0.,  12.],\n",
      "         ...,\n",
      "         [ -1.,   0.,  -1.,  ...,  -1.,  -1.,   0.],\n",
      "         [  2.,  -1.,  -2.,  ...,  -1.,  -2.,   0.],\n",
      "         [  1., -18.,  -7.,  ...,  32.,  38.,  45.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ -5.,  -4.,  -5.,  ...,  -3.,  -3.,  -8.],\n",
      "         [  8.,   8.,   7.,  ..., -12., -13., -15.],\n",
      "         [  2.,   3.,   2.,  ...,   1.,  -2.,  -2.],\n",
      "         ...,\n",
      "         [ -7.,  -5.,  -1.,  ...,  15.,  12.,   8.],\n",
      "         [-10.,  -7.,  -4.,  ...,  10.,  10.,   9.],\n",
      "         [169., 173., 162.,  ..., -22., -14.,  -1.]],\n",
      "\n",
      "        [[  8.,   5.,   4.,  ..., -35., -36., -36.],\n",
      "         [  2.,   0.,   0.,  ..., -27., -26., -24.],\n",
      "         [  7.,   6.,   6.,  ..., -13., -13., -12.],\n",
      "         ...,\n",
      "         [  7.,   8.,   8.,  ...,   0.,   0.,  -1.],\n",
      "         [  3.,   4.,   4.,  ...,   3.,   3.,   2.],\n",
      "         [-18., -23., -27.,  ..., -11., -11., -12.]],\n",
      "\n",
      "        [[-12.,  -9.,  -7.,  ..., -17., -17., -16.],\n",
      "         [-23., -21., -19.,  ...,  -6.,  -6.,  -4.],\n",
      "         [  9.,   9.,   8.,  ...,  -1.,  -1.,   1.],\n",
      "         ...,\n",
      "         [  1.,   1.,   1.,  ...,  -4.,  -5.,  -4.],\n",
      "         [  4.,   4.,   4.,  ...,   2.,   3.,   3.],\n",
      "         [-60., -66., -70.,  ..., -19., -19., -20.]]]),\n",
      " 'symptom': [['normal', 'smi'],\n",
      "             ['normal', 'smi'],\n",
      "             ['dementia', 'ad', 'load'],\n",
      "             ['dementia', 'ad', 'load'],\n",
      "             ['normal', 'cb_normal'],\n",
      "             ['normal', 'cb_normal'],\n",
      "             ['dementia', 'ad', 'eoad'],\n",
      "             ['dementia', 'ad', 'eoad'],\n",
      "             ['normal', 'smi'],\n",
      "             ['normal', 'smi'],\n",
      "             ['normal'],\n",
      "             ['normal'],\n",
      "             ['normal', 'cb_normal'],\n",
      "             ['normal', 'cb_normal'],\n",
      "             ['normal', 'cb_normal'],\n",
      "             ['normal', 'cb_normal']]}\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*10,       # crop: 10s\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=2, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=8,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    pprint.pprint(sample_batched, width=250)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Preprocessing steps run by the PyTorch Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*10,       # crop: 10s\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=2, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=2,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To GPU device if it is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      ")\n",
      "- Before -\n",
      "{'age': tensor([82., 82., 74., 74.]),\n",
      " 'class_label': tensor([1, 1, 1, 1]),\n",
      " 'class_name': ['Abnormal', 'Abnormal', 'Abnormal', 'Abnormal'],\n",
      " 'serial': ['00580', '00580', '00563', '00563'],\n",
      " 'signal': tensor([[[ -43.,  -43.,  -45.,  ...,  -10.,  -11.,  -16.],\n",
      "         [  -4.,   -7.,  -12.,  ...,   14.,   14.,   13.],\n",
      "         [   1.,    2.,    0.,  ...,    1.,    3.,    3.],\n",
      "         ...,\n",
      "         [  15.,   11.,    6.,  ...,   -6.,   -5.,   -4.],\n",
      "         [  11.,   14.,   14.,  ...,   -7.,   -8.,   -8.],\n",
      "         [ -90., -112., -118.,  ...,   61.,   72.,   76.]],\n",
      "\n",
      "        [[ -12.,  -13.,  -16.,  ...,  -10.,  -12.,  -12.],\n",
      "         [   6.,    2.,   -2.,  ...,  -13.,  -19.,  -23.],\n",
      "         [  -8.,  -10.,  -12.,  ...,  -10.,  -14.,  -14.],\n",
      "         ...,\n",
      "         [   1.,   -1.,   -3.,  ...,   -3.,   -3.,   -1.],\n",
      "         [  12.,   15.,   17.,  ...,  -12.,  -13.,   -9.],\n",
      "         [  60.,   43.,   23.,  ...,  -44.,  -44.,  -45.]],\n",
      "\n",
      "        [[  11.,   12.,   15.,  ..., -134., -129., -130.],\n",
      "         [  59.,   61.,   61.,  ...,  -35.,  -41.,  -44.],\n",
      "         [  -1.,    2.,    6.,  ...,    9.,    8.,   10.],\n",
      "         ...,\n",
      "         [  -7.,   -7.,   -7.,  ...,  -46.,  -48.,  -50.],\n",
      "         [  -5.,   -6.,   -7.,  ...,    9.,    9.,   11.],\n",
      "         [  49.,   55.,   39.,  ...,   32.,   26.,    7.]],\n",
      "\n",
      "        [[ -11.,  -14.,  -16.,  ...,  -52.,  -59.,  -51.],\n",
      "         [ -10.,  -12.,   -9.,  ...,  -38.,  -42.,  -38.],\n",
      "         [   3.,    3.,    4.,  ...,    6.,    7.,    7.],\n",
      "         ...,\n",
      "         [  22.,   22.,   22.,  ...,   10.,   10.,    9.],\n",
      "         [  -4.,   -2.,    1.,  ...,    5.,    2.,   -1.],\n",
      "         [  58.,   52.,   32.,  ...,   -2.,   -8.,   -7.]]]),\n",
      " 'symptom': [['mci', 'mci_amnestic', 'mci_amnestic_rf'],\n",
      "             ['mci', 'mci_amnestic', 'mci_amnestic_rf'],\n",
      "             ['mci', 'mci_amnestic'],\n",
      "             ['mci', 'mci_amnestic']]}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "{'age': tensor([82., 82., 74., 74.], device='cuda:0'),\n",
      " 'class_label': tensor([1, 1, 1, 1], device='cuda:0'),\n",
      " 'class_name': ['Abnormal', 'Abnormal', 'Abnormal', 'Abnormal'],\n",
      " 'serial': ['00580', '00580', '00563', '00563'],\n",
      " 'signal': tensor([[[ -43.,  -43.,  -45.,  ...,  -10.,  -11.,  -16.],\n",
      "         [  -4.,   -7.,  -12.,  ...,   14.,   14.,   13.],\n",
      "         [   1.,    2.,    0.,  ...,    1.,    3.,    3.],\n",
      "         ...,\n",
      "         [  15.,   11.,    6.,  ...,   -6.,   -5.,   -4.],\n",
      "         [  11.,   14.,   14.,  ...,   -7.,   -8.,   -8.],\n",
      "         [ -90., -112., -118.,  ...,   61.,   72.,   76.]],\n",
      "\n",
      "        [[ -12.,  -13.,  -16.,  ...,  -10.,  -12.,  -12.],\n",
      "         [   6.,    2.,   -2.,  ...,  -13.,  -19.,  -23.],\n",
      "         [  -8.,  -10.,  -12.,  ...,  -10.,  -14.,  -14.],\n",
      "         ...,\n",
      "         [   1.,   -1.,   -3.,  ...,   -3.,   -3.,   -1.],\n",
      "         [  12.,   15.,   17.,  ...,  -12.,  -13.,   -9.],\n",
      "         [  60.,   43.,   23.,  ...,  -44.,  -44.,  -45.]],\n",
      "\n",
      "        [[  11.,   12.,   15.,  ..., -134., -129., -130.],\n",
      "         [  59.,   61.,   61.,  ...,  -35.,  -41.,  -44.],\n",
      "         [  -1.,    2.,    6.,  ...,    9.,    8.,   10.],\n",
      "         ...,\n",
      "         [  -7.,   -7.,   -7.,  ...,  -46.,  -48.,  -50.],\n",
      "         [  -5.,   -6.,   -7.,  ...,    9.,    9.,   11.],\n",
      "         [  49.,   55.,   39.,  ...,   32.,   26.,    7.]],\n",
      "\n",
      "        [[ -11.,  -14.,  -16.,  ...,  -52.,  -59.,  -51.],\n",
      "         [ -10.,  -12.,   -9.,  ...,  -38.,  -42.,  -38.],\n",
      "         [   3.,    3.,    4.,  ...,    6.,    7.,    7.],\n",
      "         ...,\n",
      "         [  22.,   22.,   22.,  ...,   10.,   10.,    9.],\n",
      "         [  -4.,   -2.,    1.,  ...,    5.,    2.,   -1.],\n",
      "         [  58.,   52.,   32.,  ...,   -2.,   -8.,   -7.]]], device='cuda:0'),\n",
      " 'symptom': [['mci', 'mci_amnestic', 'mci_amnestic_rf'],\n",
      "             ['mci', 'mci_amnestic', 'mci_amnestic_rf'],\n",
      "             ['mci', 'mci_amnestic'],\n",
      "             ['mci', 'mci_amnestic']]}\n"
     ]
    }
   ],
   "source": [
    "print('device:', device)\n",
    "print()\n",
    "\n",
    "preprocess_train = transforms.Compose([EegToDevice(device=device)])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    pprint.pprint(sample_batched)\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    pprint.pprint(sample_batched)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization per signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizePerSignal(eps=1e-08)\n",
      ")\n",
      "- Before -\n",
      "Mean: tensor([[  6.4520,   4.1240,   5.4440,  -2.4650,  -0.5790,   8.6005,   4.8075,\n",
      "         -13.1735,  -7.1335,  -3.3060,   5.6695,  -2.9920,   3.6250,  -0.0810,\n",
      "           8.9990,   0.6855,   0.8340,  -1.2190,  -3.2995,   0.1295],\n",
      "        [  0.6530,   2.8260,   0.8645,   1.1610,   1.0980,   1.6790,  -1.1485,\n",
      "          -3.1490,  -2.7160,  -1.8175,  -0.3910,   0.5745,   1.4915,   1.1840,\n",
      "           3.7535,  -0.3780,  -2.7430,  -0.0540,  -0.5885,  -0.0520],\n",
      "        [  2.8785,   2.8445,   0.8880,   0.0995,   0.1575,  -5.0670,  -1.5020,\n",
      "          -0.2590,  -0.5920,  -0.2060,   1.3025,   1.0405,   0.5200,  -5.5765,\n",
      "           0.1480,  -0.9880,   0.7060,   1.0980,   0.2615,  -1.3680],\n",
      "        [ -3.5925,   0.4550,   0.1645,   0.2800,   1.1640,  -7.1715,  -3.1490,\n",
      "          -1.2005,   0.1525,   1.4280,   1.5335,   1.1865,   1.2040,  -1.0580,\n",
      "           0.0375,   0.7515,  -3.2665,   0.5960,  -0.2400,   0.1535]])\n",
      "\n",
      "Std: tensor([[ 34.4151,  33.5259,  17.4359,  20.1573,  26.1651,  23.5245,  14.4532,\n",
      "          84.3885,  49.1444,  49.5067,  28.3960,  14.5718,  44.0845,  31.7237,\n",
      "          39.1749,  19.1495,  22.1053,  10.3491,  18.8075,  84.4206],\n",
      "        [ 15.8516,  18.1534,  12.9564,  13.3285,  11.0651,  14.5488,  14.6625,\n",
      "          11.1601,   9.6850,  10.5365,  10.8713,  24.4014,  12.2654,  13.5253,\n",
      "          25.6570,   9.8161,  13.5704,   8.0632,   7.1674,  81.2647],\n",
      "        [ 26.5703,  13.1484,   8.4855,   8.3555,   8.6825,  42.0349,  17.0687,\n",
      "           8.3739,   7.7635,   7.9478,  27.6667,  11.0456,   8.5277,  35.3103,\n",
      "          10.9577,   7.6733,  10.1664,  10.5005,   7.4923, 120.1359],\n",
      "        [ 21.0159,  10.9912,   6.9235,   7.2124,   8.9519,  29.4059,  12.1677,\n",
      "           7.5391,   7.4502,   8.5620,  19.7060,   9.0000,   7.7376,  22.3337,\n",
      "           9.8267,   8.1942,  14.3902,   7.8139,   7.6127, 118.5431]])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "Mean: tensor([[ 0.0000e+00, -1.1802e-08, -1.5736e-08,  6.1989e-09, -1.1444e-08,\n",
      "         -2.3842e-08, -4.5776e-08, -7.8678e-09, -7.1526e-09, -5.7220e-09,\n",
      "          9.5367e-09,  2.6703e-08, -1.9073e-09,  7.6294e-09, -4.7684e-09,\n",
      "          2.8610e-09,  1.0014e-08, -1.2398e-08, -1.8120e-08, -2.8610e-09],\n",
      "        [ 5.7220e-09, -3.1948e-08,  1.9073e-09,  5.1498e-08,  6.6757e-09,\n",
      "         -9.0599e-09,  1.2398e-08,  0.0000e+00, -3.0518e-08,  2.8610e-09,\n",
      "          0.0000e+00, -2.6226e-08, -1.0967e-08,  2.1458e-09, -1.8597e-08,\n",
      "          4.2915e-09,  4.2915e-09,  1.1444e-08,  1.1444e-08, -5.7220e-09],\n",
      "        [-2.8610e-09,  8.5831e-09, -1.1444e-08, -2.8610e-09,  7.6294e-09,\n",
      "          6.6757e-09,  2.8610e-09, -7.6294e-09, -6.6757e-09,  7.1526e-09,\n",
      "         -7.6294e-09,  1.1444e-08, -1.9073e-08, -5.7220e-09,  0.0000e+00,\n",
      "         -4.7684e-09, -3.3379e-09,  1.0967e-08,  3.8147e-09, -4.7684e-09],\n",
      "        [ 7.6294e-09,  0.0000e+00, -1.8120e-08, -3.8147e-09,  1.1444e-08,\n",
      "          2.6703e-08,  3.8147e-09,  1.3351e-08, -1.9073e-08,  3.0518e-08,\n",
      "         -5.7220e-09,  7.6294e-09, -1.5259e-08, -7.6294e-09,  0.0000e+00,\n",
      "          0.0000e+00,  3.8147e-09, -1.1444e-08, -2.2888e-08, -1.0490e-08]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Std: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizePerSignal()\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal normalization using the specified mean and std values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and standard deviation for signal:\n",
      "tensor([[[ 0.0112],\n",
      "         [-0.0979],\n",
      "         [-0.1854],\n",
      "         [-0.0261],\n",
      "         [ 0.2286],\n",
      "         [ 0.2173],\n",
      "         [ 0.0367],\n",
      "         [-0.0019],\n",
      "         [ 0.0108],\n",
      "         [ 0.0986],\n",
      "         [-0.3425],\n",
      "         [-0.0903],\n",
      "         [ 0.0697],\n",
      "         [-0.0039],\n",
      "         [ 0.3391],\n",
      "         [ 0.0294],\n",
      "         [ 0.1369],\n",
      "         [-0.0167],\n",
      "         [-0.0780],\n",
      "         [-0.0110]]])\n",
      "-\n",
      "tensor([[[46.4446],\n",
      "         [20.7298],\n",
      "         [12.0584],\n",
      "         [12.2802],\n",
      "         [16.0450],\n",
      "         [51.3411],\n",
      "         [21.0485],\n",
      "         [10.9341],\n",
      "         [11.9656],\n",
      "         [16.5442],\n",
      "         [21.6827],\n",
      "         [15.0109],\n",
      "         [13.8311],\n",
      "         [22.3359],\n",
      "         [17.9284],\n",
      "         [15.6722],\n",
      "         [20.1076],\n",
      "         [11.5512],\n",
      "         [13.0562],\n",
      "         [97.4733]]])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeMeanStd(mean=tensor([ 0.0112, -0.0979, -0.1854, -0.0261,  0.2286,  0.2173,  0.0367, -0.0019,\n",
      "           0.0108,  0.0986, -0.3425, -0.0903,  0.0697, -0.0039,  0.3391,  0.0294,\n",
      "           0.1369, -0.0167, -0.0780, -0.0110]),std=tensor([46.4446, 20.7298, 12.0584, 12.2802, 16.0450, 51.3411, 21.0485, 10.9341,\n",
      "          11.9656, 16.5442, 21.6827, 15.0109, 13.8311, 22.3359, 17.9284, 15.6722,\n",
      "          20.1076, 11.5512, 13.0562, 97.4733]),eps=1e-08)\n",
      ")\n",
      "- Before -\n",
      "Mean: tensor([[ 2.4810e+00,  1.5940e+00, -1.2850e+00, -9.6150e-01, -1.7030e+00,\n",
      "          1.8530e+00,  2.6455e+00,  1.3140e+00, -9.1850e-01, -1.4395e+00,\n",
      "         -2.8330e+00, -1.8510e+00, -2.4140e+00,  2.4800e+00, -6.9900e-01,\n",
      "         -9.9800e-01,  5.7375e+00,  1.5550e+00, -2.1350e-01, -9.8900e-01],\n",
      "        [-6.0565e+00, -1.2695e+00,  1.9050e-01,  5.2200e-01,  3.3950e-01,\n",
      "         -5.3650e+00, -9.8050e-01,  1.2450e-01,  6.6450e-01,  6.1500e-02,\n",
      "          8.9300e-01,  1.0860e+00,  6.1200e-01,  9.0000e-03,  4.7550e-01,\n",
      "          1.2680e+00, -2.8075e+00, -5.1500e-01, -6.9650e-01,  2.3635e+00],\n",
      "        [-6.9725e+00, -4.2305e+00, -4.1600e-01,  6.6950e-01, -1.7550e-01,\n",
      "         -8.8935e+00, -3.0155e+00,  2.0140e+00, -6.7500e-01, -3.1250e-01,\n",
      "         -1.0980e+00,  2.8450e-01, -3.2700e-01,  1.1475e+00,  2.0680e+00,\n",
      "         -6.0300e-01,  2.6850e+00,  1.1590e+00,  8.4450e-01,  4.2200e-01],\n",
      "        [ 5.8005e+00,  1.6620e+00, -1.3925e+00,  1.7080e+00, -6.5000e-01,\n",
      "         -1.9416e+01, -9.9550e-01,  1.2300e+00, -1.3555e+00, -4.0950e-01,\n",
      "         -1.9180e+00, -1.7280e+00, -1.4280e+00,  1.6890e+00, -1.2415e+00,\n",
      "         -1.3270e+00, -5.9750e-01,  1.5650e-01,  6.5780e+00, -5.3400e-01]])\n",
      "\n",
      "Std: tensor([[ 55.1256,  20.0591,   7.7243,   6.5964,  10.3074,  86.3787,  15.5913,\n",
      "           7.4071,  10.5981,   9.6383,  20.0208,   7.1447,   8.6751,  20.4115,\n",
      "           9.2396,   8.7153,  21.4741,   9.6821,   8.0873, 133.5766],\n",
      "        [ 30.5510,  12.1458,   6.8588,   6.6771,   7.9484,  54.2775,  16.6620,\n",
      "           6.6604,   4.4278,   9.3046,  26.8437,   9.4447,   7.3909,  23.4539,\n",
      "           6.5776,   7.7855,  15.1967,   4.7321,   8.3636, 154.7437],\n",
      "        [ 29.7630,  11.2430,   5.4573,  10.2156,   8.3569,  34.2854,  13.6965,\n",
      "           4.7937,   6.0701,   8.1020,  13.1287,   7.9214,   6.6694,  16.5324,\n",
      "           7.7266,   6.7218,  20.3011,  11.4296,  22.6102,  92.0681],\n",
      "        [ 30.5102,   8.7159,   6.1124,  18.5401,   6.2753,  49.9991,  15.5142,\n",
      "          16.1556,   7.0416,   5.8991,  11.3008,   8.5493,   8.5584,  18.4731,\n",
      "           8.8354,   7.6674,  15.8729,  20.8223,  24.6530,  93.2371]])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "Mean: tensor([[ 0.0532,  0.0816, -0.0912, -0.0762, -0.1204,  0.0319,  0.1239,  0.1203,\n",
      "         -0.0777, -0.0930, -0.1149, -0.1173, -0.1796,  0.1112, -0.0579, -0.0656,\n",
      "          0.2785,  0.1361, -0.0104, -0.0100],\n",
      "        [-0.1306, -0.0565,  0.0312,  0.0446,  0.0069, -0.1087, -0.0483,  0.0116,\n",
      "          0.0546, -0.0022,  0.0570,  0.0784,  0.0392,  0.0006,  0.0076,  0.0790,\n",
      "         -0.1464, -0.0431, -0.0474,  0.0244],\n",
      "        [-0.1504, -0.1994, -0.0191,  0.0566, -0.0252, -0.1775, -0.1450,  0.1844,\n",
      "         -0.0573, -0.0248, -0.0348,  0.0250, -0.0287,  0.0515,  0.0964, -0.0404,\n",
      "          0.1267,  0.1018,  0.0707,  0.0044],\n",
      "        [ 0.1246,  0.0849, -0.1001,  0.1412, -0.0548, -0.3824, -0.0490,  0.1127,\n",
      "         -0.1142, -0.0307, -0.0727, -0.1091, -0.1083,  0.0758, -0.0882, -0.0865,\n",
      "         -0.0365,  0.0150,  0.5098, -0.0054]], device='cuda:0')\n",
      "\n",
      "Std: tensor([[1.1869, 0.9676, 0.6406, 0.5372, 0.6424, 1.6824, 0.7407, 0.6774, 0.8857,\n",
      "         0.5826, 0.9234, 0.4760, 0.6272, 0.9138, 0.5154, 0.5561, 1.0680, 0.8382,\n",
      "         0.6194, 1.3704],\n",
      "        [0.6578, 0.5859, 0.5688, 0.5437, 0.4954, 1.0572, 0.7916, 0.6091, 0.3700,\n",
      "         0.5624, 1.2380, 0.6292, 0.5344, 1.0501, 0.3669, 0.4968, 0.7558, 0.4097,\n",
      "         0.6406, 1.5875],\n",
      "        [0.6408, 0.5424, 0.4526, 0.8319, 0.5208, 0.6678, 0.6507, 0.4384, 0.5073,\n",
      "         0.4897, 0.6055, 0.5277, 0.4822, 0.7402, 0.4310, 0.4289, 1.0096, 0.9895,\n",
      "         1.7318, 0.9445],\n",
      "        [0.6569, 0.4205, 0.5069, 1.5097, 0.3911, 0.9739, 0.7371, 1.4775, 0.5885,\n",
      "         0.3566, 0.5212, 0.5695, 0.6188, 0.8271, 0.4928, 0.4892, 0.7894, 1.8026,\n",
      "         1.8882, 0.9565]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "signal_mean, signal_std = calculate_signal_statistics(train_loader, repeats=1, verbose=True)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age mean and standard deviation:\n",
      "tensor([70.6025]) tensor([6.4713])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6025]),std=tensor([6.4713]),eps=1e-08)\n",
      ")\n",
      "- Before -\n",
      "tensor([73., 73., 62., 62.])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "tensor([ 0.3705,  0.3705, -1.3293, -1.3293], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "age_mean, age_std = calculate_age_statistics(train_loader, verbose=True)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    pprint.pprint(sample_batched['age'])\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    pprint.pprint(sample_batched['age'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short time Fourier transform (STFT or spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegSpectrogram(n_fft=200, complex_mode=as_real, stft_kwargs={})\n",
      ")\n",
      "- Before -\n",
      "torch.Size([4, 20, 2000])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "torch.Size([4, 40, 101, 41])\n"
     ]
    }
   ],
   "source": [
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegSpectrogram(n_fft=200, complex_mode='as_real')\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    pprint.pprint(sample_batched['signal'].shape)\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    pprint.pprint(sample_batched['signal'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal normalization after STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegSpectrogram(n_fft=200, complex_mode=as_real, stft_kwargs={})\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegNormalizeMeanStd(mean=tensor([[-3.1690e+01, -3.7667e-01,  1.5687e-03,  ..., -8.1782e-03,\n",
      "           -8.0691e-03, -1.3191e-02],\n",
      "          [-4.7364e+00, -1.3662e-03,  9.4536e-03,  ...,  5.5986e-03,\n",
      "            2.6490e-03,  1.5448e-02],\n",
      "          [ 3.3595e-01, -7.8127e-02, -1.9920e-03,  ...,  8.7425e-03,\n",
      "            7.8993e-03, -7.4004e-03],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -3.0341e-01, -1.0968e-01,  ...,  4.6328e-04,\n",
      "            6.6100e-04, -2.7577e-09],\n",
      "          [ 0.0000e+00, -3.7279e-01, -1.8398e-01,  ...,  7.3652e-05,\n",
      "           -1.0610e-04, -2.2872e-08],\n",
      "          [ 0.0000e+00, -9.4285e-01, -8.8958e-01,  ...,  2.8520e-03,\n",
      "           -4.1753e-03,  1.4242e-07]], device='cuda:0'),std=tensor([[7.6877e+03, 1.5605e+03, 8.1076e+02,  ..., 2.9823e+01, 2.9799e+01,\n",
      "           3.0013e+01],\n",
      "          [3.2892e+03, 6.0161e+02, 3.0946e+02,  ..., 1.3446e+01, 1.3407e+01,\n",
      "           1.3788e+01],\n",
      "          [1.8601e+03, 2.9312e+02, 1.5717e+02,  ..., 8.3304e+00, 8.2801e+00,\n",
      "           8.8463e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 4.5171e+02, 2.4463e+02,  ..., 2.7905e+00, 2.8834e+00,\n",
      "           3.2255e-06],\n",
      "          [0.0000e+00, 4.9502e+02, 2.6684e+02,  ..., 2.7967e+00, 2.8836e+00,\n",
      "           3.2240e-06],\n",
      "          [0.0000e+00, 2.1218e+03, 2.0217e+03,  ..., 3.7146e+00, 4.9426e+00,\n",
      "           6.1509e-05]], device='cuda:0'),eps=1e-08)\n",
      ")\n",
      "- Before -\n",
      "Mean: tensor([[[ 4.1834e+02, -5.6177e+00, -5.1175e+00,  ...,  1.1322e+00,\n",
      "           1.1732e+00,  1.2195e+00],\n",
      "         [ 2.9993e+02, -2.6865e+00, -4.2711e+00,  ..., -5.8323e-03,\n",
      "           6.4207e-02, -2.4391e-02],\n",
      "         [-1.1563e+02, -4.9231e+00, -4.7549e-01,  ...,  1.8783e-01,\n",
      "           9.1102e-02,  1.1951e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -5.1617e+00, -2.4599e+00,  ...,  3.3642e-03,\n",
      "           2.9189e-02,  3.7724e-07],\n",
      "         [ 0.0000e+00,  2.1139e+01,  8.5937e+00,  ..., -4.4309e-02,\n",
      "          -7.0422e-02, -2.9303e-07],\n",
      "         [ 0.0000e+00, -8.7713e+01, -8.4681e+01,  ..., -2.5409e-02,\n",
      "          -3.5744e-01, -1.6286e-05]],\n",
      "\n",
      "        [[-1.0299e+03, -1.3163e+02,  5.6484e+01,  ..., -2.5871e+00,\n",
      "          -2.6101e+00, -2.8293e+00],\n",
      "         [-1.1434e+02, -2.9645e+01,  1.0953e+01,  ...,  1.3337e-01,\n",
      "           2.3227e-01, -1.4634e-01],\n",
      "         [ 2.8341e+01,  4.4571e+00, -5.8166e-01,  ...,  5.5080e-01,\n",
      "           5.4208e-01, -2.4390e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -3.1877e+00,  2.1361e+00,  ...,  1.0781e-01,\n",
      "           2.8100e-01, -3.8110e-07],\n",
      "         [ 0.0000e+00, -1.1354e+01, -5.2297e+00,  ..., -4.0601e-02,\n",
      "          -1.1243e-01, -1.6722e-07],\n",
      "         [ 0.0000e+00,  8.3858e+01,  7.0543e+01,  ..., -8.5806e-02,\n",
      "          -4.7755e-01, -4.3622e-06]],\n",
      "\n",
      "        [[-1.1345e+03,  3.4566e+01, -4.8710e+00,  ..., -6.9863e-01,\n",
      "          -6.2626e-01,  8.0488e-01],\n",
      "         [ 2.8715e+02,  1.4955e+01,  2.9685e+00,  ..., -4.1668e-01,\n",
      "          -4.2123e-01, -1.5854e+00],\n",
      "         [ 1.6749e+02,  7.3142e+00,  2.1272e+00,  ...,  2.3299e-01,\n",
      "           1.6338e-01, -1.7073e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  2.5924e+01,  1.1078e+01,  ...,  9.4525e-02,\n",
      "           3.9768e-02, -1.2838e-06],\n",
      "         [ 0.0000e+00,  2.3105e+01,  8.1563e+00,  ..., -4.5644e-02,\n",
      "          -1.1265e-01, -1.2182e-06],\n",
      "         [ 0.0000e+00,  3.6280e+00,  1.7528e+01,  ...,  1.4700e-02,\n",
      "          -4.8575e-02,  6.3698e-06]],\n",
      "\n",
      "        [[ 2.0966e+02,  1.7043e+01,  2.2984e+01,  ..., -1.6677e+00,\n",
      "          -1.6746e+00, -3.9024e+00],\n",
      "         [ 1.7600e+02,  9.8043e+00,  4.3955e+00,  ..., -7.7050e-01,\n",
      "          -7.5025e-01, -1.0732e+00],\n",
      "         [ 8.7780e+01,  3.4444e+00, -5.7999e+00,  ..., -4.6823e-01,\n",
      "          -5.5834e-01, -2.6585e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -2.8743e+01, -1.5851e+01,  ..., -2.8690e-02,\n",
      "          -1.9266e-01, -3.1892e-06],\n",
      "         [ 0.0000e+00, -6.6779e+00, -5.1486e+00,  ...,  3.8540e-02,\n",
      "          -5.5023e-03, -3.5973e-06],\n",
      "         [ 0.0000e+00, -1.1611e+02, -3.2421e+01,  ...,  8.4754e-02,\n",
      "          -8.7117e-02,  6.3954e-06]]], device='cuda:0')\n",
      "\n",
      "Std: tensor([[[5.4262e+03, 1.0211e+03, 2.3535e+02,  ..., 2.1677e+01,\n",
      "          2.1839e+01, 2.2615e+01],\n",
      "         [1.2651e+03, 2.6649e+02, 1.1879e+02,  ..., 5.4835e+00,\n",
      "          5.0718e+00, 6.5593e+00],\n",
      "         [8.9781e+02, 1.5444e+02, 6.9752e+01,  ..., 4.3947e+00,\n",
      "          4.1779e+00, 6.6001e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 3.2458e+02, 1.8014e+02,  ..., 2.2883e+00,\n",
      "          3.2091e+00, 1.6929e-06],\n",
      "         [0.0000e+00, 1.5077e+02, 1.0595e+02,  ..., 3.5867e+00,\n",
      "          3.7136e+00, 1.6187e-06],\n",
      "         [0.0000e+00, 2.1070e+03, 4.4909e+03,  ..., 3.9437e+00,\n",
      "          3.1422e+00, 4.1377e-05]],\n",
      "\n",
      "        [[3.2303e+03, 2.3350e+03, 1.4691e+03,  ..., 2.3836e+01,\n",
      "          2.4010e+01, 2.4140e+01],\n",
      "         [9.9893e+02, 5.6157e+02, 3.1302e+02,  ..., 6.1331e+00,\n",
      "          5.7933e+00, 6.0314e+00],\n",
      "         [5.8654e+02, 1.7469e+02, 1.2669e+02,  ..., 4.7075e+00,\n",
      "          3.9917e+00, 6.8449e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 3.1552e+02, 1.3936e+02,  ..., 2.1197e+00,\n",
      "          3.6060e+00, 1.4949e-06],\n",
      "         [0.0000e+00, 4.4403e+02, 2.0426e+02,  ..., 2.5523e+00,\n",
      "          3.0055e+00, 1.8549e-06],\n",
      "         [0.0000e+00, 2.0393e+03, 4.0502e+03,  ..., 2.9130e+00,\n",
      "          3.9298e+00, 4.2037e-05]],\n",
      "\n",
      "        [[1.3121e+04, 2.2704e+03, 1.5595e+03,  ..., 4.7400e+01,\n",
      "          4.7224e+01, 4.7860e+01],\n",
      "         [1.8488e+03, 6.0620e+02, 2.7756e+02,  ..., 9.8604e+00,\n",
      "          9.9814e+00, 1.0213e+01],\n",
      "         [7.0089e+02, 2.9587e+02, 1.8596e+02,  ..., 4.3198e+00,\n",
      "          5.1634e+00, 4.4040e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 4.3336e+02, 3.0283e+02,  ..., 2.2115e+00,\n",
      "          2.2653e+00, 5.2295e-06],\n",
      "         [0.0000e+00, 4.2128e+02, 3.0894e+02,  ..., 1.7516e+00,\n",
      "          2.5601e+00, 2.8935e-06],\n",
      "         [0.0000e+00, 3.1310e+03, 5.0956e+03,  ..., 4.4936e+00,\n",
      "          4.2074e+00, 5.8420e-05]],\n",
      "\n",
      "        [[5.5858e+03, 1.3441e+03, 1.1407e+03,  ..., 2.6549e+01,\n",
      "          2.6764e+01, 2.4870e+01],\n",
      "         [1.8267e+03, 4.7445e+02, 3.7268e+02,  ..., 1.1483e+01,\n",
      "          1.1568e+01, 1.0226e+01],\n",
      "         [3.0057e+03, 3.5524e+02, 1.6666e+02,  ..., 1.0246e+01,\n",
      "          1.0312e+01, 8.5896e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 2.4123e+02, 1.6386e+02,  ..., 2.4662e+00,\n",
      "          3.0649e+00, 4.7012e-06],\n",
      "         [0.0000e+00, 2.7395e+02, 1.2400e+02,  ..., 2.0541e+00,\n",
      "          4.1164e+00, 4.0525e-06],\n",
      "         [0.0000e+00, 2.4437e+03, 4.8594e+03,  ..., 3.1008e+00,\n",
      "          3.1952e+00, 4.7841e-05]]], device='cuda:0')\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "Mean: tensor([[[ 5.8539e-02, -3.3585e-03, -6.3139e-03,  ...,  3.8237e-02,\n",
      "           3.9642e-02,  4.1072e-02],\n",
      "         [ 9.2624e-02, -4.4631e-03, -1.3832e-02,  ..., -8.5012e-04,\n",
      "           4.5913e-03, -2.8893e-03],\n",
      "         [-6.2345e-02, -1.6529e-02, -3.0126e-03,  ...,  2.1498e-02,\n",
      "           1.0049e-02,  1.3594e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -1.0755e-02, -9.6071e-03,  ...,  1.0396e-03,\n",
      "           9.8941e-03,  1.1744e-01],\n",
      "         [ 0.0000e+00,  4.3455e-02,  3.2895e-02,  ..., -1.5870e-02,\n",
      "          -2.4385e-02, -8.3539e-02],\n",
      "         [ 0.0000e+00, -4.0895e-02, -4.1447e-02,  ..., -7.6081e-03,\n",
      "          -7.1473e-02, -2.6705e-01]],\n",
      "\n",
      "        [[-1.2985e-01, -8.4109e-02,  6.9666e-02,  ..., -8.6473e-02,\n",
      "          -8.7319e-02, -9.3827e-02],\n",
      "         [-3.3322e-02, -4.9274e-02,  3.5362e-02,  ...,  9.5026e-03,\n",
      "           1.7126e-02, -1.1734e-02],\n",
      "         [ 1.5056e-02,  1.5472e-02, -3.6881e-03,  ...,  6.5069e-02,\n",
      "           6.4514e-02, -2.7488e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -6.3852e-03,  9.1802e-03,  ...,  3.8469e-02,\n",
      "           9.7225e-02, -1.1693e-01],\n",
      "         [ 0.0000e+00, -2.2183e-02, -1.8909e-02,  ..., -1.4544e-02,\n",
      "          -3.8952e-02, -4.4636e-02],\n",
      "         [ 0.0000e+00,  3.9967e-02,  3.5333e-02,  ..., -2.3867e-02,\n",
      "          -9.5773e-02, -7.3223e-02]],\n",
      "\n",
      "        [[-1.4345e-01,  2.2391e-02, -6.0098e-03,  ..., -2.3151e-02,\n",
      "          -2.0746e-02,  2.7257e-02],\n",
      "         [ 8.8738e-02,  2.4860e-02,  9.5619e-03,  ..., -3.1406e-02,\n",
      "          -3.1615e-02, -1.1610e-01],\n",
      "         [ 8.9860e-02,  2.5219e-02,  1.3547e-02,  ...,  2.6919e-02,\n",
      "           1.8778e-02, -1.8463e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  5.8063e-02,  4.5731e-02,  ...,  3.3708e-02,\n",
      "           1.3563e-02, -3.9593e-01],\n",
      "         [ 0.0000e+00,  4.7427e-02,  3.1256e-02,  ..., -1.6347e-02,\n",
      "          -3.9029e-02, -3.6963e-01],\n",
      "         [ 0.0000e+00,  2.1542e-03,  9.1100e-03,  ...,  3.1897e-03,\n",
      "          -8.9831e-03,  1.0123e-01]],\n",
      "\n",
      "        [[ 3.1394e-02,  1.1162e-02,  2.8347e-02,  ..., -5.5644e-02,\n",
      "          -5.5926e-02, -1.2958e-01],\n",
      "         [ 5.4948e-02,  1.6299e-02,  1.4173e-02,  ..., -5.7719e-02,\n",
      "          -5.6155e-02, -7.8953e-02],\n",
      "         [ 4.7010e-02,  1.2017e-02, -3.6889e-02,  ..., -5.7257e-02,\n",
      "          -6.8385e-02, -2.9969e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -6.2959e-02, -6.4347e-02,  ..., -1.0447e-02,\n",
      "          -6.7049e-02, -9.8483e-01],\n",
      "         [ 0.0000e+00, -1.2737e-02, -1.8605e-02,  ...,  1.3754e-02,\n",
      "          -1.8714e-03, -1.1053e+00],\n",
      "         [ 0.0000e+00, -5.4277e-02, -1.5597e-02,  ...,  2.2049e-02,\n",
      "          -1.6781e-02,  1.0164e-01]]], device='cuda:0')\n",
      "\n",
      "Std: tensor([[[0.7058, 0.6543, 0.2903,  ..., 0.7269, 0.7329, 0.7535],\n",
      "         [0.3846, 0.4430, 0.3838,  ..., 0.4078, 0.3783, 0.4757],\n",
      "         [0.4827, 0.5269, 0.4438,  ..., 0.5275, 0.5046, 0.7461],\n",
      "         ...,\n",
      "         [0.0000, 0.7186, 0.7364,  ..., 0.8200, 1.1130, 0.5232],\n",
      "         [0.0000, 0.3046, 0.3971,  ..., 1.2825, 1.2878, 0.5005],\n",
      "         [0.0000, 0.9930, 2.2214,  ..., 1.0617, 0.6357, 0.6726]],\n",
      "\n",
      "        [[0.4202, 1.4963, 1.8120,  ..., 0.7992, 0.8057, 0.8043],\n",
      "         [0.3037, 0.9334, 1.0115,  ..., 0.4561, 0.4321, 0.4374],\n",
      "         [0.3153, 0.5960, 0.8061,  ..., 0.5651, 0.4821, 0.7738],\n",
      "         ...,\n",
      "         [0.0000, 0.6985, 0.5697,  ..., 0.7596, 1.2506, 0.4620],\n",
      "         [0.0000, 0.8970, 0.7655,  ..., 0.9126, 1.0423, 0.5736],\n",
      "         [0.0000, 0.9611, 2.0034,  ..., 0.7842, 0.7951, 0.6833]],\n",
      "\n",
      "        [[1.7067, 1.4549, 1.9235,  ..., 1.5893, 1.5848, 1.5946],\n",
      "         [0.5621, 1.0076, 0.8969,  ..., 0.7333, 0.7445, 0.7407],\n",
      "         [0.3768, 1.0094, 1.1832,  ..., 0.5186, 0.6236, 0.4978],\n",
      "         ...,\n",
      "         [0.0000, 0.9594, 1.2379,  ..., 0.7925, 0.7856, 1.6163],\n",
      "         [0.0000, 0.8510, 1.1578,  ..., 0.6263, 0.8878, 0.8947],\n",
      "         [0.0000, 1.4756, 2.5205,  ..., 1.2097, 0.8512, 0.9496]],\n",
      "\n",
      "        [[0.7266, 0.8613, 1.4070,  ..., 0.8902, 0.8982, 0.8286],\n",
      "         [0.5554, 0.7886, 1.2043,  ..., 0.8540, 0.8628, 0.7416],\n",
      "         [1.6158, 1.2119, 1.0604,  ..., 1.2299, 1.2454, 0.9710],\n",
      "         ...,\n",
      "         [0.0000, 0.5340, 0.6698,  ..., 0.8838, 1.0629, 1.4530],\n",
      "         [0.0000, 0.5534, 0.4647,  ..., 0.7345, 1.4275, 1.2531],\n",
      "         [0.0000, 1.1517, 2.4037,  ..., 0.8348, 0.6465, 0.7777]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegSpectrogram(n_fft=200, complex_mode='as_real')\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "\n",
    "signal_2d_mean, signal_2d_std = calculate_signal_statistics(train_loader, preprocess_train)\n",
    "\n",
    "preprocess_train2 = transforms.Compose([\n",
    "    EegNormalizeMeanStd(mean=signal_2d_mean, std=signal_2d_std)\n",
    "])\n",
    "preprocess_train2 = torch.nn.Sequential(*preprocess_train2.transforms).to(device)\n",
    "\n",
    "pprint.pprint(preprocess_train)\n",
    "pprint.pprint(preprocess_train2)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    preprocess_train(sample_batched)   \n",
    "    \n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "    \n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    print('- After -')\n",
    "    preprocess_train2(sample_batched)\n",
    "    \n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Speed check without STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_length = 200 * 10\n",
    "multiple = 4\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `EDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=120000, multiple=4, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6025]),std=tensor([6.4713]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([ 0.0112, -0.0979, -0.1854, -0.0261,  0.2286,  0.2173,  0.0367, -0.0019,\n",
      "           0.0108,  0.0986, -0.3425, -0.0903,  0.0697, -0.0039,  0.3391,  0.0294,\n",
      "           0.1369, -0.0167, -0.0780, -0.0110]),std=tensor([46.4446, 20.7298, 12.0584, 12.2802, 16.0450, 51.3411, 21.0485, 10.9341,\n",
      "          11.9656, 16.5442, 21.6827, 15.0109, 13.8311, 22.3359, 17.9284, 15.6722,\n",
      "          20.1076, 11.5512, 13.0562, 97.4733]),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 26min 55s\n",
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Feather`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=120000, multiple=4, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6025]),std=tensor([6.4713]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([ 0.0112, -0.0979, -0.1854, -0.0261,  0.2286,  0.2173,  0.0367, -0.0019,\n",
      "           0.0108,  0.0986, -0.3425, -0.0903,  0.0697, -0.0039,  0.3391,  0.0294,\n",
      "           0.1369, -0.0167, -0.0780, -0.0110]),std=tensor([46.4446, 20.7298, 12.0584, 12.2802, 16.0450, 51.3411, 21.0485, 10.9341,\n",
      "          11.9656, 16.5442, 21.6827, 15.0109, 13.8311, 22.3359, 17.9284, 15.6722,\n",
      "          20.1076, 11.5512, 13.0562, 97.4733]),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 1min 3s\n",
      "Wall time: 4.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `memmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=120000, multiple=4, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6025]),std=tensor([6.4713]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([ 0.0112, -0.0979, -0.1854, -0.0261,  0.2286,  0.2173,  0.0367, -0.0019,\n",
      "           0.0108,  0.0986, -0.3425, -0.0903,  0.0697, -0.0039,  0.3391,  0.0294,\n",
      "           0.1369, -0.0167, -0.0780, -0.0110]),std=tensor([46.4446, 20.7298, 12.0584, 12.2802, 16.0450, 51.3411, 21.0485, 10.9341,\n",
      "          11.9656, 16.5442, 21.6827, 15.0109, 13.8311, 22.3359, 17.9284, 15.6722,\n",
      "          20.1076, 11.5512, 13.0562, 97.4733]),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 18 s\n",
      "Wall time: 1.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    " \n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `memmap` (Drop  Crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegRandomCrop(crop_length=2000, length_limit=120000, multiple=4, latency=2000, return_timing=False)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6025]),std=tensor([6.4713]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([ 0.0112, -0.0979, -0.1854, -0.0261,  0.2286,  0.2173,  0.0367, -0.0019,\n",
      "           0.0108,  0.0986, -0.3425, -0.0903,  0.0697, -0.0039,  0.3391,  0.0294,\n",
      "           0.1369, -0.0167, -0.0780, -0.0110]),std=tensor([46.4446, 20.7298, 12.0584, 12.2802, 16.0450, 51.3411, 21.0485, 10.9341,\n",
      "          11.9656, 16.5442, 21.6827, 15.0109, 13.8311, 22.3359, 17.9284, 15.6722,\n",
      "          20.1076, 11.5512, 13.0562, 97.4733]),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 1min 21s\n",
      "Wall time: 6.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    " \n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Speed check with STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_length = 200 * 10\n",
    "multiple = 2\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `EDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=120000, multiple=2, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6025]),std=tensor([6.4713]),eps=1e-08)\n",
      "  (2): EegSpectrogram(n_fft=200, complex_mode=as_real, stft_kwargs={})\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([[-3.1690e+01, -3.7667e-01,  1.5687e-03,  ..., -8.1782e-03,\n",
      "           -8.0691e-03, -1.3191e-02],\n",
      "          [-4.7364e+00, -1.3662e-03,  9.4536e-03,  ...,  5.5986e-03,\n",
      "            2.6490e-03,  1.5448e-02],\n",
      "          [ 3.3595e-01, -7.8127e-02, -1.9920e-03,  ...,  8.7425e-03,\n",
      "            7.8993e-03, -7.4004e-03],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -3.0341e-01, -1.0968e-01,  ...,  4.6328e-04,\n",
      "            6.6100e-04, -2.7577e-09],\n",
      "          [ 0.0000e+00, -3.7279e-01, -1.8398e-01,  ...,  7.3652e-05,\n",
      "           -1.0610e-04, -2.2872e-08],\n",
      "          [ 0.0000e+00, -9.4285e-01, -8.8958e-01,  ...,  2.8520e-03,\n",
      "           -4.1753e-03,  1.4242e-07]], device='cuda:0'),std=tensor([[7.6877e+03, 1.5605e+03, 8.1076e+02,  ..., 2.9823e+01, 2.9799e+01,\n",
      "           3.0013e+01],\n",
      "          [3.2892e+03, 6.0161e+02, 3.0946e+02,  ..., 1.3446e+01, 1.3407e+01,\n",
      "           1.3788e+01],\n",
      "          [1.8601e+03, 2.9312e+02, 1.5717e+02,  ..., 8.3304e+00, 8.2801e+00,\n",
      "           8.8463e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 4.5171e+02, 2.4463e+02,  ..., 2.7905e+00, 2.8834e+00,\n",
      "           3.2255e-06],\n",
      "          [0.0000e+00, 4.9502e+02, 2.6684e+02,  ..., 2.7967e+00, 2.8836e+00,\n",
      "           3.2240e-06],\n",
      "          [0.0000e+00, 2.1218e+03, 2.0217e+03,  ..., 3.7146e+00, 4.9426e+00,\n",
      "           6.1509e-05]], device='cuda:0'),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 26min 48s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf',\n",
    "                                                                                  transform=transform)\n",
    " \n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegSpectrogram(n_fft=200, complex_mode='as_real'),\n",
    "    EegNormalizeMeanStd(mean=signal_2d_mean, std=signal_2d_std),\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Feather`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=120000, multiple=2, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6025]),std=tensor([6.4713]),eps=1e-08)\n",
      "  (2): EegSpectrogram(n_fft=200, complex_mode=as_real, stft_kwargs={})\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([[-3.1690e+01, -3.7667e-01,  1.5687e-03,  ..., -8.1782e-03,\n",
      "           -8.0691e-03, -1.3191e-02],\n",
      "          [-4.7364e+00, -1.3662e-03,  9.4536e-03,  ...,  5.5986e-03,\n",
      "            2.6490e-03,  1.5448e-02],\n",
      "          [ 3.3595e-01, -7.8127e-02, -1.9920e-03,  ...,  8.7425e-03,\n",
      "            7.8993e-03, -7.4004e-03],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -3.0341e-01, -1.0968e-01,  ...,  4.6328e-04,\n",
      "            6.6100e-04, -2.7577e-09],\n",
      "          [ 0.0000e+00, -3.7279e-01, -1.8398e-01,  ...,  7.3652e-05,\n",
      "           -1.0610e-04, -2.2872e-08],\n",
      "          [ 0.0000e+00, -9.4285e-01, -8.8958e-01,  ...,  2.8520e-03,\n",
      "           -4.1753e-03,  1.4242e-07]], device='cuda:0'),std=tensor([[7.6877e+03, 1.5605e+03, 8.1076e+02,  ..., 2.9823e+01, 2.9799e+01,\n",
      "           3.0013e+01],\n",
      "          [3.2892e+03, 6.0161e+02, 3.0946e+02,  ..., 1.3446e+01, 1.3407e+01,\n",
      "           1.3788e+01],\n",
      "          [1.8601e+03, 2.9312e+02, 1.5717e+02,  ..., 8.3304e+00, 8.2801e+00,\n",
      "           8.8463e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 4.5171e+02, 2.4463e+02,  ..., 2.7905e+00, 2.8834e+00,\n",
      "           3.2255e-06],\n",
      "          [0.0000e+00, 4.9502e+02, 2.6684e+02,  ..., 2.7967e+00, 2.8836e+00,\n",
      "           3.2240e-06],\n",
      "          [0.0000e+00, 2.1218e+03, 2.0217e+03,  ..., 3.7146e+00, 4.9426e+00,\n",
      "           6.1509e-05]], device='cuda:0'),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 1min 4s\n",
      "Wall time: 3.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegSpectrogram(n_fft=200, complex_mode='as_real'),\n",
    "    EegNormalizeMeanStd(mean=signal_2d_mean, std=signal_2d_std),\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `memmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=120000, multiple=2, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6025]),std=tensor([6.4713]),eps=1e-08)\n",
      "  (2): EegSpectrogram(n_fft=200, complex_mode=as_real, stft_kwargs={})\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([[-3.1690e+01, -3.7667e-01,  1.5687e-03,  ..., -8.1782e-03,\n",
      "           -8.0691e-03, -1.3191e-02],\n",
      "          [-4.7364e+00, -1.3662e-03,  9.4536e-03,  ...,  5.5986e-03,\n",
      "            2.6490e-03,  1.5448e-02],\n",
      "          [ 3.3595e-01, -7.8127e-02, -1.9920e-03,  ...,  8.7425e-03,\n",
      "            7.8993e-03, -7.4004e-03],\n",
      "          ...,\n",
      "          [ 0.0000e+00, -3.0341e-01, -1.0968e-01,  ...,  4.6328e-04,\n",
      "            6.6100e-04, -2.7577e-09],\n",
      "          [ 0.0000e+00, -3.7279e-01, -1.8398e-01,  ...,  7.3652e-05,\n",
      "           -1.0610e-04, -2.2872e-08],\n",
      "          [ 0.0000e+00, -9.4285e-01, -8.8958e-01,  ...,  2.8520e-03,\n",
      "           -4.1753e-03,  1.4242e-07]], device='cuda:0'),std=tensor([[7.6877e+03, 1.5605e+03, 8.1076e+02,  ..., 2.9823e+01, 2.9799e+01,\n",
      "           3.0013e+01],\n",
      "          [3.2892e+03, 6.0161e+02, 3.0946e+02,  ..., 1.3446e+01, 1.3407e+01,\n",
      "           1.3788e+01],\n",
      "          [1.8601e+03, 2.9312e+02, 1.5717e+02,  ..., 8.3304e+00, 8.2801e+00,\n",
      "           8.8463e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 4.5171e+02, 2.4463e+02,  ..., 2.7905e+00, 2.8834e+00,\n",
      "           3.2255e-06],\n",
      "          [0.0000e+00, 4.9502e+02, 2.6684e+02,  ..., 2.7967e+00, 2.8836e+00,\n",
      "           3.2240e-06],\n",
      "          [0.0000e+00, 2.1218e+03, 2.0217e+03,  ..., 3.7146e+00, 4.9426e+00,\n",
      "           6.1509e-05]], device='cuda:0'),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 13.1 s\n",
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegSpectrogram(n_fft=200, complex_mode='as_real'),\n",
    "    EegNormalizeMeanStd(mean=signal_2d_mean, std=signal_2d_std),\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test on longer sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=12000, length_limit=120000, multiple=2, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeMeanStd(mean=tensor([ 0.0112, -0.0979, -0.1854, -0.0261,  0.2286,  0.2173,  0.0367, -0.0019,\n",
      "           0.0108,  0.0986, -0.3425, -0.0903,  0.0697, -0.0039,  0.3391,  0.0294,\n",
      "           0.1369, -0.0167, -0.0780, -0.0110]),std=tensor([46.4446, 20.7298, 12.0584, 12.2802, 16.0450, 51.3411, 21.0485, 10.9341,\n",
      "          11.9656, 16.5442, 21.6827, 15.0109, 13.8311, 22.3359, 17.9284, 15.6722,\n",
      "          20.1076, 11.5512, 13.0562, 97.4733]),eps=1e-08)\n",
      "  (2): EegNormalizeAge(mean=tensor([70.6025]),std=tensor([6.4713]),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 10.8 s\n",
      "Wall time: 973 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "longer_transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*10*6,     # crop: 1m\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=2, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(longer_transform)\n",
    "\n",
    "config_data, longer_test_dataset = load_caueeg_task_split(dataset_path=data_path, \n",
    "                                                          task='task2', \n",
    "                                                          split='test',\n",
    "                                                          load_event=False,\n",
    "                                                          file_format='feather', \n",
    "                                                          transform=longer_transform)\n",
    "\n",
    "longer_test_loader = DataLoader(longer_test_dataset,\n",
    "                                batch_size=32,\n",
    "                                shuffle=True,\n",
    "                                drop_last=False,\n",
    "                                num_workers=num_workers,\n",
    "                                pin_memory=pin_memory,\n",
    "                                collate_fn=eeg_collate_fn)\n",
    " \n",
    "preprocess_test = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std),\n",
    "    EegNormalizeAge(mean=age_mean, std=age_std),\n",
    "])\n",
    "preprocess_test = torch.nn.Sequential(*preprocess_test.transforms).to(device)\n",
    "pprint.pprint(preprocess_test)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_test(sample_batched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
