{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Networks\n",
    "\n",
    "- Three-way SoftMax or Multi-BCE classifier of normal, non-vascular MCI, and non-vascular dementia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pprint\n",
    "import wandb\n",
    "\n",
    "# custom package\n",
    "from models import *\n",
    "from utils.eeg_dataset import *\n",
    "from utils.train_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook name\n",
    "def get_notebook_name():\n",
    "    import ipynbname\n",
    "    return ipynbname.name()\n",
    "nb_fname = get_notebook_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.9.0\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Set the default configuration for building datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_data = {}\n",
    "cfg_data['device'] = device\n",
    "cfg_data['dataset'] = 'CAUHS'\n",
    "cfg_data['data_path'] = r'dataset/02_Curated_Data/'\n",
    "cfg_data['meta_path'] = os.path.join(cfg_data['data_path'], 'metadata_debug.json')\n",
    "cfg_data['target_task'] = 'Normal, MCI, Dementia' # 'Norml, MCI, Dementia'\n",
    "cfg_data['vascular'] = 'X'\n",
    "cfg_data['segment'] = 'no' # 'train', 'all', 'no'\n",
    "cfg_data['seed'] = 0\n",
    "cfg_data['crop_length'] = 200 * 10 # 10 seconds\n",
    "cfg_data['longer_crop_length'] = 200 * 10 * 10 # 100 seconds\n",
    "cfg_data['input_norm'] = 'dataset' # 'datatset', 'datapoint', 'no'\n",
    "cfg_data['EKG'] = 'O'\n",
    "cfg_data['photic'] = 'X'\n",
    "cfg_data['awgn'] = 5e-2\n",
    "cfg_data['awgn_age'] = 5e-2\n",
    "cfg_data['minibatch'] = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_label_to_type: ['Normal', 'Non-vascular MCI', 'Non-vascular dementia']\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- There are 463 data belonging to Normal\n",
      "- There are 347 data belonging to Non-vascular MCI\n",
      "- There are 229 data belonging to Non-vascular dementia\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Train data label distribution\t: [370, 278, 183] 831\n",
      "Train data label distribution\t: [46, 35, 23] 104\n",
      "Train data label distribution\t: [47, 34, 23] 104\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "composed_train: Compose(\n",
      "    <utils.eeg_dataset.EEGRandomCrop object at 0x0000017BC5947280>\n",
      "    <utils.eeg_dataset.EEGNormalizeMeanStd object at 0x0000017BC59B6040>\n",
      "    <utils.eeg_dataset.EEGNormalizeAge object at 0x0000017BD6B5B640>\n",
      "    <utils.eeg_dataset.EEGDropPhoticChannel object at 0x0000017BD77F4070>\n",
      "    <utils.eeg_dataset.EEGAddGaussianNoise object at 0x0000017BD77F4D00>\n",
      "    <utils.eeg_dataset.EEGAddGaussianNoiseAge object at 0x0000017BD77F4100>\n",
      "    <utils.eeg_dataset.EEGToTensor object at 0x0000017BD77F4640>\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "composed_test: Compose(\n",
      "    <utils.eeg_dataset.EEGRandomCrop object at 0x0000017BCEF1D430>\n",
      "    <utils.eeg_dataset.EEGNormalizeMeanStd object at 0x0000017BD6B5BD00>\n",
      "    <utils.eeg_dataset.EEGNormalizeAge object at 0x0000017BD77F49D0>\n",
      "    <utils.eeg_dataset.EEGDropPhoticChannel object at 0x0000017BD77F4D90>\n",
      "    <utils.eeg_dataset.EEGToTensor object at 0x0000017BD77F4D30>\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "longer_composed_test: Compose(\n",
      "    <utils.eeg_dataset.EEGRandomCrop object at 0x0000017BD77F4B50>\n",
      "    <utils.eeg_dataset.EEGNormalizeMeanStd object at 0x0000017BCAECA2B0>\n",
      "    <utils.eeg_dataset.EEGNormalizeAge object at 0x0000017BCAECAE80>\n",
      "    <utils.eeg_dataset.EEGDropPhoticChannel object at 0x0000017BCAECACA0>\n",
      "    <utils.eeg_dataset.EEGToTensor object at 0x0000017BCAECA100>\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "train_dataset[0]:\n",
      "torch.Size([20, 2000])\n",
      "{'signal': tensor([[ 0.9947,  0.7649,  1.0146,  ..., -0.0916, -0.0544,  0.0518],\n",
      "        [ 1.2301,  1.2500,  1.3435,  ..., -1.2444, -1.3342, -1.2826],\n",
      "        [ 0.7723,  0.9515,  0.9462,  ...,  0.9009,  0.9841,  0.9491],\n",
      "        ...,\n",
      "        [ 0.0610,  0.2702,  0.0926,  ...,  0.9182,  1.0686,  1.2152],\n",
      "        [-0.7882, -0.6840, -0.7352,  ...,  0.8339,  0.9674,  0.9365],\n",
      "        [-0.5602, -0.4085, -0.4109,  ..., -0.2105, -0.2726, -0.1966]]), 'age': tensor(-1.2251), 'class_label': tensor(0), 'metadata': {'serial': '01012', 'edfname': '01212635_270515', 'birth': '1956-06-01', 'record': '2015-05-27T09:37:24', 'age': 58, 'dx1': 'cb_normal', 'label': ['normal', 'cb_normal'], 'events': [[0, 'Start Recording'], [0, 'New Montage - Montage 002'], [400, 'Eyes Open'], [7918, 'Eyes Closed'], [14091, 'Eyes Open'], [18208, 'Eyes Closed'], [24256, 'Eyes Open'], [30724, 'Eyes Closed'], [36562, 'Eyes Open'], [42190, 'Eyes Closed'], [48910, 'Eyes Open'], [55126, 'Eyes Closed'], [60417, 'Eyes Open'], [66004, 'Eyes Closed'], [71968, 'Eyes Open'], [78310, 'Eyes Closed'], [84442, 'Eyes Open'], [90070, 'Eyes Closed'], [96076, 'Eyes Open'], [102082, 'Eyes Closed'], [108844, 'Eyes Open'], [113674, 'Eyes Closed'], [120000, 'Paused']], 'class_type': 'Normal', 'class_label': 0}}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "val_dataset[0]:\n",
      "torch.Size([20, 2000])\n",
      "{'signal': tensor([[ 8.2308e-02,  8.2308e-02, -5.5794e-02,  ...,  5.8868e-01,\n",
      "          6.1170e-01,  6.8075e-01],\n",
      "        [-6.4715e-01, -9.9358e-01, -9.4409e-01,  ...,  2.9315e-01,\n",
      "          2.9315e-01,  3.9213e-01],\n",
      "        [ 7.1454e-01,  7.1454e-01,  8.9262e-01,  ..., -1.7587e-01,\n",
      "          2.2117e-03,  2.2117e-03],\n",
      "        ...,\n",
      "        [ 7.0478e-01,  6.1663e-01,  6.1663e-01,  ..., -3.8256e-04,\n",
      "         -8.8528e-02, -8.8528e-02],\n",
      "        [ 4.3535e-01,  3.4664e-01,  3.4664e-01,  ..., -8.1608e-03,\n",
      "         -2.7426e-01, -3.6297e-01],\n",
      "        [-1.3811e-01, -1.7002e-01, -1.7002e-01,  ..., -4.1468e-01,\n",
      "         -4.7851e-01, -2.9767e-01]]), 'age': tensor(0.7204), 'class_label': tensor(1), 'metadata': {'serial': '00700', 'edfname': '00985401_011117', 'birth': '1940-09-09', 'record': '2017-11-01T14:20:48', 'age': 77, 'dx1': 'mci amnestic', 'label': ['mci', 'mci_amnestic'], 'events': [[0, 'Start Recording'], [0, 'New Montage - Montage 002'], [1705, 'Eyes Open'], [5402, 'Eyes Closed'], [13046, 'Eyes Open'], [17666, 'Eyes Closed'], [30308, 'Eyes Closed'], [36272, 'Eyes Open'], [41774, 'Eyes Closed'], [48958, 'Eyes Open'], [55510, 'Eyes Closed'], [61641, 'Eyes Open'], [66766, 'Eyes Closed'], [72730, 'Eyes Open'], [78988, 'Eyes Closed'], [87770, 'Eyes Open'], [90542, 'Eyes Closed'], [97096, 'Eyes Open'], [102178, 'Eyes Closed'], [110872, 'Eyes Open'], [113728, 'Eyes Closed'], [122052, 'Photic On - 3.0 Hz'], [122428, 'Eyes Open'], [123309, 'Eyes Closed'], [124068, 'Photic Off'], [126126, 'Photic On - 6.0 Hz'], [128142, 'Photic Off'], [130158, 'Photic On - 9.0 Hz'], [132216, 'Photic Off'], [132718, 'Eyes Open'], [133600, 'Eyes Closed'], [134232, 'Photic On - 12.0 Hz'], [136248, 'Photic Off'], [138306, 'Photic On - 15.0 Hz'], [140322, 'Photic Off'], [142380, 'Photic On - 18.0 Hz'], [142630, 'Eyes Open'], [143302, 'Eyes Closed'], [144396, 'Photic Off'], [146412, 'Photic On - 21.0 Hz'], [148428, 'Photic Off'], [150486, 'Photic On - 24.0 Hz'], [152502, 'Photic Off'], [152710, 'Eyes Open'], [153550, 'Eyes Closed'], [154560, 'Photic On - 27.0 Hz'], [156576, 'Photic Off'], [158592, 'Photic On - 30.0 Hz'], [160608, 'Photic Off'], [160942, 'Eyes Open'], [161698, 'Eyes Closed'], [169132, 'Eyes Open'], [170098, 'Eyes Closed'], [173600, 'Paused']], 'class_type': 'Non-vascular MCI', 'class_label': 1}}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_dataset[0]:\n",
      "torch.Size([20, 2000])\n",
      "{'signal': tensor([[ 0.5426,  0.4966,  0.4506,  ..., -0.0328,  0.0593,  0.1744],\n",
      "        [-0.1028, -0.1523, -0.2017,  ..., -0.6966, -0.5482, -0.3997],\n",
      "        [ 0.0022,  0.0913,  0.1803,  ..., -0.7992, -0.8882, -0.8882],\n",
      "        ...,\n",
      "        [-0.7055, -0.6174, -0.3530,  ..., -0.4411, -0.4411, -0.2648],\n",
      "        [-0.6291, -0.4517, -0.2743,  ..., -0.2743, -0.4517, -0.5404],\n",
      "        [-0.0849, -0.1594, -0.3509,  ...,  0.3618,  0.3938,  0.5852]]), 'age': tensor(1.0259), 'class_label': tensor(0), 'metadata': {'serial': '00299', 'edfname': '00671212_160819', 'birth': '1938-08-17', 'record': '2019-08-16T10:57:03', 'age': 80, 'dx1': 'smi', 'label': ['normal', 'smi'], 'events': [[0, 'Start Recording'], [0, 'New Montage - Montage 005'], [1773, 'Eyes Closed'], [6000, 'Cz check'], [7612, 'Eyes Open'], [12912, 'Eyes Closed'], [18078, 'Eyes Open'], [23958, 'Eyes Closed'], [29288, 'Eyes Open'], [35934, 'Eyes Closed'], [41856, 'Eyes Open'], [47862, 'Eyes Closed'], [54460, 'Eyes Open'], [59962, 'Eyes Closed'], [66178, 'Eyes Open'], [71008, 'Eyes Closed'], [73948, 'Photic On - 3.0 Hz'], [74158, 'Eyes Open'], [75166, 'Eyes Closed'], [75964, 'Photic Off'], [77980, 'Photic On - 6.0 Hz'], [78358, 'Eyes Open'], [79282, 'Eyes Closed'], [80038, 'Photic Off'], [82054, 'Photic On - 9.0 Hz'], [84070, 'Photic Off'], [86128, 'Photic On - 12.0 Hz'], [87640, 'Eyes Open'], [88144, 'Photic Off'], [88396, 'Eyes Closed'], [90202, 'Photic On - 15.0 Hz'], [92218, 'Photic Off'], [92722, 'Eyes Open'], [93772, 'Eyes Closed'], [94234, 'Photic On - 18.0 Hz'], [96250, 'Photic Off'], [98308, 'Photic On - 21.0 Hz'], [100324, 'Photic Off'], [102382, 'Photic On - 24.0 Hz'], [104398, 'Photic Off'], [106414, 'Photic On - 27.0 Hz'], [108430, 'Photic Off'], [110488, 'Photic On - 30.0 Hz'], [111580, 'Eyes Open'], [111790, 'Photic Off'], [112420, 'Eyes Closed'], [113200, 'Paused']], 'class_type': 'Normal', 'class_label': 0}}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_dataset_longer[0]:\n",
      "torch.Size([20, 20000])\n",
      "{'signal': tensor([[-5.5794e-02, -1.7088e-01, -1.7088e-01,  ...,  6.1170e-01,\n",
      "          5.6567e-01,  4.7360e-01],\n",
      "        [ 6.3958e-01,  4.9111e-01,  2.9315e-01,  ...,  1.4468e-01,\n",
      "          4.5703e-02, -3.7864e-03],\n",
      "        [-6.2107e-01, -7.1011e-01, -5.3203e-01,  ..., -2.6491e-01,\n",
      "         -3.5395e-01, -3.5395e-01],\n",
      "        ...,\n",
      "        [-4.4111e-01, -5.2925e-01, -5.2925e-01,  ..., -3.8256e-04,\n",
      "         -8.8528e-02, -8.8528e-02],\n",
      "        [-4.5167e-01, -4.5167e-01, -2.7426e-01,  ..., -7.1777e-01,\n",
      "         -6.2907e-01, -5.4037e-01],\n",
      "        [-1.1274e+00, -3.0831e-01, -1.9130e-01,  ...,  8.0739e+00,\n",
      "          6.1166e+00,  5.8826e+00]]), 'age': tensor(1.0259), 'class_label': tensor(0), 'metadata': {'serial': '00299', 'edfname': '00671212_160819', 'birth': '1938-08-17', 'record': '2019-08-16T10:57:03', 'age': 80, 'dx1': 'smi', 'label': ['normal', 'smi'], 'events': [[0, 'Start Recording'], [0, 'New Montage - Montage 005'], [1773, 'Eyes Closed'], [6000, 'Cz check'], [7612, 'Eyes Open'], [12912, 'Eyes Closed'], [18078, 'Eyes Open'], [23958, 'Eyes Closed'], [29288, 'Eyes Open'], [35934, 'Eyes Closed'], [41856, 'Eyes Open'], [47862, 'Eyes Closed'], [54460, 'Eyes Open'], [59962, 'Eyes Closed'], [66178, 'Eyes Open'], [71008, 'Eyes Closed'], [73948, 'Photic On - 3.0 Hz'], [74158, 'Eyes Open'], [75166, 'Eyes Closed'], [75964, 'Photic Off'], [77980, 'Photic On - 6.0 Hz'], [78358, 'Eyes Open'], [79282, 'Eyes Closed'], [80038, 'Photic Off'], [82054, 'Photic On - 9.0 Hz'], [84070, 'Photic Off'], [86128, 'Photic On - 12.0 Hz'], [87640, 'Eyes Open'], [88144, 'Photic Off'], [88396, 'Eyes Closed'], [90202, 'Photic On - 15.0 Hz'], [92218, 'Photic Off'], [92722, 'Eyes Open'], [93772, 'Eyes Closed'], [94234, 'Photic On - 18.0 Hz'], [96250, 'Photic Off'], [98308, 'Photic On - 21.0 Hz'], [100324, 'Photic Off'], [102382, 'Photic On - 24.0 Hz'], [104398, 'Photic Off'], [106414, 'Photic On - 27.0 Hz'], [108430, 'Photic Off'], [110488, 'Photic On - 30.0 Hz'], [111580, 'Eyes Open'], [111790, 'Photic Off'], [112420, 'Eyes Closed'], [113200, 'Paused']], 'class_type': 'Normal', 'class_label': 0}}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "0 torch.Size([32, 20, 2000]) torch.Size([32]) torch.Size([32]) 32\n",
      "1 torch.Size([32, 20, 2000]) torch.Size([32]) torch.Size([32]) 32\n",
      "2 torch.Size([32, 20, 2000]) torch.Size([32]) torch.Size([32]) 32\n",
      "3 torch.Size([32, 20, 2000]) torch.Size([32]) torch.Size([32]) 32\n",
      "4 torch.Size([32, 20, 2000]) torch.Size([32]) torch.Size([32]) 32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = build_dataset(cfg_data, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Define Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_common_model = {'in_channels': _[0].dataset[0]['signal'].shape[0], \n",
    "                    'out_dims': len(_[-1])}\n",
    "cfg_model_pool = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D Tiny CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-Tiny-CNN'\n",
    "# cfg_model['generator'] = TinyCNN1D\n",
    "# cfg_model['fc_stages'] = 1\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = 1e-3\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# # tensorboard visualization\n",
    "# # visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M7 model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-Mx'\n",
    "# cfg_model['generator'] = M7\n",
    "# cfg_model['fc_stages'] = 1\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 256\n",
    "# cfg_model['LR'] = 1e-3\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# # tensorboard visualization\n",
    "# # visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNet model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNet-2x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = 1e-3\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# # tensorboard visualization\n",
    "# # visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deeper 1D ResNet model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNet-5x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = 1e-3\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# # tensorboard visualization\n",
    "# # visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shallower 1D ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNet-2x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BasicBlock1D\n",
    "# cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = 1e-3\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# # tensorboard visualization\n",
    "# # visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tiny 1D ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNet-1x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BasicBlock1D\n",
    "# cfg_model['conv_layers'] = [1, 1, 1, 1]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = 1e-3\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# # tensorboard visualization\n",
    "# # visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Dilated 1D ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-Multi-Dilated-ResNet-5x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = MultiBottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 32\n",
    "# cfg_model['LR'] = 1e-3\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# # tensorboard visualization\n",
    "# # visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNeXt-53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNeXt-5x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['groups'] = 32\n",
    "# cfg_model['LR'] = 1e-3\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# # tensorboard visualization\n",
    "# # visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNeXt-103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNeXt-10x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 23, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['groups'] = 32\n",
    "# cfg_model['LR'] = 1e-3\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# # tensorboard visualization\n",
    "# # visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNet-20 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '2D-ResNet-2x' # resnet-18 + three more fc layer\n",
    "# cfg_model['generator'] = ResNet2D\n",
    "# cfg_model['block'] = BasicBlock2D\n",
    "# cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['n_fft'] = 100\n",
    "# cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "# cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "# cfg_model['LR'] = 1e-3\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# # tensorboard visualization\n",
    "# # visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNet-52 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '2D-ResNet-5x' # resnet-50 + three more fc layer\n",
    "# cfg_model['generator'] = ResNet2D\n",
    "# cfg_model['block'] = Bottleneck2D\n",
    "# cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['n_fft'] = 100\n",
    "# cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "# cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "# cfg_model['LR'] = 1e-3\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# # tensorboard visualization\n",
    "# # visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNeXt-104 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '2D-ResNeXt-10x' # resnet-101 + three more fc layer\n",
    "# cfg_model['generator'] = ResNet2D\n",
    "# cfg_model['block'] = Bottleneck2D\n",
    "# cfg_model['conv_layers'] = [3, 4, 23, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['n_fft'] = 100\n",
    "# cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "# cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "# cfg_model['groups'] = 32\n",
    "# cfg_model['width_per_group'] = 8\n",
    "# cfg_model['LR'] = 1e-3\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# # tensorboard visualization\n",
    "# # visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN-Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Model config:'\n",
      "{'LR': 0.001,\n",
      " 'base_channels': 256,\n",
      " 'dropout': 0.2,\n",
      " 'fc_stages': 2,\n",
      " 'final_pool': 'max',\n",
      " 'generator': <class 'models.transformer.CNNTransformer'>,\n",
      " 'in_channels': 20,\n",
      " 'model': '1D-CNN-Transformer',\n",
      " 'n_encoders': 4,\n",
      " 'n_heads': 4,\n",
      " 'out_dims': 3,\n",
      " 'use_age': 'fc'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "CNNTransformer(\n",
      "  (conv1): Conv1d(20, 256, kernel_size=(21,), stride=(9,))\n",
      "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(3,))\n",
      "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv1d(256, 512, kernel_size=(9,), stride=(3,))\n",
      "  (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv1d(512, 512, kernel_size=(9,), stride=(3,))\n",
      "  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (final_pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc_stage): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=513, out_features=256, bias=False)\n",
      "      (1): Dropout(p=0.2, inplace=False)\n",
      "      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=False)\n",
      "      (1): Dropout(p=0.2, inplace=False)\n",
      "      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-CNN-Transformer'\n",
    "cfg_model['generator'] = CNNTransformer\n",
    "cfg_model['fc_stages'] = 2\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 256\n",
    "cfg_model['n_encoders'] = 4\n",
    "cfg_model['n_heads'] = 4\n",
    "cfg_model['dropout'] = 0.2\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize the loaded models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_channels': 20,\n",
      " 'out_dims': 3,\n",
      " 'model': '1D-CNN-Transformer',\n",
      " 'generator': <class 'models.transformer.CNNTransformer'>,\n",
      " 'fc_stages': 2,\n",
      " 'use_age': 'fc',\n",
      " 'final_pool': 'max',\n",
      " 'base_channels': 256,\n",
      " 'n_encoders': 4,\n",
      " 'n_heads': 4,\n",
      " 'dropout': 0.2,\n",
      " 'LR': 0.001}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cfg_model in cfg_model_pool:\n",
    "    pprint.pp(cfg_model, width=150)\n",
    "    print('\\n' + '-' * 100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Default Configurations for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training configurations\n",
    "cfg_train = {}\n",
    "cfg_train['iterations'] = 100000\n",
    "cfg_train['history_interval'] = cfg_train['iterations'] // 500\n",
    "cfg_train['lr_decay_step'] = round(cfg_train['iterations'] * 0.8)\n",
    "cfg_train['lr_decay_gamma'] = 0.1\n",
    "cfg_train['weight_decay'] = 1e-2\n",
    "cfg_train['mixup'] = 0.0 # 0 for no usage\n",
    "cfg_train['criterion'] = 'cross-entropy' # 'cross-entropy', 'multi-bce'\n",
    "\n",
    "cfg_train['device'] = device\n",
    "cfg_train['save_model'] = True\n",
    "cfg_train['save_temporary'] = False\n",
    "cfg_train['draw_result'] = True\n",
    "cfg_train['watch_model'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_wandb(config, train_loader, val_loader, test_loader, test_loader_longer, class_label_to_type):\n",
    "    print('*'*120)\n",
    "    print(f'{\"*\"*30}{config[\"model\"] + \" train starts\":^60}{\"*\"*30}')\n",
    "    print('*'*120)\n",
    "\n",
    "    # generate model and its trainer        \n",
    "    model = config['generator'](**config).to(device)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), \n",
    "                            lr=config['LR'], \n",
    "                            weight_decay=config['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, \n",
    "                                          step_size=config['lr_decay_step'], \n",
    "                                          gamma=config['lr_decay_gamma'])\n",
    "    \n",
    "    tr_ms = train_multistep if config.get('mixup', 0) < 1e-12 else train_mixup_multistep\n",
    "    \n",
    "    # track granients and weights statistics\n",
    "    if config.get('watch_model', None):\n",
    "        wandb.watch(model, log='all', \n",
    "                    log_freq=config['history_interval'], \n",
    "                    log_graph=True)\n",
    "\n",
    "    # train and validation routine\n",
    "    best_val_acc = 0\n",
    "    for i in range(0, config[\"iterations\"], config[\"history_interval\"]):\n",
    "        # train 'history_interval' steps\n",
    "        loss, train_acc = tr_ms(model, train_loader, optimizer, scheduler, \n",
    "                                config, config[\"history_interval\"])\n",
    "\n",
    "        # validation\n",
    "        val_acc, _, _, _, _ = check_accuracy(model, val_loader, config, repeat=10)\n",
    "\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = deepcopy(model.state_dict())\n",
    "            if config['save_model'] and config['save_temporary']:\n",
    "                save_path = f'checkpoint_temp/{wandb.run.name}/'\n",
    "                os.makedirs(save_path, exist_ok=True)\n",
    "                path = os.path.join(save_path, f'{config[\"model\"]}')\n",
    "                torch.save(best_model_state, path)\n",
    "\n",
    "        # log\n",
    "        wandb.log({'Loss': loss, \n",
    "                   'Train Accuracy': train_acc, \n",
    "                   'Validation Accuracy': val_acc}, step=i)\n",
    "\n",
    "    # calculate the test accuracies for best and last models\n",
    "    last_model_state = deepcopy(model.state_dict())\n",
    "    last_test_result = check_accuracy(model, test_loader, config, repeat=30)\n",
    "    last_test_acc = last_test_result[0]\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "    best_test_result = check_accuracy(model, test_loader, config, repeat=30)\n",
    "    best_test_acc = best_test_result[0]\n",
    "\n",
    "    if last_test_acc < best_test_acc:\n",
    "        model_state = best_model_state\n",
    "        test_result = best_test_result\n",
    "    else:\n",
    "        model_state = last_model_state\n",
    "        test_result = last_test_result\n",
    "\n",
    "    model.load_state_dict(model_state)\n",
    "    test_acc, test_confusion, test_debug, score, target = test_result\n",
    "\n",
    "    # calculate the test accuracies for final model on much longer sequence\n",
    "    last_test_result = check_accuracy(model, test_loader_longer, config, repeat=30)\n",
    "    longer_test_acc = last_test_result[0]\n",
    "\n",
    "    # save the model\n",
    "    if config['save_model']:\n",
    "        save_path = f'checkpoint_temp/{wandb.run.name}/'\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        path = os.path.join(save_path, f'{config[\"model\"]}')\n",
    "        torch.save(model_state, path)\n",
    "\n",
    "    # leave the message\n",
    "    wandb.config.final_shape = model.get_final_shape()\n",
    "    wandb.config.num_params = count_parameters(model)\n",
    "    wandb.log({'Test Accuracy': test_acc,\n",
    "               '(Best / Last) Test Accuracy': ('Best' if last_test_acc < best_test_acc else 'Last', \n",
    "                                               round(best_test_acc, 2), round(last_test_acc, 2)),\n",
    "               'Confusion Matrix (Array)': test_confusion,\n",
    "               'Test Accuracy (Longer)': longer_test_acc, \n",
    "               'Test Debug Table/Serial': test_debug[0], \n",
    "               'Test Debug Table/EDF': test_debug[1], \n",
    "               'Test Debug Table/Pred': test_debug[2], \n",
    "               'Test Debug Table/GT': test_debug[3]})\n",
    "\n",
    "    if 'lr_search' in config:\n",
    "        draw_learning_rate_record(config['lr_search'], use_wandb=True)\n",
    "\n",
    "    if config['draw_result']:\n",
    "        draw_roc_curve(score, target, class_label_to_type, use_wandb=True)\n",
    "        draw_confusion(test_confusion, class_label_to_type, use_wandb=True)\n",
    "        draw_debug_table(test_debug, use_wandb=True)\n",
    "        wandb.log({\"Confusion Matrix\": wandb.plot.confusion_matrix(y_true=target, \n",
    "                                                                   preds=score.argmax(axis=-1), \n",
    "                                                                   class_names=class_label_to_type)})\n",
    "        wandb.log({\"ROC Curve\": wandb.plot.roc_curve(target, score, labels=class_label_to_type)})\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sweep(cfg_data, cfg_train, cfg_model_pool):\n",
    "    wandb_run = wandb.init()\n",
    "    wandb.run.name = wandb.run.id\n",
    "    with wandb_run:\n",
    "        # wandb config update\n",
    "        cfg_model = cfg_model_pool[wandb.config.model_index]\n",
    "        config = {}\n",
    "        for k, v in {**cfg_data, **cfg_train, **cfg_model}.items():\n",
    "            if k not in wandb.config:\n",
    "                config[k] = v\n",
    "        \n",
    "        # to prevent callables from type-conversion to str\n",
    "        wandb.config.update(config)\n",
    "        for k, v in wandb.config.items():\n",
    "            if k not in config:\n",
    "                config[k] = v\n",
    "                \n",
    "        # build dataset\n",
    "        train_loader, val_loader, test_loader, test_loader_longer, class_label_to_type = build_dataset(config)\n",
    "        \n",
    "        config['in_channels'] = train_loader.dataset[0]['signal'].shape[0]\n",
    "        config['out_dims'] = len(class_label_to_type)\n",
    "        \n",
    "        # learning rate search if needed\n",
    "        if config[\"LR\"] is None:\n",
    "            config['LR'], config['lr_search'] = learning_rate_search(config, train_loader, \n",
    "                                                                     min_log_lr=-4.5, max_log_lr=-3.0, \n",
    "                                                                     trials=100, steps=100)\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \n",
    "        # train the model\n",
    "        train_with_wandb(config, train_loader, val_loader, test_loader, test_loader_longer, class_label_to_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_data = {}\n",
    "sweep_data['crop_length'] = {\n",
    "    'values': [200 * 10, # 10 sec\n",
    "               200 * 20, # 20 sec\n",
    "              ],\n",
    "}\n",
    "\n",
    "sweep_data['EKG'] = {\n",
    "    'values': ['O', 'X'],\n",
    "}\n",
    "\n",
    "sweep_data['photic'] = {\n",
    "    'values': ['O', 'X'],\n",
    "}\n",
    "\n",
    "sweep_data['awgn'] = {\n",
    "    'distribution': 'uniform',\n",
    "    'min': 0,\n",
    "    'max': 0.3,\n",
    "}\n",
    "\n",
    "sweep_data['awgn_age'] = {\n",
    "    'distribution': 'uniform',\n",
    "    'min': 0,\n",
    "    'max': 0.3,\n",
    "}\n",
    "\n",
    "sweep_data['minibatch'] = {\n",
    "    'values': [32, ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_model = {}\n",
    "sweep_model['model_index'] = { \n",
    "    'values' : [i for i in range(len(cfg_model_pool))] \n",
    "}\n",
    "\n",
    "sweep_model['fc_stages'] = { \n",
    "    'distribution' : 'int_uniform',\n",
    "    'min': 0,\n",
    "    'max': 4,\n",
    "}\n",
    "\n",
    "sweep_model['use_age'] = { \n",
    "    'values' : ['fc', 'conv']\n",
    "}\n",
    "\n",
    "sweep_model['final_pool'] = { \n",
    "    'values' : ['max', 'average']\n",
    "}\n",
    "\n",
    "sweep_model['first_dilation'] = { \n",
    "    'distribution' : 'int_uniform',\n",
    "    'min': 1,\n",
    "    'max': 2,\n",
    "}\n",
    "\n",
    "sweep_model['base_stride'] = { \n",
    "    'distribution' : 'int_uniform',\n",
    "    'min': 2,\n",
    "    'max': 4,\n",
    "}\n",
    "\n",
    "cfg_model['base_channels'] = 256\n",
    "cfg_model['n_encoders'] = 4\n",
    "cfg_model['n_heads'] = 4\n",
    "\n",
    "sweep_model['dropout'] = {\n",
    "    'distribution': 'uniform',\n",
    "    'min': 0.0,\n",
    "    'max': 0.5\n",
    "}\n",
    "\n",
    "sweep_model['base_channels'] = {\n",
    "    'values' : [64, 128, 192, 256]\n",
    "}\n",
    "\n",
    "sweep_model['n_encoders'] = {\n",
    "    'distribution': 'int_uniform',\n",
    "    'min': 2,\n",
    "    'max': 5\n",
    "}\n",
    "\n",
    "sweep_model['n_heads'] = {\n",
    "    'values' : [2, 4, 8]\n",
    "\n",
    "}\n",
    "\n",
    "sweep_model['LR'] = {\n",
    "    'distribution': 'log_uniform',\n",
    "    'min': math.log(5e-5),\n",
    "    'max': math.log(1e-3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_train = {}\n",
    "sweep_train['iterations'] = {\n",
    "    'values' : [100000, 150000]\n",
    "}\n",
    "\n",
    "sweep_train['lr_decay_gamma'] = {\n",
    "    'distribution' : 'uniform',\n",
    "    'min': 0.1,\n",
    "    'max': 0.5,\n",
    "}\n",
    "\n",
    "sweep_train['lr_decay_step'] = {\n",
    "    'values' : [45000, 80000]\n",
    "}\n",
    "\n",
    "sweep_train['weight_decay'] = {\n",
    "    'distribution' : 'log_uniform',\n",
    "    'min': math.log(1e-5),\n",
    "    'max': math.log(1e-1)\n",
    "}\n",
    "\n",
    "sweep_train['mixup'] = {\n",
    "    'values': [0, 0.15, 0.3]\n",
    "}\n",
    "\n",
    "sweep_train['criterion'] = {\n",
    "    'values': ['cross-entropy', 'multi-bce']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: gulbpswr\n",
      "Sweep URL: https://wandb.ai/ipis-mjkim/eeg-analysis/sweeps/gulbpswr\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "    \"entity\": \"ipis-mjkim\",\n",
    "    \"name\" : \"my-sweep\",\n",
    "    \"method\" : \"random\",\n",
    "    \"parameters\" : \n",
    "    {\n",
    "        **sweep_data,\n",
    "        **sweep_model,\n",
    "        **sweep_train,\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"eeg-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xu6bfrmo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tEKG: O\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tLR: 0.0002408886090770098\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tawgn: 0.021245485386101336\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tawgn_age: 0.2187108571812161\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbase_channels: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbase_stride: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: cross-entropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcrop_length: 2000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.06235112677070481\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_stages: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfinal_pool: average\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfirst_dilation: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \titerations: 100000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_decay_gamma: 0.3451810817373891\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_decay_step: 45000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tminibatch: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmixup: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_index: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_encoders: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tn_heads: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tphotic: O\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_age: conv\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 2.7135028016184343e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mipis-mjkim\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis/runs/xu6bfrmo\" target=\"_blank\">astral-sweep-1</a></strong> to <a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis/sweeps/gulbpswr\" target=\"_blank\">https://wandb.ai/ipis-mjkim/eeg-analysis/sweeps/gulbpswr</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "******************************              1D-CNN-Transformer train starts               ******************************\n",
      "************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=lambda: train_sweep(cfg_data, cfg_train, cfg_model_pool), count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
