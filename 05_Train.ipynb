{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Networks\n",
    "\n",
    "- Three-way SoftMax or Multi-BCE classifier of normal, non-vascular MCI, and non-vascular dementia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pprint\n",
    "import wandb\n",
    "\n",
    "# custom package\n",
    "from models import *\n",
    "from utils.eeg_dataset import *\n",
    "from utils.train_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook name\n",
    "def get_notebook_name():\n",
    "    import ipynbname\n",
    "    return ipynbname.name()\n",
    "nb_fname = get_notebook_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Set the default configuration for building datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_data = {}\n",
    "cfg_data['device'] = device\n",
    "cfg_data['dataset'] = 'CAUHS'\n",
    "cfg_data['data_path'] = r'dataset/02_Curated_Data/'\n",
    "cfg_data['meta_path'] = os.path.join(cfg_data['data_path'], 'metadata_debug.json')\n",
    "cfg_data['target_task'] = 'Normal, MCI, Dementia' # 'Norml, MCI, Dementia'\n",
    "cfg_data['vascular'] = 'X'\n",
    "cfg_data['segment'] = 'no' # 'train', 'all', 'no'\n",
    "cfg_data['seed'] = 0\n",
    "cfg_data['crop_length'] = 200 * 10 # 10 seconds\n",
    "cfg_data['longer_crop_length'] = 200 * 10 * 10 # 100 seconds\n",
    "cfg_data['input_norm'] = 'dataset' # 'datatset', 'datapoint', 'no'\n",
    "cfg_data['EKG'] = 'O'\n",
    "cfg_data['photic'] = 'X'\n",
    "cfg_data['awgn'] = 5e-2\n",
    "cfg_data['awgn_age'] = 5e-2\n",
    "cfg_data['minibatch'] = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = build_dataset(cfg_data, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Define Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_common_model = {'in_channels': _[0].dataset[0]['signal'].shape[0], \n",
    "                    'out_dims': len(_[-1])}\n",
    "cfg_model_pool = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D Tiny CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-Tiny-CNN'\n",
    "cfg_model['generator'] = TinyCNN1D\n",
    "cfg_model['fc_stages'] = 1\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M7 model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-Mx'\n",
    "cfg_model['generator'] = M7\n",
    "cfg_model['fc_stages'] = 1\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 256\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNet model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-2x'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deeper 1D ResNet model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-5x'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shallower 1D ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-2x'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BasicBlock1D\n",
    "cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tiny 1D ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-1x'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BasicBlock1D\n",
    "cfg_model['conv_layers'] = [1, 1, 1, 1]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Dilated 1D ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-Multi-Dilated-ResNet-5x'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = MultiBottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 32\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNeXt-53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNeXt-5x'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['groups'] = 32\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNeXt-103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNeXt-10x'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [3, 4, 23, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['groups'] = 32\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNet-20 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '2D-ResNet-2x' # resnet-18 + three more fc layer\n",
    "cfg_model['generator'] = ResNet2D\n",
    "cfg_model['block'] = BasicBlock2D\n",
    "cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['n_fft'] = 100\n",
    "cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNet-52 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '2D-ResNet-5x' # resnet-50 + three more fc layer\n",
    "cfg_model['generator'] = ResNet2D\n",
    "cfg_model['block'] = Bottleneck2D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['n_fft'] = 100\n",
    "cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNeXt-104 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '2D-ResNeXt-10x' # resnet-101 + three more fc layer\n",
    "cfg_model['generator'] = ResNet2D\n",
    "cfg_model['block'] = Bottleneck2D\n",
    "cfg_model['conv_layers'] = [3, 4, 23, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['n_fft'] = 100\n",
    "cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "cfg_model['groups'] = 32\n",
    "cfg_model['width_per_group'] = 8\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN-Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-CNN-Transformer'\n",
    "cfg_model['generator'] = CNNTransformer\n",
    "cfg_model['fc_stages'] = 2\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 256\n",
    "cfg_model['n_encoders'] = 4\n",
    "cfg_model['n_heads'] = 4\n",
    "cfg_model['dropout'] = 0.2\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize the loaded models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cfg_model in cfg_model_pool:\n",
    "    pprint.pp(cfg_model, width=150)\n",
    "    print('\\n' + '-' * 100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Default Configurations for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training configurations\n",
    "cfg_train = {}\n",
    "cfg_train['iterations'] = 100000\n",
    "cfg_train['history_interval'] = cfg_train['iterations'] // 500\n",
    "cfg_train['lr_decay_step'] = round(cfg_train['iterations'] * 0.8)\n",
    "cfg_train['lr_decay_gamma'] = 0.1\n",
    "cfg_train['weight_decay'] = 1e-2\n",
    "cfg_train['mixup'] = 0.0 # 0 for no usage\n",
    "cfg_train['criterion'] = 'cross-entropy' # 'cross-entropy', 'multi-bce'\n",
    "\n",
    "cfg_train['device'] = device\n",
    "cfg_train['save_model'] = True\n",
    "cfg_train['save_temporary'] = False\n",
    "cfg_train['draw_result'] = True\n",
    "cfg_train['watch_model'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_wandb(config, train_loader, val_loader, test_loader, test_loader_longer, class_label_to_type):\n",
    "    print('*'*120)\n",
    "    print(f'{\"*\"*30}{config[\"model\"] + \" train starts\":^60}{\"*\"*30}')\n",
    "    print('*'*120)\n",
    "\n",
    "    # generate model and its trainer        \n",
    "    model = config['generator'](**config).to(device)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), \n",
    "                            lr=config['LR'], \n",
    "                            weight_decay=config['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, \n",
    "                                          step_size=config['lr_decay_step'], \n",
    "                                          gamma=config['lr_decay_gamma'])\n",
    "    \n",
    "    tr_ms = train_multistep if config.get('mixup', 0) < 1e-12 else train_mixup_multistep\n",
    "    \n",
    "    # track granients and weights statistics\n",
    "    if config.get('watch_model', None):\n",
    "        wandb.watch(model, log='all', \n",
    "                    log_freq=config['history_interval'], \n",
    "                    log_graph=True)\n",
    "\n",
    "    # train and validation routine\n",
    "    best_val_acc = 0\n",
    "    for i in range(0, config[\"iterations\"], config[\"history_interval\"]):\n",
    "        # train 'history_interval' steps\n",
    "        loss, train_acc = tr_ms(model, train_loader, optimizer, scheduler, \n",
    "                                config, config[\"history_interval\"])\n",
    "\n",
    "        # validation\n",
    "        val_acc, _, _, _, _ = check_accuracy(model, val_loader, config, repeat=10)\n",
    "\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = deepcopy(model.state_dict())\n",
    "            if config['save_model'] and config['save_temporary']:\n",
    "                save_path = f'checkpoint_temp/{wandb.run.name}/'\n",
    "                os.makedirs(save_path, exist_ok=True)\n",
    "                path = os.path.join(save_path, f'{config[\"model\"]}')\n",
    "                torch.save(best_model_state, path)\n",
    "\n",
    "        # log\n",
    "        wandb.log({'Loss': loss, \n",
    "                   'Train Accuracy': train_acc, \n",
    "                   'Validation Accuracy': val_acc}, step=i)\n",
    "\n",
    "    # calculate the test accuracies for best and last models\n",
    "    last_model_state = deepcopy(model.state_dict())\n",
    "    last_test_result = check_accuracy(model, test_loader, config, repeat=30)\n",
    "    last_test_acc = last_test_result[0]\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "    best_test_result = check_accuracy(model, test_loader, config, repeat=30)\n",
    "    best_test_acc = best_test_result[0]\n",
    "\n",
    "    if last_test_acc < best_test_acc:\n",
    "        model_state = best_model_state\n",
    "        test_result = best_test_result\n",
    "    else:\n",
    "        model_state = last_model_state\n",
    "        test_result = last_test_result\n",
    "\n",
    "    model.load_state_dict(model_state)\n",
    "    test_acc, test_confusion, test_debug, score, target = test_result\n",
    "\n",
    "    # calculate the test accuracies for final model on much longer sequence\n",
    "    last_test_result = check_accuracy(model, test_loader_longer, config, repeat=30)\n",
    "    longer_test_acc = last_test_result[0]\n",
    "\n",
    "    # save the model\n",
    "    if config['save_model']:\n",
    "        save_path = f'checkpoint_temp/{wandb.run.name}/'\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        path = os.path.join(save_path, f'{config[\"model\"]}')\n",
    "        torch.save(model_state, path)\n",
    "\n",
    "    # leave the message\n",
    "    wandb.config.final_shape = model.get_final_shape()\n",
    "    wandb.config.num_params = count_parameters(model)\n",
    "    wandb.log({'Test Accuracy': test_acc,\n",
    "               '(Best / Last) Test Accuracy': ('Best' if last_test_acc < best_test_acc else 'Last', \n",
    "                                               round(best_test_acc, 2), round(last_test_acc, 2)),\n",
    "               'Confusion Matrix (Array)': test_confusion,\n",
    "               'Test Accuracy (Longer)': longer_test_acc, \n",
    "               'Test Debug Table/Serial': test_debug[0], \n",
    "               'Test Debug Table/EDF': test_debug[1], \n",
    "               'Test Debug Table/Pred': test_debug[2], \n",
    "               'Test Debug Table/GT': test_debug[3]})\n",
    "\n",
    "    if 'lr_search' in config:\n",
    "        draw_learning_rate_record(config['lr_search'], use_wandb=True)\n",
    "\n",
    "    if config['draw_result']:\n",
    "        draw_roc_curve(score, target, class_label_to_type, use_wandb=True)\n",
    "        draw_confusion(test_confusion, class_label_to_type, use_wandb=True)\n",
    "        draw_debug_table(test_debug, use_wandb=True)\n",
    "        wandb.log({\"Confusion Matrix\": wandb.plot.confusion_matrix(y_true=target, \n",
    "                                                                   preds=score.argmax(axis=-1), \n",
    "                                                                   class_names=class_label_to_type)})\n",
    "        wandb.log({\"ROC Curve\": wandb.plot.roc_curve(target, score, labels=class_label_to_type)})\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sweep(cfg_data, cfg_train, cfg_model_pool):\n",
    "    wandb_run = wandb.init()\n",
    "    wandb.run.name = wandb.run.id\n",
    "    with wandb_run:\n",
    "        # wandb config update\n",
    "        cfg_model = cfg_model_pool[wandb.config.model_index]\n",
    "        config = {}\n",
    "        for k, v in {**cfg_data, **cfg_train, **cfg_model}.items():\n",
    "            if k not in wandb.config:\n",
    "                config[k] = v\n",
    "        \n",
    "        # to prevent callables from type-conversion to str\n",
    "        wandb.config.update(config)\n",
    "        for k, v in wandb.config.items():\n",
    "            if k not in config:\n",
    "                config[k] = v\n",
    "                \n",
    "        # build dataset\n",
    "        train_loader, val_loader, test_loader, test_loader_longer, class_label_to_type = build_dataset(config)\n",
    "        \n",
    "        config['in_channels'] = train_loader.dataset[0]['signal'].shape[0]\n",
    "        config['out_dims'] = len(class_label_to_type)\n",
    "        \n",
    "        # learning rate search if needed\n",
    "        if config[\"LR\"] is None:\n",
    "            config['LR'], config['lr_search'] = learning_rate_search(config, train_loader, \n",
    "                                                                     min_log_lr=-4.5, max_log_lr=-3.0, \n",
    "                                                                     trials=100, steps=100)\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \n",
    "        # train the model\n",
    "        train_with_wandb(config, train_loader, val_loader, test_loader, test_loader_longer, class_label_to_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_data = {}\n",
    "sweep_data['crop_length'] = {\n",
    "    'values': [200 * 10, # 10 sec\n",
    "               200 * 20, # 20 sec\n",
    "              ],\n",
    "}\n",
    "\n",
    "sweep_data['EKG'] = {\n",
    "    'values': ['O', 'X'],\n",
    "}\n",
    "\n",
    "sweep_data['photic'] = {\n",
    "    'values': ['O', 'X'],\n",
    "}\n",
    "\n",
    "sweep_data['awgn'] = {\n",
    "    'distribution': 'uniform',\n",
    "    'min': 0,\n",
    "    'max': 0.3,\n",
    "}\n",
    "\n",
    "sweep_data['awgn_age'] = {\n",
    "    'distribution': 'uniform',\n",
    "    'min': 0,\n",
    "    'max': 0.3,\n",
    "}\n",
    "\n",
    "sweep_data['minibatch'] = {\n",
    "    'values': [32, ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_model = {}\n",
    "sweep_model['model_index'] = { \n",
    "    'values' : [i for i in range(len(cfg_model_pool))] \n",
    "}\n",
    "\n",
    "sweep_model['fc_stages'] = { \n",
    "    'distribution' : 'int_uniform',\n",
    "    'min': 0,\n",
    "    'max': 4,\n",
    "}\n",
    "\n",
    "sweep_model['use_age'] = { \n",
    "    'values' : ['fc', 'conv']\n",
    "}\n",
    "\n",
    "sweep_model['final_pool'] = { \n",
    "    'values' : ['max', 'average']\n",
    "}\n",
    "\n",
    "sweep_model['first_dilation'] = { \n",
    "    'distribution' : 'int_uniform',\n",
    "    'min': 1,\n",
    "    'max': 2,\n",
    "}\n",
    "\n",
    "sweep_model['base_stride'] = { \n",
    "    'distribution' : 'int_uniform',\n",
    "    'min': 2,\n",
    "    'max': 4,\n",
    "}\n",
    "\n",
    "sweep_model['dropout'] = {\n",
    "    'distribution': 'uniform',\n",
    "    'min': 0.0,\n",
    "    'max': 0.5\n",
    "}\n",
    "\n",
    "sweep_model['LR'] = {\n",
    "    'distribution': 'log_uniform',\n",
    "    'min': math.log(1e-5),\n",
    "    'max': math.log(1e-3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_train = {}\n",
    "sweep_train['iterations'] = {\n",
    "    'values' : [100000, 150000]\n",
    "}\n",
    "\n",
    "sweep_train['lr_decay_gamma'] = {\n",
    "    'distribution' : 'uniform',\n",
    "    'min': 0.1,\n",
    "    'max': 0.5,\n",
    "}\n",
    "\n",
    "sweep_train['lr_decay_step'] = {\n",
    "    'values' : [45000, 80000]\n",
    "}\n",
    "\n",
    "sweep_train['weight_decay'] = {\n",
    "    'distribution' : 'log_uniform',\n",
    "    'min': math.log(1e-5),\n",
    "    'max': math.log(1e-1)\n",
    "}\n",
    "\n",
    "sweep_train['mixup'] = {\n",
    "    'values': [0, 0.15, 0.3]\n",
    "}\n",
    "\n",
    "sweep_train['criterion'] = {\n",
    "    'values': ['cross-entropy', 'multi-bce']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"entity\": \"ipis-mjkim\",\n",
    "    \"name\" : \"my-sweep\",\n",
    "    \"method\" : \"random\",\n",
    "    \"parameters\" : \n",
    "    {\n",
    "        **sweep_data,\n",
    "        **sweep_model,\n",
    "        **sweep_train,\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"eeg-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, function=lambda: train_sweep(cfg_data, cfg_train, cfg_model_pool), count=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
