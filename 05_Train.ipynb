{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Networks\n",
    "\n",
    "- Three-way SoftMax or Multi-BCE classifier of normal, non-vascular MCI, and non-vascular dementia\n",
    "- `Weights and Biases` sweep is used for hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pprint\n",
    "import wandb\n",
    "\n",
    "# custom package\n",
    "from datasets.cau_eeg_dataset import *\n",
    "from datasets.cau_eeg_script import *\n",
    "from models import *\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.11.0\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Set the default configuration for building datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_data = {}\n",
    "cfg_data['device'] = device\n",
    "cfg_data['dataset'] = 'CAUHS'\n",
    "cfg_data['data_path'] = r'local/dataset/02_Curated_Data_220322/'\n",
    "cfg_data['meta_path'] = os.path.join(cfg_data['data_path'], 'metadata_debug.json')\n",
    "cfg_data['file_format'] = 'feather'  # 'feather', 'memmap'\n",
    "cfg_data['target_task'] = 'Normal, MCI, Dementia' # 'Norml, MCI, Dementia'\n",
    "cfg_data['vascular'] = 'X'\n",
    "cfg_data['segment'] = 'no' # 'train', 'all', 'no'\n",
    "cfg_data['seed'] = 0\n",
    "cfg_data['crop_length'] = 200 * 10 # 10 seconds\n",
    "cfg_data['longer_crop_length'] = 200 * 10 * 10 # 100 seconds\n",
    "cfg_data['crop_multiple'] = 8\n",
    "cfg_data['minibatch'] = 1024\n",
    "cfg_data['input_norm'] = 'dataset' # 'datatset', 'datapoint', 'no'\n",
    "cfg_data['EKG'] = 'O'\n",
    "cfg_data['photic'] = 'X'\n",
    "cfg_data['awgn'] = 5e-2\n",
    "cfg_data['mgn'] = 1e-4\n",
    "cfg_data['awgn_age'] = 5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_label_to_type: ['Normal', 'Non-vascular MCI', 'Non-vascular dementia']\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- There are 458 data belonging to Normal\n",
      "- There are 350 data belonging to Non-vascular MCI\n",
      "- There are 233 data belonging to Non-vascular dementia\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Train data label distribution\t: [366, 280, 186] 832\n",
      "Train data label distribution\t: [46, 35, 23] 104\n",
      "Train data label distribution\t: [46, 35, 24] 105\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "composed_train: Compose(\n",
      "    <datasets.pipeline.EegDropPhoticChannel object at 0x00000205E1795C70>\n",
      "    <datasets.pipeline.EegRandomCrop object at 0x00000205E17DC310>\n",
      "    <datasets.pipeline.EegToTensor object at 0x00000205BE130D00>\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "composed_test: Compose(\n",
      "    <datasets.pipeline.EegDropPhoticChannel object at 0x00000205E1795D00>\n",
      "    <datasets.pipeline.EegRandomCrop object at 0x00000205BE130C10>\n",
      "    <datasets.pipeline.EegToTensor object at 0x00000205BE130EE0>\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "longer_composed_test: Compose(\n",
      "    <datasets.pipeline.EegRandomCrop object at 0x00000205BE130D90>\n",
      "    <datasets.pipeline.EegRandomCrop object at 0x00000205BE1F2490>\n",
      "    <datasets.pipeline.EegToTensor object at 0x00000205BE1F2F70>\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "train_dataset[0].keys():\n",
      "dict_keys(['signal', 'age', 'class_label', 'metadata'])\n",
      "train_dataset[0][\"signal\"]:\n",
      "[tensor([[ 11.,  10.,   9.,  ...,   1.,   1.,   0.],\n",
      "        [  3.,   2.,   0.,  ...,   7.,   7.,   5.],\n",
      "        [-11., -10., -10.,  ...,  -4.,  -5.,  -5.],\n",
      "        ...,\n",
      "        [  5.,   7.,   8.,  ...,   2.,   2.,   2.],\n",
      "        [ -4.,  -2.,   1.,  ..., -22., -21., -20.],\n",
      "        [ -7., -10., -12.,  ...,  -9., -10., -10.]]),\n",
      " tensor([[ 20.,  19.,  18.,  ..., -17., -13., -10.],\n",
      "        [-11., -10.,  -9.,  ...,   4.,   6.,   6.],\n",
      "        [-42., -40., -39.,  ..., -28., -27., -28.],\n",
      "        ...,\n",
      "        [ 20.,  19.,  18.,  ...,   4.,   4.,   5.],\n",
      "        [ -2.,  -2.,  -2.,  ...,  11.,  10.,   9.],\n",
      "        [ -8.,  -8.,  -9.,  ...,  -9.,  -7.,  -5.]]),\n",
      " tensor([[  7.,   6.,   6.,  ...,   6.,   8.,  10.],\n",
      "        [  6.,   9.,   7.,  ...,   7.,   8.,  10.],\n",
      "        [ 28.,  31.,  31.,  ...,  36.,  36.,  37.],\n",
      "        ...,\n",
      "        [ -8.,  -8.,  -8.,  ...,  -5.,  -3.,  -1.],\n",
      "        [ -2.,  -2.,  -2.,  ...,  -1.,   0.,   1.],\n",
      "        [194., 221., 224.,  ..., -10., -11.,  -9.]]),\n",
      " tensor([[-23., -18., -16.,  ..., -26., -25., -25.],\n",
      "        [ 18.,  21.,  21.,  ...,   0.,  -9.,  -3.],\n",
      "        [-12., -13., -14.,  ..., -15., -19., -16.],\n",
      "        ...,\n",
      "        [ -3.,  -3.,  -3.,  ...,  -5.,  -5.,  -8.],\n",
      "        [ -2.,  -2.,  -2.,  ..., -30., -31., -33.],\n",
      "        [-18., -15., -12.,  ..., -34., -47., -56.]]),\n",
      " tensor([[-27., -30., -30.,  ...,  32.,  34.,  34.],\n",
      "        [-17., -17., -18.,  ...,  28.,  29.,  28.],\n",
      "        [ 36.,  36.,  36.,  ...,   9.,  10.,  10.],\n",
      "        ...,\n",
      "        [  3.,   2.,   3.,  ...,  38.,  37.,  37.],\n",
      "        [ 16.,  17.,  18.,  ..., -14., -17., -17.],\n",
      "        [ -6.,  -3.,  -7.,  ...,  -6.,  -7.,  -7.]]),\n",
      " tensor([[ 30.,  29.,  29.,  ...,  16.,  19.,  21.],\n",
      "        [ 13.,  13.,  13.,  ...,  17.,  18.,  20.],\n",
      "        [ 12.,  12.,  11.,  ...,  -8.,  -6.,  -5.],\n",
      "        ...,\n",
      "        [  1.,   1.,   0.,  ...,   3.,   5.,   6.],\n",
      "        [  2.,   3.,   4.,  ...,  -8.,  -7.,  -7.],\n",
      "        [-24., -24., -19.,  ..., -14., -12., -13.]]),\n",
      " tensor([[  6.,   7.,   9.,  ...,   5.,   5.,   5.],\n",
      "        [-17., -16., -16.,  ...,   9.,   8.,   7.],\n",
      "        [  3.,   3.,   3.,  ...,   1.,  -1.,  -2.],\n",
      "        ...,\n",
      "        [  7.,   9.,  12.,  ...,   0.,  -3.,  -5.],\n",
      "        [-23., -23., -24.,  ...,  12.,  11.,  10.],\n",
      "        [  7.,   4.,   4.,  ...,  26.,  26.,  16.]]),\n",
      " tensor([[ 61.,  61.,  61.,  ...,   4.,   3.,   3.],\n",
      "        [ -1.,  -1.,  -1.,  ...,   6.,   5.,   4.],\n",
      "        [ -5.,  -4.,  -2.,  ...,  -9., -12., -15.],\n",
      "        ...,\n",
      "        [  1.,   2.,   2.,  ...,   5.,   3.,   1.],\n",
      "        [-13., -10.,  -7.,  ...,  10.,   9.,   9.],\n",
      "        [ 19.,  16.,  15.,  ...,   9.,   4.,  -1.]])]\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "val_dataset[0].keys():\n",
      "dict_keys(['signal', 'age', 'class_label', 'metadata'])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_dataset[0].keys():\n",
      "dict_keys(['signal', 'age', 'class_label', 'metadata'])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_dataset_longer[0].keys():\n",
      "dict_keys(['signal', 'age', 'class_label', 'metadata'])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "train_loader:\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x00000205BE1F2100>\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "val_loader:\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x00000205BE1F2730>\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_loader:\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x00000205BE1F2310>\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_loader_longer:\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x00000205BE1F2130>\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "preprocess_train: Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeMeanStd(mean=tensor([ 0.0419,  0.0611,  0.0122, -0.0214, -0.0477,  0.0878, -0.0552,  0.0514,\n",
      "           0.0158, -0.0359,  0.0417,  0.0059, -0.0518,  0.0123,  0.0034, -0.0292,\n",
      "           0.0080,  0.0287,  0.0126,  0.0067]),std=tensor([44.4359, 19.6209, 11.3385, 11.2604, 14.7509, 47.5771, 19.1881, 10.0506,\n",
      "          10.8645, 15.2180, 20.1039, 13.9994, 13.2211, 21.0542, 16.3715, 13.9404,\n",
      "          19.0494, 10.7430, 10.9046, 94.9458]),eps=1e-08)\n",
      "  (2): EegNormalizeAge(mean=tensor([70.4180]),std=tensor([9.5846]),eps=1e-08)\n",
      "  (3): EegAdditiveGaussianNoise(mean=0.0,std=0.05)\n",
      "  (4): EegMultiplicativeGaussianNoise(mean=0.0,std=0.0001)\n",
      "  (5): EegAddGaussianNoiseAge(mean=0.0,std=0.05)\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "preprocess_test: Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeMeanStd(mean=tensor([ 0.0419,  0.0611,  0.0122, -0.0214, -0.0477,  0.0878, -0.0552,  0.0514,\n",
      "           0.0158, -0.0359,  0.0417,  0.0059, -0.0518,  0.0123,  0.0034, -0.0292,\n",
      "           0.0080,  0.0287,  0.0126,  0.0067]),std=tensor([44.4359, 19.6209, 11.3385, 11.2604, 14.7509, 47.5771, 19.1881, 10.0506,\n",
      "          10.8645, 15.2180, 20.1039, 13.9994, 13.2211, 21.0542, 16.3715, 13.9404,\n",
      "          19.0494, 10.7430, 10.9046, 94.9458]),eps=1e-08)\n",
      "  (2): EegNormalizeAge(mean=tensor([70.4180]),std=tensor([9.5846]),eps=1e-08)\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "0 torch.Size([1024, 20, 2000]) torch.Size([1024]) torch.Size([1024]) 1024\n",
      "1 torch.Size([1024, 20, 2000]) torch.Size([1024]) torch.Size([1024]) 1024\n",
      "2 torch.Size([1024, 20, 2000]) torch.Size([1024]) torch.Size([1024]) 1024\n",
      "3 torch.Size([1024, 20, 2000]) torch.Size([1024]) torch.Size([1024]) 1024\n",
      "4 torch.Size([1024, 20, 2000]) torch.Size([1024]) torch.Size([1024]) 1024\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = build_dataset(cfg_data, verbose=True)\n",
    "train_loader = _[0]\n",
    "val_loader = _[1]\n",
    "test_loader = _[2]\n",
    "test_loader_longer = _[3]\n",
    "preprocess_train = _[4]\n",
    "preprocess_test = _[5]\n",
    "class_label_to_type = _[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Define Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg_data.get('crop_multiple', 1) == 1:\n",
    "    cfg_common_model = {'in_channels': _[0].dataset[0]['signal'].shape[0], \n",
    "                        'out_dims': len(_[-1])}\n",
    "else:\n",
    "    cfg_common_model = {'in_channels': _[0].dataset[0]['signal'][0].shape[0], \n",
    "                        'out_dims': len(_[-1])}\n",
    "\n",
    "del _\n",
    "cfg_model_pool = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D Tiny CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Model config:'\n",
      "{'LR': None,\n",
      " 'activation': 'mish',\n",
      " 'base_channels': 64,\n",
      " 'dropout': 0.3,\n",
      " 'fc_stages': 3,\n",
      " 'final_pool': 'max',\n",
      " 'generator': <class 'models.simple_cnn_1d.TinyCNN1D'>,\n",
      " 'in_channels': 20,\n",
      " 'model': '1D-Tiny-CNN',\n",
      " 'out_dims': 3,\n",
      " 'use_age': 'fc'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "TinyCNN1D(\n",
      "  (conv1): Conv1d(20, 64, kernel_size=(35,), stride=(7,))\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (final_pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc_stage): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=65, out_features=32, bias=False)\n",
      "      (1): Dropout(p=0.3, inplace=False)\n",
      "      (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Mish()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=16, bias=False)\n",
      "      (1): Dropout(p=0.3, inplace=False)\n",
      "      (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Mish()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=8, bias=False)\n",
      "      (1): Dropout(p=0.3, inplace=False)\n",
      "      (2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Mish()\n",
      "    )\n",
      "    (3): Linear(in_features=8, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-Tiny-CNN'\n",
    "cfg_model['generator'] = TinyCNN1D\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = None\n",
    "cfg_model['dropout'] = 0.3\n",
    "cfg_model['activation'] = 'mish'\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M7 model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-Mx'\n",
    "# cfg_model['generator'] = M7\n",
    "# cfg_model['fc_stages'] = 1\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 256\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNet model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNet-2x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deeper 1D ResNet model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNet-5x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shallower 1D ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNet-2x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BasicBlock1D\n",
    "# cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tiny 1D ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Model config:'\n",
      "{'LR': None,\n",
      " 'activation': 'mish',\n",
      " 'base_channels': 64,\n",
      " 'block': <class 'models.resnet_1d.BasicBlock1D'>,\n",
      " 'conv_layers': [1, 1, 1, 1],\n",
      " 'fc_stages': 3,\n",
      " 'final_pool': 'max',\n",
      " 'generator': <class 'models.resnet_1d.ResNet1D'>,\n",
      " 'in_channels': 20,\n",
      " 'model': '1D-ResNet-1x',\n",
      " 'out_dims': 3,\n",
      " 'use_age': 'fc'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "ResNet1D(\n",
      "  (input_stage): Sequential(\n",
      "    (0): Conv1d(20, 64, kernel_size=(27,), stride=(2,), padding=(13,), bias=False)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Mish()\n",
      "  )\n",
      "  (conv_stage1): Sequential(\n",
      "    (0): BasicBlock1D(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): Mish()\n",
      "    )\n",
      "    (1): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage2): Sequential(\n",
      "    (0): BasicBlock1D(\n",
      "      (conv1): Conv1d(64, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): Mish()\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage3): Sequential(\n",
      "    (0): BasicBlock1D(\n",
      "      (conv1): Conv1d(128, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): Mish()\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage4): Sequential(\n",
      "    (0): BasicBlock1D(\n",
      "      (conv1): Conv1d(256, 512, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): Mish()\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (final_pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc_stage): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=513, out_features=256, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Mish()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Mish()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=64, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Mish()\n",
      "    )\n",
      "    (3): Linear(in_features=64, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-1x'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BasicBlock1D\n",
    "cfg_model['conv_layers'] = [1, 1, 1, 1]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = None\n",
    "cfg_model['activation'] = 'mish'\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Dilated 1D ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-Multi-Dilated-ResNet-5x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = MultiBottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 32\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNeXt-53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNeXt-5x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['groups'] = 32\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNeXt-103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNeXt-10x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 23, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['groups'] = 32\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNet-20 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '2D-ResNet-2x' # resnet-18 + three more fc layer\n",
    "# cfg_model['generator'] = ResNet2D\n",
    "# cfg_model['block'] = BasicBlock2D\n",
    "# cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['n_fft'] = 100\n",
    "# cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "# cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNet-52 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '2D-ResNet-5x' # resnet-50 + three more fc layer\n",
    "# cfg_model['generator'] = ResNet2D\n",
    "# cfg_model['block'] = Bottleneck2D\n",
    "# cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['n_fft'] = 100\n",
    "# cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "# cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNeXt-104 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '2D-ResNeXt-10x' # resnet-101 + three more fc layer\n",
    "# cfg_model['generator'] = ResNet2D\n",
    "# cfg_model['block'] = Bottleneck2D\n",
    "# cfg_model['conv_layers'] = [3, 4, 23, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['n_fft'] = 100\n",
    "# cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "# cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "# cfg_model['groups'] = 32\n",
    "# cfg_model['width_per_group'] = 8\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN-Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-CNN-Transformer'\n",
    "# cfg_model['generator'] = CNNTransformer\n",
    "# cfg_model['fc_stages'] = 2\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 256\n",
    "# cfg_model['n_encoders'] = 4\n",
    "# cfg_model['n_heads'] = 4\n",
    "# cfg_model['dropout'] = 0.2\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize the model pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_channels': 20,\n",
      " 'out_dims': 3,\n",
      " 'model': '1D-Tiny-CNN',\n",
      " 'generator': <class 'models.simple_cnn_1d.TinyCNN1D'>,\n",
      " 'fc_stages': 3,\n",
      " 'use_age': 'fc',\n",
      " 'final_pool': 'max',\n",
      " 'base_channels': 64,\n",
      " 'LR': None,\n",
      " 'dropout': 0.3,\n",
      " 'activation': 'mish'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "{'in_channels': 20,\n",
      " 'out_dims': 3,\n",
      " 'model': '1D-ResNet-1x',\n",
      " 'generator': <class 'models.resnet_1d.ResNet1D'>,\n",
      " 'block': <class 'models.resnet_1d.BasicBlock1D'>,\n",
      " 'conv_layers': [1, 1, 1, 1],\n",
      " 'fc_stages': 3,\n",
      " 'use_age': 'fc',\n",
      " 'final_pool': 'max',\n",
      " 'base_channels': 64,\n",
      " 'LR': None,\n",
      " 'activation': 'mish'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cfg_model in cfg_model_pool:\n",
    "    pprint.pp(cfg_model, width=150)\n",
    "    print('\\n' + '-' * 100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_channels': 20,\n",
      " 'out_dims': 3,\n",
      " 'model': '1D-Tiny-CNN',\n",
      " 'generator': <class 'models.simple_cnn_1d.TinyCNN1D'>,\n",
      " 'fc_stages': 3,\n",
      " 'use_age': 'fc',\n",
      " 'final_pool': 'max',\n",
      " 'base_channels': 64,\n",
      " 'LR': None,\n",
      " 'dropout': 0.3,\n",
      " 'activation': 'mish'}\n"
     ]
    }
   ],
   "source": [
    "model_index = 0\n",
    "cfg_model = cfg_model_pool[model_index]\n",
    "\n",
    "pprint.pp(cfg_model, width=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Default Configurations for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training configurations\n",
    "cfg_train = {}\n",
    "cfg_train['iterations'] = 150000 // cfg_data.get('crop_multiple', 1) \n",
    "cfg_train['num_history'] = 500\n",
    "cfg_train['lr_decay_timing'] = 0.8\n",
    "cfg_train['lr_decay_gamma'] = 0.1\n",
    "cfg_train['weight_decay'] = 1e-2\n",
    "cfg_train['mixup'] = 0.0 # 0 for no usage\n",
    "cfg_train['criterion'] = 'cross-entropy' # 'cross-entropy', 'multi-bce'\n",
    "\n",
    "cfg_train['device'] = device\n",
    "cfg_train['save_model'] = True\n",
    "cfg_train['save_temporary'] = False\n",
    "cfg_train['draw_result'] = True\n",
    "cfg_train['watch_model'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mipis-mjkim\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\bengb\\OneDrive\\문서\\GitHub\\eeg_analysis\\wandb\\run-20220324_030504-4sfhm4jr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis/runs/4sfhm4jr\" target=\"_blank\">upbeat-shape-85</a></strong> to <a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "******************************                  1D-Tiny-CNN train starts                  ******************************\n",
      "************************************************************************************************************************\n",
      "  1> 1.00423\n",
      "  2> 0.00000\n",
      "  3> 0.17504\n",
      "  4> 1.11125\n",
      "  5> 0.00000\n",
      "  6> 0.07002\n",
      "  7> 0.00200\n",
      "  8> 0.00100\n",
      "  9> 0.01900\n",
      "\n",
      " 10> 1.01023\n",
      " 11> 0.00100\n",
      " 12> 0.05401\n",
      " 13> 0.00200\n",
      " 14> 0.00100\n",
      " 15> 0.00100\n",
      " 16> 0.00300\n",
      " 17> 0.00000\n",
      " 18> 0.03101\n",
      "\n",
      " 19> 0.99122\n",
      " 20> 0.00000\n",
      " 21> 0.04901\n",
      " 22> 0.00200\n",
      " 23> 0.00000\n",
      " 24> 0.00200\n",
      " 25> 0.00200\n",
      " 26> 0.00000\n",
      " 27> 0.03001\n",
      "\n",
      " 28> 0.97722\n",
      " 29> 0.00000\n",
      " 30> 0.04701\n",
      " 31> 0.00200\n",
      " 32> 0.00000\n",
      " 33> 0.00200\n",
      " 34> 0.00300\n",
      " 35> 0.00000\n",
      " 36> 0.02901\n",
      "\n",
      " 37> 0.95422\n",
      " 38> 0.00100\n",
      " 39> 0.04701\n",
      " 40> 0.00100\n",
      " 41> 0.00100\n",
      " 42> 0.00100\n",
      " 43> 0.00200\n",
      " 44> 0.00000\n",
      " 45> 0.02701\n",
      "\n",
      " 46> 0.94221\n",
      " 47> 0.00100\n",
      " 48> 0.04901\n",
      " 49> 0.00100\n",
      " 50> 0.00000\n",
      " 51> 0.00200\n",
      " 52> 0.00300\n",
      " 53> 0.00000\n",
      " 54> 0.02801\n",
      "\n",
      " 55> 0.00000\n",
      "----------------------------------------------------------------------\n",
      "  1> 0.95221\n",
      "  2> 0.00000\n",
      "  3> 0.04701\n",
      "  4> 0.00200\n",
      "  5> 0.00000\n",
      "  6> 0.00200\n",
      "  7> 0.00200\n",
      "  8> 0.00000\n",
      "  9> 0.02601\n",
      "\n",
      " 10> 0.92821\n",
      " 11> 0.00000\n",
      " 12> 0.04701\n",
      " 13> 0.00200\n",
      " 14> 0.00000\n",
      " 15> 0.00100\n",
      " 16> 0.00300\n",
      " 17> 0.00000\n",
      " 18> 0.02601\n",
      "\n",
      " 19> 0.91621\n",
      " 20> 0.00000\n",
      " 21> 0.04701\n",
      " 22> 0.00200\n",
      " 23> 0.00000\n",
      " 24> 0.00200\n",
      " 25> 0.00200\n",
      " 26> 0.00000\n",
      " 27> 0.02601\n",
      "\n",
      " 28> 0.92721\n",
      " 29> 0.00000\n",
      " 30> 0.05001\n",
      " 31> 0.00100\n",
      " 32> 0.00100\n",
      " 33> 0.00200\n",
      " 34> 0.00200\n",
      " 35> 0.00000\n",
      " 36> 0.02801\n",
      "\n",
      " 37> 1.05824\n",
      " 38> 0.00100\n",
      " 39> 0.04601\n",
      " 40> 0.00200\n",
      " 41> 0.00000\n",
      " 42> 0.00200\n",
      " 43> 0.00200\n",
      " 44> 0.00000\n",
      " 45> 0.02601\n",
      "\n",
      " 46> 0.96222\n",
      " 47> 0.00100\n",
      " 48> 0.04801\n",
      " 49> 0.00200\n",
      " 50> 0.00000\n",
      " 51> 0.00200\n",
      " 52> 0.00200\n",
      " 53> 0.00000\n",
      " 54> 0.02801\n",
      "\n",
      " 55> 0.00100\n",
      "----------------------------------------------------------------------\n",
      "  1> 0.94421\n",
      "  2> 0.00000\n",
      "  3> 0.04701\n",
      "  4> 0.00200\n",
      "  5> 0.00000\n",
      "  6> 0.00200\n",
      "  7> 0.00200\n",
      "  8> 0.00000\n",
      "  9> 0.02601\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.053 MB of 0.053 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">upbeat-shape-85</strong>: <a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis/runs/4sfhm4jr\" target=\"_blank\">https://wandb.ai/ipis-mjkim/eeg-analysis/runs/4sfhm4jr</a><br/>Synced 7 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220324_030504-4sfhm4jr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout_dims\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(class_label_to_type)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mtrain_with_wandb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader_longer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mpreprocess_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_label_to_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\문서\\GitHub\\eeg_analysis\\train\\train_script.py:62\u001b[0m, in \u001b[0;36mtrain_with_wandb\u001b[1;34m(config, train_loader, val_loader, test_loader, test_loader_longer, preprocess_train, preprocess_test, class_label_to_type)\u001b[0m\n\u001b[0;32m     60\u001b[0m model_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 62\u001b[0m     config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m'\u001b[39m], lr_search, model_state \u001b[38;5;241m=\u001b[39m \u001b[43mlearning_rate_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mLR \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLR\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     67\u001b[0m     draw_learning_rate_record(lr_search, use_wandb\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\OneDrive\\문서\\GitHub\\eeg_analysis\\train\\train_script.py:38\u001b[0m, in \u001b[0;36mlearning_rate_search\u001b[1;34m(config, train_loader, preprocess, trials, steps)\u001b[0m\n\u001b[0;32m     33\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer,\n\u001b[0;32m     34\u001b[0m                                       step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterations\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_decay_timing\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m     35\u001b[0m                                       gamma\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_decay_gamma\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     37\u001b[0m tr_ms \u001b[38;5;241m=\u001b[39m train_multistep \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmixup\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-12\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m train_mixup_multistep\n\u001b[1;32m---> 38\u001b[0m _, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtr_ms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Train accuracy for the final epoch is stored\u001b[39;00m\n\u001b[0;32m     41\u001b[0m learning_rate_record\u001b[38;5;241m.\u001b[39mappend((log_lr, train_accuracy))\n",
      "File \u001b[1;32m~\\OneDrive\\문서\\GitHub\\eeg_analysis\\train\\train_core.py:19\u001b[0m, in \u001b[0;36mtrain_multistep\u001b[1;34m(model, loader, preprocess, optimizer, scheduler, config, steps)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     te \u001b[38;5;241m=\u001b[39m TimeElapsed()\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sample_batched \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28mprint\u001b[39m(te\u001b[38;5;241m.\u001b[39melapsed_str())\n\u001b[0;32m     22\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg_analysis\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg_analysis\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg_analysis\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg_analysis\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\OneDrive\\문서\\GitHub\\eeg_analysis\\datasets\\cau_eeg_dataset.py:221\u001b[0m, in \u001b[0;36mCauEegDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# signal\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeather\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 221\u001b[0m     signal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_feather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     signal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_memmap(m)\n",
      "File \u001b[1;32m~\\OneDrive\\문서\\GitHub\\eeg_analysis\\datasets\\cau_eeg_dataset.py:242\u001b[0m, in \u001b[0;36mCauEegDataset.read_feather\u001b[1;34m(self, m)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_feather\u001b[39m(\u001b[38;5;28mself\u001b[39m, m):\n\u001b[0;32m    241\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msignal/feather\u001b[39m\u001b[38;5;124m'\u001b[39m, m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserial\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.feather\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 242\u001b[0m     signal \u001b[38;5;241m=\u001b[39m \u001b[43mfeather\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_feather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# m['channel'] = df.columns.to_list()\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m signal\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg_analysis\\lib\\site-packages\\pyarrow\\feather.py:220\u001b[0m, in \u001b[0;36mread_feather\u001b[1;34m(source, columns, use_threads, memory_map)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03mRead a pandas.DataFrame from Feather format. To read as pyarrow.Table use\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03mfeather.read_table.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03mdf : pandas.DataFrame\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m _check_pandas_version()\n\u001b[1;32m--> 220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_pandas(use_threads\u001b[38;5;241m=\u001b[39muse_threads))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg_analysis\\lib\\site-packages\\pyarrow\\feather.py:248\u001b[0m, in \u001b[0;36mread_table\u001b[1;34m(source, columns, memory_map, use_threads)\u001b[0m\n\u001b[0;32m    244\u001b[0m reader \u001b[38;5;241m=\u001b[39m _feather\u001b[38;5;241m.\u001b[39mFeatherReader(\n\u001b[0;32m    245\u001b[0m     source, use_memory_map\u001b[38;5;241m=\u001b[39mmemory_map, use_threads\u001b[38;5;241m=\u001b[39muse_threads)\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    250\u001b[0m column_types \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtype\u001b[39m(column) \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m columns]\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m t: t \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mint\u001b[39m, column_types)):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wandb_run = wandb.init(project=\"eeg-analysis\")\n",
    "wandb.run.name = wandb.run.id\n",
    "\n",
    "with wandb_run:\n",
    "    # wandb config update\n",
    "    config = {}\n",
    "    for k, v in {**cfg_data, **cfg_train, **cfg_model}.items():\n",
    "        if k not in wandb.config:\n",
    "            config[k] = v\n",
    "\n",
    "    # to prevent callables from type-conversion to str\n",
    "    config['history_interval'] = config['iterations'] // config['num_history']\n",
    "    wandb.config.update(config)\n",
    "    for k, v in wandb.config.items():\n",
    "        if k not in config:\n",
    "            config[k] = v\n",
    "\n",
    "    if cfg_data.get('crop_multiple', 1) == 1:\n",
    "        config['in_channels'] = train_loader.dataset[0]['signal'].shape[0]\n",
    "    else:\n",
    "        config['in_channels'] = train_loader.dataset[0]['signal'][0].shape[0]\n",
    "    config['out_dims'] = len(class_label_to_type)\n",
    "\n",
    "    # train the model\n",
    "    train_with_wandb(config, train_loader, val_loader, test_loader, test_loader_longer, \n",
    "                     preprocess_train, preprocess_test, class_label_to_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
