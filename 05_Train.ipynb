{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Networks\n",
    "\n",
    "- Three-way SoftMax or Multi-BCE classifier of normal, non-vascular MCI, and non-vascular dementia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pprint\n",
    "import wandb\n",
    "\n",
    "# custom package\n",
    "from models import *\n",
    "from utils.eeg_dataset import *\n",
    "from utils.train_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook name\n",
    "def get_notebook_name():\n",
    "    import ipynbname\n",
    "    return ipynbname.name()\n",
    "nb_fname = get_notebook_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.9.0\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Set the default configuration for building datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_data = {}\n",
    "cfg_data['device'] = device\n",
    "cfg_data['dataset'] = 'CAUHS'\n",
    "cfg_data['data_path'] = r'dataset/02_Curated_Data/'\n",
    "cfg_data['meta_path'] = os.path.join(cfg_data['data_path'], 'metadata_debug.json')\n",
    "cfg_data['target_task'] = 'Normal, MCI, Dementia' # 'Norml, MCI, Dementia'\n",
    "cfg_data['vascular'] = 'X'\n",
    "cfg_data['segment'] = 'no' # 'train', 'all', 'no'\n",
    "cfg_data['seed'] = 0\n",
    "cfg_data['crop_length'] = 200 * 10 # 10 seconds\n",
    "cfg_data['longer_crop_length'] = 200 * 10 * 10 # 100 seconds\n",
    "cfg_data['input_norm'] = 'dataset' # 'datatset', 'datapoint', 'no'\n",
    "cfg_data['EKG'] = 'O'\n",
    "cfg_data['photic'] = 'X'\n",
    "cfg_data['awgn'] = 5e-2\n",
    "cfg_data['awgn_age'] = 5e-2\n",
    "cfg_data['minibatch'] = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_label_to_type: ['Normal', 'Non-vascular MCI', 'Non-vascular dementia']\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- There are 463 data belonging to Normal\n",
      "- There are 347 data belonging to Non-vascular MCI\n",
      "- There are 229 data belonging to Non-vascular dementia\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Train data label distribution\t: [370, 278, 183] 831\n",
      "Train data label distribution\t: [46, 35, 23] 104\n",
      "Train data label distribution\t: [47, 34, 23] 104\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "composed_train: Compose(\n",
      "    <utils.eeg_dataset.EEGRandomCrop object at 0x0000025FCB6DAAC0>\n",
      "    <utils.eeg_dataset.EEGNormalizeMeanStd object at 0x0000025FC861A8E0>\n",
      "    <utils.eeg_dataset.EEGNormalizeAge object at 0x0000025FCC6CC430>\n",
      "    <utils.eeg_dataset.EEGDropPhoticChannel object at 0x0000025FD431D880>\n",
      "    <utils.eeg_dataset.EEGAddGaussianNoise object at 0x0000025FD431DCD0>\n",
      "    <utils.eeg_dataset.EEGAddGaussianNoiseAge object at 0x0000025FD43159A0>\n",
      "    <utils.eeg_dataset.EEGToTensor object at 0x0000025FD4315730>\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "composed_test: Compose(\n",
      "    <utils.eeg_dataset.EEGRandomCrop object at 0x0000025FCC6CC3D0>\n",
      "    <utils.eeg_dataset.EEGNormalizeMeanStd object at 0x0000025FCC6CC400>\n",
      "    <utils.eeg_dataset.EEGNormalizeAge object at 0x0000025FCC6BE910>\n",
      "    <utils.eeg_dataset.EEGDropPhoticChannel object at 0x0000025FD431DC70>\n",
      "    <utils.eeg_dataset.EEGToTensor object at 0x0000025FD4315D60>\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "longer_composed_test: Compose(\n",
      "    <utils.eeg_dataset.EEGRandomCrop object at 0x0000025FD4315DF0>\n",
      "    <utils.eeg_dataset.EEGNormalizeMeanStd object at 0x0000025FD4315C70>\n",
      "    <utils.eeg_dataset.EEGNormalizeAge object at 0x0000025FD4315400>\n",
      "    <utils.eeg_dataset.EEGDropPhoticChannel object at 0x0000025FD43150A0>\n",
      "    <utils.eeg_dataset.EEGToTensor object at 0x0000025FD4315FA0>\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "train_dataset[0]:\n",
      "torch.Size([20, 2000])\n",
      "{'signal': tensor([[-0.2518, -0.2477, -0.3010,  ...,  0.3459,  0.3826,  0.3517],\n",
      "        [ 1.2181,  1.2335,  1.1762,  ...,  1.3601,  1.4364,  1.3324],\n",
      "        [ 0.0562, -0.1588, -0.5602,  ...,  1.4140,  1.2781,  1.0074],\n",
      "        ...,\n",
      "        [ 1.0331,  1.0331,  0.8950,  ..., -0.3154, -0.4958, -0.5168],\n",
      "        [-1.2334, -1.0541, -1.1851,  ..., -1.5839, -1.5567, -1.5537],\n",
      "        [-0.1293,  0.0662,  0.0063,  ...,  0.0717,  0.2505,  0.0508]]), 'age': tensor(-1.1974), 'class_label': tensor(0), 'metadata': {'serial': '01012', 'edfname': '01212635_270515', 'birth': '1956-06-01', 'record': '2015-05-27T09:37:24', 'age': 58, 'dx1': 'cb_normal', 'label': ['normal', 'cb_normal'], 'events': [[0, 'Start Recording'], [0, 'New Montage - Montage 002'], [400, 'Eyes Open'], [7918, 'Eyes Closed'], [14091, 'Eyes Open'], [18208, 'Eyes Closed'], [24256, 'Eyes Open'], [30724, 'Eyes Closed'], [36562, 'Eyes Open'], [42190, 'Eyes Closed'], [48910, 'Eyes Open'], [55126, 'Eyes Closed'], [60417, 'Eyes Open'], [66004, 'Eyes Closed'], [71968, 'Eyes Open'], [78310, 'Eyes Closed'], [84442, 'Eyes Open'], [90070, 'Eyes Closed'], [96076, 'Eyes Open'], [102082, 'Eyes Closed'], [108844, 'Eyes Open'], [113674, 'Eyes Closed'], [120000, 'Paused']], 'class_type': 'Normal', 'class_label': 0}}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "val_dataset[0]:\n",
      "torch.Size([20, 2000])\n",
      "{'signal': tensor([[-0.9372, -0.8709, -0.8709,  ...,  0.4557,  0.5441,  0.6547],\n",
      "        [-0.9229, -0.8747, -1.0192,  ...,  0.6182,  0.8590,  1.1479],\n",
      "        [-0.3535, -0.4410, -0.5284,  ..., -0.1786,  0.0839,  0.4337],\n",
      "        ...,\n",
      "        [-0.5370, -0.5370, -0.5370,  ...,  0.1011,  0.4657,  0.5569],\n",
      "        [ 0.1841, -0.0842, -0.1736,  ...,  0.3629,  0.3629,  0.1841],\n",
      "        [-0.4040, -0.3083, -0.3402,  ..., -0.1062, -0.0530, -0.0424]]), 'age': tensor(0.7204), 'class_label': tensor(1), 'metadata': {'serial': '00700', 'edfname': '00985401_011117', 'birth': '1940-09-09', 'record': '2017-11-01T14:20:48', 'age': 77, 'dx1': 'mci amnestic', 'label': ['mci', 'mci_amnestic'], 'events': [[0, 'Start Recording'], [0, 'New Montage - Montage 002'], [1705, 'Eyes Open'], [5402, 'Eyes Closed'], [13046, 'Eyes Open'], [17666, 'Eyes Closed'], [30308, 'Eyes Closed'], [36272, 'Eyes Open'], [41774, 'Eyes Closed'], [48958, 'Eyes Open'], [55510, 'Eyes Closed'], [61641, 'Eyes Open'], [66766, 'Eyes Closed'], [72730, 'Eyes Open'], [78988, 'Eyes Closed'], [87770, 'Eyes Open'], [90542, 'Eyes Closed'], [97096, 'Eyes Open'], [102178, 'Eyes Closed'], [110872, 'Eyes Open'], [113728, 'Eyes Closed'], [122052, 'Photic On - 3.0 Hz'], [122428, 'Eyes Open'], [123309, 'Eyes Closed'], [124068, 'Photic Off'], [126126, 'Photic On - 6.0 Hz'], [128142, 'Photic Off'], [130158, 'Photic On - 9.0 Hz'], [132216, 'Photic Off'], [132718, 'Eyes Open'], [133600, 'Eyes Closed'], [134232, 'Photic On - 12.0 Hz'], [136248, 'Photic Off'], [138306, 'Photic On - 15.0 Hz'], [140322, 'Photic Off'], [142380, 'Photic On - 18.0 Hz'], [142630, 'Eyes Open'], [143302, 'Eyes Closed'], [144396, 'Photic Off'], [146412, 'Photic On - 21.0 Hz'], [148428, 'Photic Off'], [150486, 'Photic On - 24.0 Hz'], [152502, 'Photic Off'], [152710, 'Eyes Open'], [153550, 'Eyes Closed'], [154560, 'Photic On - 27.0 Hz'], [156576, 'Photic Off'], [158592, 'Photic On - 30.0 Hz'], [160608, 'Photic Off'], [160942, 'Eyes Open'], [161698, 'Eyes Closed'], [169132, 'Eyes Open'], [170098, 'Eyes Closed'], [173600, 'Paused']], 'class_type': 'Non-vascular MCI', 'class_label': 1}}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_dataset[0]:\n",
      "torch.Size([20, 2000])\n",
      "{'signal': tensor([[-0.0307, -0.0307,  0.0135,  ...,  5.1208,  5.1429,  5.1651],\n",
      "        [ 0.4256,  0.3774,  0.3292,  ...,  2.0630,  2.2074,  2.3037],\n",
      "        [-0.1786, -0.2660, -0.4410,  ..., -1.1407, -0.9658, -0.8783],\n",
      "        ...,\n",
      "        [-0.4459, -0.1724, -0.1724,  ..., -0.3547, -0.3547, -0.3547],\n",
      "        [-0.7995, -0.4418, -0.3524,  ..., -1.7831, -1.7831, -1.7831],\n",
      "        [-0.4147, -0.3189, -0.1488,  ...,  0.1065,  0.0852,  0.0533]]), 'age': tensor(1.0259), 'class_label': tensor(0), 'metadata': {'serial': '00299', 'edfname': '00671212_160819', 'birth': '1938-08-17', 'record': '2019-08-16T10:57:03', 'age': 80, 'dx1': 'smi', 'label': ['normal', 'smi'], 'events': [[0, 'Start Recording'], [0, 'New Montage - Montage 005'], [1773, 'Eyes Closed'], [6000, 'Cz check'], [7612, 'Eyes Open'], [12912, 'Eyes Closed'], [18078, 'Eyes Open'], [23958, 'Eyes Closed'], [29288, 'Eyes Open'], [35934, 'Eyes Closed'], [41856, 'Eyes Open'], [47862, 'Eyes Closed'], [54460, 'Eyes Open'], [59962, 'Eyes Closed'], [66178, 'Eyes Open'], [71008, 'Eyes Closed'], [73948, 'Photic On - 3.0 Hz'], [74158, 'Eyes Open'], [75166, 'Eyes Closed'], [75964, 'Photic Off'], [77980, 'Photic On - 6.0 Hz'], [78358, 'Eyes Open'], [79282, 'Eyes Closed'], [80038, 'Photic Off'], [82054, 'Photic On - 9.0 Hz'], [84070, 'Photic Off'], [86128, 'Photic On - 12.0 Hz'], [87640, 'Eyes Open'], [88144, 'Photic Off'], [88396, 'Eyes Closed'], [90202, 'Photic On - 15.0 Hz'], [92218, 'Photic Off'], [92722, 'Eyes Open'], [93772, 'Eyes Closed'], [94234, 'Photic On - 18.0 Hz'], [96250, 'Photic Off'], [98308, 'Photic On - 21.0 Hz'], [100324, 'Photic Off'], [102382, 'Photic On - 24.0 Hz'], [104398, 'Photic Off'], [106414, 'Photic On - 27.0 Hz'], [108430, 'Photic Off'], [110488, 'Photic On - 30.0 Hz'], [111580, 'Eyes Open'], [111790, 'Photic Off'], [112420, 'Eyes Closed'], [113200, 'Paused']], 'class_type': 'Normal', 'class_label': 0}}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_dataset_longer[0]:\n",
      "torch.Size([20, 20000])\n",
      "{'signal': tensor([[ 0.9642,  1.0305,  1.0969,  ..., -0.8488, -0.8488, -0.7604],\n",
      "        [-0.2005, -0.1042, -0.0560,  ..., -0.2968, -0.2487, -0.0560],\n",
      "        [-0.3535, -0.3535, -0.2660,  ...,  0.3463,  0.4337,  0.5212],\n",
      "        ...,\n",
      "        [-0.0812, -0.0812, -0.0812,  ...,  0.1922,  0.1011,  0.1011],\n",
      "        [-0.5313, -0.7995, -0.7995,  ...,  0.5417,  0.3629,  0.2735],\n",
      "        [ 2.9783,  1.8934,  1.2340,  ...,  0.3086,  0.1171,  0.0533]]), 'age': tensor(1.0259), 'class_label': tensor(0), 'metadata': {'serial': '00299', 'edfname': '00671212_160819', 'birth': '1938-08-17', 'record': '2019-08-16T10:57:03', 'age': 80, 'dx1': 'smi', 'label': ['normal', 'smi'], 'events': [[0, 'Start Recording'], [0, 'New Montage - Montage 005'], [1773, 'Eyes Closed'], [6000, 'Cz check'], [7612, 'Eyes Open'], [12912, 'Eyes Closed'], [18078, 'Eyes Open'], [23958, 'Eyes Closed'], [29288, 'Eyes Open'], [35934, 'Eyes Closed'], [41856, 'Eyes Open'], [47862, 'Eyes Closed'], [54460, 'Eyes Open'], [59962, 'Eyes Closed'], [66178, 'Eyes Open'], [71008, 'Eyes Closed'], [73948, 'Photic On - 3.0 Hz'], [74158, 'Eyes Open'], [75166, 'Eyes Closed'], [75964, 'Photic Off'], [77980, 'Photic On - 6.0 Hz'], [78358, 'Eyes Open'], [79282, 'Eyes Closed'], [80038, 'Photic Off'], [82054, 'Photic On - 9.0 Hz'], [84070, 'Photic Off'], [86128, 'Photic On - 12.0 Hz'], [87640, 'Eyes Open'], [88144, 'Photic Off'], [88396, 'Eyes Closed'], [90202, 'Photic On - 15.0 Hz'], [92218, 'Photic Off'], [92722, 'Eyes Open'], [93772, 'Eyes Closed'], [94234, 'Photic On - 18.0 Hz'], [96250, 'Photic Off'], [98308, 'Photic On - 21.0 Hz'], [100324, 'Photic Off'], [102382, 'Photic On - 24.0 Hz'], [104398, 'Photic Off'], [106414, 'Photic On - 27.0 Hz'], [108430, 'Photic Off'], [110488, 'Photic On - 30.0 Hz'], [111580, 'Eyes Open'], [111790, 'Photic Off'], [112420, 'Eyes Closed'], [113200, 'Paused']], 'class_type': 'Normal', 'class_label': 0}}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "0 torch.Size([32, 20, 2000]) torch.Size([32]) torch.Size([32]) 32\n",
      "1 torch.Size([32, 20, 2000]) torch.Size([32]) torch.Size([32]) 32\n",
      "2 torch.Size([32, 20, 2000]) torch.Size([32]) torch.Size([32]) 32\n",
      "3 torch.Size([32, 20, 2000]) torch.Size([32]) torch.Size([32]) 32\n",
      "4 torch.Size([32, 20, 2000]) torch.Size([32]) torch.Size([32]) 32\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = build_dataset(cfg_data, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Define Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_common_model = {'in_channels': _[0].dataset[0]['signal'].shape[0], \n",
    "                    'out_dims': len(_[-1])}\n",
    "cfg_model_pool = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D Tiny CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Model config:'\n",
      "{'LR': 0.001,\n",
      " 'base_channels': 64,\n",
      " 'fc_stages': 1,\n",
      " 'final_pool': 'max',\n",
      " 'generator': <class 'models.simple_cnn_1d.TinyCNN1D'>,\n",
      " 'in_channels': 20,\n",
      " 'model': '1D-Tiny-CNN',\n",
      " 'out_dims': 3,\n",
      " 'use_age': 'fc'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "TinyCNN1D(\n",
      "  (conv1): Conv1d(20, 64, kernel_size=(35,), stride=(7,))\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (final_pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc_stage): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=65, out_features=32, bias=False)\n",
      "      (1): Dropout(p=0.3, inplace=False)\n",
      "      (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Linear(in_features=32, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-Tiny-CNN'\n",
    "cfg_model['generator'] = TinyCNN1D\n",
    "cfg_model['fc_stages'] = 1\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M7 model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Model config:'\n",
      "{'LR': 0.001,\n",
      " 'base_channels': 256,\n",
      " 'fc_stages': 1,\n",
      " 'final_pool': 'max',\n",
      " 'generator': <class 'models.simple_cnn_1d.M7'>,\n",
      " 'in_channels': 20,\n",
      " 'model': '1D-Mx',\n",
      " 'out_dims': 3,\n",
      " 'use_age': 'fc'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "M7(\n",
      "  (conv1): Conv1d(20, 256, kernel_size=(41,), stride=(2,))\n",
      "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(256, 256, kernel_size=(11,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(256, 512, kernel_size=(11,), stride=(1,))\n",
      "  (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv1d(512, 512, kernel_size=(11,), stride=(1,))\n",
      "  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool4): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv5): Conv1d(512, 512, kernel_size=(11,), stride=(1,))\n",
      "  (bn5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (final_pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc_stage): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=513, out_features=256, bias=False)\n",
      "      (1): Dropout(p=0.3, inplace=False)\n",
      "      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Linear(in_features=256, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-Mx'\n",
    "cfg_model['generator'] = M7\n",
    "cfg_model['fc_stages'] = 1\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 256\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNet model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Model config:'\n",
      "{'LR': 0.001,\n",
      " 'base_channels': 64,\n",
      " 'block': <class 'models.resnet_1d.BottleneckBlock1D'>,\n",
      " 'conv_layers': [2, 2, 2, 2],\n",
      " 'fc_stages': 3,\n",
      " 'final_pool': 'max',\n",
      " 'generator': <class 'models.resnet_1d.ResNet1D'>,\n",
      " 'in_channels': 20,\n",
      " 'model': '1D-ResNet-2x',\n",
      " 'out_dims': 3,\n",
      " 'use_age': 'fc'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "ResNet1D(\n",
      "  (input_stage): Sequential(\n",
      "    (0): Conv1d(20, 64, kernel_size=(27,), stride=(2,), padding=(13,), bias=False)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (conv_stage1): Sequential(\n",
      "    (0): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage2): Sequential(\n",
      "    (0): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage3): Sequential(\n",
      "    (0): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage4): Sequential(\n",
      "    (0): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (final_pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc_stage): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=2049, out_features=1024, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=256, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (3): Linear(in_features=256, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-2x'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deeper 1D ResNet model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Model config:'\n",
      "{'LR': 0.001,\n",
      " 'base_channels': 64,\n",
      " 'base_stride': 4,\n",
      " 'block': <class 'models.resnet_1d.BottleneckBlock1D'>,\n",
      " 'conv_layers': [3, 4, 6, 3],\n",
      " 'fc_stages': 3,\n",
      " 'final_pool': 'max',\n",
      " 'first_dilation': 2,\n",
      " 'generator': <class 'models.resnet_1d.ResNet1D'>,\n",
      " 'in_channels': 20,\n",
      " 'model': '1D-ResNet-5x',\n",
      " 'out_dims': 3,\n",
      " 'use_age': 'fc'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "ResNet1D(\n",
      "  (input_stage): Sequential(\n",
      "    (0): Conv1d(20, 64, kernel_size=(27,), stride=(2,), padding=(13,), dilation=(2,), bias=False)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (conv_stage1): Sequential(\n",
      "    (0): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage2): Sequential(\n",
      "    (0): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage3): Sequential(\n",
      "    (0): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage4): Sequential(\n",
      "    (0): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): BottleneckBlock1D(\n",
      "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (final_pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc_stage): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=2049, out_features=1024, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=256, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (3): Linear(in_features=256, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "torch.Size([32, 2048, 3])\n"
     ]
    }
   ],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-5x'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shallower 1D ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-2x'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BasicBlock1D\n",
    "cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tiny 1D ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-1x'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BasicBlock1D\n",
    "cfg_model['conv_layers'] = [1, 1, 1, 1]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Dilated 1D ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-Multi-Dilated-ResNet-5x'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = MultiBottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 32\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNeXt-53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNeXt-5x'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['groups'] = 32\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNeXt-103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNeXt-10x'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [3, 4, 23, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['groups'] = 32\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNet-20 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '2D-ResNet-2x' # resnet-18 + three more fc layer\n",
    "cfg_model['generator'] = ResNet2D\n",
    "cfg_model['block'] = BasicBlock2D\n",
    "cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['n_fft'] = 100\n",
    "cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNet-52 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '2D-ResNet-5x' # resnet-50 + three more fc layer\n",
    "cfg_model['generator'] = ResNet2D\n",
    "cfg_model['block'] = Bottleneck2D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['n_fft'] = 100\n",
    "cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNeXt-104 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '2D-ResNeXt-10x' # resnet-101 + three more fc layer\n",
    "cfg_model['generator'] = ResNet2D\n",
    "cfg_model['block'] = Bottleneck2D\n",
    "cfg_model['conv_layers'] = [3, 4, 23, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['n_fft'] = 100\n",
    "cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "cfg_model['groups'] = 32\n",
    "cfg_model['width_per_group'] = 8\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN-Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-CNN-Transformer'\n",
    "cfg_model['generator'] = CNNTransformer\n",
    "cfg_model['fc_stages'] = 2\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 256\n",
    "cfg_model['n_encoders'] = 4\n",
    "cfg_model['n_heads'] = 4\n",
    "cfg_model['dropout'] = 0.2\n",
    "cfg_model['LR'] = 1e-3\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, train_loader, device, nb_fname, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize the loaded models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cfg_model in cfg_model_pool:\n",
    "    pprint.pp(cfg_model, width=150)\n",
    "    print('\\n' + '-' * 100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Default Configurations for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training configurations\n",
    "cfg_train = {}\n",
    "cfg_train['iterations'] = 100000\n",
    "cfg_train['history_interval'] = cfg_train['iterations'] // 500\n",
    "cfg_train['lr_decay_step'] = round(cfg_train['iterations'] * 0.8)\n",
    "cfg_train['lr_decay_gamma'] = 0.1\n",
    "cfg_train['weight_decay'] = 1e-2\n",
    "cfg_train['mixup'] = 0.0 # 0 for no usage\n",
    "cfg_train['criterion'] = 'cross-entropy' # 'cross-entropy', 'multi-bce'\n",
    "\n",
    "cfg_train['device'] = device\n",
    "cfg_train['save_model'] = True\n",
    "cfg_train['save_temporary'] = False\n",
    "cfg_train['draw_result'] = True\n",
    "cfg_train['watch_model'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_wandb(config, train_loader, val_loader, test_loader, test_loader_longer, class_label_to_type):\n",
    "    print('*'*120)\n",
    "    print(f'{\"*\"*30}{config[\"model\"] + \" train starts\":^60}{\"*\"*30}')\n",
    "    print('*'*120)\n",
    "\n",
    "    # generate model and its trainer        \n",
    "    model = config['generator'](**config).to(device)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), \n",
    "                            lr=config['LR'], \n",
    "                            weight_decay=config['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, \n",
    "                                          step_size=config['lr_decay_step'], \n",
    "                                          gamma=config['lr_decay_gamma'])\n",
    "    \n",
    "    tr_ms = train_multistep if config.get('mixup', 0) < 1e-12 else train_mixup_multistep\n",
    "    \n",
    "    # track granients and weights statistics\n",
    "    if config.get('watch_model', None):\n",
    "        wandb.watch(model, log='all', \n",
    "                    log_freq=config['history_interval'], \n",
    "                    log_graph=True)\n",
    "\n",
    "    # train and validation routine\n",
    "    best_val_acc = 0\n",
    "    for i in range(0, config[\"iterations\"], config[\"history_interval\"]):\n",
    "        # train 'history_interval' steps\n",
    "        loss, train_acc = tr_ms(model, train_loader, optimizer, scheduler, \n",
    "                                config, config[\"history_interval\"])\n",
    "\n",
    "        # validation\n",
    "        val_acc, _, _, _, _ = check_accuracy(model, val_loader, config, repeat=10)\n",
    "\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = deepcopy(model.state_dict())\n",
    "            if config['save_model'] and config['save_temporary']:\n",
    "                save_path = f'checkpoint_temp/{wandb.run.name}/'\n",
    "                os.makedirs(save_path, exist_ok=True)\n",
    "                path = os.path.join(save_path, f'{config[\"model\"]}')\n",
    "                torch.save(best_model_state, path)\n",
    "\n",
    "        # log\n",
    "        wandb.log({'Loss': loss, \n",
    "                   'Train Accuracy': train_acc, \n",
    "                   'Validation Accuracy': val_acc}, step=i)\n",
    "\n",
    "    # calculate the test accuracies for best and last models\n",
    "    last_model_state = deepcopy(model.state_dict())\n",
    "    last_test_result = check_accuracy(model, test_loader, config, repeat=30)\n",
    "    last_test_acc = last_test_result[0]\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "    best_test_result = check_accuracy(model, test_loader, config, repeat=30)\n",
    "    best_test_acc = best_test_result[0]\n",
    "\n",
    "    if last_test_acc < best_test_acc:\n",
    "        model_state = best_model_state\n",
    "        test_result = best_test_result\n",
    "    else:\n",
    "        model_state = last_model_state\n",
    "        test_result = last_test_result\n",
    "\n",
    "    model.load_state_dict(model_state)\n",
    "    test_acc, test_confusion, test_debug, score, target = test_result\n",
    "\n",
    "    # calculate the test accuracies for final model on much longer sequence\n",
    "    last_test_result = check_accuracy(model, test_loader_longer, config, repeat=30)\n",
    "    longer_test_acc = last_test_result[0]\n",
    "\n",
    "    # save the model\n",
    "    if config['save_model']:\n",
    "        save_path = f'checkpoint_temp/{wandb.run.name}/'\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        path = os.path.join(save_path, f'{config[\"model\"]}')\n",
    "        torch.save(model_state, path)\n",
    "\n",
    "    # leave the message\n",
    "    wandb.config.final_shape = model.get_final_shape()\n",
    "    wandb.config.num_params = count_parameters(model)\n",
    "    wandb.log({'Test Accuracy': test_acc,\n",
    "               '(Best / Last) Test Accuracy': ('Best' if last_test_acc < best_test_acc else 'Last', \n",
    "                                               round(best_test_acc, 2), round(last_test_acc, 2)),\n",
    "               'Confusion Matrix (Array)': test_confusion,\n",
    "               'Test Accuracy (Longer)': longer_test_acc, \n",
    "               'Test Debug Table/Serial': test_debug[0], \n",
    "               'Test Debug Table/EDF': test_debug[1], \n",
    "               'Test Debug Table/Pred': test_debug[2], \n",
    "               'Test Debug Table/GT': test_debug[3]})\n",
    "\n",
    "    if 'lr_search' in config:\n",
    "        draw_learning_rate_record(config['lr_search'], use_wandb=True)\n",
    "\n",
    "    if config['draw_result']:\n",
    "        draw_roc_curve(score, target, class_label_to_type, use_wandb=True)\n",
    "        draw_confusion(test_confusion, class_label_to_type, use_wandb=True)\n",
    "        draw_debug_table(test_debug, use_wandb=True)\n",
    "        wandb.log({\"Confusion Matrix\": wandb.plot.confusion_matrix(y_true=target, \n",
    "                                                                   preds=score.argmax(axis=-1), \n",
    "                                                                   class_names=class_label_to_type)})\n",
    "        wandb.log({\"ROC Curve\": wandb.plot.roc_curve(target, score, labels=class_label_to_type)})\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sweep(cfg_data, cfg_train, cfg_model_pool):\n",
    "    wandb_run = wandb.init()\n",
    "    wandb.run.name = wandb.run.id\n",
    "    with wandb_run:\n",
    "        # wandb config update\n",
    "        cfg_model = cfg_model_pool[wandb.config.model_index]\n",
    "        config = {}\n",
    "        for k, v in {**cfg_data, **cfg_train, **cfg_model}.items():\n",
    "            if k not in wandb.config:\n",
    "                config[k] = v\n",
    "        \n",
    "        # to prevent callables from type-conversion to str\n",
    "        wandb.config.update(config)\n",
    "        for k, v in wandb.config.items():\n",
    "            if k not in config:\n",
    "                config[k] = v\n",
    "                \n",
    "        # build dataset\n",
    "        train_loader, val_loader, test_loader, test_loader_longer, class_label_to_type = build_dataset(config)\n",
    "        \n",
    "        config['in_channels'] = train_loader.dataset[0]['signal'].shape[0]\n",
    "        config['out_dims'] = len(class_label_to_type)\n",
    "        \n",
    "        # learning rate search if needed\n",
    "        if config[\"LR\"] is None:\n",
    "            config['LR'], config['lr_search'] = learning_rate_search(config, train_loader, \n",
    "                                                                     min_log_lr=-4.5, max_log_lr=-3.0, \n",
    "                                                                     trials=100, steps=100)\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \n",
    "        # train the model\n",
    "        train_with_wandb(config, train_loader, val_loader, test_loader, test_loader_longer, class_label_to_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_data = {}\n",
    "sweep_data['crop_length'] = {\n",
    "    'values': [200 * 10, # 10 sec\n",
    "               200 * 20, # 20 sec\n",
    "              ],\n",
    "}\n",
    "\n",
    "sweep_data['EKG'] = {\n",
    "    'values': ['O', 'X'],\n",
    "}\n",
    "\n",
    "sweep_data['photic'] = {\n",
    "    'values': ['O', 'X'],\n",
    "}\n",
    "\n",
    "sweep_data['awgn'] = {\n",
    "    'distribution': 'uniform',\n",
    "    'min': 0,\n",
    "    'max': 0.3,\n",
    "}\n",
    "\n",
    "sweep_data['awgn_age'] = {\n",
    "    'distribution': 'uniform',\n",
    "    'min': 0,\n",
    "    'max': 0.3,\n",
    "}\n",
    "\n",
    "sweep_data['minibatch'] = {\n",
    "    'values': [32, ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_model = {}\n",
    "sweep_model['model_index'] = { \n",
    "    'values' : [i for i in range(len(cfg_model_pool))] \n",
    "}\n",
    "\n",
    "sweep_model['fc_stages'] = { \n",
    "    'distribution' : 'int_uniform',\n",
    "    'min': 0,\n",
    "    'max': 4,\n",
    "}\n",
    "\n",
    "sweep_model['use_age'] = { \n",
    "    'values' : ['fc', 'conv']\n",
    "}\n",
    "\n",
    "sweep_model['final_pool'] = { \n",
    "    'values' : ['max', 'average']\n",
    "}\n",
    "\n",
    "sweep_model['first_dilation'] = { \n",
    "    'distribution' : 'int_uniform',\n",
    "    'min': 1,\n",
    "    'max': 2,\n",
    "}\n",
    "\n",
    "sweep_model['base_stride'] = { \n",
    "    'distribution' : 'int_uniform',\n",
    "    'min': 2,\n",
    "    'max': 4,\n",
    "}\n",
    "\n",
    "sweep_model['dropout'] = {\n",
    "    'distribution': 'uniform',\n",
    "    'min': 0.0,\n",
    "    'max': 0.5\n",
    "}\n",
    "\n",
    "sweep_model['LR'] = {\n",
    "    'distribution': 'log_uniform',\n",
    "    'min': math.log(1e-5),\n",
    "    'max': math.log(1e-3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_train = {}\n",
    "sweep_train['iterations'] = {\n",
    "    'values' : [100000, 150000]\n",
    "}\n",
    "\n",
    "sweep_train['lr_decay_gamma'] = {\n",
    "    'distribution' : 'uniform',\n",
    "    'min': 0.1,\n",
    "    'max': 0.5,\n",
    "}\n",
    "\n",
    "sweep_train['lr_decay_step'] = {\n",
    "    'values' : [45000, 80000]\n",
    "}\n",
    "\n",
    "sweep_train['weight_decay'] = {\n",
    "    'distribution' : 'uniform',\n",
    "    'min': math.log(1e-5),\n",
    "    'max': math.log(1e-1)\n",
    "}\n",
    "\n",
    "sweep_train['mixup'] = {\n",
    "    'values': [0, 0.15, 0.3]\n",
    "}\n",
    "\n",
    "sweep_train['criterion'] = {\n",
    "    'values': ['cross-entropy', 'multi-bce']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"entity\": \"ipis-mjkim\",\n",
    "    \"name\" : \"my-sweep\",\n",
    "    \"method\" : \"random\",\n",
    "    \"parameters\" : \n",
    "    {\n",
    "        **sweep_data,\n",
    "        **sweep_model,\n",
    "        **sweep_train,\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"eeg-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, function=lambda: train_sweep(cfg_data, cfg_train, cfg_model_pool), count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
