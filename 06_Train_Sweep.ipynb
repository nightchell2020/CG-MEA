{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Networks\n",
    "\n",
    "- Train SoftMax or Multi-BCE classifier for the EEG diagnosis classification\n",
    "    - CAUEEG-task1 benchmark: Classification of **Normal**, **MCI**, and **Dementia** symptoms\n",
    "    - CAUEEG-task2 benchmark: Classification of **Normal** and **Abnormal** symptoms\n",
    "- `Weights and Biases` sweep is used for hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pprint\n",
    "import wandb\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_dataset import *\n",
    "from datasets.caueeg_script import *\n",
    "from models import *\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.11.0+cu113\n",
      "cuda is available: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    print('cuda is available:', torch.cuda.get_device_name(0))\n",
    "else: \n",
    "    print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Set the default configuration for building datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_data = {}\n",
    "cfg_data['device'] = device\n",
    "cfg_data['task'] = 'task1'\n",
    "cfg_data['dataset_path'] = r'local/dataset/02_Curated_Data_220419/'\n",
    "cfg_data['file_format'] = 'memmap'  # 'feather', 'memmap'\n",
    "cfg_data['load_event'] = False\n",
    "cfg_data['latency'] = 200 * 10      # 10 seconds\n",
    "cfg_data['seq_length'] = 200 * 10  # 10 seconds\n",
    "cfg_data['crop_multiple'] = 4\n",
    "cfg_data['test_crop_multiple'] = 8\n",
    "cfg_data['EKG'] = 'O'\n",
    "cfg_data['photic'] = 'X'\n",
    "cfg_data['input_norm'] = 'dataset'  # 'datatset', 'datapoint', 'no'\n",
    "cfg_data['awgn'] = 5e-2\n",
    "cfg_data['mgn'] = 1e-4\n",
    "cfg_data['awgn_age'] = 5e-2\n",
    "\n",
    "if '3090' in torch.cuda.get_device_name(0):\n",
    "    cfg_data['minibatch'] = 256\n",
    "elif '2080' in torch.cuda.get_device_name(0):\n",
    "    cfg_data['minibatch'] = 128\n",
    "elif '1070' in torch.cuda.get_device_name(0):\n",
    "    cfg_data['minibatch'] = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform: Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=4, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=[20])\n",
      "    EegToTensor()\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "transform_multicrop: Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=8, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=[20])\n",
      "    EegToTensor()\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "task config:\n",
      "{'class_label_to_name': ['Normal', 'MCI', 'Dementia'],\n",
      " 'class_name_to_label': {'Dementia': 2, 'MCI': 1, 'Normal': 0},\n",
      " 'task_description': 'Classification of [Normal], [MCI], and [Dementia] '\n",
      "                     'symptoms.',\n",
      " 'task_name': 'CAUEEG-task1 benchmark'}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "train_dataset[0].keys():\n",
      "dict_keys(['serial', 'age', 'symptom', 'class_name', 'class_label', 'signal'])\n",
      "train signal shape: torch.Size([20, 2000])\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "val_dataset[0].keys():\n",
      "dict_keys(['serial', 'age', 'symptom', 'class_name', 'class_label', 'signal'])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_dataset[0].keys():\n",
      "dict_keys(['serial', 'age', 'symptom', 'class_name', 'class_label', 'signal'])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_dataset[0].keys():\n",
      "dict_keys(['serial', 'age', 'symptom', 'class_name', 'class_label', 'signal'])\n",
      "test signal shape: torch.Size([20, 2000])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "preprocess_train: Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.8962]),std=tensor([9.9162]),eps=1e-08)\n",
      "  (2): EegAddGaussianNoiseAge(mean=0.0,std=0.05)\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([ 0.0805, -0.0197,  0.0003,  0.0080,  0.0154,  0.0918,  0.0047,  0.0038,\n",
      "           0.0347, -0.0032,  0.0276, -0.0596, -0.0327,  0.1034, -0.1042,  0.0311,\n",
      "          -0.0152,  0.0459,  0.0067,  0.0005]),std=tensor([44.3603, 20.2338, 11.5250, 11.5805, 15.2315, 47.3792, 19.7362, 10.3109,\n",
      "          11.5719, 15.2321, 20.3539, 14.0820, 13.6807, 21.7345, 16.0586, 14.6191,\n",
      "          19.3845, 11.0596, 11.2502, 95.0004]),eps=1e-08)\n",
      "  (4): EegAdditiveGaussianNoise(mean=0.0,std=0.05)\n",
      "  (5): EegMultiplicativeGaussianNoise(mean=0.0,std=0.0001)\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "preprocess_test: Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.8962]),std=tensor([9.9162]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([ 0.0805, -0.0197,  0.0003,  0.0080,  0.0154,  0.0918,  0.0047,  0.0038,\n",
      "           0.0347, -0.0032,  0.0276, -0.0596, -0.0327,  0.1034, -0.1042,  0.0311,\n",
      "          -0.0152,  0.0459,  0.0067,  0.0005]),std=tensor([44.3603, 20.2338, 11.5250, 11.5805, 15.2315, 47.3792, 19.7362, 10.3109,\n",
      "          11.5719, 15.2321, 20.3539, 14.0820, 13.6807, 21.7345, 16.0586, 14.6191,\n",
      "          19.3845, 11.0596, 11.2502, 95.0004]),eps=1e-08)\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "0 torch.Size([256, 20, 2000]) torch.Size([256]) torch.Size([256])\n",
      "1 torch.Size([256, 20, 2000]) torch.Size([256]) torch.Size([256])\n",
      "2 torch.Size([256, 20, 2000]) torch.Size([256]) torch.Size([256])\n",
      "3 torch.Size([256, 20, 2000]) torch.Size([256]) torch.Size([256])\n",
      "4 torch.Size([256, 20, 2000]) torch.Size([256]) torch.Size([256])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg_data_temp = deepcopy(cfg_data)\n",
    "_ = build_dataset_for_train(cfg_data_temp, verbose=True)\n",
    "\n",
    "in_channels = cfg_data_temp['preprocess_train'](next(iter(_[0])))['signal'].shape[1]\n",
    "out_dims = len(cfg_data_temp['class_label_to_name'])\n",
    "\n",
    "del _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EKG': 'O',\n",
      " 'age_mean': tensor([70.8962]),\n",
      " 'age_std': tensor([9.9162]),\n",
      " 'awgn': 0.05,\n",
      " 'awgn_age': 0.05,\n",
      " 'class_label_to_name': ['Normal', 'MCI', 'Dementia'],\n",
      " 'class_name_to_label': {'Dementia': 2, 'MCI': 1, 'Normal': 0},\n",
      " 'crop_multiple': 4,\n",
      " 'dataset_name': 'CAUEEG dataset',\n",
      " 'dataset_path': 'local/dataset/02_Curated_Data_220419/',\n",
      " 'device': device(type='cuda'),\n",
      " 'file_format': 'memmap',\n",
      " 'input_norm': 'dataset',\n",
      " 'latency': 2000,\n",
      " 'load_event': False,\n",
      " 'mgn': 0.0001,\n",
      " 'minibatch': 256,\n",
      " 'photic': 'X',\n",
      " 'preprocess_test': Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.8962]),std=tensor([9.9162]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([ 0.0805, -0.0197,  0.0003,  0.0080,  0.0154,  0.0918,  0.0047,  0.0038,\n",
      "           0.0347, -0.0032,  0.0276, -0.0596, -0.0327,  0.1034, -0.1042,  0.0311,\n",
      "          -0.0152,  0.0459,  0.0067,  0.0005]),std=tensor([44.3603, 20.2338, 11.5250, 11.5805, 15.2315, 47.3792, 19.7362, 10.3109,\n",
      "          11.5719, 15.2321, 20.3539, 14.0820, 13.6807, 21.7345, 16.0586, 14.6191,\n",
      "          19.3845, 11.0596, 11.2502, 95.0004]),eps=1e-08)\n",
      "),\n",
      " 'preprocess_train': Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.8962], device='cuda:0'),std=tensor([9.9162]),eps=1e-08)\n",
      "  (2): EegAddGaussianNoiseAge(mean=0.0,std=0.05)\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([ 0.0805, -0.0197,  0.0003,  0.0080,  0.0154,  0.0918,  0.0047,  0.0038,\n",
      "           0.0347, -0.0032,  0.0276, -0.0596, -0.0327,  0.1034, -0.1042,  0.0311,\n",
      "          -0.0152,  0.0459,  0.0067,  0.0005], device='cuda:0'),std=tensor([44.3603, 20.2338, 11.5250, 11.5805, 15.2315, 47.3792, 19.7362, 10.3109,\n",
      "          11.5719, 15.2321, 20.3539, 14.0820, 13.6807, 21.7345, 16.0586, 14.6191,\n",
      "          19.3845, 11.0596, 11.2502, 95.0004]),eps=1e-08)\n",
      "  (4): EegAdditiveGaussianNoise(mean=0.0,std=0.05)\n",
      "  (5): EegMultiplicativeGaussianNoise(mean=0.0,std=0.0001)\n",
      "),\n",
      " 'seq_length': 2000,\n",
      " 'signal_header': ['Fp1-AVG', 'F3-AVG', 'C3-AVG', 'P3-AVG', 'O1-AVG', 'Fp2-AVG', 'F4-AVG', 'C4-AVG', 'P4-AVG', 'O2-AVG', 'F7-AVG', 'T3-AVG', 'T5-AVG', 'F8-AVG', 'T4-AVG', 'T6-AVG', 'FZ-AVG', 'CZ-AVG', 'PZ-AVG', 'EKG', 'Photic'],\n",
      " 'signal_mean': tensor([[[ 0.0805],\n",
      "         [-0.0197],\n",
      "         [ 0.0003],\n",
      "         [ 0.0080],\n",
      "         [ 0.0154],\n",
      "         [ 0.0918],\n",
      "         [ 0.0047],\n",
      "         [ 0.0038],\n",
      "         [ 0.0347],\n",
      "         [-0.0032],\n",
      "         [ 0.0276],\n",
      "         [-0.0596],\n",
      "         [-0.0327],\n",
      "         [ 0.1034],\n",
      "         [-0.1042],\n",
      "         [ 0.0311],\n",
      "         [-0.0152],\n",
      "         [ 0.0459],\n",
      "         [ 0.0067],\n",
      "         [ 0.0005]]]),\n",
      " 'signal_std': tensor([[[44.3603],\n",
      "         [20.2338],\n",
      "         [11.5250],\n",
      "         [11.5805],\n",
      "         [15.2315],\n",
      "         [47.3792],\n",
      "         [19.7362],\n",
      "         [10.3109],\n",
      "         [11.5719],\n",
      "         [15.2321],\n",
      "         [20.3539],\n",
      "         [14.0820],\n",
      "         [13.6807],\n",
      "         [21.7345],\n",
      "         [16.0586],\n",
      "         [14.6191],\n",
      "         [19.3845],\n",
      "         [11.0596],\n",
      "         [11.2502],\n",
      "         [95.0004]]]),\n",
      " 'task': 'task1',\n",
      " 'task_description': 'Classification of [Normal], [MCI], and [Dementia] symptoms.',\n",
      " 'task_name': 'CAUEEG-task1 benchmark',\n",
      " 'test_crop_multiple': 8,\n",
      " 'transform': Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=4, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=[20])\n",
      "    EegToTensor()\n",
      "),\n",
      " 'transform_multicrop': Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=8, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=[20])\n",
      "    EegToTensor()\n",
      ")}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(cfg_data_temp, width=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Define Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft, hop_length, seq_len_2d = calculate_stft_params(seq_length=cfg_data['seq_length'])\n",
    "cfg_temp_model = {\n",
    "    'in_channels': in_channels, \n",
    "    'out_dims': out_dims, \n",
    "    'seq_length': cfg_data['seq_length'],\n",
    "    'stft_params': {'n_fft': n_fft, 'hop_length': hop_length,\n",
    "                    'complex_mode': 'as_real',  # 'as_real', 'power', 'remove'\n",
    "                   }\n",
    "}\n",
    "\n",
    "cfg_model_pool = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Tiny CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model['model'] = '1D-Tiny-CNN'\n",
    "# cfg_model['generator'] = TinyCNN1D\n",
    "# cfg_model['fc_stages'] = 1\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'average'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model['model'] = '1D-M5'\n",
    "# cfg_model['generator'] = M5\n",
    "# cfg_model['fc_stages'] = 1\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'average'\n",
    "# cfg_model['base_channels'] = 256\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model['model'] = '1D-VGG-19'\n",
    "# cfg_model['generator'] = VGG1D\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['batch_norm'] = True\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'average'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D ResNet variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model['model'] = '1D-ResNet-18'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BasicBlock1D\n",
    "# cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'average'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model['model'] = '1D-ResNet-50'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'average'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model['model'] = '1D-ResNet-101'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 23, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'average'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D ResNeXt variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model['model'] = '1D-ResNeXt-50'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'average'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['groups'] = 32\n",
    "# cfg_model['width_per_group'] = 4\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model['model'] = '1D-ResNeXt-101'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 23, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'average'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['groups'] = 32\n",
    "# cfg_model['width_per_group'] = 8\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model['model'] = '2D-VGG-19'\n",
    "# cfg_model['generator'] = VGG2D\n",
    "# cfg_model['seq_len_2d'] = seq_len_2d\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['batch_norm'] = True\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'average'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D ResNet variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model['model'] = '2D-ResNet-18'\n",
    "# cfg_model['generator'] = ResNet2D\n",
    "# cfg_model['block'] = BasicBlock2D\n",
    "# cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "# cfg_model['seq_len_2d'] = seq_len_2d\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'average'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model['model'] = '2D-ResNet-50'\n",
    "# cfg_model['generator'] = ResNet2D\n",
    "# cfg_model['block'] = Bottleneck2D\n",
    "# cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "# cfg_model['seq_len_2d'] = seq_len_2d\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'average'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D ResNeXt variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model['model'] = '2D-ResNeXt-50'\n",
    "# cfg_model['generator'] = ResNet2D\n",
    "# cfg_model['block'] = Bottleneck2D\n",
    "# cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "# cfg_model['seq_len_2d'] = seq_len_2d\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'average'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['groups'] = 32\n",
    "# cfg_model['width_per_group'] = 4\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model['model'] = '2D-ResNeXt-101'\n",
    "# cfg_model['generator'] = ResNet2D\n",
    "# cfg_model['block'] = Bottleneck2D\n",
    "# cfg_model['conv_layers'] = [3, 4, 23, 3]\n",
    "# cfg_model['seq_len_2d'] = seq_len_2d\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'average'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['groups'] = 32\n",
    "# cfg_model['width_per_group'] = 8\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN-Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model['model'] = '1D-CNN-Transformer'\n",
    "# cfg_model['generator'] = CNNTransformer\n",
    "# cfg_model['seq_len_2d'] = seq_len_2d\n",
    "# cfg_model['fc_stages'] = 2\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'average'\n",
    "# cfg_model['base_channels'] = 256  #\n",
    "# cfg_model['n_encoders'] = 8  #\n",
    "# cfg_model['n_heads'] = 8     #\n",
    "# cfg_model['dropout'] = 0.2   #\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vision Transformer (ViT-B-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Model config:'\n",
      "{'LR': None,\n",
      " 'attention_dropout': 0.1,\n",
      " 'dropout': 0.1,\n",
      " 'fc_stages': 2,\n",
      " 'generator': <function vit_b_16 at 0x000001D9E3CBAAF0>,\n",
      " 'minibatch': 64,\n",
      " 'model': '2D-ViT-B-16',\n",
      " 'seq_len_2d': (64, 63),\n",
      " 'use_age': 'conv'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "VisionTransformer(\n",
      "  (conv_proj): Conv2d(21, 768, kernel_size=(4, 5), stride=(4, 4))\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (layers): Sequential(\n",
      "      (encoder_layer_0): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_1): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_2): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_3): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_4): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_5): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_6): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_7): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_8): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_9): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_10): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_11): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (linear_1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU()\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (linear_2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (heads): Sequential(\n",
      "    (linear1): Linear(in_features=768, out_features=384, bias=True)\n",
      "    (act1): Tanh()\n",
      "    (head): Linear(in_features=384, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg_model = {}\n",
    "cfg_model['model'] = '2D-ViT-B-16'\n",
    "cfg_model['generator'] = vit_b_16\n",
    "cfg_model['seq_len_2d'] = seq_len_2d\n",
    "cfg_model['fc_stages'] = 2\n",
    "cfg_model['use_age'] = 'conv'\n",
    "cfg_model['dropout'] = 0.1\n",
    "cfg_model['attention_dropout'] = 0.1\n",
    "cfg_model['LR'] = None\n",
    "cfg_model['minibatch'] = 64  # ViT requires enormous memory to train\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Summarize the loaded models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': '2D-ViT-B-16',\n",
      " 'generator': <function vit_b_16 at 0x000001D9E3CBAAF0>,\n",
      " 'seq_len_2d': (64, 63),\n",
      " 'fc_stages': 2,\n",
      " 'use_age': 'conv',\n",
      " 'dropout': 0.1,\n",
      " 'attention_dropout': 0.1,\n",
      " 'LR': None,\n",
      " 'minibatch': 64}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cfg_model in cfg_model_pool:\n",
    "    pprint.pp(cfg_model, width=150)\n",
    "    print('\\n' + '-' * 100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Default Configurations for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training configurations\n",
    "cfg_train = {}\n",
    "cfg_train['iterations'] = (300000 * 64) // cfg_data['minibatch']\n",
    "cfg_train['warmup_steps'] = max(round(cfg_train['iterations'] * 0.05), 3000)\n",
    "cfg_train['num_history'] = 500\n",
    "cfg_train['lr_scheduler_type'] = 'constant_with_decay'\n",
    "cfg_train['weight_decay'] = 1e-2\n",
    "cfg_train['mixup'] = 0.0  # 0.0 for no usage\n",
    "cfg_train['criterion'] = 'cross-entropy' # 'cross-entropy', 'multi-bce'\n",
    "\n",
    "cfg_train['device'] = device\n",
    "cfg_train['save_model'] = True\n",
    "cfg_train['draw_result'] = True\n",
    "cfg_train['watch_model'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_data = {}\n",
    "sweep_data['seq_length'] = {\n",
    "    'values': [\n",
    "        # 200 *  5, #  5 sec\n",
    "        # 200 * 10, # 10 sec\n",
    "        200 * 20, # 20 sec\n",
    "        # 200 * 30, # 30 sec\n",
    "              ],\n",
    "}\n",
    "\n",
    "sweep_data['EKG'] = {\n",
    "    'values': ['O', 'X'],\n",
    "}\n",
    "\n",
    "sweep_data['photic'] = {\n",
    "    'values': ['O', 'X'],\n",
    "}\n",
    "\n",
    "sweep_data['awgn'] = {\n",
    "    'distribution': 'uniform',\n",
    "    'min': 0,\n",
    "    'max': 0.3,\n",
    "}\n",
    "\n",
    "sweep_data['mgn'] = {\n",
    "    'distribution': 'uniform',\n",
    "    'min': 0,\n",
    "    'max': 0.1,\n",
    "}\n",
    "\n",
    "sweep_data['awgn_age'] = {\n",
    "    'distribution': 'uniform',\n",
    "    'min': 0,\n",
    "    'max': 0.3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_model = {}\n",
    "sweep_model['model_index'] = { \n",
    "    'values': [i for i in range(len(cfg_model_pool))] \n",
    "}\n",
    "\n",
    "sweep_model['fc_stages'] = { \n",
    "    'distribution': 'int_uniform',\n",
    "    'min': 2,\n",
    "    'max': 4,\n",
    "}\n",
    "\n",
    "sweep_model['use_age'] = { \n",
    "    'values': ['fc', 'conv']  # 'fc', 'conv', 'no'\n",
    "}\n",
    "\n",
    "sweep_model['dropout'] = {\n",
    "    'values': [0, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "sweep_model['activation'] = {\n",
    "    'values': ['relu', 'gelu', 'mish']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_train = {}\n",
    "\n",
    "sweep_train['lr_scheduler_type'] = {\n",
    "    'values': [\n",
    "#        'constant_with_decay',\n",
    "        'constant_with_twice_decay',\n",
    "        'transformer_style',\n",
    "        'cosine_decay_with_warmup_half',\n",
    "        'cosine_decay_with_warmup_one_and_half',\n",
    "#        'cosine_decay_with_warmup_two_and_half',\n",
    "        'linear_decay_with_warmup',\n",
    "    ]\n",
    "\n",
    "}\n",
    "\n",
    "# sweep_train['search_multiplier'] = {\n",
    "#     'values': [1.0, 1.2, 2.0]\n",
    "# }\n",
    "\n",
    "sweep_train['weight_decay'] = {\n",
    "    'distribution' : 'log_uniform_values',\n",
    "    'min': 1e-5,\n",
    "    'max': 1e-1\n",
    "}\n",
    "\n",
    "sweep_train['mixup'] = {\n",
    "    'values': [0, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "sweep_train['criterion'] = {\n",
    "    'values': ['cross-entropy', 'multi-bce']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: bn5rzhwe\n",
      "Sweep URL: https://wandb.ai/ipis-mjkim/caueeg-task1/sweeps/bn5rzhwe\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "    \"entity\": \"ipis-mjkim\",\n",
    "    \"name\" : \"my-sweep\",\n",
    "    \"method\": \"random\",\n",
    "    \"parameters\": \n",
    "    {\n",
    "        **sweep_data,\n",
    "        **sweep_model,\n",
    "        **sweep_train,\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=f\"caueeg-{cfg_data['task']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # initialize the wandb log\n",
    "    wandb_run = wandb.init()\n",
    "    wandb.run.name = wandb.run.id\n",
    "\n",
    "    with wandb_run:\n",
    "        # collect some garbages\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "        # load default config\n",
    "        config = {}\n",
    "        cfg_model = cfg_model_pool[wandb.config.model_index]\n",
    "        for k, v in {**cfg_data,  **cfg_model, **cfg_train}.items():\n",
    "            if k not in wandb.config:\n",
    "                config[k] = v\n",
    "                \n",
    "        # load the selected configurations from wandb sweep with preventing callables from type-conversion to str\n",
    "        for k, v in wandb.config.items():\n",
    "            if k not in config:\n",
    "                config[k] = v\n",
    "\n",
    "        # build dataset\n",
    "        train_loader, val_loader, test_loader, multicrop_test_loader = build_dataset_for_train(config)\n",
    "        \n",
    "        # train the model\n",
    "        model = train_with_wandb(config, train_loader, val_loader, test_loader, multicrop_test_loader, \n",
    "                                 config['preprocess_train'], config['preprocess_test'])\n",
    "        \n",
    "        # release memory\n",
    "        del model\n",
    "        del train_loader, val_loader\n",
    "        del test_loader, multicrop_test_loader\n",
    "        del config\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nc5oi7he with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tEKG: X\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tawgn: 0.08285082622965506\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tawgn_age: 0.1629603400450007\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcriterion: cross-entropy\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_stages: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler_type: linear_decay_with_warmup\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmgn: 0.01360874491688574\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmixup: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_index: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tphotic: O\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseq_length: 4000\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_age: conv\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.012134710445872329\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mipis-mjkim\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Minjae\\Desktop\\EEG_Project\\wandb\\run-20220430_015412-nc5oi7he</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ipis-mjkim/caueeg-task1/runs/nc5oi7he\" target=\"_blank\">wise-sweep-1</a></strong> to <a href=\"https://wandb.ai/ipis-mjkim/caueeg-task1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/ipis-mjkim/caueeg-task1/sweeps/bn5rzhwe\" target=\"_blank\">https://wandb.ai/ipis-mjkim/caueeg-task1/sweeps/bn5rzhwe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "******************************                  2D-ViT-B-16 train starts                  ******************************\n",
      "************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=train, count=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
