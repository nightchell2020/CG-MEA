{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Networks\n",
    "\n",
    "- Train SoftMax or Multi-BCE classifier for the EEG diagnosis classification\n",
    "    - CAUEEG-task1 benchmark: Classification of **Normal**, **MCI**, and **Dementia** symptoms\n",
    "    - CAUEEG-task2 benchmark: Classification of **Normal** and **Abnormal** symptoms\n",
    "- PyTorch DDP is used for multi-node/GPU environment\n",
    "- `Weights and Biases` sweep is used for hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import pprint\n",
    "import wandb\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_dataset import *\n",
    "from datasets.caueeg_script import *\n",
    "from models import *\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.11.0+cu113\n",
      "cuda is available: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    print('cuda is available:', torch.cuda.get_device_name(0))\n",
    "else: \n",
    "    print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Set the default configuration for building datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_data = {}\n",
    "cfg_data['device'] = device\n",
    "cfg_data['task'] = 'task1'\n",
    "cfg_data['dataset_path'] = r'local/dataset/02_Curated_Data_220419/'\n",
    "cfg_data['file_format'] = 'memmap'  # 'feather', 'memmap'\n",
    "cfg_data['load_event'] = False\n",
    "cfg_data['latency'] = 200 * 10      # 10 seconds\n",
    "cfg_data['seq_length'] = 200 * 10  # 10 seconds\n",
    "cfg_data['crop_multiple'] = 4\n",
    "cfg_data['test_crop_multiple'] = 8\n",
    "cfg_data['EKG'] = 'O'\n",
    "cfg_data['photic'] = 'X'\n",
    "cfg_data['input_norm'] = 'dataset'  # 'datatset', 'datapoint', 'no'\n",
    "cfg_data['awgn'] = 5e-2\n",
    "cfg_data['mgn'] = 1e-4\n",
    "cfg_data['awgn_age'] = 5e-2\n",
    "\n",
    "if '3090' in torch.cuda.get_device_name(0):\n",
    "    cfg_data['minibatch'] = 256\n",
    "elif '2080' in torch.cuda.get_device_name(0):\n",
    "    cfg_data['minibatch'] = 128\n",
    "elif '1070' in torch.cuda.get_device_name(0):\n",
    "    cfg_data['minibatch'] = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform: Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=4, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=[20])\n",
      "    EegToTensor()\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "transform_multicrop: Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=8, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=[20])\n",
      "    EegToTensor()\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "task config:\n",
      "{'class_label_to_name': ['Normal', 'MCI', 'Dementia'],\n",
      " 'class_name_to_label': {'Dementia': 2, 'MCI': 1, 'Normal': 0},\n",
      " 'task_description': 'Classification of [Normal], [MCI], and [Dementia] '\n",
      "                     'symptoms.',\n",
      " 'task_name': 'CAUEEG-task1 benchmark'}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "train_dataset[0].keys():\n",
      "dict_keys(['serial', 'age', 'symptom', 'class_name', 'class_label', 'signal'])\n",
      "train signal shape: torch.Size([20, 2000])\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "val_dataset[0].keys():\n",
      "dict_keys(['serial', 'age', 'symptom', 'class_name', 'class_label', 'signal'])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_dataset[0].keys():\n",
      "dict_keys(['serial', 'age', 'symptom', 'class_name', 'class_label', 'signal'])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_dataset[0].keys():\n",
      "dict_keys(['serial', 'age', 'symptom', 'class_name', 'class_label', 'signal'])\n",
      "test signal shape: torch.Size([20, 2000])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "preprocess_train: Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.7924]),std=tensor([9.7796]),eps=1e-08)\n",
      "  (2): EegAddGaussianNoiseAge(mean=0.0,std=0.05)\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([-0.0131, -0.0537, -0.0270, -0.0130,  0.0671,  0.1447,  0.0241, -0.0065,\n",
      "           0.0358,  0.0454,  0.0042, -0.0076,  0.0100, -0.0491,  0.1222, -0.0020,\n",
      "          -0.0455, -0.0090, -0.0075, -0.0007]),std=tensor([44.3636, 19.8341, 11.1687, 11.5708, 15.1467, 46.4805, 19.3917, 10.3994,\n",
      "          11.3963, 15.3145, 20.5728, 13.9113, 13.3876, 21.5652, 15.1473, 14.1777,\n",
      "          19.4869, 10.9581, 10.9338, 94.4190]),eps=1e-08)\n",
      "  (4): EegAdditiveGaussianNoise(mean=0.0,std=0.05)\n",
      "  (5): EegMultiplicativeGaussianNoise(mean=0.0,std=0.0001)\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "preprocess_test: Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.7924]),std=tensor([9.7796]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([-0.0131, -0.0537, -0.0270, -0.0130,  0.0671,  0.1447,  0.0241, -0.0065,\n",
      "           0.0358,  0.0454,  0.0042, -0.0076,  0.0100, -0.0491,  0.1222, -0.0020,\n",
      "          -0.0455, -0.0090, -0.0075, -0.0007]),std=tensor([44.3636, 19.8341, 11.1687, 11.5708, 15.1467, 46.4805, 19.3917, 10.3994,\n",
      "          11.3963, 15.3145, 20.5728, 13.9113, 13.3876, 21.5652, 15.1473, 14.1777,\n",
      "          19.4869, 10.9581, 10.9338, 94.4190]),eps=1e-08)\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "0 torch.Size([256, 20, 2000]) torch.Size([256]) torch.Size([256])\n",
      "1 torch.Size([256, 20, 2000]) torch.Size([256]) torch.Size([256])\n",
      "2 torch.Size([256, 20, 2000]) torch.Size([256]) torch.Size([256])\n",
      "3 torch.Size([256, 20, 2000]) torch.Size([256]) torch.Size([256])\n",
      "4 torch.Size([256, 20, 2000]) torch.Size([256]) torch.Size([256])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg_data_temp = deepcopy(cfg_data)\n",
    "_ = build_dataset_for_train(cfg_data_temp, verbose=True)\n",
    "\n",
    "in_channels = cfg_data_temp['preprocess_train'](next(iter(_[0])))['signal'].shape[1]\n",
    "out_dims = len(cfg_data_temp['class_label_to_name'])\n",
    "\n",
    "del _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EKG': 'O',\n",
      " 'age_mean': tensor([70.7924]),\n",
      " 'age_std': tensor([9.7796]),\n",
      " 'awgn': 0.05,\n",
      " 'awgn_age': 0.05,\n",
      " 'class_label_to_name': ['Normal', 'MCI', 'Dementia'],\n",
      " 'class_name_to_label': {'Dementia': 2, 'MCI': 1, 'Normal': 0},\n",
      " 'crop_multiple': 4,\n",
      " 'dataset_name': 'CAUEEG dataset',\n",
      " 'dataset_path': 'local/dataset/02_Curated_Data_220419/',\n",
      " 'device': device(type='cuda'),\n",
      " 'file_format': 'memmap',\n",
      " 'input_norm': 'dataset',\n",
      " 'latency': 2000,\n",
      " 'load_event': False,\n",
      " 'mgn': 0.0001,\n",
      " 'minibatch': 256,\n",
      " 'photic': 'X',\n",
      " 'preprocess_test': Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.7924]),std=tensor([9.7796]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([-0.0131, -0.0537, -0.0270, -0.0130,  0.0671,  0.1447,  0.0241, -0.0065,\n",
      "           0.0358,  0.0454,  0.0042, -0.0076,  0.0100, -0.0491,  0.1222, -0.0020,\n",
      "          -0.0455, -0.0090, -0.0075, -0.0007]),std=tensor([44.3636, 19.8341, 11.1687, 11.5708, 15.1467, 46.4805, 19.3917, 10.3994,\n",
      "          11.3963, 15.3145, 20.5728, 13.9113, 13.3876, 21.5652, 15.1473, 14.1777,\n",
      "          19.4869, 10.9581, 10.9338, 94.4190]),eps=1e-08)\n",
      "),\n",
      " 'preprocess_train': Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.7924], device='cuda:0'),std=tensor([9.7796]),eps=1e-08)\n",
      "  (2): EegAddGaussianNoiseAge(mean=0.0,std=0.05)\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([-0.0131, -0.0537, -0.0270, -0.0130,  0.0671,  0.1447,  0.0241, -0.0065,\n",
      "           0.0358,  0.0454,  0.0042, -0.0076,  0.0100, -0.0491,  0.1222, -0.0020,\n",
      "          -0.0455, -0.0090, -0.0075, -0.0007], device='cuda:0'),std=tensor([44.3636, 19.8341, 11.1687, 11.5708, 15.1467, 46.4805, 19.3917, 10.3994,\n",
      "          11.3963, 15.3145, 20.5728, 13.9113, 13.3876, 21.5652, 15.1473, 14.1777,\n",
      "          19.4869, 10.9581, 10.9338, 94.4190]),eps=1e-08)\n",
      "  (4): EegAdditiveGaussianNoise(mean=0.0,std=0.05)\n",
      "  (5): EegMultiplicativeGaussianNoise(mean=0.0,std=0.0001)\n",
      "),\n",
      " 'seq_length': 2000,\n",
      " 'signal_header': ['Fp1-AVG', 'F3-AVG', 'C3-AVG', 'P3-AVG', 'O1-AVG', 'Fp2-AVG', 'F4-AVG', 'C4-AVG', 'P4-AVG', 'O2-AVG', 'F7-AVG', 'T3-AVG', 'T5-AVG', 'F8-AVG', 'T4-AVG', 'T6-AVG', 'FZ-AVG', 'CZ-AVG', 'PZ-AVG', 'EKG', 'Photic'],\n",
      " 'signal_mean': tensor([[[-0.0131],\n",
      "         [-0.0537],\n",
      "         [-0.0270],\n",
      "         [-0.0130],\n",
      "         [ 0.0671],\n",
      "         [ 0.1447],\n",
      "         [ 0.0241],\n",
      "         [-0.0065],\n",
      "         [ 0.0358],\n",
      "         [ 0.0454],\n",
      "         [ 0.0042],\n",
      "         [-0.0076],\n",
      "         [ 0.0100],\n",
      "         [-0.0491],\n",
      "         [ 0.1222],\n",
      "         [-0.0020],\n",
      "         [-0.0455],\n",
      "         [-0.0090],\n",
      "         [-0.0075],\n",
      "         [-0.0007]]]),\n",
      " 'signal_std': tensor([[[44.3636],\n",
      "         [19.8341],\n",
      "         [11.1687],\n",
      "         [11.5708],\n",
      "         [15.1467],\n",
      "         [46.4805],\n",
      "         [19.3917],\n",
      "         [10.3994],\n",
      "         [11.3963],\n",
      "         [15.3145],\n",
      "         [20.5728],\n",
      "         [13.9113],\n",
      "         [13.3876],\n",
      "         [21.5652],\n",
      "         [15.1473],\n",
      "         [14.1777],\n",
      "         [19.4869],\n",
      "         [10.9581],\n",
      "         [10.9338],\n",
      "         [94.4190]]]),\n",
      " 'task': 'task1',\n",
      " 'task_description': 'Classification of [Normal], [MCI], and [Dementia] symptoms.',\n",
      " 'task_name': 'CAUEEG-task1 benchmark',\n",
      " 'test_crop_multiple': 8,\n",
      " 'transform': Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=4, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=[20])\n",
      "    EegToTensor()\n",
      "),\n",
      " 'transform_multicrop': Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=8, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=[20])\n",
      "    EegToTensor()\n",
      ")}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(cfg_data_temp, width=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Define Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft, hop_length, seq_len_2d = calculate_stft_params(seq_length=cfg_data['seq_length'])\n",
    "cfg_temp_model = {\n",
    "    'in_channels': in_channels, \n",
    "    'out_dims': out_dims, \n",
    "    'seq_length': cfg_data['seq_length'],\n",
    "    'stft_params': {'n_fft': n_fft, 'hop_length': hop_length,\n",
    "                    'complex_mode': 'as_real',  # 'as_real', 'power', 'remove'\n",
    "                   }\n",
    "}\n",
    "\n",
    "cfg_model_pool = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Tiny CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model['model'] = '1D-Tiny-CNN'\n",
    "# cfg_model['generator'] = TinyCNN1D\n",
    "# cfg_model['fc_stages'] = 1\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'average'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model['model'] = '1D-M5'\n",
    "# cfg_model['generator'] = M5\n",
    "# cfg_model['fc_stages'] = 1\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'average'\n",
    "# cfg_model['base_channels'] = 256\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Model config:'\n",
      "{'LR': None,\n",
      " 'activation': 'relu',\n",
      " 'base_channels': 64,\n",
      " 'batch_norm': True,\n",
      " 'fc_stages': 3,\n",
      " 'final_pool': 'average',\n",
      " 'generator': <class 'models.vgg_1d.VGG1D'>,\n",
      " 'model': '1D-VGG-19',\n",
      " 'use_age': 'fc'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 3 required positional arguments: 'in_channels', 'out_dims', and 'seq_length'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m pprint\u001b[38;5;241m.\u001b[39mpprint(cfg_model)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m model \u001b[38;5;241m=\u001b[39m cfg_model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m'\u001b[39m](\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcfg_model)\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 3 required positional arguments: 'in_channels', 'out_dims', and 'seq_length'"
     ]
    }
   ],
   "source": [
    "cfg_model = {}\n",
    "cfg_model['model'] = '1D-VGG-19'\n",
    "cfg_model['generator'] = VGG1D\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['batch_norm'] = True\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'average'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = None\n",
    "cfg_model['activation'] = 'relu'\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D ResNet variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model['model'] = '1D-ResNet-18'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BasicBlock1D\n",
    "cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'average'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = None\n",
    "cfg_model['activation'] = 'relu'\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model['model'] = '1D-ResNet-50'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'average'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = None\n",
    "cfg_model['activation'] = 'relu'\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model['model'] = '1D-ResNet-101'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 23, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'average'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D ResNeXt variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model['model'] = '1D-ResNeXt-50'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'average'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['groups'] = 32\n",
    "cfg_model['width_per_group'] = 4\n",
    "cfg_model['LR'] = None\n",
    "cfg_model['activation'] = 'relu'\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model['model'] = '1D-ResNeXt-101'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [3, 4, 23, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'average'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['groups'] = 32\n",
    "cfg_model['width_per_group'] = 8\n",
    "cfg_model['LR'] = None\n",
    "cfg_model['activation'] = 'relu'\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model['model'] = '2D-VGG-19'\n",
    "cfg_model['generator'] = VGG2D\n",
    "cfg_model['seq_len_2d'] = seq_len_2d\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['batch_norm'] = True\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'average'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = None\n",
    "cfg_model['activation'] = 'relu'\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D ResNet variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model['model'] = '2D-ResNet-18'\n",
    "# cfg_model['generator'] = ResNet2D\n",
    "# cfg_model['block'] = BasicBlock2D\n",
    "# cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "# cfg_model['seq_len_2d'] = seq_len_2d\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'average'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model['model'] = '2D-ResNet-50'\n",
    "cfg_model['generator'] = ResNet2D\n",
    "cfg_model['block'] = Bottleneck2D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['seq_len_2d'] = seq_len_2d\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'average'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = None\n",
    "cfg_model['activation'] = 'relu'\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D ResNeXt variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model['model'] = '2D-ResNeXt-50'\n",
    "cfg_model['generator'] = ResNet2D\n",
    "cfg_model['block'] = Bottleneck2D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['seq_len_2d'] = seq_len_2d\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'average'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['groups'] = 32\n",
    "cfg_model['width_per_group'] = 4\n",
    "cfg_model['LR'] = None\n",
    "cfg_model['activation'] = 'relu'\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model['model'] = '2D-ResNeXt-101'\n",
    "cfg_model['generator'] = ResNet2D\n",
    "cfg_model['block'] = Bottleneck2D\n",
    "cfg_model['conv_layers'] = [3, 4, 23, 3]\n",
    "cfg_model['seq_len_2d'] = seq_len_2d\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'average'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['groups'] = 32\n",
    "cfg_model['width_per_group'] = 8\n",
    "cfg_model['LR'] = None\n",
    "cfg_model['activation'] = 'relu'\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN-Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model['model'] = '1D-CNN-Transformer'\n",
    "cfg_model['generator'] = CNNTransformer\n",
    "cfg_model['seq_len_2d'] = seq_len_2d\n",
    "cfg_model['fc_stages'] = 2\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'average'\n",
    "cfg_model['base_channels'] = 256  #\n",
    "cfg_model['n_encoders'] = 8  #\n",
    "cfg_model['n_heads'] = 8     #\n",
    "cfg_model['dropout'] = 0.2   #\n",
    "cfg_model['LR'] = None\n",
    "cfg_model['activation'] = 'relu'\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vision Transformer (ViT-B-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model['model'] = '2D-ViT-B-16'\n",
    "cfg_model['generator'] = vit_b_16\n",
    "cfg_model['seq_len_2d'] = seq_len_2d\n",
    "cfg_model['fc_stages'] = 2\n",
    "cfg_model['use_age'] = 'conv'\n",
    "cfg_model['dropout'] = 0.1\n",
    "cfg_model['attention_dropout'] = 0.1\n",
    "cfg_model['LR'] = None\n",
    "cfg_model['minibatch'] = 64  # ViT requires enormous memory to train\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model, **cfg_temp_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Summarize the loaded models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cfg_model in cfg_model_pool:\n",
    "    pprint.pp(cfg_model, width=150)\n",
    "    print('\\n' + '-' * 100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Default Configurations for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training configurations\n",
    "cfg_train = {}\n",
    "cfg_train['iterations'] = (300000 * 64) // cfg_data['minibatch']\n",
    "cfg_train['warmup_steps'] = max(round(cfg_train['iterations'] * 0.05), 3000)\n",
    "cfg_train['num_history'] = 500\n",
    "cfg_train['lr_scheduler_type'] = 'constant_with_decay'\n",
    "cfg_train['weight_decay'] = 1e-2\n",
    "cfg_train['mixup'] = 0.0  # 0.0 for no usage\n",
    "cfg_train['criterion'] = 'cross-entropy' # 'cross-entropy', 'multi-bce'\n",
    "\n",
    "cfg_train['device'] = device\n",
    "cfg_train['save_model'] = True\n",
    "cfg_train['draw_result'] = True\n",
    "cfg_train['watch_model'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_data = {}\n",
    "sweep_data['seq_length'] = {\n",
    "    'values': [\n",
    "        # 200 *  5, #  5 sec\n",
    "        # 200 * 10, # 10 sec\n",
    "        200 * 20, # 20 sec\n",
    "        # 200 * 30, # 30 sec\n",
    "              ],\n",
    "}\n",
    "\n",
    "sweep_data['EKG'] = {\n",
    "    'values': ['O', 'X'],\n",
    "}\n",
    "\n",
    "sweep_data['photic'] = {\n",
    "    'values': ['O', 'X'],\n",
    "}\n",
    "\n",
    "sweep_data['awgn'] = {\n",
    "    'distribution': 'uniform',\n",
    "    'min': 0,\n",
    "    'max': 0.3,\n",
    "}\n",
    "\n",
    "sweep_data['mgn'] = {\n",
    "    'distribution': 'uniform',\n",
    "    'min': 0,\n",
    "    'max': 0.1,\n",
    "}\n",
    "\n",
    "sweep_data['awgn_age'] = {\n",
    "    'distribution': 'uniform',\n",
    "    'min': 0,\n",
    "    'max': 0.3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_model = {}\n",
    "sweep_model['model_index'] = { \n",
    "    'values': [i for i in range(len(cfg_model_pool))] \n",
    "}\n",
    "\n",
    "sweep_model['fc_stages'] = { \n",
    "    'distribution': 'int_uniform',\n",
    "    'min': 2,\n",
    "    'max': 4,\n",
    "}\n",
    "\n",
    "sweep_model['use_age'] = { \n",
    "    'values': ['fc', 'conv']  # 'fc', 'conv', 'no'\n",
    "}\n",
    "\n",
    "sweep_model['dropout'] = {\n",
    "    'values': [0, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "sweep_model['activation'] = {\n",
    "    'values': ['relu', 'gelu', 'mish']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_train = {}\n",
    "\n",
    "sweep_train['lr_scheduler_type'] = {\n",
    "    'values': [\n",
    "        'constant_with_decay',\n",
    "        'constant_with_twice_decay',\n",
    "        'transformer_style',\n",
    "        'cosine_decay_with_warmup_half',\n",
    "        'cosine_decay_with_warmup_one_and_half',\n",
    "#        'cosine_decay_with_warmup_two_and_half',\n",
    "        'linear_decay_with_warmup',\n",
    "    ]\n",
    "\n",
    "}\n",
    "\n",
    "sweep_train['search_multiplier'] = {\n",
    "    'values': [1.0, 1.2, 2.0]\n",
    "}\n",
    "\n",
    "sweep_train['weight_decay'] = {\n",
    "    'distribution' : 'log_uniform_values',\n",
    "    'min': 1e-5,\n",
    "    'max': 1e-1\n",
    "}\n",
    "\n",
    "sweep_train['mixup'] = {\n",
    "    'values': [0, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "sweep_train['criterion'] = {\n",
    "    'values': ['cross-entropy', 'multi-bce']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"entity\": \"ipis-mjkim\",\n",
    "    \"name\" : \"my-sweep\",\n",
    "    \"method\": \"random\",\n",
    "    \"parameters\": \n",
    "    {\n",
    "        **sweep_data,\n",
    "        **sweep_model,\n",
    "        **sweep_train,\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=f\"caueeg-{cfg_data['task']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_ddp(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "    # initialize the process group\n",
    "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "\n",
    "def cleanup_ddp():\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ddp(rank, world_size):\n",
    "    # initialize DDP\n",
    "    setup(rank, world_size)\n",
    "    \n",
    "    # initialize the wandb log\n",
    "    wandb_run = wandb.init()\n",
    "    wandb.run.name = wandb.run.id\n",
    "\n",
    "    with wandb_run:\n",
    "        # collect some garbages\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "        # load default config\n",
    "        config = {}\n",
    "        cfg_model = cfg_model_pool[wandb.config.model_index]\n",
    "        for k, v in {**cfg_data,  **cfg_model, **cfg_train}.items():\n",
    "            if k not in wandb.config:\n",
    "                config[k] = v\n",
    "        \n",
    "        # load the selected configurations from wandb sweep with preventing callables from type-conversion to str\n",
    "        for k, v in wandb.config.items():\n",
    "            if k not in config:\n",
    "                config[k] = v\n",
    "\n",
    "        # build dataset\n",
    "        train_loader, val_loader, test_loader, multicrop_test_loader = build_dataset_for_train(config)\n",
    "        \n",
    "        # train the model\n",
    "        model = train_with_wandb(config, train_loader, val_loader, test_loader, multicrop_test_loader, \n",
    "                                 config['preprocess_train'], config['preprocess_test'])\n",
    "        \n",
    "        # release memory\n",
    "        del model\n",
    "        del train_loader, val_loader\n",
    "        del test_loader, multicrop_test_loader\n",
    "        del config\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train():\n",
    "#     # initialize the wandb log\n",
    "#     wandb_run = wandb.init()\n",
    "#     wandb.run.name = wandb.run.id\n",
    "\n",
    "#     with wandb_run:\n",
    "#         # collect some garbages\n",
    "#         gc.collect()\n",
    "#         torch.cuda.empty_cache()\n",
    "#         torch.cuda.synchronize()\n",
    "    \n",
    "#         # load default config\n",
    "#         config = {}\n",
    "#         cfg_model = cfg_model_pool[wandb.config.model_index]\n",
    "#         for k, v in {**cfg_data,  **cfg_model, **cfg_train}.items():\n",
    "#             if k not in wandb.config:\n",
    "#                 config[k] = v\n",
    "                \n",
    "#         # load the selected configurations from wandb sweep with preventing callables from type-conversion to str\n",
    "#         for k, v in wandb.config.items():\n",
    "#             if k not in config:\n",
    "#                 config[k] = v\n",
    "\n",
    "#         # build dataset\n",
    "#         train_loader, val_loader, test_loader, multicrop_test_loader = build_dataset_for_train(config)\n",
    "        \n",
    "#         # train the model\n",
    "#         model = train_with_wandb(config, train_loader, val_loader, test_loader, multicrop_test_loader, \n",
    "#                                  config['preprocess_train'], config['preprocess_test'])\n",
    "        \n",
    "#         # release memory\n",
    "#         del model\n",
    "#         del train_loader, val_loader\n",
    "#         del test_loader, multicrop_test_loader\n",
    "#         del config\n",
    "        \n",
    "#     time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.agent(sweep_id, function=train, count=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
