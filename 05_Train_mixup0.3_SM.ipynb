{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Networks\n",
    "\n",
    "- Three-way SoftMax classifier of normal, non-vascular MCI, and non-vascular dementia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages and Get Ready for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import datetime\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from itertools import cycle\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import wandb\n",
    "\n",
    "# custom package\n",
    "from utils.eeg_dataset import *\n",
    "from models import *\n",
    "from utils.train_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook name\n",
    "def get_notebook_name():\n",
    "    import ipynbname\n",
    "    return ipynbname.name()\n",
    "nb_fname = get_notebook_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other settings\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # cleaner text\n",
    "\n",
    "plt.style.use('default') \n",
    "# ['Solarize_Light2', '_classic_test_patch', 'bmh', 'classic', 'dark_background', 'fast', \n",
    "#  'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn', 'seaborn-bright', 'seaborn-colorblind', \n",
    "#  'seaborn-dark', 'seaborn-dark-palette', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', \n",
    "#  'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', \n",
    "#  'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'tableau-colorblind10']\n",
    "\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams[\"font.family\"] = 'NanumGothic' # for Hangul in Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.9.0\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Set up the Dataset and the PyTorch Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_data = {}\n",
    "cfg_data['dataset'] = 'CAUHS'\n",
    "cfg_data['vascular'] = 'X'\n",
    "cfg_data['segment'] = 'no' # 'train', 'all'\n",
    "cfg_data['seed'] = 0\n",
    "cfg_data['crop_length'] = 200 * 10 # 10 seconds\n",
    "cfg_data['input_norm'] = 'dataset' # 'datatset', 'datapoint', 'no'\n",
    "cfg_data['EKG'] = 'O'\n",
    "cfg_data['photic'] = 'X'\n",
    "cfg_data['awgn'] = 5e-2\n",
    "cfg_data['awgn_age'] = 0.0 # 0.0 for no use\n",
    "cfg_data['minibatch'] = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data file path\n",
    "data_path = r'dataset/02_Curated_Data/'\n",
    "meta_path = os.path.join(data_path, 'metadata_debug.json')\n",
    "\n",
    "with open(meta_path, 'r') as json_file:\n",
    "    metadata = json.load(json_file)\n",
    "\n",
    "# pprint.pprint(metadata[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter the Data According to the Target Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_label_to_type: ['Normal', 'Non-vascular MCI', 'Non-vascular dementia']\n"
     ]
    }
   ],
   "source": [
    "# consider only non-vascular symptoms\n",
    "if cfg_data['vascular'] == 'X': \n",
    "    diagnosis_filter = [\n",
    "        # Normal\n",
    "        {'type': 'Normal',\n",
    "         'include': ['normal'], \n",
    "         'exclude': []},\n",
    "        # Non-vascular MCI\n",
    "        {'type': 'Non-vascular MCI',\n",
    "         'include': ['mci'], \n",
    "         'exclude': ['mci_vascular']},\n",
    "        # Non-vascular dementia\n",
    "        {'type': 'Non-vascular dementia',\n",
    "         'include': ['dementia'], \n",
    "         'exclude': ['vd']},\n",
    "    ]\n",
    "# consider all cases\n",
    "elif cfg_data['vascular'] == 'O':\n",
    "    diagnosis_filter = [\n",
    "        # Normal\n",
    "        {'type': 'Normal',\n",
    "         'include': ['normal'], \n",
    "         'exclude': []},\n",
    "        # Non-vascular MCI\n",
    "        {'type': 'Non-vascular MCI',\n",
    "         'include': ['mci'], \n",
    "         'exclude': []},\n",
    "        # Non-vascular dementia\n",
    "        {'type': 'Non-vascular dementia',\n",
    "         'include': ['dementia'], \n",
    "         'exclude': []},\n",
    "    ]\n",
    "else:\n",
    "    raise ValueError(f\"cfg_data['vascular'] have to be set to one of ['O', 'X']\")\n",
    "\n",
    "    \n",
    "class_label_to_type = [d_f['type'] for d_f in diagnosis_filter]\n",
    "print('class_label_to_type:', class_label_to_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- There are 463 data belonging to Normal\n",
      "- There are 347 data belonging to Non-vascular MCI\n",
      "- There are 229 data belonging to Non-vascular dementia\n"
     ]
    }
   ],
   "source": [
    "def generate_class_label(label):\n",
    "    for c, f in enumerate(diagnosis_filter):\n",
    "        inc = set(f['include']) & set(label) == set(f['include'])\n",
    "        # inc = len(set(f['include']) & set(label)) > 0        \n",
    "        exc = len(set(f['exclude']) & set(label)) == 0\n",
    "        if  inc and exc:\n",
    "            return (c, f['type'])\n",
    "    return (-1, 'The others')\n",
    "\n",
    "\n",
    "splitted_metadata = [[] for i in diagnosis_filter]\n",
    "\n",
    "for m in metadata:\n",
    "    c, n = generate_class_label(m['label'])\n",
    "    if c >= 0:\n",
    "        m['class_type'] = n\n",
    "        m['class_label'] = c\n",
    "        splitted_metadata[c].append(m)\n",
    "        \n",
    "for i, split in enumerate(splitted_metadata):\n",
    "    if len(split) == 0:\n",
    "        print(f'(Warning) Split group {i} has no data.')\n",
    "    else:\n",
    "        print(f'- There are {len(split):} data belonging to {split[0][\"class_type\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the filtered dataset and shuffle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size\t\t: 831\n",
      "Validation data size\t: 104\n",
      "Test data size\t\t: 104\n",
      "\n",
      " --- Recheck --- \n",
      "\n",
      "Train data label distribution\t: [370 278 183] 831\n",
      "Val data label distribution\t: [46 35 23] 104\n",
      "Test data label distribution\t: [47 34 23] 104\n"
     ]
    }
   ],
   "source": [
    "# random seed\n",
    "random.seed(cfg_data['seed'])\n",
    "\n",
    "# Train : Val : Test = 8 : 1 : 1\n",
    "ratio1 = 0.8\n",
    "ratio2 = 0.1\n",
    "\n",
    "metadata_train = []\n",
    "metadata_val = []\n",
    "metadata_test = []\n",
    "\n",
    "for split in splitted_metadata:\n",
    "    random.shuffle(split)\n",
    "    \n",
    "    n1 = round(len(split) * ratio1)\n",
    "    n2 = n1 + round(len(split) * ratio2)\n",
    "\n",
    "    metadata_train.extend(split[:n1])\n",
    "    metadata_val.extend(split[n1:n2])\n",
    "    metadata_test.extend(split[n2:])\n",
    "\n",
    "random.shuffle(metadata_train)\n",
    "random.shuffle(metadata_val)\n",
    "random.shuffle(metadata_test)\n",
    "\n",
    "print('Train data size\\t\\t:', len(metadata_train))\n",
    "print('Validation data size\\t:', len(metadata_val))\n",
    "print('Test data size\\t\\t:', len(metadata_test))\n",
    "\n",
    "print('\\n', '--- Recheck ---', '\\n')\n",
    "train_class_nums = np.zeros((len(class_label_to_type)), dtype=np.int32)\n",
    "for m in metadata_train:\n",
    "    train_class_nums[m['class_label']] += 1\n",
    "\n",
    "val_class_nums = np.zeros((len(class_label_to_type)), dtype=np.int32)\n",
    "for m in metadata_val:\n",
    "    val_class_nums[m['class_label']] += 1\n",
    "\n",
    "test_class_nums = np.zeros((len(class_label_to_type)), dtype=np.int32)\n",
    "for m in metadata_test:\n",
    "    test_class_nums[m['class_label']] += 1\n",
    "\n",
    "print('Train data label distribution\\t:', train_class_nums, train_class_nums.sum())\n",
    "print('Val data label distribution\\t:', val_class_nums, val_class_nums.sum())\n",
    "print('Test data label distribution\\t:', test_class_nums, test_class_nums.sum())\n",
    "\n",
    "# random seed\n",
    "random.seed()\n",
    "\n",
    "# print([m['serial']  for m in metadata_train[:15]])\n",
    "# print([m['serial']  for m in metadata_val[:15]])\n",
    "# print([m['serial']  for m in metadata_test[:15]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compose the dataset transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age mean and standard deviation:\n",
      "69.92779783393502 9.817569889945597\n"
     ]
    }
   ],
   "source": [
    "ages = []\n",
    "for m in metadata_train:\n",
    "    ages.append(m['age'])\n",
    "\n",
    "ages = np.array(ages)\n",
    "age_mean = np.mean(ages)\n",
    "age_std = np.std(ages)\n",
    "\n",
    "print('Age mean and standard deviation:')\n",
    "print(age_mean, age_std)\n",
    "\n",
    "cfg_data['age_mean'] = age_mean\n",
    "cfg_data['age_std'] = age_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "composed_train = [EEGRandomCrop(crop_length=cfg_data['crop_length']), \n",
    "                  EEGNormalizeAge(mean=cfg_data['age_mean'], std=cfg_data['age_std'])]\n",
    "composed_test = [EEGRandomCrop(crop_length=cfg_data['crop_length']), \n",
    "                 EEGNormalizeAge(mean=cfg_data['age_mean'], std=cfg_data['age_std'])]\n",
    "longer_composed_test = [EEGRandomCrop(crop_length=cfg_data['crop_length'] * 10), \n",
    "                        EEGNormalizeAge(mean=cfg_data['age_mean'], std=cfg_data['age_std'])]\n",
    "\n",
    "if cfg_data['awgn_age'] is None or cfg_data['awgn_age'] <= 1e-12:\n",
    "    pass\n",
    "elif cfg_data['awgn_age'] > 0.0:\n",
    "    composed_train += [EEGAddGaussianNoiseAge(mean=0.0, std=cfg_data['awgn_age'])]\n",
    "else:\n",
    "    raise ValueError(f\"cfg_data['awgn'] have to be None or a positive floating point number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg_data['input_norm'] == 'dataset':\n",
    "    # composed = transforms.Compose([EEGRandomCrop(crop_length=cfg_data['crop_length'])])\n",
    "    # train_dataset = EEGDataset(data_path, metadata_train, composed)\n",
    "\n",
    "    # signal_means = []\n",
    "    # signal_stds = []\n",
    "\n",
    "    # for i in range(10):\n",
    "    #     for d in train_dataset:\n",
    "    #         signal_means.append(d['signal'].mean(axis=1, keepdims=True))\n",
    "    #         signal_stds.append(d['signal'].std(axis=1, keepdims=True))\n",
    "\n",
    "    # signal_mean = np.mean(np.array(signal_means), axis=0)\n",
    "    # signal_std = np.mean(np.array(signal_stds), axis=0)\n",
    "\n",
    "    # print('Mean and standard deviation for signal:')\n",
    "    # print(signal_means, '\\n\\n', signal_stds)\n",
    "\n",
    "    # SPEED-UP\n",
    "    signal_mean = np.array([[ 0.1127599 ], [ 0.06298441], [-0.02522413], [ 0.00508518], \n",
    "                             [ 0.12026667], [-0.19987741], [-0.00516898], [ 0.00239212], \n",
    "                             [-0.02861219], [-0.02973673], [-0.02515898], [-0.00060568], \n",
    "                             [ 0.04921601], [-0.00562142], [-0.04888308], [-0.0438447 ], \n",
    "                             [ 0.07532331], [-0.01890181], [-0.044876  ], [-0.00365138], [-0.01564376]])\n",
    "    signal_std = np.array([[46.09896  ], [20.50783  ], [11.196733 ], [11.236944 ], [15.070532 ], \n",
    "                            [47.664406 ], [19.32747  ], [10.106162 ], [11.314243 ], [15.065008 ],\n",
    "                            [20.478817 ], [13.86243  ], [13.2378435], [21.554531 ], [16.875841 ],\n",
    "                            [13.989367 ], [19.789454 ], [10.839711 ], [11.179158 ], [94.12114  ], [65.64865  ]])\n",
    "    \n",
    "    cfg_data['signal_mean'] = signal_mean\n",
    "    cfg_data['signal_std'] = signal_std\n",
    "    \n",
    "    composed_train += [EEGNormalizeMeanStd(mean=cfg_data['signal_mean'], \n",
    "                                           std=cfg_data['signal_std'])]\n",
    "    composed_test += [EEGNormalizeMeanStd(mean=cfg_data['signal_mean'], \n",
    "                                          std=cfg_data['signal_std'])]\n",
    "    longer_composed_test += [EEGNormalizeMeanStd(mean=cfg_data['signal_mean'], \n",
    "                                                 std=cfg_data['signal_std'])]\n",
    "    \n",
    "elif cfg_data['input_norm'] == 'datapoint':\n",
    "    composed_train += [EEGNormalizePerSignal()]\n",
    "    composed_test += [EEGNormalizePerSignal()]\n",
    "    longer_composed_test += [EEGNormalizePerSignal()]\n",
    "elif cfg_data['input_norm'] == 'no':\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError(f\"cfg_data['input_norm'] have to be set to one of ['dataset', 'datapoint', 'no']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg_data['EKG'] == 'O':\n",
    "    pass\n",
    "elif cfg_data['EKG'] == 'X':\n",
    "    composed_train += [EEGDropEKGChannel()]\n",
    "    composed_test += [EEGDropEKGChannel()]\n",
    "    longer_composed_test += [EEGDropEKGChannel()]\n",
    "else:\n",
    "    raise ValueError(f\"cfg_data['EKG'] have to be set to one of ['O', 'X']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg_data['photic'] == 'O':\n",
    "    pass\n",
    "elif cfg_data['photic'] == 'X':\n",
    "    composed_train += [EEGDropPhoticChannel()]\n",
    "    composed_test += [EEGDropPhoticChannel()]\n",
    "    longer_composed_test += [EEGDropPhoticChannel()]\n",
    "else:\n",
    "    raise ValueError(f\"cfg_data['photic'] have to be set to one of ['O', 'X']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg_data['awgn'] is None or cfg_data['awgn'] <= 1e-12:\n",
    "    pass\n",
    "elif cfg_data['awgn'] > 0.0:\n",
    "    composed_train += [EEGAddGaussianNoise(mean=0.0, std=cfg_data['awgn'])]\n",
    "else:\n",
    "    raise ValueError(f\"cfg_data['awgn'] have to be None or a positive floating point number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "composed_train: Compose(\n",
      "    <utils.eeg_dataset.EEGRandomCrop object at 0x00000241D7A4A8B0>\n",
      "    <utils.eeg_dataset.EEGNormalizeAge object at 0x00000241D7A4A880>\n",
      "    <utils.eeg_dataset.EEGAddGaussianNoiseAge object at 0x00000241D7A4AC40>\n",
      "    <utils.eeg_dataset.EEGNormalizeMeanStd object at 0x00000241D7A4A9D0>\n",
      "    <utils.eeg_dataset.EEGDropPhoticChannel object at 0x00000241D7A53F40>\n",
      "    <utils.eeg_dataset.EEGAddGaussianNoise object at 0x00000241D7A532B0>\n",
      "    <utils.eeg_dataset.EEGToTensor object at 0x00000241D7A53460>\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "composed_test: Compose(\n",
      "    <utils.eeg_dataset.EEGRandomCrop object at 0x00000241D7A4AE20>\n",
      "    <utils.eeg_dataset.EEGNormalizeAge object at 0x00000241D7A4AB50>\n",
      "    <utils.eeg_dataset.EEGNormalizeMeanStd object at 0x00000241D7A4AC70>\n",
      "    <utils.eeg_dataset.EEGDropPhoticChannel object at 0x00000241D7A53E50>\n",
      "    <utils.eeg_dataset.EEGToTensor object at 0x00000241D7A533D0>\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "longer_composed_test: Compose(\n",
      "    <utils.eeg_dataset.EEGRandomCrop object at 0x00000241D7A4AE80>\n",
      "    <utils.eeg_dataset.EEGNormalizeAge object at 0x00000241D7A4AFD0>\n",
      "    <utils.eeg_dataset.EEGNormalizeMeanStd object at 0x00000241D7A4A070>\n",
      "    <utils.eeg_dataset.EEGDropPhoticChannel object at 0x00000241D7A53A00>\n",
      "    <utils.eeg_dataset.EEGToTensor object at 0x00000241D7A53100>\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "composed_train += [EEGToTensor()]\n",
    "composed_test += [EEGToTensor()]\n",
    "longer_composed_test += [EEGToTensor()]\n",
    "\n",
    "composed_train = transforms.Compose(composed_train)\n",
    "composed_test = transforms.Compose(composed_test)\n",
    "longer_composed_test = transforms.Compose(longer_composed_test)\n",
    "\n",
    "print('composed_train:', composed_train)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "print('composed_test:', composed_test)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "print('longer_composed_test:', longer_composed_test)\n",
    "print('\\n' + '-' * 100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrap the splitted data using PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2000])\n",
      "{'signal': tensor([[-0.4584, -0.4401, -0.4497,  ..., -0.3400, -0.0579,  0.1065],\n",
      "        [ 0.1802,  0.1075,  0.0680,  ..., -1.6218, -1.2906, -1.0759],\n",
      "        [-3.3574, -3.3894, -3.3975,  ...,  0.9290,  0.9126,  0.8690],\n",
      "        ...,\n",
      "        [ 0.1724,  0.2863,  0.0761,  ...,  0.3179, -0.2891, -0.3299],\n",
      "        [ 0.7899,  0.7073,  0.6664,  ...,  0.9740,  0.5815,  0.2774],\n",
      "        [ 3.2502,  3.2426,  3.3715,  ...,  0.5742,  0.6972,  0.7168]]), 'age': tensor(-1.2096), 'class_label': tensor(0), 'metadata': {'serial': '01012', 'edfname': '01212635_270515', 'birth': '1956-06-01', 'record': '2015-05-27T09:37:24', 'age': 58, 'dx1': 'cb_normal', 'label': ['normal', 'cb_normal'], 'events': [[0, 'Start Recording'], [0, 'New Montage - Montage 002'], [400, 'Eyes Open'], [7918, 'Eyes Closed'], [14091, 'Eyes Open'], [18208, 'Eyes Closed'], [24256, 'Eyes Open'], [30724, 'Eyes Closed'], [36562, 'Eyes Open'], [42190, 'Eyes Closed'], [48910, 'Eyes Open'], [55126, 'Eyes Closed'], [60417, 'Eyes Open'], [66004, 'Eyes Closed'], [71968, 'Eyes Open'], [78310, 'Eyes Closed'], [84442, 'Eyes Open'], [90070, 'Eyes Closed'], [96076, 'Eyes Open'], [102082, 'Eyes Closed'], [108844, 'Eyes Open'], [113674, 'Eyes Closed'], [120000, 'Paused']], 'class_type': 'Normal', 'class_label': 0}}\n",
      "tensor(57.9395)\n",
      "tensor(58.1183)\n",
      "tensor(57.8480)\n",
      "tensor(58.1783)\n",
      "58\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "torch.Size([20, 2000])\n",
      "{'signal': tensor([[-0.9569, -1.0003, -1.0654,  ..., -0.2844, -0.2628, -0.1543],\n",
      "        [-0.8320, -0.9295, -0.8808,  ..., -0.2956, -0.2956, -0.2956],\n",
      "        [-0.6229, -0.6229, -0.8016,  ...,  0.2702,  0.3595,  0.4488],\n",
      "        ...,\n",
      "        [-0.3673, -0.7363, -1.1053,  ..., -0.3673, -0.4595, -0.3673],\n",
      "        [-0.0854, -0.2643, -0.5327,  ..., -0.2643, -0.2643, -0.1749],\n",
      "        [ 1.8168,  1.5300,  1.7637,  ..., -0.0531, -0.1487, -0.2762]]), 'age': tensor(0.7204), 'class_label': tensor(1), 'metadata': {'serial': '00700', 'edfname': '00985401_011117', 'birth': '1940-09-09', 'record': '2017-11-01T14:20:48', 'age': 77, 'dx1': 'mci amnestic', 'label': ['mci', 'mci_amnestic'], 'events': [[0, 'Start Recording'], [0, 'New Montage - Montage 002'], [1705, 'Eyes Open'], [5402, 'Eyes Closed'], [13046, 'Eyes Open'], [17666, 'Eyes Closed'], [30308, 'Eyes Closed'], [36272, 'Eyes Open'], [41774, 'Eyes Closed'], [48958, 'Eyes Open'], [55510, 'Eyes Closed'], [61641, 'Eyes Open'], [66766, 'Eyes Closed'], [72730, 'Eyes Open'], [78988, 'Eyes Closed'], [87770, 'Eyes Open'], [90542, 'Eyes Closed'], [97096, 'Eyes Open'], [102178, 'Eyes Closed'], [110872, 'Eyes Open'], [113728, 'Eyes Closed'], [122052, 'Photic On - 3.0 Hz'], [122428, 'Eyes Open'], [123309, 'Eyes Closed'], [124068, 'Photic Off'], [126126, 'Photic On - 6.0 Hz'], [128142, 'Photic Off'], [130158, 'Photic On - 9.0 Hz'], [132216, 'Photic Off'], [132718, 'Eyes Open'], [133600, 'Eyes Closed'], [134232, 'Photic On - 12.0 Hz'], [136248, 'Photic Off'], [138306, 'Photic On - 15.0 Hz'], [140322, 'Photic Off'], [142380, 'Photic On - 18.0 Hz'], [142630, 'Eyes Open'], [143302, 'Eyes Closed'], [144396, 'Photic Off'], [146412, 'Photic On - 21.0 Hz'], [148428, 'Photic Off'], [150486, 'Photic On - 24.0 Hz'], [152502, 'Photic Off'], [152710, 'Eyes Open'], [153550, 'Eyes Closed'], [154560, 'Photic On - 27.0 Hz'], [156576, 'Photic Off'], [158592, 'Photic On - 30.0 Hz'], [160608, 'Photic Off'], [160942, 'Eyes Open'], [161698, 'Eyes Closed'], [169132, 'Eyes Open'], [170098, 'Eyes Closed'], [173600, 'Paused']], 'class_type': 'Non-vascular MCI', 'class_label': 1}}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "torch.Size([20, 2000])\n",
      "{'signal': tensor([[ -1.3257,  -1.3040,  -1.3257,  ...,  -0.1543,  -0.0675,  -0.0892],\n",
      "        [ -0.7833,  -0.6857,  -0.5882,  ...,  -0.4419,  -0.5395,  -0.2956],\n",
      "        [ -1.1588,  -1.2481,  -1.0695,  ...,  -0.8016,  -0.7122,  -0.5336],\n",
      "        ...,\n",
      "        [ -0.9208,  -1.0130,  -1.0130,  ...,  -0.7363,  -0.6440,  -0.4595],\n",
      "        [ -1.3378,  -1.3378,  -1.2483,  ...,  -0.6222,  -0.5327,  -0.3538],\n",
      "        [-25.4778, -23.2891, -23.3635,  ...,   1.9125,  -3.3255, -17.8493]]), 'age': tensor(1.0259), 'class_label': tensor(0), 'metadata': {'serial': '00299', 'edfname': '00671212_160819', 'birth': '1938-08-17', 'record': '2019-08-16T10:57:03', 'age': 80, 'dx1': 'smi', 'label': ['normal', 'smi'], 'events': [[0, 'Start Recording'], [0, 'New Montage - Montage 005'], [1773, 'Eyes Closed'], [6000, 'Cz check'], [7612, 'Eyes Open'], [12912, 'Eyes Closed'], [18078, 'Eyes Open'], [23958, 'Eyes Closed'], [29288, 'Eyes Open'], [35934, 'Eyes Closed'], [41856, 'Eyes Open'], [47862, 'Eyes Closed'], [54460, 'Eyes Open'], [59962, 'Eyes Closed'], [66178, 'Eyes Open'], [71008, 'Eyes Closed'], [73948, 'Photic On - 3.0 Hz'], [74158, 'Eyes Open'], [75166, 'Eyes Closed'], [75964, 'Photic Off'], [77980, 'Photic On - 6.0 Hz'], [78358, 'Eyes Open'], [79282, 'Eyes Closed'], [80038, 'Photic Off'], [82054, 'Photic On - 9.0 Hz'], [84070, 'Photic Off'], [86128, 'Photic On - 12.0 Hz'], [87640, 'Eyes Open'], [88144, 'Photic Off'], [88396, 'Eyes Closed'], [90202, 'Photic On - 15.0 Hz'], [92218, 'Photic Off'], [92722, 'Eyes Open'], [93772, 'Eyes Closed'], [94234, 'Photic On - 18.0 Hz'], [96250, 'Photic Off'], [98308, 'Photic On - 21.0 Hz'], [100324, 'Photic Off'], [102382, 'Photic On - 24.0 Hz'], [104398, 'Photic Off'], [106414, 'Photic On - 27.0 Hz'], [108430, 'Photic Off'], [110488, 'Photic On - 30.0 Hz'], [111580, 'Eyes Open'], [111790, 'Photic Off'], [112420, 'Eyes Closed'], [113200, 'Paused']], 'class_type': 'Normal', 'class_label': 0}}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "torch.Size([20, 20000])\n",
      "{'signal': tensor([[ 0.0409,  0.0192, -0.0024,  ...,  1.5377,  1.5160,  1.4943],\n",
      "        [-0.0518, -0.1494, -0.2956,  ..., -0.3932, -0.4419, -0.4419],\n",
      "        [-0.2657, -0.2657, -0.3550,  ..., -0.2657, -0.0871,  0.0023],\n",
      "        ...,\n",
      "        [-0.5518, -0.5518, -0.6440,  ..., -0.8285, -0.7363, -0.7363],\n",
      "        [-0.1749,  0.0040,  0.0040,  ..., -0.5327, -0.4432, -0.3538],\n",
      "        [-0.5737, -0.1168, -0.1168,  ..., -0.4462, -0.2762, -0.2550]]), 'age': tensor(1.0259), 'class_label': tensor(0), 'metadata': {'serial': '00299', 'edfname': '00671212_160819', 'birth': '1938-08-17', 'record': '2019-08-16T10:57:03', 'age': 80, 'dx1': 'smi', 'label': ['normal', 'smi'], 'events': [[0, 'Start Recording'], [0, 'New Montage - Montage 005'], [1773, 'Eyes Closed'], [6000, 'Cz check'], [7612, 'Eyes Open'], [12912, 'Eyes Closed'], [18078, 'Eyes Open'], [23958, 'Eyes Closed'], [29288, 'Eyes Open'], [35934, 'Eyes Closed'], [41856, 'Eyes Open'], [47862, 'Eyes Closed'], [54460, 'Eyes Open'], [59962, 'Eyes Closed'], [66178, 'Eyes Open'], [71008, 'Eyes Closed'], [73948, 'Photic On - 3.0 Hz'], [74158, 'Eyes Open'], [75166, 'Eyes Closed'], [75964, 'Photic Off'], [77980, 'Photic On - 6.0 Hz'], [78358, 'Eyes Open'], [79282, 'Eyes Closed'], [80038, 'Photic Off'], [82054, 'Photic On - 9.0 Hz'], [84070, 'Photic Off'], [86128, 'Photic On - 12.0 Hz'], [87640, 'Eyes Open'], [88144, 'Photic Off'], [88396, 'Eyes Closed'], [90202, 'Photic On - 15.0 Hz'], [92218, 'Photic Off'], [92722, 'Eyes Open'], [93772, 'Eyes Closed'], [94234, 'Photic On - 18.0 Hz'], [96250, 'Photic Off'], [98308, 'Photic On - 21.0 Hz'], [100324, 'Photic Off'], [102382, 'Photic On - 24.0 Hz'], [104398, 'Photic Off'], [106414, 'Photic On - 27.0 Hz'], [108430, 'Photic Off'], [110488, 'Photic On - 30.0 Hz'], [111580, 'Eyes Open'], [111790, 'Photic Off'], [112420, 'Eyes Closed'], [113200, 'Paused']], 'class_type': 'Normal', 'class_label': 0}}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = EEGDataset(data_path, metadata_train, composed_train)\n",
    "val_dataset = EEGDataset(data_path, metadata_val, composed_test)\n",
    "test_dataset = EEGDataset(data_path, metadata_test, composed_test)\n",
    "longer_test_dataset = EEGDataset(data_path, metadata_test, longer_composed_test)\n",
    "\n",
    "print(train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0])\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "print(val_dataset[0]['signal'].shape)\n",
    "print(val_dataset[0])\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "print(test_dataset[0]['signal'].shape)\n",
    "print(test_dataset[0])\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "print(longer_test_dataset[0]['signal'].shape)\n",
    "print(longer_test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train, validation, test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == 'cuda':\n",
    "    num_workers = 0 # A number other than 0 causes an error\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=cfg_data['minibatch'], \n",
    "                          shuffle=True, \n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers, \n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                        batch_size=cfg_data['minibatch'], \n",
    "                        shuffle=False, \n",
    "                        drop_last=False,\n",
    "                        num_workers=num_workers, \n",
    "                        pin_memory=pin_memory,\n",
    "                        collate_fn=eeg_collate_fn)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         batch_size=cfg_data['minibatch'], \n",
    "                         shuffle=False, \n",
    "                         drop_last=False,\n",
    "                         num_workers=num_workers, \n",
    "                         pin_memory=pin_memory,\n",
    "                         collate_fn=eeg_collate_fn)\n",
    "\n",
    "longer_test_loader = DataLoader(longer_test_dataset, \n",
    "                                batch_size=cfg_data['minibatch'] // 2, # memory capacity\n",
    "                                shuffle=False, \n",
    "                                drop_last=False,\n",
    "                                num_workers=num_workers, \n",
    "                                pin_memory=pin_memory,\n",
    "                                collate_fn=eeg_collate_fn)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    sample_batched['signal'].to(device)\n",
    "    sample_batched['age'].to(device)\n",
    "    sample_batched['class_label'].to(device)\n",
    "    \n",
    "    print(i_batch, \n",
    "          sample_batched['signal'].shape, \n",
    "          sample_batched['age'].shape, \n",
    "          sample_batched['class_label'].shape, \n",
    "          len(sample_batched['metadata']))\n",
    "    \n",
    "    if i_batch > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Define Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def calculate_final_shape(model):\n",
    "    x = torch.zeros_like(sample_batched['signal']).to(device)\n",
    "    model(x, age=sample_batched['age'].to(device))\n",
    "    return model.get_final_shape()\n",
    "\n",
    "\n",
    "def visualize_network_tensorboard(model, name):\n",
    "    # default `log_dir` is \"runs\" - we'll be more specific here\n",
    "    writer = SummaryWriter('runs/' + nb_fname + '_' + name)\n",
    "\n",
    "    for batch_i, sample_batched in enumerate(train_loader):\n",
    "        # pull up the batch data\n",
    "        x = sample_batched['signal'].to(device)\n",
    "        age = sample_batched['age'].to(device)\n",
    "        target = sample_batched['class_label'].to(device)\n",
    "\n",
    "        # apply model on whole batch directly on device\n",
    "        writer.add_graph(model, (x, age))\n",
    "        output = model(x, age, print_shape=True)\n",
    "        break\n",
    "        \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_common_model = {'in_channels': train_dataset[0]['signal'].shape[0], \n",
    "                    'out_dims': len(class_label_to_type)}\n",
    "model_pool = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D Tiny CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-Tiny-CNN'\n",
    "cfg_model['generator'] = TinyCNN1D\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = None\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M7 model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = 'M7'\n",
    "cfg_model['generator'] = M7\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 256\n",
    "cfg_model['LR'] = None\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M7 model (conv-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = 'M7'\n",
    "cfg_model['generator'] = M7\n",
    "cfg_model['use_age'] = 'conv'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 256\n",
    "cfg_model['LR'] = None\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M7 model (no-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = 'M7'\n",
    "cfg_model['generator'] = M7\n",
    "cfg_model['use_age'] = None\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 256\n",
    "cfg_model['LR'] = None\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNet model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-29'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = None\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNet model (conv-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-29'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'conv'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = None\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNet model (no-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-29'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = None\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = None\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deeper 1D ResNet model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-53'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = None\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deeper 1D ResNet model (conv-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-53'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'conv'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = None\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shallower 1D ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-21'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BasicBlock1D\n",
    "cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = None\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tiny 1D ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNet-13'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BasicBlock1D\n",
    "cfg_model['conv_layers'] = [1, 1, 1, 1]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = None\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Dilated 1D ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-Multi-Dilated-ResNet-53'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = MultiBottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 32\n",
    "cfg_model['LR'] = None\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNeXt-53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-ResNeXt-53'\n",
    "cfg_model['generator'] = ResNet1D\n",
    "cfg_model['block'] = BottleneckBlock1D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['groups'] = 32\n",
    "cfg_model['LR'] = None\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNet-20 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '2D-ResNet-20' # resnet-18 + two more fc layer\n",
    "cfg_model['generator'] = ResNet2D\n",
    "cfg_model['block'] = BasicBlock2D\n",
    "cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['n_fft'] = 100\n",
    "cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "cfg_model['LR'] = None\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNet-52 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '2D-ResNet-52' # resnet-18 + two more fc layer\n",
    "cfg_model['generator'] = ResNet2D\n",
    "cfg_model['block'] = Bottleneck2D\n",
    "cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['n_fft'] = 100\n",
    "cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "cfg_model['LR'] = None\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "cfg_model['num_params'] = count_parameters(model)\n",
    "cfg_model['final_shape'] = calculate_final_shape(model)\n",
    "\n",
    "print(f'- The Number of parameters of the model: {cfg_model[\"num_params\"]:,}')\n",
    "print('- Tensor shape right before FC stage:', cfg_model[\"final_shape\"])\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN-fc-age')\n",
    "\n",
    "del model\n",
    "model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cfg_model in model_pool:\n",
    "    pprint.pp(cfg_model, width=150)\n",
    "    print('\\n' + '-' * 100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Some useful functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multistep(model, loader, optimizer, scheduler, config, steps):\n",
    "    model.train()\n",
    "        \n",
    "    i = 0\n",
    "    cumu_loss = 0\n",
    "    correct, total = (0, 0)\n",
    "    \n",
    "    while True:\n",
    "        for sample_batched in loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # load the mini-batched data\n",
    "            x = sample_batched['signal'].to(device)\n",
    "            age = sample_batched['age'].to(device)\n",
    "            y = sample_batched['class_label'].to(device)\n",
    "            \n",
    "            # forward pass\n",
    "            output = model(x, age)\n",
    "            \n",
    "            # loss function\n",
    "            if config['criterion'] == 'cross-entropy':\n",
    "                s = F.log_softmax(output, dim=1)\n",
    "                loss = F.nll_loss(s, y)\n",
    "            elif config['criterion'] == 'multi-bce':\n",
    "                y_oh = F.one_hot(y, num_classes=len(class_label_to_type))\n",
    "                s = torch.sigmoid(output)\n",
    "                loss = F.binary_cross_entropy_with_logits(output, y_oh.float())\n",
    "\n",
    "            # backward and update\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # train accuracy\n",
    "            pred = s.argmax(dim=-1)\n",
    "            correct += pred.squeeze().eq(y).sum().item()\n",
    "            total += pred.shape[0]\n",
    "            cumu_loss += loss.item()\n",
    "            \n",
    "            i += 1\n",
    "            if steps <= i: break\n",
    "        if steps <= i: break\n",
    "            \n",
    "    train_acc = 100.0 * correct / total\n",
    "    avg_loss = cumu_loss / steps\n",
    "    \n",
    "    return (avg_loss, train_acc)\n",
    "\n",
    "\n",
    "def train_mixup_multistep(model, loader, optimizer, scheduler, config, steps):\n",
    "    model.train()\n",
    "        \n",
    "    i = 0\n",
    "    cumu_loss = 0\n",
    "    correct, total = (0, 0)\n",
    "    \n",
    "    while True:\n",
    "        for sample_batched in loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # load and mixup the mini-batched data\n",
    "            x1 = sample_batched['signal'].to(device)\n",
    "            age1 = sample_batched['age'].to(device)\n",
    "            y1 = sample_batched['class_label'].to(device)\n",
    "\n",
    "            index = torch.randperm(x1.shape[0]).cuda()                \n",
    "            x2 = x1[index]\n",
    "            age2 = age1[index]\n",
    "            y2 = y1[index]\n",
    "            \n",
    "            mixup_alpha = config['mixup']\n",
    "            lam = np.random.beta(mixup_alpha, mixup_alpha)\n",
    "            x = lam * x1 + (1.0 - lam) * x2\n",
    "            age = lam * age1 + (1.0 - lam) * age2\n",
    "\n",
    "            # forward pass\n",
    "            output = model(x, age)\n",
    "            \n",
    "            # loss function\n",
    "            if config['criterion'] == 'cross-entropy':\n",
    "                s = F.log_softmax(output, dim=1)\n",
    "                loss1 = F.nll_loss(s, y1)\n",
    "                loss2 = F.nll_loss(s, y2)\n",
    "                loss = lam * loss1 + (1 - lam) * loss2\n",
    "            elif config['criterion'] == 'multi-bce':\n",
    "                y1_oh = F.one_hot(y1, num_classes=len(class_label_to_type))\n",
    "                y2_oh = F.one_hot(y2, num_classes=len(class_label_to_type))\n",
    "                y_oh = lam * y1_oh + (1.0 - lam) * y2_oh\n",
    "                s = torch.sigmoid(output)\n",
    "                loss = F.binary_cross_entropy_with_logits(output, y_oh)\n",
    "\n",
    "            # backward and update\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # train accuracy\n",
    "            pred = s.argmax(dim=-1)\n",
    "            correct1 = pred.squeeze().eq(y1).sum().item()\n",
    "            correct2 = pred.squeeze().eq(y2).sum().item()\n",
    "            correct += lam * correct1 + (1.0 - lam) * correct2\n",
    "            total += pred.shape[0]\n",
    "            cumu_loss += loss.item()\n",
    "            \n",
    "            i += 1\n",
    "            if steps <= i: break\n",
    "        if steps <= i: break\n",
    "            \n",
    "    train_acc = 100.0 * correct / total\n",
    "    avg_loss = cumu_loss / steps\n",
    "    \n",
    "    return (avg_loss, train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, loader, config, repeat=1):\n",
    "    model.eval()\n",
    "    \n",
    "    # for accuracy\n",
    "    correct, total = (0, 0) \n",
    "    \n",
    "    # for confusion matrix\n",
    "    C = len(class_label_to_type)\n",
    "    confusion_matrix = np.zeros((C, C), dtype=np.int32)\n",
    "    \n",
    "    # for debug table\n",
    "    debug_table = {data['metadata']['serial']: {'GT': data['class_label'].item(), \n",
    "                                                'Acc': 0, \n",
    "                                                'Pred': [0] * C} for data in loader.dataset}\n",
    "    \n",
    "    # for ROC curve\n",
    "    score = None\n",
    "    target = None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for k in range(repeat):\n",
    "            for sample_batched in loader:\n",
    "                # pull up the data\n",
    "                x = sample_batched['signal'].to(device)\n",
    "                age = sample_batched['age'].to(device)\n",
    "                y = sample_batched['class_label'].to(device)\n",
    "\n",
    "                # apply model on whole batch directly on device\n",
    "                output = model(x, age)\n",
    "                \n",
    "                if config['criterion'] == 'cross-entropy':\n",
    "                    s = F.softmax(output, dim=1)\n",
    "                elif config['criterion'] == 'multi-bce':\n",
    "                    s = torch.sigmoid(output)\n",
    "                \n",
    "                # calculate accuracy\n",
    "                pred = s.argmax(dim=-1)\n",
    "                correct += pred.squeeze().eq(y).sum().item()\n",
    "                total += pred.shape[0]\n",
    "\n",
    "                if score is None:\n",
    "                    score = s.detach().cpu().numpy()\n",
    "                    target = y.detach().cpu().numpy()\n",
    "                else:\n",
    "                    score = np.concatenate((score, s.detach().cpu().numpy()), axis=0)\n",
    "                    target = np.concatenate((target, y.detach().cpu().numpy()), axis=0)\n",
    "\n",
    "                # confusion matrix\n",
    "                confusion_matrix += calculate_confusion_matrix(pred, y)\n",
    "\n",
    "                # debug table\n",
    "                for n in range(pred.shape[0]):\n",
    "                    serial = sample_batched['metadata'][n]['serial']\n",
    "                    debug_table[serial]['edfname'] = sample_batched['metadata'][n]['edfname']\n",
    "                    debug_table[serial]['Pred'][pred[n].item()] += 1\n",
    "                    acc = debug_table[serial]['Pred'][y[n].item()] / np.sum(debug_table[serial]['Pred']) * 100\n",
    "                    debug_table[serial]['Acc'] = f'{acc:>6.02f}%'\n",
    "\n",
    "    # debug table update\n",
    "    debug_table_serial = []\n",
    "    debug_table_edf = []\n",
    "    debug_table_pred = []\n",
    "    debug_table_gt = []\n",
    "    \n",
    "    for key, val in debug_table.items():\n",
    "        debug_table_serial.append(key)\n",
    "        debug_table_edf.append(val['edfname'])\n",
    "        debug_table_pred.append(val['Pred'])\n",
    "        debug_table_gt.append(val['GT'])\n",
    "        \n",
    "    debug_table = (debug_table_serial, debug_table_edf, debug_table_pred, debug_table_gt)\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    return (accuracy, confusion_matrix, debug_table, score, target)\n",
    "\n",
    "\n",
    "def calculate_confusion_matrix(pred, target):\n",
    "    N = target.shape[0]\n",
    "    C = len(class_label_to_type)\n",
    "    confusion = np.zeros((C, C), dtype=np.int32)\n",
    "    \n",
    "    for i in range(N):\n",
    "        r = target[i]\n",
    "        c = pred[i]\n",
    "        confusion[r, c] += 1\n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion(confusion, use_wandb=False):\n",
    "    C = len(class_label_to_type)\n",
    "    \n",
    "    plt.style.use('default') # default, ggplot, fivethirtyeight, classic\n",
    "    plt.rcParams['image.cmap'] = 'jet' # 'nipy_spectral'\n",
    "\n",
    "    fig = plt.figure(num=1, clear=True, figsize=(4.0, 4.0), constrained_layout=True)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    im = ax.imshow(confusion, alpha=0.8)\n",
    "\n",
    "    ax.set_xticks(np.arange(C))\n",
    "    ax.set_yticks(np.arange(C))\n",
    "    ax.set_xticklabels(class_label_to_type)\n",
    "    ax.set_yticklabels(class_label_to_type)\n",
    "    \n",
    "    for r in range(C):\n",
    "        for c in range(C):\n",
    "            text = ax.text(c, r, confusion[r, c],\n",
    "                           ha=\"center\", va=\"center\", color='k')\n",
    "    \n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.set_xlabel('Prediction')\n",
    "    ax.set_ylabel('Ground Truth')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    \n",
    "    # draw\n",
    "    if use_wandb:\n",
    "        wandb.log({'Confusion Matrix (Image)': wandb.Image(plt)})\n",
    "    else: \n",
    "        plt.show()\n",
    "    \n",
    "    fig.clear()\n",
    "    plt.close(fig)\n",
    "    \n",
    "\n",
    "def draw_roc_curve(score, target, use_wandb=False):\n",
    "    plt.style.use('default') # default, ggplot, fivethirtyeight, classic\n",
    "    \n",
    "    # Binarize the output\n",
    "    n_classes = len(class_label_to_type)\n",
    "    target = label_binarize(target, classes=np.arange(n_classes))\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(target[:, i], score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(target.ravel(), score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    # aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "    \n",
    "    # draw class-agnostic ROC curve\n",
    "    fig = plt.figure(num=1, clear=True, figsize=(8.5, 4.0), constrained_layout=True)\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    lw = 1.5\n",
    "    colors = cycle(['limegreen', 'mediumpurple', 'darkorange', \n",
    "                    'dodgerblue', 'lightcoral', 'goldenrod', \n",
    "                    'indigo', 'darkgreen', 'navy', 'brown'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        ax.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                label='{0} (area = {1:0.2f})'\n",
    "                ''.format(class_label_to_type[i], roc_auc[i]))    \n",
    "    ax.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Class-Wise ROC Curves')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    # Plot class-aware ROC curves\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label='micro-average (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"micro\"]),\n",
    "             color='deeppink', linestyle='-', linewidth=lw)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "             label='macro-average (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"macro\"]),\n",
    "             color='navy', linestyle='-', linewidth=lw)\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Class-Agnostic ROC Curves')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    \n",
    "    # draw\n",
    "    if use_wandb:\n",
    "        wandb.log({'ROC Curve (Image)': wandb.Image(plt)})\n",
    "    else: \n",
    "        plt.show()\n",
    "        \n",
    "    fig.clear()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    \n",
    "def draw_debug_table(debug_table, use_wandb=False):\n",
    "    (debug_table_serial, debug_table_edf, debug_table_pred, debug_table_gt) = debug_table\n",
    "    \n",
    "    fig = plt.figure(num=1, clear=True, figsize=(20.0, 4.0), constrained_layout=True)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    total_error, total_count = (0, 0)\n",
    "\n",
    "    for edf in np.unique(debug_table_edf):\n",
    "        indices = [i for i, x in enumerate(debug_table_edf) if x == edf]\n",
    "\n",
    "        err, cnt = (0, 0)\n",
    "        for i in indices:\n",
    "            cnt += sum(debug_table_pred[i])\n",
    "            err += sum(debug_table_pred[i]) - debug_table_pred[i][debug_table_gt[i]]\n",
    "\n",
    "        total_error += err\n",
    "        total_count += cnt\n",
    "\n",
    "        ax.bar(edf, err / cnt, color=['g', 'b', 'r'][debug_table_gt[i]])\n",
    "\n",
    "    ax.set_title(f'Debug Table (Acc. {1.0 - total_error / total_count: .2f}%)', fontsize=18)\n",
    "    ax.set_ylim(0.0, 1.0)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\", fontsize=9, visible=True)\n",
    "    \n",
    "    if use_wandb:\n",
    "        table = [[serial, edf, pred, gt] for serial, edf, pred, gt in zip(*debug_table)]\n",
    "        table = wandb.Table(data=table, columns=['Serial', 'EDF', 'Prediction', 'Ground-truth'])\n",
    "        wandb.log({'Debug Table': table})\n",
    "        \n",
    "        wandb.log({'Debug Table (Image)': wandb.Image(plt)})\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    fig.clear()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_search(model, min_log_lr, max_log_lr, trials, config, steps):\n",
    "    learning_rate_record = []\n",
    "#     for t in tqdm(range(trials)):\n",
    "#         log_lr = np.random.uniform(min_log_lr, max_log_lr)\n",
    "#         lr = 10 ** log_lr\n",
    "        \n",
    "#         model.reset_weights()\n",
    "#         model.train()\n",
    "        \n",
    "#         optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=config[\"weight_decay\"])\n",
    "#         scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=config['lr_decay_step'], gamma=config['lr_decay_gamma'])        \n",
    "        \n",
    "#         _, train_accuracy = config['tr_ms'](model, train_loader, optimizer, scheduler, config, steps)\n",
    "        \n",
    "#         # Train accuracy for the final epoch is stored\n",
    "#         learning_rate_record.append((log_lr, train_accuracy))\n",
    "\n",
    "    for log_lr in tqdm(np.linspace(min_log_lr, max_log_lr, num=trials)):\n",
    "        lr = 10 ** log_lr\n",
    "        \n",
    "        model.reset_weights()\n",
    "        model.train()\n",
    "        \n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=config[\"weight_decay\"])\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=config['lr_decay_step'], gamma=config['lr_decay_gamma'])        \n",
    "        \n",
    "        _, train_accuracy = config['tr_ms'](model, train_loader, optimizer, scheduler, config, steps)\n",
    "        \n",
    "        # Train accuracy for the final epoch is stored\n",
    "        learning_rate_record.append((log_lr, train_accuracy))\n",
    "    \n",
    "    return learning_rate_record\n",
    "\n",
    "\n",
    "def draw_learning_rate_record(learning_rate_record, use_wandb=False):\n",
    "    plt.style.use('default') # default, ggplot, fivethirtyeight, classic\n",
    "\n",
    "    fig = plt.figure(num=1, clear=True, constrained_layout=True, figsize=(5.0, 5.0))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    ax.set_title('Learning Rate Search')\n",
    "    ax.set_xlabel('Learning rate in log-scale')\n",
    "    ax.set_ylabel('Train accuracy')\n",
    "\n",
    "    ax.scatter(*max(learning_rate_record, key=lambda x: x[1]), \n",
    "               s=150, c='w', marker='o', edgecolors='limegreen')\n",
    "    \n",
    "    for log_lr, val_accuracy in learning_rate_record:\n",
    "        ax.scatter(log_lr, val_accuracy, c='r',\n",
    "                   alpha=0.5, edgecolors='none')\n",
    "    \n",
    "    if use_wandb:\n",
    "        wandb.log({'Learning Rate Search Plot': plt})\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "    fig.clear()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training configurations\n",
    "cfg_train = {}\n",
    "cfg_train['iterations'] = 100000\n",
    "cfg_train['history_interval'] = cfg_train['iterations'] // 500\n",
    "cfg_train['lr_decay_step'] = round(cfg_train['iterations'] * 0.8)\n",
    "cfg_train['lr_decay_gamma'] = 0.1\n",
    "cfg_train['weight_decay'] = 1e-2\n",
    "cfg_train['mixup'] = 0.3 # 0 for no usage\n",
    "cfg_train['criterion'] = 'cross-entropy' # 'cross-entropy', 'multi-bce'\n",
    "cfg_train['tr_ms'] = train_multistep if cfg_train.get('mixup', 0) < 1e-12 else train_mixup_multistep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cfg_model in model_pool:\n",
    "    if cfg_model[\"LR\"] is None:\n",
    "        print(f'{cfg_model[\"model\"]} LR searching..')\n",
    "        model = cfg_model['generator'](**cfg_model).to(device)\n",
    "        model.train()\n",
    "        \n",
    "        record = learning_rate_search(model, min_log_lr=-4.5, max_log_lr=-1.8, \n",
    "                                      trials=100, config=cfg_train, steps=100)\n",
    "        best_log_lr = record[np.argmax(np.array([v for lr, v in record]))][0]\n",
    "        \n",
    "        cfg_model['LR'] = 10 ** best_log_lr\n",
    "        cfg_model['lr_search'] = record\n",
    "        \n",
    "        print(f'best lr {cfg_model[\"LR\"]:.5e} / log_lr {best_log_lr}')\n",
    "    else:\n",
    "        print(f'{cfg_model[\"model\"]}: {cfg_model[\"LR\"]:.5e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = True\n",
    "save_temporary = False\n",
    "draw_result = True\n",
    "\n",
    "# progress bar\n",
    "pbar = tqdm(total=len(model_pool) * cfg_train['iterations'])\n",
    "\n",
    "# train process on model_pool\n",
    "for cfg_model in model_pool:\n",
    "    print('*'*110)\n",
    "    print(f'{\"*\"*40} {cfg_model[\"model\"]:^30} train starts {\"*\"*40}')\n",
    "    print('*'*110)\n",
    "    \n",
    "    # wandb initialization\n",
    "    config = {}\n",
    "    config.update(cfg_data)\n",
    "    config.update(cfg_train)\n",
    "    config.update(cfg_model)\n",
    "    \n",
    "    # generate model and its trainer\n",
    "    model = config['generator'](**config).to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), \n",
    "                            lr=config['LR'], \n",
    "                            weight_decay=config['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, \n",
    "                                          step_size=config['lr_decay_step'], \n",
    "                                          gamma=config['lr_decay_gamma'])\n",
    "    \n",
    "    wandb_run = wandb.init(project=\"eeg-analysis\", \n",
    "                           entity=\"ipis-mjkim\", \n",
    "                           reinit=True,\n",
    "                           save_code=True, \n",
    "                           notes=nb_fname,\n",
    "                           config=config)\n",
    "    wandb.run.name = wandb.run.id\n",
    "    \n",
    "    save_path = f'history_temp/{wandb.run.name}/'\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    with wandb_run:\n",
    "        wandb.watch(model, log='all', \n",
    "                    log_freq=config['history_interval'], \n",
    "                    log_graph=True)\n",
    "        \n",
    "        # train and validation routine\n",
    "        best_val_acc = 0\n",
    "        for i in range(0, config[\"iterations\"], config[\"history_interval\"]):\n",
    "            # train 'history_interval' steps\n",
    "            loss, train_acc = cfg_train['tr_ms'](model, train_loader, optimizer, scheduler, \n",
    "                                                 config, config[\"history_interval\"])\n",
    "            \n",
    "            # validation\n",
    "            val_acc, _, _, _, _ = check_accuracy(model, val_loader, config, repeat=10)\n",
    "            \n",
    "            if best_val_acc < val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_model_state = deepcopy(model.state_dict())                \n",
    "                if save_model and save_temporary:\n",
    "                    path = os.path.join(save_path, f'{config[\"model\"]}')\n",
    "                    torch.save(best_model_state, path)                    \n",
    "                \n",
    "            # log\n",
    "            wandb.log({'Loss': loss, \n",
    "                       'Train Accuracy': train_acc, \n",
    "                       'Validation Accuracy': val_acc}, step=i)\n",
    "            pbar.update(config['history_interval'])\n",
    "\n",
    "        # calculate the test accuracies for best and last models\n",
    "        last_model_state = deepcopy(model.state_dict())\n",
    "        last_test_result = check_accuracy(model, test_loader, config, repeat=30)\n",
    "        last_test_acc = last_test_result[0]\n",
    "        \n",
    "        model.load_state_dict(best_model_state)\n",
    "        best_test_result = check_accuracy(model, test_loader, config, repeat=30)\n",
    "        best_test_acc = best_test_result[0]\n",
    " \n",
    "        if last_test_acc < best_test_acc:\n",
    "            model_state = best_model_state\n",
    "            test_result = best_test_result\n",
    "        else:\n",
    "            model_state = last_model_state\n",
    "            test_result = last_test_result\n",
    "            \n",
    "        model.load_state_dict(model_state)\n",
    "        test_acc, test_confusion, test_debug, score, target = test_result\n",
    "        \n",
    "        # calculate the test accuracies for final model on much longer sequence\n",
    "        last_test_result = check_accuracy(model, longer_test_loader, config, repeat=30)\n",
    "        longer_test_acc = last_test_result[0]\n",
    "        \n",
    "        # save the model\n",
    "        if save_model:\n",
    "            path = os.path.join(save_path, f'{config[\"model\"]}')\n",
    "            torch.save(model_state, path)\n",
    "            \n",
    "        # leave the message\n",
    "        wandb.log({'Test Accuracy': test_acc,\n",
    "                   '(Best / Last) Test Accuracy': ('Best' if last_test_acc < best_test_acc else 'Last', \n",
    "                                                   round(best_test_acc, 2), round(last_test_acc, 2)),\n",
    "                   'Confusion Matrix (Array)': test_confusion,\n",
    "                   'Test Accuracy (Longer)': longer_test_acc, \n",
    "                   'Test Debug Table/Serial': test_debug[0], \n",
    "                   'Test Debug Table/EDF': test_debug[1], \n",
    "                   'Test Debug Table/Pred': test_debug[2], \n",
    "                   'Test Debug Table/GT': test_debug[3]})\n",
    "        \n",
    "        if 'lr_search' in config:\n",
    "            draw_learning_rate_record(config['lr_search'], use_wandb=True)\n",
    "            \n",
    "        \n",
    "        if draw_result:\n",
    "            draw_roc_curve(score, target, use_wandb=True)\n",
    "            draw_confusion(test_confusion, use_wandb=True)\n",
    "            draw_debug_table(test_debug, use_wandb=True)\n",
    "            wandb.log({\"Confusion Matrix\": wandb.plot.confusion_matrix(y_true=target, \n",
    "                                                                              preds=score.argmax(axis=-1), \n",
    "                                                                              class_names=class_label_to_type)})\n",
    "            wandb.log({\"ROC Curve\": wandb.plot.roc_curve(target, score, labels=class_label_to_type)})\n",
    "            \n",
    "            \n",
    "    print('\\n' + '-' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
