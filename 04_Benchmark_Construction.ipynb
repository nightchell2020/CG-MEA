{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Construction\n",
    "\n",
    "This notebook organizes the standard benchmark of our `CAUEEG` dataset using the previously generated signal, annotation, and event files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 환경 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_dataset import *\n",
    "from datasets.pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data file path\n",
    "data_path = r'local/dataset/02_Curated_Data_220419/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'age': 78, 'serial': '00001', 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf']},\n",
      "          {'age': 56, 'serial': '00002', 'symptom': ['normal', 'smi']},\n",
      "          {'age': 93, 'serial': '00003', 'symptom': ['mci', 'mci_vascular']},\n",
      "          {'age': 78, 'serial': '00004', 'symptom': ['dementia', 'ad', 'load']},\n",
      "          {'age': 75, 'serial': '00005', 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_ef', 'mci_multi_domain']}],\n",
      " 'dataset_name': 'CAUEEG dataset',\n",
      " 'signal_header': ['Fp1-AVG', 'F3-AVG', 'C3-AVG', 'P3-AVG', 'O1-AVG', 'Fp2-AVG', 'F4-AVG', 'C4-AVG', 'P4-AVG', 'O2-AVG', 'F7-AVG', 'T3-AVG', 'T5-AVG', 'F8-AVG', 'T4-AVG', 'T6-AVG', 'FZ-AVG', 'CZ-AVG', 'PZ-AVG', 'EKG', 'Photic']}\n"
     ]
    }
   ],
   "source": [
    "anno_path = os.path.join(data_path, 'annotation.json')\n",
    "with open(anno_path, 'r') as json_file:\n",
    "    annotation = json.load(json_file)\n",
    "\n",
    "pprint.pprint({k: (v if k != 'data' else v[:5]) for (k, v) in annotation.items()}, width=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_splitted_metadata(splitted_metadata, class_label_to_name, ratios, seed=None, verbose=False):\n",
    "    # random seed\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    else:\n",
    "        random.seed()\n",
    "\n",
    "    metadata_train = []\n",
    "    metadata_val = []\n",
    "    metadata_test = []\n",
    "\n",
    "    for split in splitted_metadata:\n",
    "        random.shuffle(split)\n",
    "\n",
    "        n1 = round(len(split) * ratios[0])\n",
    "        n2 = n1 + round(len(split) * ratios[1])\n",
    "\n",
    "        metadata_train.extend(split[:n1])\n",
    "        metadata_val.extend(split[n1:n2])\n",
    "        metadata_test.extend(split[n2:])\n",
    "\n",
    "    random.shuffle(metadata_train)\n",
    "    random.shuffle(metadata_val)\n",
    "    random.shuffle(metadata_test)\n",
    "\n",
    "    if verbose:\n",
    "        train_class_dist = [np.sum([1 for m in metadata_train if m['class_label'] == i])\n",
    "                            for i in range(len(class_label_to_name))]\n",
    "\n",
    "        val_class_dist = [np.sum([1 for m in metadata_val if m['class_label'] == i])\n",
    "                          for i in range(len(class_label_to_name))]\n",
    "\n",
    "        test_class_dist = [np.sum([1 for m in metadata_test if m['class_label'] == i])\n",
    "                           for i in range(len(class_label_to_name))]\n",
    "\n",
    "        print(f'<{\"Train\":^15}> data label distribution\\t:', train_class_dist, '=', np.sum(train_class_dist))\n",
    "        print(f'<{\"Validation\":^15}> data label distribution\\t:', val_class_dist, '=', np.sum(val_class_dist))\n",
    "        print(f'<{\"Test\":^15}> data label distribution\\t:', test_class_dist, '=', np.sum(test_class_dist))\n",
    "\n",
    "    # restore random seed (stochastic)\n",
    "    random.seed()\n",
    "\n",
    "    return metadata_train, metadata_val, metadata_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "-----\n",
    "\n",
    "## Main Task 1: Classification of Three Symptoms (Normal, MCI, Dementia)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the target diagnoses and split them by their symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_label_to_name: ['Normal', 'MCI', 'Dementia']\n",
      "class_name_to_label: {'Normal': 0, 'MCI': 1, 'Dementia': 2}\n"
     ]
    }
   ],
   "source": [
    "diagnosis_filter = [\n",
    "    # Normal\n",
    "    {'name': 'Normal',\n",
    "     'include': ['normal'], \n",
    "     'exclude': []},\n",
    "    # Non-vascular MCI\n",
    "    {'name': 'MCI',\n",
    "     'include': ['mci'], \n",
    "     'exclude': []},\n",
    "    # Non-vascular dementia\n",
    "    {'name': 'Dementia',\n",
    "     'include': ['dementia'], \n",
    "     'exclude': []},\n",
    "]\n",
    "\n",
    "class_label_to_name = [d_f['name'] for d_f in diagnosis_filter]\n",
    "print('class_label_to_name:', class_label_to_name)\n",
    "\n",
    "class_name_to_label = {d_f['name']: i for i, d_f in enumerate(diagnosis_filter)}\n",
    "print('class_name_to_label:', class_name_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- There are 459 data belonging to Normal\n",
      "- There are 417 data belonging to MCI\n",
      "- There are 311 data belonging to Dementia\n"
     ]
    }
   ],
   "source": [
    "# Split the filtered dataset\n",
    "splitted_metadata = [[] for _ in diagnosis_filter]\n",
    "\n",
    "for m in annotation['data']:\n",
    "    symptom = m['symptom']\n",
    "    for c, f in enumerate(diagnosis_filter):\n",
    "        inc = set(f['include']) & set(symptom) == set(f['include'])\n",
    "        # inc = len(set(f['include']) & set(label)) > 0\n",
    "        exc = len(set(f['exclude']) & set(symptom)) == 0\n",
    "        if inc and exc:\n",
    "            m['class_name'] = f['name']\n",
    "            m['class_label'] = c\n",
    "            splitted_metadata[c].append(m)\n",
    "            break\n",
    "\n",
    "for i, split in enumerate(splitted_metadata):\n",
    "    if len(split) == 0:\n",
    "        raise ValueError(f'(Warning) Split group {i} has no data.')\n",
    "    print(f'- There are {len(split):} data belonging to {split[0][\"class_name\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle the divided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, validation, test sets ratios: [0.8 0.1 0.1]\n"
     ]
    }
   ],
   "source": [
    "ratios = np.array([8, 1, 1])\n",
    "ratios = ratios / ratios.sum()\n",
    "print('Train, validation, test sets ratios:', ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<     Train     > data label distribution\t: [367, 334, 249] = 950\n",
      "<  Validation   > data label distribution\t: [46, 42, 31] = 119\n",
      "<     Test      > data label distribution\t: [46, 41, 31] = 118\n"
     ]
    }
   ],
   "source": [
    "metadata_train, metadata_val, metadata_test = shuffle_splitted_metadata(splitted_metadata, \n",
    "                                                                        class_label_to_name, \n",
    "                                                                        ratios, \n",
    "                                                                        seed=None, \n",
    "                                                                        verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the dataset as JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\ttask_name:\n",
      "\t\tCAUEEG-task1 benchmark\n",
      "\n",
      "\ttask_description:\n",
      "\t\tClassification of [Normal], [MCI], and [Dementia] symptoms.\n",
      "\n",
      "\tclass_label_to_name:\n",
      "\t\t['Normal', 'MCI', 'Dementia']\n",
      "\n",
      "\tclass_name_to_label:\n",
      "\t\t{'Normal': 0, 'MCI': 1, 'Dementia': 2}\n",
      "\n",
      "\ttrain_split:\n",
      "\t\t{'serial': '00422', 'age': 72, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\t\t{'serial': '01137', 'age': 61, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\t\t{'serial': '00634', 'age': 73, 'symptom': ['mci', 'mci_amnestic'], 'class_name': 'MCI', 'class_label': 1}\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t{'serial': '00594', 'age': 75, 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_ef'], 'class_name': 'MCI', 'class_label': 1}\n",
      "\n",
      "\tvalidation_split:\n",
      "\t\t{'serial': '00916', 'age': 72, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\t\t{'serial': '00918', 'age': 71, 'symptom': ['normal', 'smi'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\t\t{'serial': '00606', 'age': 64, 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf'], 'class_name': 'MCI', 'class_label': 1}\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t{'serial': '01074', 'age': 75, 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_ef'], 'class_name': 'MCI', 'class_label': 1}\n",
      "\n",
      "\ttest_split:\n",
      "\t\t{'serial': '00385', 'age': 81, 'symptom': ['normal', 'smi'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\t\t{'serial': '00120', 'age': 77, 'symptom': ['dementia', 'vd', 'sivd'], 'class_name': 'Dementia', 'class_label': 2}\n",
      "\t\t{'serial': '00671', 'age': 71, 'symptom': ['dementia', 'ad', 'load'], 'class_name': 'Dementia', 'class_label': 2}\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t{'serial': '00074', 'age': 64, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\n",
      "}\n",
      "task1.json file is saved.\n"
     ]
    }
   ],
   "source": [
    "task_dict = dict()\n",
    "\n",
    "task_dict['task_name'] = 'CAUEEG-task1 benchmark'\n",
    "task_dict['task_description'] = 'Classification of [Normal], [MCI], and [Dementia] symptoms.'\n",
    "task_dict['class_label_to_name'] = class_label_to_name\n",
    "task_dict['class_name_to_label'] = class_name_to_label\n",
    "\n",
    "task_dict['train_split'] = metadata_train\n",
    "task_dict['validation_split'] = metadata_val\n",
    "task_dict['test_split'] = metadata_test\n",
    "\n",
    "print('{')\n",
    "for k, v in task_dict.items():\n",
    "    print(f'\\t{k}:')\n",
    "    if isinstance(v, list) and len(v) > 3:\n",
    "        print(f'\\t\\t{v[0]}')\n",
    "        print(f'\\t\\t{v[1]}')\n",
    "        print(f'\\t\\t{v[2]}')\n",
    "        print(f'\\t\\t.')\n",
    "        print(f'\\t\\t.')\n",
    "        print(f'\\t\\t.')\n",
    "        print(f'\\t\\t{v[-1]}')\n",
    "    else:\n",
    "        print(f'\\t\\t{v}')\n",
    "    print()\n",
    "print('}')\n",
    "\n",
    "with open(os.path.join(data_path, 'task1.json'), 'w') as json_file:\n",
    "    json.dump(task_dict, json_file, indent=4)\n",
    "    print('task1.json file is saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 2: Classification of Normal and Abnormal Symptoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the target diagnoses and split them by their symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_label_to_name: ['Normal', 'Abnormal']\n",
      "class_name_to_label: {'Normal': 0, 'Abnormal': 1}\n"
     ]
    }
   ],
   "source": [
    "diagnosis_filter = [\n",
    "    # Normal\n",
    "    {'name': 'Normal',\n",
    "     'include': ['normal'], \n",
    "     'exclude': []},\n",
    "    # Abnormal\n",
    "    {'name': 'Abnormal',\n",
    "     'include': [], \n",
    "     'exclude': ['normal']},\n",
    "]\n",
    "\n",
    "class_label_to_name = [d_f['name'] for d_f in diagnosis_filter]\n",
    "print('class_label_to_name:', class_label_to_name)\n",
    "\n",
    "class_name_to_label = {d_f['name']: i for i, d_f in enumerate(diagnosis_filter)}\n",
    "print('class_name_to_label:', class_name_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- There are 459 data belonging to Normal\n",
      "- There are 929 data belonging to Abnormal\n"
     ]
    }
   ],
   "source": [
    "# Split the filtered dataset\n",
    "splitted_metadata = [[] for _ in diagnosis_filter]\n",
    "\n",
    "for m in annotation['data']:\n",
    "    symptom = m['symptom']\n",
    "    for c, f in enumerate(diagnosis_filter):\n",
    "        inc = set(f['include']) & set(symptom) == set(f['include'])\n",
    "        # inc = len(set(f['include']) & set(label)) > 0\n",
    "        exc = len(set(f['exclude']) & set(symptom)) == 0\n",
    "        if inc and exc:\n",
    "            m['class_name'] = f['name']\n",
    "            m['class_label'] = c\n",
    "            splitted_metadata[c].append(m)\n",
    "            break\n",
    "\n",
    "for i, split in enumerate(splitted_metadata):\n",
    "    if len(split) == 0:\n",
    "        raise ValueError(f'(Warning) Split group {i} has no data.')\n",
    "    print(f'- There are {len(split):} data belonging to {split[0][\"class_name\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle the divided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, validation, test sets ratios: [0.8 0.1 0.1]\n"
     ]
    }
   ],
   "source": [
    "ratios = np.array([8, 1, 1])\n",
    "ratios = ratios / ratios.sum()\n",
    "print('Train, validation, test sets ratios:', ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<     Train     > data label distribution\t: [367, 743] = 1110\n",
      "<  Validation   > data label distribution\t: [46, 93] = 139\n",
      "<     Test      > data label distribution\t: [46, 93] = 139\n"
     ]
    }
   ],
   "source": [
    "metadata_train, metadata_val, metadata_test = shuffle_splitted_metadata(splitted_metadata, \n",
    "                                                                        class_label_to_name, \n",
    "                                                                        ratios, \n",
    "                                                                        seed=None, \n",
    "                                                                        verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the dataset as JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\ttask_name:\n",
      "\t\tCAUEEG-task2 benchmark\n",
      "\n",
      "\ttask_description:\n",
      "\t\tClassification of [Normal] and [Abnormal] symptoms\n",
      "\n",
      "\tclass_label_to_name:\n",
      "\t\t['Normal', 'Abnormal']\n",
      "\n",
      "\tclass_name_to_label:\n",
      "\t\t{'Normal': 0, 'Abnormal': 1}\n",
      "\n",
      "\ttrain_split:\n",
      "\t\t{'serial': '00763', 'age': 76, 'symptom': ['dementia', 'ad', 'load'], 'class_name': 'Abnormal', 'class_label': 1}\n",
      "\t\t{'serial': '01206', 'age': 77, 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_ef'], 'class_name': 'Abnormal', 'class_label': 1}\n",
      "\t\t{'serial': '00685', 'age': 72, 'symptom': ['mci', 'mci_vascular'], 'class_name': 'Abnormal', 'class_label': 1}\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t{'serial': '00767', 'age': 61, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\n",
      "\tvalidation_split:\n",
      "\t\t{'serial': '01249', 'age': 68, 'symptom': ['normal', 'smi'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\t\t{'serial': '00252', 'age': 85, 'symptom': ['dementia', 'vd', 'sivd'], 'class_name': 'Abnormal', 'class_label': 1}\n",
      "\t\t{'serial': '00891', 'age': 69, 'symptom': ['ftd', 'semantic_aphasia'], 'class_name': 'Abnormal', 'class_label': 1}\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t{'serial': '00538', 'age': 57, 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf'], 'class_name': 'Abnormal', 'class_label': 1}\n",
      "\n",
      "\ttest_split:\n",
      "\t\t{'serial': '01335', 'age': 81, 'symptom': ['mci', 'mci_vascular'], 'class_name': 'Abnormal', 'class_label': 1}\n",
      "\t\t{'serial': '00998', 'age': 40, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\t\t{'serial': '00674', 'age': 68, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t{'serial': '00453', 'age': 75, 'symptom': ['dementia', 'vd', 'sivd'], 'class_name': 'Abnormal', 'class_label': 1}\n",
      "\n",
      "}\n",
      "task2.json file is saved.\n"
     ]
    }
   ],
   "source": [
    "task_dict = dict()\n",
    "\n",
    "task_dict['task_name'] = 'CAUEEG-task2 benchmark'\n",
    "task_dict['task_description'] = 'Classification of [Normal] and [Abnormal] symptoms'\n",
    "task_dict['class_label_to_name'] = class_label_to_name\n",
    "task_dict['class_name_to_label'] = class_name_to_label\n",
    "\n",
    "task_dict['train_split'] = metadata_train\n",
    "task_dict['validation_split'] = metadata_val\n",
    "task_dict['test_split'] = metadata_test\n",
    "\n",
    "print('{')\n",
    "for k, v in task_dict.items():\n",
    "    print(f'\\t{k}:')\n",
    "    if isinstance(v, list) and len(v) > 3:\n",
    "        print(f'\\t\\t{v[0]}')\n",
    "        print(f'\\t\\t{v[1]}')\n",
    "        print(f'\\t\\t{v[2]}')\n",
    "        print(f'\\t\\t.')\n",
    "        print(f'\\t\\t.')\n",
    "        print(f'\\t\\t.')\n",
    "        print(f'\\t\\t{v[-1]}')\n",
    "    else:\n",
    "        print(f'\\t\\t{v}')\n",
    "    print()\n",
    "print('}')\n",
    "\n",
    "with open(os.path.join(data_path, 'task2.json'), 'w') as json_file:\n",
    "    json.dump(task_dict, json_file, indent=4)\n",
    "    print('task2.json file is saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
