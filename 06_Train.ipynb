{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Networks\n",
    "\n",
    "- Three-way SoftMax or Multi-BCE classifier of normal, non-vascular MCI, and non-vascular dementia\n",
    "- `Weights and Biases` sweep is used for hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pprint\n",
    "import wandb\n",
    "\n",
    "# custom package\n",
    "from datasets.cau_eeg_dataset import *\n",
    "from datasets.cau_eeg_script import *\n",
    "from models import *\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.11.0\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Set the default configuration for building datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_data = {}\n",
    "cfg_data['device'] = device\n",
    "cfg_data['dataset'] = 'CAUHS'\n",
    "cfg_data['data_path'] = r'local/dataset/02_Curated_Data_220322/'\n",
    "cfg_data['meta_path'] = os.path.join(cfg_data['data_path'], 'metadata_debug.json')\n",
    "cfg_data['file_format'] = 'feather'  # 'feather', 'memmap'\n",
    "cfg_data['target_task'] = 'Normal, MCI, Dementia' # 'Norml, MCI, Dementia'\n",
    "cfg_data['vascular'] = 'X'\n",
    "cfg_data['segment'] = 'no' # 'train', 'all', 'no'\n",
    "cfg_data['seed'] = 0\n",
    "cfg_data['latency'] = 200 * 10  # 10 seconds\n",
    "cfg_data['crop_length'] = 200 * 10 # 10 seconds\n",
    "cfg_data['longer_crop_length'] = 200 * 10 * 10 # 100 seconds\n",
    "cfg_data['crop_multiple'] = 4\n",
    "cfg_data['minibatch'] = 128\n",
    "cfg_data['input_norm'] = 'dataset' # 'datatset', 'datapoint', 'no'\n",
    "cfg_data['EKG'] = 'X'\n",
    "cfg_data['photic'] = 'X'\n",
    "cfg_data['awgn'] = 3e-2\n",
    "cfg_data['mgn'] = 1e-4\n",
    "cfg_data['awgn_age'] = 5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_label_to_type: ['Normal', 'Non-vascular MCI', 'Non-vascular dementia']\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- There are 458 data belonging to Normal\n",
      "- There are 350 data belonging to Non-vascular MCI\n",
      "- There are 233 data belonging to Non-vascular dementia\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Train data label distribution\t: [366, 280, 186] 832\n",
      "Train data label distribution\t: [46, 35, 23] 104\n",
      "Train data label distribution\t: [46, 35, 24] 105\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "composed_train: Compose(\n",
      "    <datasets.pipeline.EegDropEKGChannel object at 0x0000028F05273040>\n",
      "    <datasets.pipeline.EegDropPhoticChannel object at 0x0000028F05182FD0>\n",
      "    <datasets.pipeline.EegRandomCrop object at 0x0000028F289FF0A0>\n",
      "    <datasets.pipeline.EegToTensor object at 0x0000028F289FF1C0>\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "composed_test: Compose(\n",
      "    <datasets.pipeline.EegDropEKGChannel object at 0x0000028F05273160>\n",
      "    <datasets.pipeline.EegDropPhoticChannel object at 0x0000028F289FF040>\n",
      "    <datasets.pipeline.EegRandomCrop object at 0x0000028F289FF100>\n",
      "    <datasets.pipeline.EegToTensor object at 0x0000028F289FF1F0>\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "longer_composed_test: Compose(\n",
      "    <datasets.pipeline.EegDropEKGChannel object at 0x0000028F052737C0>\n",
      "    <datasets.pipeline.EegDropPhoticChannel object at 0x0000028F289FF070>\n",
      "    <datasets.pipeline.EegRandomCrop object at 0x0000028F289FF160>\n",
      "    <datasets.pipeline.EegToTensor object at 0x0000028F289FF220>\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "train_dataset[0].keys():\n",
      "dict_keys(['signal', 'age', 'class_label', 'metadata'])\n",
      "train_dataset[0][\"signal\"]:\n",
      "[tensor([[ 11.,  11.,  10.,  ..., -10.,  -8.,  -8.],\n",
      "        [ -5.,  -5.,  -6.,  ...,  20.,  22.,  23.],\n",
      "        [-15., -16., -17.,  ...,  35.,  36.,  36.],\n",
      "        ...,\n",
      "        [  5.,   4.,   3.,  ...,  39.,  41.,  42.],\n",
      "        [  5.,   5.,   4.,  ...,  -5.,  -3.,  -3.],\n",
      "        [-10., -10., -10.,  ...,  -2.,  -3.,  -5.]]),\n",
      " tensor([[  9.,   9.,  10.,  ..., -37., -37., -37.],\n",
      "        [-19., -19., -17.,  ..., -10., -11., -11.],\n",
      "        [  1.,   0.,   0.,  ...,   6.,   6.,   6.],\n",
      "        ...,\n",
      "        [ 21.,  20.,  20.,  ...,   7.,   5.,   4.],\n",
      "        [ 25.,  24.,  23.,  ...,   3.,   1.,  -1.],\n",
      "        [ 11.,  10.,   9.,  ..., -18., -20., -21.]]),\n",
      " tensor([[-75., -74., -75.,  ...,  29.,  29.,  29.],\n",
      "        [-26., -25., -24.,  ...,  -4.,  -5.,  -4.],\n",
      "        [  8.,   7.,   7.,  ...,   4.,   3.,   2.],\n",
      "        ...,\n",
      "        [-35., -33., -33.,  ...,  -1.,  -2.,  -2.],\n",
      "        [-11., -10.,  -8.,  ...,   6.,   4.,   4.],\n",
      "        [ 10.,  10.,  10.,  ..., -21., -21., -21.]]),\n",
      " tensor([[ 58.,  58.,  58.,  ...,  33.,  33.,  33.],\n",
      "        [ -1.,  -1.,   0.,  ...,  -3.,  -4.,  -4.],\n",
      "        [-40., -40., -40.,  ...,  20.,  19.,  17.],\n",
      "        ...,\n",
      "        [ -5.,  -4.,  -4.,  ...,  -3.,  -3.,  -3.],\n",
      "        [-15., -13., -12.,  ...,  17.,  17.,  18.],\n",
      "        [ 19.,  20.,  21.,  ...,  28.,  28.,  28.]])]\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "val_dataset[0].keys():\n",
      "dict_keys(['signal', 'age', 'class_label', 'metadata'])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_dataset[0].keys():\n",
      "dict_keys(['signal', 'age', 'class_label', 'metadata'])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_dataset_longer[0].keys():\n",
      "dict_keys(['signal', 'age', 'class_label', 'metadata'])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "train_loader:\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x0000028F05273850>\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "val_loader:\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x0000028F289FFBE0>\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_loader:\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x0000028F289FFC40>\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_loader_longer:\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x0000028F289FF9A0>\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "preprocess_train: Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeMeanStd(mean=tensor([ 0.3127,  0.0253, -0.0662, -0.0145, -0.0289,  0.3294,  0.0466,  0.0035,\n",
      "          -0.0323,  0.0394,  0.0848, -0.0136,  0.0065,  0.0279,  0.0233, -0.0263,\n",
      "          -0.0350, -0.0129,  0.0016]),std=tensor([44.5796, 19.7940, 11.4045, 11.3983, 15.0371, 47.7395, 18.8919, 10.2774,\n",
      "          11.0191, 15.0637, 20.2013, 14.0815, 13.2244, 21.2146, 16.3532, 14.1033,\n",
      "          18.8851, 10.8567, 11.1762]),eps=1e-08)\n",
      "  (2): EegNormalizeAge(mean=tensor([70.3113]),std=tensor([9.5873]),eps=1e-08)\n",
      "  (3): EegAdditiveGaussianNoise(mean=0.0,std=0.03)\n",
      "  (4): EegMultiplicativeGaussianNoise(mean=0.0,std=0.0001)\n",
      "  (5): EegAddGaussianNoiseAge(mean=0.0,std=0.05)\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "preprocess_test: Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeMeanStd(mean=tensor([ 0.3127,  0.0253, -0.0662, -0.0145, -0.0289,  0.3294,  0.0466,  0.0035,\n",
      "          -0.0323,  0.0394,  0.0848, -0.0136,  0.0065,  0.0279,  0.0233, -0.0263,\n",
      "          -0.0350, -0.0129,  0.0016]),std=tensor([44.5796, 19.7940, 11.4045, 11.3983, 15.0371, 47.7395, 18.8919, 10.2774,\n",
      "          11.0191, 15.0637, 20.2013, 14.0815, 13.2244, 21.2146, 16.3532, 14.1033,\n",
      "          18.8851, 10.8567, 11.1762]),eps=1e-08)\n",
      "  (2): EegNormalizeAge(mean=tensor([70.3113]),std=tensor([9.5873]),eps=1e-08)\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "0 torch.Size([128, 19, 2000]) torch.Size([128]) torch.Size([128]) 128\n",
      "1 torch.Size([128, 19, 2000]) torch.Size([128]) torch.Size([128]) 128\n",
      "2 torch.Size([128, 19, 2000]) torch.Size([128]) torch.Size([128]) 128\n",
      "3 torch.Size([128, 19, 2000]) torch.Size([128]) torch.Size([128]) 128\n",
      "4 torch.Size([128, 19, 2000]) torch.Size([128]) torch.Size([128]) 128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = build_dataset(cfg_data, verbose=True)\n",
    "train_loader = _[0]\n",
    "val_loader = _[1]\n",
    "test_loader = _[2]\n",
    "test_loader_longer = _[3]\n",
    "preprocess_train = _[4]\n",
    "preprocess_test = _[5]\n",
    "class_label_to_type = _[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Define Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg_data.get('crop_multiple', 1) == 1:\n",
    "    cfg_common_model = {'in_channels': _[0].dataset[0]['signal'].shape[0], \n",
    "                        'out_dims': len(_[-1])}\n",
    "else:\n",
    "    cfg_common_model = {'in_channels': _[0].dataset[0]['signal'][0].shape[0], \n",
    "                        'out_dims': len(_[-1])}\n",
    "\n",
    "del _\n",
    "cfg_model_pool = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D Tiny CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-Tiny-CNN'\n",
    "cfg_model['generator'] = TinyCNN1D\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = None\n",
    "cfg_model['dropout'] = 0.3\n",
    "cfg_model['activation'] = 'mish'\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M7 model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-Mx'\n",
    "# cfg_model['generator'] = M7\n",
    "# cfg_model['fc_stages'] = 1\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 256\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNet model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNet-2x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deeper 1D ResNet model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNet-5x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shallower 1D ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNet-2x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BasicBlock1D\n",
    "# cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tiny 1D ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNet-1x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BasicBlock1D\n",
    "# cfg_model['conv_layers'] = [1, 1, 1, 1]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['dropout'] = 0.2\n",
    "# cfg_model['activation'] = 'mish'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Dilated 1D ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-Multi-Dilated-ResNet-5x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = MultiBottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 32\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNeXt-53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNeXt-5x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['groups'] = 32\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNeXt-103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNeXt-10x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 23, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['groups'] = 32\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNet-20 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '2D-ResNet-2x' # resnet-18 + three more fc layer\n",
    "# cfg_model['generator'] = ResNet2D\n",
    "# cfg_model['block'] = BasicBlock2D\n",
    "# cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['n_fft'] = 100\n",
    "# cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "# cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNet-52 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '2D-ResNet-5x' # resnet-50 + three more fc layer\n",
    "# cfg_model['generator'] = ResNet2D\n",
    "# cfg_model['block'] = Bottleneck2D\n",
    "# cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['n_fft'] = 100\n",
    "# cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "# cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNeXt-104 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '2D-ResNeXt-10x' # resnet-101 + three more fc layer\n",
    "# cfg_model['generator'] = ResNet2D\n",
    "# cfg_model['block'] = Bottleneck2D\n",
    "# cfg_model['conv_layers'] = [3, 4, 23, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['n_fft'] = 100\n",
    "# cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "# cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "# cfg_model['groups'] = 32\n",
    "# cfg_model['width_per_group'] = 8\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN-Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Model config:'\n",
      "{'LR': None,\n",
      " 'activation': 'relu',\n",
      " 'base_channels': 192,\n",
      " 'dropout': 0.2,\n",
      " 'fc_stages': 2,\n",
      " 'final_pool': 'max',\n",
      " 'generator': <class 'models.cnn_transformer.CNNTransformer'>,\n",
      " 'in_channels': 19,\n",
      " 'model': '1D-CNN-Transformer',\n",
      " 'n_encoders': 8,\n",
      " 'n_heads': 4,\n",
      " 'out_dims': 3,\n",
      " 'use_age': 'fc'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "CNNTransformer(\n",
      "  (conv1): Conv1d(19, 192, kernel_size=(21,), stride=(9,))\n",
      "  (bn1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv1d(192, 192, kernel_size=(9,), stride=(3,))\n",
      "  (bn2): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (6): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (7): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv1d(192, 384, kernel_size=(9,), stride=(3,))\n",
      "  (bn3): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv1d(384, 384, kernel_size=(9,), stride=(3,))\n",
      "  (bn4): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (final_pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc_stage): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=385, out_features=192, bias=False)\n",
      "      (1): Dropout(p=0.2, inplace=False)\n",
      "      (2): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=192, out_features=96, bias=False)\n",
      "      (1): Dropout(p=0.2, inplace=False)\n",
      "      (2): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Linear(in_features=96, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-CNN-Transformer'\n",
    "cfg_model['generator'] = CNNTransformer\n",
    "cfg_model['fc_stages'] = 2\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 192\n",
    "cfg_model['n_encoders'] = 8\n",
    "cfg_model['n_heads'] = 4\n",
    "cfg_model['dropout'] = 0.2\n",
    "cfg_model['LR'] = None\n",
    "cfg_model['activation'] = 'relu'\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize the model pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_channels': 19,\n",
      " 'out_dims': 3,\n",
      " 'model': '1D-Tiny-CNN',\n",
      " 'generator': <class 'models.simple_cnn_1d.TinyCNN1D'>,\n",
      " 'fc_stages': 3,\n",
      " 'use_age': 'fc',\n",
      " 'final_pool': 'max',\n",
      " 'base_channels': 64,\n",
      " 'LR': None,\n",
      " 'dropout': 0.3,\n",
      " 'activation': 'mish'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "{'in_channels': 19,\n",
      " 'out_dims': 3,\n",
      " 'model': '1D-CNN-Transformer',\n",
      " 'generator': <class 'models.cnn_transformer.CNNTransformer'>,\n",
      " 'fc_stages': 2,\n",
      " 'use_age': 'fc',\n",
      " 'final_pool': 'max',\n",
      " 'base_channels': 192,\n",
      " 'n_encoders': 8,\n",
      " 'n_heads': 4,\n",
      " 'dropout': 0.2,\n",
      " 'LR': None,\n",
      " 'activation': 'relu'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "{'in_channels': 19,\n",
      " 'out_dims': 3,\n",
      " 'model': '1D-CNN-Transformer',\n",
      " 'generator': <class 'models.cnn_transformer.CNNTransformer'>,\n",
      " 'fc_stages': 2,\n",
      " 'use_age': 'fc',\n",
      " 'final_pool': 'max',\n",
      " 'base_channels': 192,\n",
      " 'n_encoders': 8,\n",
      " 'n_heads': 4,\n",
      " 'dropout': 0.2,\n",
      " 'LR': None,\n",
      " 'activation': 'relu'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cfg_model in cfg_model_pool:\n",
    "    pprint.pp(cfg_model, width=150)\n",
    "    print('\\n' + '-' * 100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_channels': 19,\n",
      " 'out_dims': 3,\n",
      " 'model': '1D-CNN-Transformer',\n",
      " 'generator': <class 'models.cnn_transformer.CNNTransformer'>,\n",
      " 'fc_stages': 2,\n",
      " 'use_age': 'fc',\n",
      " 'final_pool': 'max',\n",
      " 'base_channels': 192,\n",
      " 'n_encoders': 8,\n",
      " 'n_heads': 4,\n",
      " 'dropout': 0.2,\n",
      " 'LR': None,\n",
      " 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "model_index = 1\n",
    "cfg_model = cfg_model_pool[model_index]\n",
    "\n",
    "pprint.pp(cfg_model, width=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Default Configurations for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training configurations\n",
    "cfg_train = {}\n",
    "cfg_train['iterations'] = (250000 * 32) // cfg_data['minibatch']\n",
    "cfg_train['num_history'] = 500\n",
    "cfg_train['lr_decay_timing'] = 0.8\n",
    "cfg_train['lr_decay_gamma'] = 0.1\n",
    "cfg_train['weight_decay'] = 1e-2\n",
    "cfg_train['mixup'] = 0.3 # 0 for no usage\n",
    "cfg_train['criterion'] = 'cross-entropy' # 'cross-entropy', 'multi-bce'\n",
    "\n",
    "cfg_train['device'] = device\n",
    "cfg_train['save_model'] = True\n",
    "cfg_train['save_temporary'] = False\n",
    "cfg_train['draw_result'] = True\n",
    "cfg_train['watch_model'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\bengb\\OneDrive\\문서\\GitHub\\eeg_analysis\\wandb\\run-20220327_034055-2gy28zwn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis/runs/2gy28zwn\" target=\"_blank\">grateful-serenity-127</a></strong> to <a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "******************************              1D-CNN-Transformer train starts               ******************************\n",
      "************************************************************************************************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.141 MB of 0.145 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.968459…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▆▅▄▄▄▃▃▂▃▂▂▂▁▁▁▂▂▁▁████████████████████</td></tr><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Accuracy (Longer)</td><td>▁</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇██▇██▁▂▁▁▁▁▂▁▁▂▁▁▁▂▂▂▁▁▁▂</td></tr><tr><td>Validation Accuracy</td><td>▃▇▆▇▄▄██▇▆▇▆▆▄▃▇▅▇▇▇▇▂▂▁▂▂▃▂▂▁▁▂▂▂▂▂▂▄▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>0.97606</td></tr><tr><td>Test Accuracy</td><td>57.36508</td></tr><tr><td>Test Accuracy (Longer)</td><td>55.04762</td></tr><tr><td>Train Accuracy</td><td>51.35749</td></tr><tr><td>Validation Accuracy</td><td>52.88462</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">grateful-serenity-127</strong>: <a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis/runs/2gy28zwn\" target=\"_blank\">https://wandb.ai/ipis-mjkim/eeg-analysis/runs/2gy28zwn</a><br/>Synced 7 W&B file(s), 5 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220327_034055-2gy28zwn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize the wandb log\n",
    "wandb_run = wandb.init(project=\"eeg-analysis\")\n",
    "wandb.run.name = wandb.run.id\n",
    "\n",
    "with wandb_run:\n",
    "    # collect some garbages\n",
    "    time.sleep(10)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    # load default config\n",
    "    config = {}\n",
    "    for k, v in {**cfg_data, **cfg_train, **cfg_model}.items():\n",
    "        if k not in wandb.config:\n",
    "            config[k] = v\n",
    "\n",
    "    # to prevent callables from type-conversion to str\n",
    "    config['history_interval'] = config['iterations'] // config['num_history']\n",
    "    wandb.config.update(config)\n",
    "    for k, v in wandb.config.items():\n",
    "        if k not in config:\n",
    "            config[k] = v\n",
    "\n",
    "    if cfg_data.get('crop_multiple', 1) == 1:\n",
    "        config['in_channels'] = train_loader.dataset[0]['signal'].shape[0]\n",
    "    else:\n",
    "        config['in_channels'] = train_loader.dataset[0]['signal'][0].shape[0]\n",
    "    config['out_dims'] = len(class_label_to_type)\n",
    "\n",
    "    # train the model\n",
    "    model = train_with_wandb(config, train_loader, val_loader, test_loader, test_loader_longer, \n",
    "                             preprocess_train, preprocess_test, class_label_to_type)\n",
    "    \n",
    "    # release memory\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
