{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Networks\n",
    "\n",
    "- Three-way SoftMax or Multi-BCE classifier of normal, non-vascular MCI, and non-vascular dementia\n",
    "- `Weights and Biases` sweep is used for hyperparameter search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pprint\n",
    "import wandb\n",
    "\n",
    "# custom package\n",
    "from datasets.cau_eeg_dataset import *\n",
    "from datasets.cau_eeg_script import *\n",
    "from models import *\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.10.1+cu113\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Set the default configuration for building datatset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_data = {}\n",
    "cfg_data['device'] = device\n",
    "cfg_data['dataset'] = 'CAUHS'\n",
    "cfg_data['data_path'] = r'local/dataset/02_Curated_Data_220402/'\n",
    "cfg_data['meta_path'] = os.path.join(cfg_data['data_path'], 'metadata.json')\n",
    "cfg_data['file_format'] = 'feather'  # 'feather', 'memmap'\n",
    "cfg_data['target_task'] = 'Normal, MCI, Dementia' # 'Norml, MCI, Dementia'\n",
    "cfg_data['vascular'] = 'X'\n",
    "cfg_data['segment'] = 'no' # 'train', 'all', 'no'\n",
    "cfg_data['seed'] = 0\n",
    "cfg_data['latency'] = 200 * 10  # 10 seconds\n",
    "cfg_data['crop_length'] = 200 * 10 # 10 seconds\n",
    "cfg_data['longer_crop_length'] = 200 * 10 * 10 # 100 seconds\n",
    "cfg_data['crop_multiple'] = 4\n",
    "cfg_data['minibatch'] = 128\n",
    "cfg_data['input_norm'] = 'dataset' # 'datatset', 'datapoint', 'no'\n",
    "cfg_data['EKG'] = 'X'\n",
    "cfg_data['photic'] = 'X'\n",
    "cfg_data['awgn'] = 3e-2\n",
    "cfg_data['mgn'] = 1e-4\n",
    "cfg_data['awgn_age'] = 5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_label_to_name: ['Normal', 'Non-vascular MCI', 'Non-vascular dementia']\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- There are 458 data belonging to Normal\n",
      "- There are 350 data belonging to Non-vascular MCI\n",
      "- There are 233 data belonging to Non-vascular dementia\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Train data label distribution\t: [366, 280, 186] 832\n",
      "Train data label distribution\t: [46, 35, 23] 104\n",
      "Train data label distribution\t: [46, 35, 24] 105\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "composed_train: Compose(\n",
      "    EegDropEKGChannel()\n",
      "    EegDropPhoticChannel()\n",
      "    EegRandomCrop(crop_length=2000, multiple=4, latency=2000, return_timing=False)\n",
      "    EegToTensor()\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "composed_test: Compose(\n",
      "    EegDropEKGChannel()\n",
      "    EegDropPhoticChannel()\n",
      "    EegRandomCrop(crop_length=2000, multiple=4, latency=2000, return_timing=False)\n",
      "    EegToTensor()\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "longer_composed_test: Compose(\n",
      "    EegDropEKGChannel()\n",
      "    EegDropPhoticChannel()\n",
      "    EegRandomCrop(crop_length=20000, multiple=4, latency=2000, return_timing=False)\n",
      "    EegToTensor()\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "train_dataset[0].keys():\n",
      "dict_keys(['signal', 'age', 'class_label', 'metadata'])\n",
      "train_dataset[0][\"signal\"]:\n",
      "[tensor([[ 11.,   9.,   9.,  ..., -38., -36., -35.],\n",
      "        [ 13.,  11.,  10.,  ..., -14., -13., -11.],\n",
      "        [-14., -16., -17.,  ...,  -7.,  -6.,  -4.],\n",
      "        ...,\n",
      "        [-24., -25., -24.,  ...,   2.,   2.,   2.],\n",
      "        [ -5.,  -5.,  -7.,  ...,   4.,   4.,   4.],\n",
      "        [-24., -22., -21.,  ...,   1.,   1.,   2.]]),\n",
      " tensor([[-73., -73., -72.,  ...,  -1.,   0.,  -2.],\n",
      "        [  4.,   5.,   5.,  ...,   3.,   6.,   7.],\n",
      "        [ 10.,  13.,  14.,  ..., -22., -21., -19.],\n",
      "        ...,\n",
      "        [-35., -35., -34.,  ..., -20., -18., -17.],\n",
      "        [  0.,  -2.,  -3.,  ...,  18.,  18.,  18.],\n",
      "        [-25., -25., -25.,  ...,  22.,  21.,  20.]]),\n",
      " tensor([[-11., -10., -10.,  ...,  19.,  19.,  20.],\n",
      "        [ -7.,  -6.,  -5.,  ...,   4.,   6.,   6.],\n",
      "        [-20., -20., -20.,  ..., -25., -23., -22.],\n",
      "        ...,\n",
      "        [-53., -53., -54.,  ..., -31., -33., -34.],\n",
      "        [ -4.,  -5.,  -6.,  ...,  17.,  17.,  17.],\n",
      "        [-18., -22., -24.,  ...,  35.,  34.,  34.]]),\n",
      " tensor([[ 25.,  27.,  27.,  ...,  -3.,  -3.,  -2.],\n",
      "        [ -3.,  -1.,   1.,  ...,  -1.,   0.,   0.],\n",
      "        [ 12.,  14.,  16.,  ...,   1.,   0.,  -1.],\n",
      "        ...,\n",
      "        [ -5.,  -4.,  -1.,  ..., -22., -22., -22.],\n",
      "        [  7.,   8.,  11.,  ...,  -2.,  -2.,  -2.],\n",
      "        [ -9., -10.,  -9.,  ...,   3.,   2.,   0.]])]\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "val_dataset[0].keys():\n",
      "dict_keys(['signal', 'age', 'class_label', 'metadata'])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_dataset[0].keys():\n",
      "dict_keys(['signal', 'age', 'class_label', 'metadata'])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_dataset_longer[0].keys():\n",
      "dict_keys(['signal', 'age', 'class_label', 'metadata'])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "train_loader:\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000001A527360D60>\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "val_loader:\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000001A527360820>\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_loader:\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000001A517AF6100>\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_loader_longer:\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000001A517AF61F0>\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "preprocess_train: Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeMeanStd(mean=tensor([-0.1710, -0.0236,  0.0402,  0.0260, -0.0146, -0.1994, -0.0117, -0.0040,\n",
      "          -0.0065, -0.1075, -0.0032,  0.0303,  0.0197,  0.0504, -0.0470, -0.0375,\n",
      "           0.0349,  0.0336,  0.0290]),std=tensor([45.0270, 19.9148, 11.3471, 11.3834, 14.7264, 47.9176, 19.3262, 10.3037,\n",
      "          11.1740, 15.2930, 20.0912, 13.9981, 13.3585, 21.1606, 16.5493, 13.9692,\n",
      "          19.0250, 10.8659, 11.1252]),eps=1e-08)\n",
      "  (2): EegNormalizeAge(mean=tensor([70.3113]),std=tensor([9.5389]),eps=1e-08)\n",
      "  (3): EegAdditiveGaussianNoise(mean=0.0,std=0.03)\n",
      "  (4): EegMultiplicativeGaussianNoise(mean=0.0,std=0.0001)\n",
      "  (5): EegAddGaussianNoiseAge(mean=0.0,std=0.05)\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "preprocess_test: Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeMeanStd(mean=tensor([-0.1710, -0.0236,  0.0402,  0.0260, -0.0146, -0.1994, -0.0117, -0.0040,\n",
      "          -0.0065, -0.1075, -0.0032,  0.0303,  0.0197,  0.0504, -0.0470, -0.0375,\n",
      "           0.0349,  0.0336,  0.0290]),std=tensor([45.0270, 19.9148, 11.3471, 11.3834, 14.7264, 47.9176, 19.3262, 10.3037,\n",
      "          11.1740, 15.2930, 20.0912, 13.9981, 13.3585, 21.1606, 16.5493, 13.9692,\n",
      "          19.0250, 10.8659, 11.1252]),eps=1e-08)\n",
      "  (2): EegNormalizeAge(mean=tensor([70.3113]),std=tensor([9.5389]),eps=1e-08)\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "0 torch.Size([128, 19, 2000]) torch.Size([128]) torch.Size([128]) 128\n",
      "1 torch.Size([128, 19, 2000]) torch.Size([128]) torch.Size([128]) 128\n",
      "2 torch.Size([128, 19, 2000]) torch.Size([128]) torch.Size([128]) 128\n",
      "3 torch.Size([128, 19, 2000]) torch.Size([128]) torch.Size([128]) 128\n",
      "4 torch.Size([128, 19, 2000]) torch.Size([128]) torch.Size([128]) 128\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = build_dataset(cfg_data, verbose=True)\n",
    "train_loader = _[0]\n",
    "val_loader = _[1]\n",
    "test_loader = _[2]\n",
    "test_loader_longer = _[3]\n",
    "preprocess_train = _[4]\n",
    "preprocess_test = _[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Define Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_common_model = {'in_channels': next(iter(train_loader))['signal'].shape[1], \n",
    "                    'out_dims': len(cfg_data['class_label_to_name'])}\n",
    "\n",
    "cfg_model_pool = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D Tiny CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Model config:'\n",
      "{'LR': None,\n",
      " 'activation': 'mish',\n",
      " 'base_channels': 64,\n",
      " 'dropout': 0.3,\n",
      " 'fc_stages': 3,\n",
      " 'final_pool': 'max',\n",
      " 'generator': <class 'models.simple_cnn_1d.TinyCNN1D'>,\n",
      " 'in_channels': 19,\n",
      " 'model': '1D-Tiny-CNN',\n",
      " 'out_dims': 3,\n",
      " 'use_age': 'fc'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "TinyCNN1D(\n",
      "  (conv1): Conv1d(19, 64, kernel_size=(35,), stride=(7,))\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (final_pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc_stage): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=65, out_features=32, bias=False)\n",
      "      (1): Dropout(p=0.3, inplace=False)\n",
      "      (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Mish()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=16, bias=False)\n",
      "      (1): Dropout(p=0.3, inplace=False)\n",
      "      (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Mish()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=8, bias=False)\n",
      "      (1): Dropout(p=0.3, inplace=False)\n",
      "      (2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Mish()\n",
      "    )\n",
      "    (3): Linear(in_features=8, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-Tiny-CNN'\n",
    "cfg_model['generator'] = TinyCNN1D\n",
    "cfg_model['fc_stages'] = 3\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 64\n",
    "cfg_model['LR'] = None\n",
    "cfg_model['dropout'] = 0.3\n",
    "cfg_model['activation'] = 'mish'\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M7 model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-Mx'\n",
    "# cfg_model['generator'] = M7\n",
    "# cfg_model['fc_stages'] = 1\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 256\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNet model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNet-2x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deeper 1D ResNet model (fc-age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNet-5x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shallower 1D ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNet-2x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BasicBlock1D\n",
    "# cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tiny 1D ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNet-1x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BasicBlock1D\n",
    "# cfg_model['conv_layers'] = [1, 1, 1, 1]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['dropout'] = 0.2\n",
    "# cfg_model['activation'] = 'mish'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Dilated 1D ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-Multi-Dilated-ResNet-5x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = MultiBottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 32\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNeXt-53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNeXt-5x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['groups'] = 32\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNeXt-103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '1D-ResNeXt-10x'\n",
    "# cfg_model['generator'] = ResNet1D\n",
    "# cfg_model['block'] = BottleneckBlock1D\n",
    "# cfg_model['conv_layers'] = [3, 4, 23, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['groups'] = 32\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "    \n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNet-20 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '2D-ResNet-2x' # resnet-18 + three more fc layer\n",
    "# cfg_model['generator'] = ResNet2D\n",
    "# cfg_model['block'] = BasicBlock2D\n",
    "# cfg_model['conv_layers'] = [2, 2, 2, 2]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['n_fft'] = 100\n",
    "# cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "# cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNet-52 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '2D-ResNet-5x' # resnet-50 + three more fc layer\n",
    "# cfg_model['generator'] = ResNet2D\n",
    "# cfg_model['block'] = Bottleneck2D\n",
    "# cfg_model['conv_layers'] = [3, 4, 6, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['n_fft'] = 100\n",
    "# cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "# cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D ResNeXt-104 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_model = {}\n",
    "# cfg_model.update(cfg_common_model)\n",
    "# cfg_model['model'] = '2D-ResNeXt-10x' # resnet-101 + three more fc layer\n",
    "# cfg_model['generator'] = ResNet2D\n",
    "# cfg_model['block'] = Bottleneck2D\n",
    "# cfg_model['conv_layers'] = [3, 4, 23, 3]\n",
    "# cfg_model['fc_stages'] = 3\n",
    "# cfg_model['use_age'] = 'fc'\n",
    "# cfg_model['final_pool'] = 'max'\n",
    "# cfg_model['base_channels'] = 64\n",
    "# cfg_model['n_fft'] = 100\n",
    "# cfg_model['complex_mode'] = 'as_real' # 'power', 'remove'\n",
    "# cfg_model['hop_length'] = cfg_model['n_fft'] // 2\n",
    "# cfg_model['groups'] = 32\n",
    "# cfg_model['width_per_group'] = 8\n",
    "# cfg_model['LR'] = None\n",
    "# cfg_model['activation'] = 'relu'\n",
    "\n",
    "# pprint.pprint('Model config:')\n",
    "# pprint.pprint(cfg_model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "# print(model)\n",
    "# print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "# del model\n",
    "# cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN-Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Model config:'\n",
      "{'LR': None,\n",
      " 'activation': 'relu',\n",
      " 'base_channels': 192,\n",
      " 'dropout': 0.2,\n",
      " 'fc_stages': 2,\n",
      " 'final_pool': 'max',\n",
      " 'generator': <class 'models.cnn_transformer.CNNTransformer'>,\n",
      " 'in_channels': 19,\n",
      " 'model': '1D-CNN-Transformer',\n",
      " 'n_encoders': 8,\n",
      " 'n_heads': 4,\n",
      " 'out_dims': 3,\n",
      " 'use_age': 'fc'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "CNNTransformer(\n",
      "  (conv1): Conv1d(19, 192, kernel_size=(21,), stride=(9,))\n",
      "  (bn1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv1d(192, 192, kernel_size=(9,), stride=(3,))\n",
      "  (bn2): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (6): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (7): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.2, inplace=False)\n",
      "        (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.2, inplace=False)\n",
      "        (dropout2): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv1d(192, 384, kernel_size=(9,), stride=(3,))\n",
      "  (bn3): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv1d(384, 384, kernel_size=(9,), stride=(3,))\n",
      "  (bn4): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (final_pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc_stage): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=385, out_features=192, bias=False)\n",
      "      (1): Dropout(p=0.2, inplace=False)\n",
      "      (2): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=192, out_features=96, bias=False)\n",
      "      (1): Dropout(p=0.2, inplace=False)\n",
      "      (2): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Linear(in_features=96, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg_model = {}\n",
    "cfg_model.update(cfg_common_model)\n",
    "cfg_model['model'] = '1D-CNN-Transformer'\n",
    "cfg_model['generator'] = CNNTransformer\n",
    "cfg_model['fc_stages'] = 2\n",
    "cfg_model['use_age'] = 'fc'\n",
    "cfg_model['final_pool'] = 'max'\n",
    "cfg_model['base_channels'] = 192\n",
    "cfg_model['n_encoders'] = 8\n",
    "cfg_model['n_heads'] = 4\n",
    "cfg_model['dropout'] = 0.2\n",
    "cfg_model['LR'] = None\n",
    "cfg_model['activation'] = 'relu'\n",
    "\n",
    "pprint.pprint('Model config:')\n",
    "pprint.pprint(cfg_model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "model = cfg_model['generator'](**cfg_model).to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print('\\n' + '-' * 100 + '\\n')\n",
    "\n",
    "del model\n",
    "cfg_model_pool.append(cfg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize the model pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_channels': 19,\n",
      " 'out_dims': 3,\n",
      " 'model': '1D-Tiny-CNN',\n",
      " 'generator': <class 'models.simple_cnn_1d.TinyCNN1D'>,\n",
      " 'fc_stages': 3,\n",
      " 'use_age': 'fc',\n",
      " 'final_pool': 'max',\n",
      " 'base_channels': 64,\n",
      " 'LR': None,\n",
      " 'dropout': 0.3,\n",
      " 'activation': 'mish'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "{'in_channels': 19,\n",
      " 'out_dims': 3,\n",
      " 'model': '1D-CNN-Transformer',\n",
      " 'generator': <class 'models.cnn_transformer.CNNTransformer'>,\n",
      " 'fc_stages': 2,\n",
      " 'use_age': 'fc',\n",
      " 'final_pool': 'max',\n",
      " 'base_channels': 192,\n",
      " 'n_encoders': 8,\n",
      " 'n_heads': 4,\n",
      " 'dropout': 0.2,\n",
      " 'LR': None,\n",
      " 'activation': 'relu'}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cfg_model in cfg_model_pool:\n",
    "    pprint.pp(cfg_model, width=150)\n",
    "    print('\\n' + '-' * 100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_channels': 19,\n",
      " 'out_dims': 3,\n",
      " 'model': '1D-CNN-Transformer',\n",
      " 'generator': <class 'models.cnn_transformer.CNNTransformer'>,\n",
      " 'fc_stages': 2,\n",
      " 'use_age': 'fc',\n",
      " 'final_pool': 'max',\n",
      " 'base_channels': 192,\n",
      " 'n_encoders': 8,\n",
      " 'n_heads': 4,\n",
      " 'dropout': 0.2,\n",
      " 'LR': None,\n",
      " 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "model_index = 1\n",
    "cfg_model = cfg_model_pool[model_index]\n",
    "\n",
    "pprint.pp(cfg_model, width=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Default Configurations for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training configurations\n",
    "cfg_train = {}\n",
    "cfg_train['iterations'] = (300000 * 32) // cfg_data['minibatch']\n",
    "cfg_train['num_history'] = 500\n",
    "cfg_train['lr_decay_timing'] = 0.45\n",
    "cfg_train['lr_decay_gamma'] = 0.2\n",
    "cfg_train['weight_decay'] = 1e-2\n",
    "cfg_train['mixup'] = 0.3 # 0 for no usage\n",
    "cfg_train['criterion'] = 'cross-entropy' # 'cross-entropy', 'multi-bce'\n",
    "\n",
    "cfg_train['device'] = device\n",
    "cfg_train['save_model'] = True\n",
    "cfg_train['save_temporary'] = False\n",
    "cfg_train['draw_result'] = True\n",
    "cfg_train['watch_model'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Minjae\\Desktop\\EEG_Project\\wandb\\run-20220405_025917-2f2m83x8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis-2/runs/2f2m83x8\" target=\"_blank\">light-snowflake-1020</a></strong> to <a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis-2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "******************************              1D-CNN-Transformer train starts               ******************************\n",
      "************************************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minjae\\anaconda3\\envs\\eeg\\lib\\site-packages\\nbformat\\validator.py:315: DeprecationWarning:\n",
      "\n",
      "Passing a schema to Validator.iter_errors is deprecated and will be removed in a future release. Call validator.evolve(schema=new_schema).iter_errors(...) instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minjae\\anaconda3\\envs\\eeg\\lib\\site-packages\\wandb\\sdk\\lib\\ipython.py:47: DeprecationWarning:\n",
      "\n",
      "Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minjae\\anaconda3\\envs\\eeg\\lib\\site-packages\\wandb\\sdk\\lib\\ipython.py:59: DeprecationWarning:\n",
      "\n",
      "Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='2.454 MB of 2.454 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▇▄▄▅▆▃▅▅▂▅▄▅▄▆▅▅▅▄▃▂▂▆▄▄▂▅▂▄▃▂▁▄▄▄▂▃▁▂</td></tr><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Accuracy (Longer)</td><td>▁</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▃▅▅▄▆▄▄█▃▄▂▅▂▃▅▃▂▅▆▄▄▄▃▅▃▅▅▄█▅▄▇▄█▇▇▅</td></tr><tr><td>Validation Accuracy</td><td>█▆▄▂▂▃▂▁▆▁▅▁▂▂▃▂▂▂▂▄▂▂▂▄▄▃▂▁▄▃▂▄▂▅▃▄▃▃▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>0.97169</td></tr><tr><td>Test Accuracy</td><td>60.0</td></tr><tr><td>Test Accuracy (Longer)</td><td>60.0</td></tr><tr><td>Train Accuracy</td><td>51.50136</td></tr><tr><td>Validation Accuracy</td><td>53.84615</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">light-snowflake-1020</strong>: <a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis-2/runs/2f2m83x8\" target=\"_blank\">https://wandb.ai/ipis-mjkim/eeg-analysis-2/runs/2f2m83x8</a><br/>Synced 7 W&B file(s), 4 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220405_025917-2f2m83x8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize the wandb log\n",
    "wandb_run = wandb.init(project=\"eeg-analysis-2\")\n",
    "wandb.run.name = wandb.run.id\n",
    "\n",
    "with wandb_run:\n",
    "    # collect some garbages\n",
    "    time.sleep(10)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    # load default config\n",
    "    config = {}\n",
    "    for k, v in {**cfg_data, **cfg_train, **cfg_model}.items():\n",
    "        if k not in wandb.config:\n",
    "            config[k] = v\n",
    "\n",
    "    # to prevent callables from type-conversion to str\n",
    "    config['history_interval'] = config['iterations'] // config['num_history']\n",
    "    wandb.config.update(config)\n",
    "    for k, v in wandb.config.items():\n",
    "        if k not in config:\n",
    "            config[k] = v\n",
    "\n",
    "    # train the model\n",
    "    model = train_with_wandb(config, train_loader, val_loader, test_loader, test_loader_longer, \n",
    "                             preprocess_train, preprocess_test)\n",
    "    \n",
    "    # release memory\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
