{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74515d5-5f25-477b-9a97-ed1f9b6d4c51",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test Ensemble\n",
    "\n",
    "This notebook classifies the input EDF using the pretrained models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a2666f-6b4b-4748-9dca-2884347a1f0f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df587e38-b1a9-42c8-9b50-680200a9bec7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bengb\\OneDrive\\문서\\GitHub\\eeg_analysis\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb41bf8-1713-4228-b799-0e1c87545a16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bengb\\anaconda3\\envs\\eeg_analysis\\lib\\site-packages\\torchaudio\\backend\\utils.py:66: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyedflib\n",
    "import datetime\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pprint\n",
    "from tqdm import auto\n",
    "import wandb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_dataset import CauEegDataset\n",
    "from datasets.caueeg_data_curation import calculate_age, birth_to_datetime\n",
    "from datasets.pipeline import EegChangeMontageOrder, EegResample\n",
    "from datasets.pipeline import eeg_collate_fn\n",
    "from datasets.pipeline import EegNormalizeMeanStd, EegNormalizePerSignal\n",
    "from datasets.pipeline import EegNormalizeAge\n",
    "from datasets.pipeline import EegToTensor, EegToDevice\n",
    "from datasets.pipeline import EegSpectrogram\n",
    "from datasets.caueeg_script import compose_transforms, compose_preprocess\n",
    "import models\n",
    "from train.evaluate import estimate_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d10e3f39-ed55-422c-b47f-376691cbeed6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.11.0\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') \n",
    "\n",
    "num_workers = 0  # A number other than 0 causes an error\n",
    "pin_memory = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00973b7-d2ba-4e54-a4ac-86879c1fe89f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7dfec22-3837-46a7-8b4d-4588300068bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lo88puq7']\n"
     ]
    }
   ],
   "source": [
    "base_repeat = 16  # 500\n",
    "crop_multiple = 8\n",
    "test_crop_multiple = 8\n",
    "verbose = False\n",
    "\n",
    "model_names = [\n",
    "    'lo88puq7',\n",
    "]\n",
    "model_pool = []\n",
    "for model_name in model_names:\n",
    "    path = os.path.join(r'./local/checkpoint', model_name, 'checkpoint.pt')\n",
    "    try:\n",
    "        ckpt = torch.load(path, map_location=device)\n",
    "        model_pool.append({'name': model_name, 'path': path})\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'- checkpoint cannot be opened: {path}')\n",
    "        \n",
    "pprint.pprint([model_dict['name'] for model_dict in model_pool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb66995a-6b9a-46dc-99a4-655f15084156",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_montage = ['Fp1-AVG', 'F3-AVG', 'C3-AVG', 'P3-AVG', 'O1-AVG', 'Fp2-AVG', 'F4-AVG', \n",
    "               'C4-AVG', 'P4-AVG', 'O2-AVG', 'F7-AVG', 'T3-AVG', 'T5-AVG', 'F8-AVG', \n",
    "               'T4-AVG', 'T6-AVG', 'FZ-AVG', 'CZ-AVG', 'PZ-AVG', 'EKG', 'Photic']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e25ca9a-48ee-4c0d-8e06-616a84e59527",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Evaluate each model and accumulate the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bee4f853-3cad-4b01-8ee8-44ac9e49adbe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected EDF: C:/Users/bengb/Desktop/drive-download-20221104T094002Z-001/ref/00010.edf\n",
      "Loaded EDF signal has the shape of : (21, 201600)\n",
      "\n",
      "70\n",
      "- checking for lo88puq7 2D-VGG-19 ...\n",
      "4.66%\n",
      "84.18%\n",
      "15.19%\n",
      "==== Finished ====\n"
     ]
    }
   ],
   "source": [
    "# file picker: EDF\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "root.focus_force()\n",
    "root.wm_attributes('-topmost', 1)\n",
    "edf_file = filedialog.askopenfile(title=\"Select an EDF file\",\n",
    "                                  filetypes=((\"EDF files\", \"*.edf\"),\n",
    "                                             (\"all files\", \"*.*\"))).name\n",
    "print(\"Selected EDF:\", edf_file)\n",
    "root.destroy()\n",
    "\n",
    "# read the EDF file\n",
    "signals, signal_headers, edf_header = pyedflib.highlevel.read_edf(edf_file)\n",
    "print(\"Loaded EDF signal has the shape of :\", signals.shape)\n",
    "print()\n",
    "\n",
    "old_sample_freq = 200\n",
    "new_sample_freq = signal_headers[0]['sample_rate']\n",
    "\n",
    "# calculate age\n",
    "if edf_header['birthdate'] != '':\n",
    "    birth = datetime.datetime.strptime(edf_header['birthdate'], \"%d %b %Y\")\n",
    "    age = calculate_age(birth, edf_header['startdate'])\n",
    "else:\n",
    "    age = 70\n",
    "\n",
    "print(age)\n",
    "    \n",
    "# change channel order of montage if required\n",
    "current_montage = [sh['label'].split(' ')[-1] for sh in signal_headers]\n",
    "eeg_change_montage_order = EegChangeMontageOrder(old_montage, current_montage)\n",
    "\n",
    "# build data list\n",
    "data_list = [{'serial': os.path.splitext(os.path.basename(edf_file))[0], 'age': age}]\n",
    "\n",
    "for model_dict in model_pool:\n",
    "    #################################\n",
    "    # load and parse the checkpoint #\n",
    "    #################################\n",
    "    ckpt = torch.load(model_dict['path'], map_location=device)\n",
    "    model_state = ckpt['model_state']\n",
    "    config = ckpt['config']\n",
    "    \n",
    "    model_dict['model'] = config['model']\n",
    "    print('- checking for', model_dict['name'], config['model'], '...')\n",
    "    \n",
    "    # initiate the model\n",
    "    if '_target_' in config:\n",
    "        model = hydra.utils.instantiate(config).to(device)\n",
    "    elif type(config['generator']) is str:\n",
    "        config['generator'] = getattr(models, config['generator'].split('.')[-1])\n",
    "        if 'block' in config:\n",
    "            config['block'] = getattr(models, config['block'].split('.')[-1])\n",
    "        model = config['generator'](**config).to(device)\n",
    "    else:\n",
    "        if 'block' in config:\n",
    "            if config['block'] == models.resnet_1d.BottleneckBlock1D:\n",
    "                config['block'] = 'bottleneck'\n",
    "            elif config['block'] == models.resnet_2d.Bottleneck2D:\n",
    "                config['block'] = 'bottleneck'\n",
    "            elif config['block'] == models.resnet_1d.BasicBlock1D:\n",
    "                config['block'] = 'basic'\n",
    "            elif config['block'] == models.resnet_2d.BasicBlock2D:\n",
    "                config['block'] = 'basic'\n",
    "                \n",
    "        model = config['generator'](**config).to(device)\n",
    "    \n",
    "    if config.get('ddp', False):\n",
    "        model_state_ddp = deepcopy(model_state)\n",
    "        model_state = OrderedDict()\n",
    "        for k, v in model_state_ddp.items():\n",
    "            name = k[7:]  # remove 'module.' of DataParallel/DistributedDataParallel\n",
    "            model_state[name] = v\n",
    "    \n",
    "    model.load_state_dict(model_state)\n",
    "    model = model.requires_grad_(False)\n",
    "    model_dict['model'] = model\n",
    "    \n",
    "    # reconfigure and update\n",
    "    config.pop('cwd', 0)\n",
    "    config['ddp'] = False\n",
    "    config['crop_multiple'] = crop_multiple\n",
    "    config['crop_timing_analysis'] = False\n",
    "    config['eval'] = True\n",
    "    config['device'] = device\n",
    "    \n",
    "    repeat = round(base_repeat / crop_multiple)\n",
    "    model_dict['repeat'] = repeat\n",
    "    model_dict['crop_multiple'] = crop_multiple\n",
    "    model_dict['test_crop_multiple'] = test_crop_multiple\n",
    "    \n",
    "    #################\n",
    "    # build dataset #\n",
    "    #################\n",
    "    if new_sample_freq != old_sample_freq:\n",
    "        config['photic'] = 'O'  # pretend to be\n",
    "    transform, transform_multicrop = compose_transforms(config)\n",
    "    \n",
    "    transform.transforms.insert(1, eeg_change_montage_order)\n",
    "    transform_multicrop.transforms.insert(1, eeg_change_montage_order)\n",
    "    \n",
    "    test_dataset = CauEegDataset(os.path.dirname(edf_file), data_list, load_event=False, \n",
    "                                 file_format='edf', use_prefix_signal=False, transform=transform)    \n",
    "    multicrop_test_dataset = CauEegDataset(os.path.dirname(edf_file), data_list, load_event=False, \n",
    "                                           file_format='edf', use_prefix_signal=False, transform=transform_multicrop)    \n",
    "    \n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, drop_last=False,\n",
    "                             num_workers=num_workers, pin_memory=pin_memory, collate_fn=eeg_collate_fn)\n",
    "    multicrop_test_loader = DataLoader(multicrop_test_dataset, batch_size=1, shuffle=False, drop_last=False,\n",
    "                                       num_workers=num_workers, pin_memory=pin_memory, collate_fn=eeg_collate_fn)\n",
    "    \n",
    "    preprocess_test = []\n",
    "    preprocess_test += [EegToDevice(device=config['device'])]\n",
    "    preprocess_test += [EegResample(orig_freq=old_sample_freq, new_freq=new_sample_freq)]\n",
    "    preprocess_test += [EegNormalizeAge(mean=config['age_mean'], std=config['age_std'])]\n",
    "\n",
    "    if config['input_norm'] == 'dataset':\n",
    "        preprocess_test += [EegNormalizeMeanStd(mean=config['signal_mean'], std=config['signal_std'])]\n",
    "    elif config['input_norm'] == 'datapoint':\n",
    "        preprocess_test += [EegNormalizePerSignal()]\n",
    "\n",
    "    if config.get('model', '1D').startswith('2D'):\n",
    "        preprocess_test += [EegSpectrogram(**config['stft_params'])]\n",
    "        \n",
    "        if config['input_norm'] == 'dataset':\n",
    "            preprocess_test += [EegNormalizeMeanStd(mean=config['signal_2d_mean'], std=config['signal_2d_std'])]\n",
    "        elif config['input_norm'] == 'datapoint':\n",
    "            preprocess_test += [EegNormalizePerSignal()]\n",
    "            \n",
    "    preprocess_test = transforms.Compose(preprocess_test)\n",
    "    preprocess_test = torch.nn.Sequential(*preprocess_test.transforms).to(device)\n",
    "    \n",
    "    ########\n",
    "    # test #\n",
    "    ########\n",
    "    for sample_batched in test_loader:\n",
    "        score = estimate_score(model, sample_batched, preprocess_test, config)\n",
    "    \n",
    "    for sample_batched in multicrop_test_loader:\n",
    "        multi_score = estimate_score(model, sample_batched, preprocess_test, config)\n",
    "    \n",
    "    score = torch.cat((score, multi_score), dim=0).mean(dim=0).detach().cpu().numpy()\n",
    "    for s in score:\n",
    "        print(f\"{s * 100:.2f}%\")\n",
    "            \n",
    "print('==== Finished ====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d45a8314-ca8a-4298-a765-89d9f134c6ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    EegRandomCrop(crop_length=4000, length_limit=10000000, multiple=8, latency=2000, return_timing=False)\n",
       "    EegChangeMontageOrder(channel_change=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20])\n",
       "    EegDropChannels(drop_index=[20])\n",
       "    EegToTensor()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f20c63-6d13-47a3-b6d5-8cbf89b5b25e",
   "metadata": {},
   "source": [
    "## Conduct ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3343a302-6361-49db-b31e-68f5b43f98b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ensemble = len(model_pool)\n",
    "\n",
    "ensemble_test_score = np.zeros_like(model_pool[0]['Test Score'])\n",
    "ensemble_multi_test_score = np.zeros_like(model_pool[0]['Multi-Crop Test Score'])\n",
    "\n",
    "ensemble_test_latency = 0\n",
    "ensemble_multi_test_latency = 0\n",
    "\n",
    "ensemble_params = 0\n",
    "ensemble_model_size = 0\n",
    "\n",
    "for model_dict in model_pool:\n",
    "    ensemble_test_score += model_dict['Test Score'] / len(model_pool)\n",
    "    ensemble_multi_test_score += model_dict['Multi-Crop Test Score'] / len(model_pool)\n",
    "    \n",
    "    ensemble_test_latency += 1 / model_dict['Test Throughput']\n",
    "    ensemble_multi_test_latency += 1 / model_dict['Multi-Crop Test Throughput']\n",
    "    \n",
    "    ensemble_params += model_dict['num_params']\n",
    "    ensemble_model_size += model_dict['model size (MiB)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412e7fa3-c13f-4b40-bf4a-74c029c1a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble accuracy\n",
    "pred = ensemble_test_score.argmax(axis=-1)\n",
    "ensemble_test_acc = 100.0 * (pred.squeeze() == model_pool[0]['Test Target']).sum() / pred.shape[0]\n",
    "\n",
    "# class wise metrics\n",
    "ensemble_test_confusion = calculate_confusion_matrix(pred, model_pool[0]['Test Target'], \n",
    "                                                     num_classes=ensemble_test_score.shape[-1])\n",
    "ensembel_test_class_wise_metrics = calculate_class_wise_metrics(ensemble_test_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849eb54a-909d-4261-99fc-49de781583f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-crop accuracy\n",
    "pred = ensemble_multi_test_score.argmax(axis=-1)\n",
    "ensemble_multi_test_acc = 100.0 * (pred.squeeze() == model_pool[0]['Multi-Crop Test Target']).sum() / pred.shape[0]\n",
    "\n",
    "# class wise metrics\n",
    "ensemble_multi_test_confusion = calculate_confusion_matrix(pred, model_pool[0]['Multi-Crop Test Target'], \n",
    "                                                           num_classes=ensemble_multi_test_score.shape[-1])\n",
    "ensembel_multi_test_class_wise_metrics = calculate_class_wise_metrics(ensemble_multi_test_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82fdfdb-b237-409a-b896-12d8c5118159",
   "metadata": {},
   "source": [
    "## Summarize the ensemble results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d045fb8c-2a4f-4c84-b3d5-a688e079fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_dict = {}\n",
    "\n",
    "ensemble_dict['name'] = 'Ensemble'\n",
    "ensemble_dict['Test Throughput'] = 1 / ensemble_test_latency\n",
    "ensemble_dict['Test Accuracy'] = ensemble_test_acc\n",
    "ensemble_dict['Multi-Crop Test Throughput'] = 1 / ensemble_multi_test_latency\n",
    "ensemble_dict['Multi-Crop Test Accuracy'] = ensemble_multi_test_acc\n",
    "ensemble_dict['num_params'] = ensemble_params\n",
    "ensemble_dict['model size (MiB)'] = ensemble_model_size\n",
    "\n",
    "for k, v in ensembel_test_class_wise_metrics.items():\n",
    "    for c in range(config['out_dims']):\n",
    "        c_name = config['class_label_to_name'][c]\n",
    "        ensemble_dict[f'{k} ({c_name})'] = ensembel_test_class_wise_metrics[k][c]\n",
    "        \n",
    "for k, v in ensembel_multi_test_class_wise_metrics.items():\n",
    "    for c in range(config['out_dims']):\n",
    "        c_name = config['class_label_to_name'][c]\n",
    "        ensemble_dict[f'Multi-Crop {k} ({c_name})'] = ensembel_multi_test_class_wise_metrics[k][c]\n",
    "        \n",
    "model_pool.append(ensemble_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f973f6-b799-4ba5-9258-9eee4f2f88ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_dict in model_pool:\n",
    "    model_dict.pop('Test Score', None)\n",
    "    model_dict.pop('Test Target', None)\n",
    "    model_dict.pop('Multi-Crop Test Score', None)\n",
    "    model_dict.pop('Multi-Crop Test Target', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ae7d8-ac60-42ad-b852-c38d3d52987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfabea6-e56f-4f29-8027-cb290a3d2d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_pool).to_csv(f'local/output/{task}-ensemble.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a48f95-0c6d-4082-99cb-b6f739699c14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b729d6f3-1b4d-444b-930b-057f4710edfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb96396c-b063-4858-9350-ca5acf3f8065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "for edf_file in glob.glob(r'C:\\Users\\bengb\\Desktop\\drive-download-20221104T094002Z-001\\*.edf'):\n",
    "    print('*' * 100)\n",
    "    print(edf_file)\n",
    "    print()\n",
    "    signals, signal_headers, edf_header = pyedflib.highlevel.read_edf(edf_file)\n",
    "    print(\"Loaded EDF signal has the shape of :\", signals.shape)\n",
    "    print()\n",
    "    \n",
    "    channel_config = [sh['label'].split(' ')[1].upper() for sh in signal_headers]\n",
    "    if channel_config != ['FP1-REF', 'F3-REF', 'C3-REF', 'P3-REF', 'O1-REF', 'FP2-REF', 'F4-REF', 'C4-REF', 'P4-REF', 'O2-REF', 'F7-REF', 'T7-REF', 'P7-REF', 'F8-REF', 'T8-REF', 'P8-REF', 'FZ-REF', 'CZ-REF', 'PZ-REF', 'EKG1-EKG2']:\n",
    "        print('WARNING:::::::::::::::::::::::::::::::')\n",
    "    print(channel_config)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906777f1-c4b6-4b1e-acc3-a13face075cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a5ca13-7958-4ef2-a441-008a33641fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import pyedflib\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "from datasets.caueeg_data_curation import calculate_age, birth_to_datetime\n",
    "import numpy as np\n",
    "\n",
    "# file picker: EDF\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "root.focus_force()\n",
    "root.wm_attributes('-topmost', 1)\n",
    "edf_file = filedialog.askopenfile(title=\"Select an EDF file\",\n",
    "                                  filetypes=((\"EDF files\", \"*.edf\"),\n",
    "                                             (\"all files\", \"*.*\"))).name\n",
    "print(\"Selected EDF:\", edf_file)\n",
    "root.destroy()\n",
    "\n",
    "# read the EDF file\n",
    "signals, signal_headers, edf_header = pyedflib.highlevel.read_edf(edf_file)\n",
    "print(\"Loaded EDF signal has the shape of :\", signals.shape)\n",
    "print()\n",
    "# pprint(signal_headers)\n",
    "# print()\n",
    "# pprint(edf_header)\n",
    "\n",
    "channel_config = [sh['label'].split(' ')[1].split('-')[0].upper() for sh in signal_headers]\n",
    "target_channel_config = [ch.split('-')[0].upper() for ch in [\"Fp1-AVG\", \"F3-AVG\", \"C3-AVG\", \"P3-AVG\", \"O1-AVG\", \"Fp2-AVG\", \"F4-AVG\", \"C4-AVG\", \"P4-AVG\",\n",
    "        \"O2-AVG\", \"F7-AVG\", \"T3-AVG\", \"T5-AVG\", \"F8-AVG\", \"T4-AVG\", \"T6-AVG\", \"FZ-AVG\", \"CZ-AVG\",\n",
    "        \"PZ-AVG\", \"EKG1\"]]\n",
    "\n",
    "print(channel_config)\n",
    "print(target_channel_config)\n",
    "print('---')\n",
    "print(set(channel_config) - set(target_channel_config))\n",
    "print(set(target_channel_config) - set(channel_config))\n",
    "print('---')\n",
    "print()\n",
    "\n",
    "# axis_move = []\n",
    "# for ch in channel_config:\n",
    "#     for i, ta_ch in enumerate(target_channel_config):\n",
    "#         if ch == ta_ch:\n",
    "#             axis_move.append(i)\\\n",
    "# print(len(axis_move))\n",
    "# print(np.array(channel_config).transpose(axis_move))\n",
    "print('***')\n",
    "print(montage)\n",
    "print('***')\n",
    "montage = [sh['label'].split('-')[1] for sh in signal_headers]\n",
    "montage1 = ['Fp1-Ref', 'F3-Ref', 'C3-Ref', 'P3-Ref', 'Fp2-Ref', 'F4-Ref', 'C4-Ref', 'P4-Ref', 'F7-Ref', 'T7-Ref', 'P7-Ref', 'O1-Ref', 'F8-Ref', 'T8-Ref', 'P8-Ref', 'O2-Ref', 'Fz-Ref', 'Cz-Ref', 'Pz-Ref', 'EKG1-EKG2']\n",
    "\n",
    "print(set(montage) - set(montage1))\n",
    "print(set(montage1) - set(montage))\n",
    "print('***')\n",
    "\n",
    "montage2 = ['Fp1-C3', 'C3-O1', 'Fp1-T7', 'T7-O1', 'Fp2-C4', 'C4-O2', 'Fp2-T8', 'T8-O2', 'F7-Fz', 'Fz-F8', 'T7-Cz', 'Cz-T8', 'Pz-P8', 'Fz-Pz', 'Fp1-O2', 'EKG1-EKG2', 'Pg2-A2']\n",
    "print(set(montage) - set(montage2))\n",
    "print(set(montage2) - set(montage))\n",
    "print('===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f27d66e-c180-407c-98f7-91104f533834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
