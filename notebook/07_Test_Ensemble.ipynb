{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74515d5-5f25-477b-9a97-ed1f9b6d4c51",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test Ensemble\n",
    "\n",
    "This notebook classifies the input EDF using the pretrained models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a2666f-6b4b-4748-9dca-2884347a1f0f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb41bf8-1713-4228-b799-0e1c87545a16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load some packages\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyedflib\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pprint\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_dataset import CauEegDataset\n",
    "from datasets.caueeg_data_curation import calculate_age, birth_to_datetime\n",
    "from datasets.pipeline import EegChangeMontageOrder, EegResample\n",
    "from datasets.pipeline import eeg_collate_fn\n",
    "from datasets.pipeline import EegNormalizeMeanStd, EegNormalizePerSignal\n",
    "from datasets.pipeline import EegNormalizeAge\n",
    "from datasets.pipeline import EegToTensor, EegToDevice\n",
    "from datasets.pipeline import EegSpectrogram\n",
    "from datasets.caueeg_script import compose_transforms, compose_preprocess\n",
    "import models\n",
    "from train.evaluate import estimate_score\n",
    "from train.visualize import draw_heatmap, annotate_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10e3f39-ed55-422c-b47f-376691cbeed6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') \n",
    "\n",
    "num_workers = 0  # A number other than 0 causes an error\n",
    "pin_memory = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00973b7-d2ba-4e54-a4ac-86879c1fe89f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dfec22-3837-46a7-8b4d-4588300068bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_multiple = 128\n",
    "test_crop_multiple = 16\n",
    "repeat = 2\n",
    "verbose = False\n",
    "\n",
    "old_montage = ['Fp1-AVG', 'F3-AVG', 'C3-AVG', 'P3-AVG', 'O1-AVG', 'Fp2-AVG', 'F4-AVG', \n",
    "               'C4-AVG', 'P4-AVG', 'O2-AVG', 'F7-AVG', 'T3-AVG', 'T5-AVG', 'F8-AVG', \n",
    "               'T4-AVG', 'T6-AVG', 'FZ-AVG', 'CZ-AVG', 'PZ-AVG', 'EKG', 'Photic']\n",
    "old_sample_freq = 200\n",
    "\n",
    "model_names = [\n",
    "    '2686pm3p',  # input_norm: datapoint\n",
    "    'jk7a4cyj',  # input_norm: datapoint\n",
    "    '2ugdkwu4',  # input_norm: datapoint\n",
    "    '1rn23vp7',  # input_norm: dataset\n",
    "    'lo88puq7',  # input_norm: dataset\n",
    "]\n",
    "model_pool = []\n",
    "for model_name in model_names:\n",
    "    path = os.path.join(r'./local/checkpoint', model_name, 'checkpoint.pt')\n",
    "    try:\n",
    "        ckpt = torch.load(path, map_location=device)\n",
    "        model_pool.append({'name': model_name, 'path': path})\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'- checkpoint cannot be opened: {path}')\n",
    "        \n",
    "pprint.pprint([model_dict['name'] for model_dict in model_pool])\n",
    "\n",
    "# Other settings\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # cleaner text\n",
    "plt.style.use('default') \n",
    "plt.rcParams[\"font.family\"] = 'DejaVu Sans' # 'NanumGothic' # for Hangul in Windows\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'jet' # 'jet', 'nipy_spectral', 'rainbow'\n",
    "\n",
    "def draw_stft(signals, montage):\n",
    "    signal = signals\n",
    "    channels = len(montage)\n",
    "    columns = 4\n",
    "        \n",
    "    fig, ax = plt.subplots(round(np.ceil(channels / columns)), columns, \n",
    "                           figsize=(15.0, 12.0), constrained_layout=True)\n",
    "    \n",
    "    for k in range(channels):\n",
    "        Pxx, freqs, bins, im = ax[k // columns, k % columns].specgram(signal[k, :20000], 256, 256)\n",
    "        ax[k // columns, k % columns].set_title(montage[k], fontsize=12, fontweight='bold', color='darkred')\n",
    "        ax[k // columns, k % columns].set_xlabel('Time', fontsize=9)\n",
    "        ax[k // columns, k % columns].set_ylabel('Frequency', fontsize=9)\n",
    "        \n",
    "    fig.suptitle('Time-Frequency Representation', fontsize=20, fontweight='semibold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close('all')\n",
    "\n",
    "def error_message(title, message):\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    root.focus_force()\n",
    "    root.wm_attributes('-topmost', 1)\n",
    "    messagebox.showerror(title, message)\n",
    "    root.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e25ca9a-48ee-4c0d-8e06-616a84e59527",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Evaluate each model and accumulate the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee4f853-3cad-4b01-8ee8-44ac9e49adbe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# file picker: EDF\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "root.focus_force()\n",
    "root.wm_attributes('-topmost', 1)\n",
    "edf_file = filedialog.askopenfile(title=\"Select an EDF file\",\n",
    "                                  filetypes=((\"EDF files\", \"*.edf\"),\n",
    "                                             (\"all files\", \"*.*\"))).name\n",
    "print(\"Selected EDF:\", edf_file)\n",
    "root.destroy()\n",
    "\n",
    "# read the EDF file\n",
    "signals, signal_headers, edf_header = pyedflib.highlevel.read_edf(edf_file)\n",
    "print(\"Loaded EDF signal has the shape of :\", signals.shape)\n",
    "print()\n",
    "\n",
    "# calculate age\n",
    "if edf_header['birthdate'] != '':\n",
    "    birth = datetime.datetime.strptime(edf_header['birthdate'], \"%d %b %Y\")\n",
    "    age = calculate_age(birth, edf_header['startdate'])\n",
    "else:\n",
    "    error_message('Error', 'Cannot parse the patients age..')\n",
    "    raise ValueError('ERROR: Cannot parse the patients age..')\n",
    "\n",
    "# sampling frequency\n",
    "new_sample_freq = signal_headers[0]['sample_rate']\n",
    "\n",
    "# change channel order of montage if required\n",
    "current_montage = [sh['label'].split(' ')[-1] for sh in signal_headers]\n",
    "eeg_change_montage_order = EegChangeMontageOrder(old_montage, current_montage)\n",
    "\n",
    "if -1 in eeg_change_montage_order.channel_change:\n",
    "    error_message('Error', 'Montage cannot be interpreted..')\n",
    "    raise ValueError('ERROR: Montage cannot be interpreted..')\n",
    "\n",
    "# draw time-frequency representation\n",
    "draw_stft(signals, current_montage)\n",
    "print()\n",
    "\n",
    "# build data list\n",
    "data_list = [{'serial': os.path.splitext(os.path.basename(edf_file))[0], 'age': age}] * repeat\n",
    "\n",
    "for model_dict in tqdm(model_pool):\n",
    "    #################################\n",
    "    # load and parse the checkpoint #\n",
    "    #################################\n",
    "    ckpt = torch.load(model_dict['path'], map_location=device)\n",
    "    model_state = ckpt['model_state']\n",
    "    config = ckpt['config']\n",
    "    \n",
    "    model_dict['model'] = config['model']\n",
    "    print('- checking for', model_dict['name'], 'model...')\n",
    "    \n",
    "    # initiate the model\n",
    "    if '_target_' in config:\n",
    "        model = hydra.utils.instantiate(config).to(device)\n",
    "    elif type(config['generator']) is str:\n",
    "        config['generator'] = getattr(models, config['generator'].split('.')[-1])\n",
    "        if 'block' in config:\n",
    "            config['block'] = getattr(models, config['block'].split('.')[-1])\n",
    "        model = config['generator'](**config).to(device)\n",
    "    else:\n",
    "        if 'block' in config:\n",
    "            if config['block'] == models.resnet_1d.BottleneckBlock1D:\n",
    "                config['block'] = 'bottleneck'\n",
    "            elif config['block'] == models.resnet_2d.Bottleneck2D:\n",
    "                config['block'] = 'bottleneck'\n",
    "            elif config['block'] == models.resnet_1d.BasicBlock1D:\n",
    "                config['block'] = 'basic'\n",
    "            elif config['block'] == models.resnet_2d.BasicBlock2D:\n",
    "                config['block'] = 'basic'\n",
    "                \n",
    "        model = config['generator'](**config).to(device)\n",
    "    \n",
    "    if config.get('ddp', False):\n",
    "        model_state_ddp = deepcopy(model_state)\n",
    "        model_state = OrderedDict()\n",
    "        for k, v in model_state_ddp.items():\n",
    "            name = k[7:]  # remove 'module.' of DataParallel/DistributedDataParallel\n",
    "            model_state[name] = v\n",
    "    \n",
    "    model.load_state_dict(model_state)\n",
    "    model = model.requires_grad_(False)\n",
    "    model_dict['model'] = model\n",
    "    \n",
    "    # reconfigure and update\n",
    "    config.pop('cwd', 0)\n",
    "    config['ddp'] = False\n",
    "    config['crop_multiple'] = crop_multiple\n",
    "    config['crop_timing_analysis'] = False\n",
    "    config['eval'] = True\n",
    "    config['device'] = device\n",
    "        \n",
    "    #################\n",
    "    # build dataset #\n",
    "    #################\n",
    "    if new_sample_freq != old_sample_freq:\n",
    "        config['photic'] = 'O'  # pretend to be\n",
    "    transform, transform_multicrop = compose_transforms(config)\n",
    "    \n",
    "    transform.transforms.insert(1, eeg_change_montage_order)\n",
    "    transform_multicrop.transforms.insert(1, eeg_change_montage_order)\n",
    "    \n",
    "    test_dataset = CauEegDataset(os.path.dirname(edf_file), data_list, load_event=False, \n",
    "                                 file_format='edf', use_prefix_signal=False, transform=transform)    \n",
    "    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, drop_last=False,\n",
    "                             num_workers=num_workers, pin_memory=pin_memory, collate_fn=eeg_collate_fn)\n",
    "    \n",
    "    preprocess_test = []\n",
    "    preprocess_test += [EegToDevice(device=config['device'])]\n",
    "    preprocess_test += [EegResample(orig_freq=old_sample_freq, new_freq=new_sample_freq)]\n",
    "    preprocess_test += [EegNormalizeAge(mean=config['age_mean'], std=config['age_std'])]\n",
    "\n",
    "    if config['input_norm'] == 'dataset':\n",
    "        preprocess_test += [EegNormalizeMeanStd(mean=config['signal_mean'], std=config['signal_std'])]\n",
    "    elif config['input_norm'] == 'datapoint':\n",
    "        preprocess_test += [EegNormalizePerSignal()]\n",
    "\n",
    "    if config.get('model', '1D').startswith('2D'):\n",
    "        preprocess_test += [EegSpectrogram(**config['stft_params'])]\n",
    "        \n",
    "        if config['input_norm'] == 'dataset':\n",
    "            preprocess_test += [EegNormalizeMeanStd(mean=config['signal_2d_mean'], std=config['signal_2d_std'])]\n",
    "        elif config['input_norm'] == 'datapoint':\n",
    "            preprocess_test += [EegNormalizePerSignal()]\n",
    "            \n",
    "    preprocess_test = transforms.Compose(preprocess_test)\n",
    "    preprocess_test = torch.nn.Sequential(*preprocess_test.transforms).to(device)\n",
    "    \n",
    "    ########\n",
    "    # test #\n",
    "    ########\n",
    "    for sample_batched in test_loader:\n",
    "        score = estimate_score(model, sample_batched, preprocess_test, config)\n",
    "        \n",
    "    score = score.mean(dim=0).detach().cpu().numpy()\n",
    "    score = score / score.sum()\n",
    "    model_dict['test_score'] = score\n",
    "    # print([f'{s:.3f}' for s in score])\n",
    "\n",
    "# calculate ensemble score\n",
    "ensemble_test_score = np.zeros_like(model_pool[0]['test_score'])\n",
    "for model_dict in model_pool:\n",
    "    ensemble_test_score += model_dict['test_score'] / len(model_pool)\n",
    "\n",
    "print()\n",
    "print('==== Estimated Score: ====')\n",
    "print()\n",
    "\n",
    "# print(edf_file.split('/')[-1].split('~')[0])\n",
    "# for i, model_dict in enumerate(model_pool):\n",
    "#     for s in model_dict['test_score']:\n",
    "#         print(s, end='\\t')\n",
    "# print()\n",
    "\n",
    "\n",
    "for i, score in enumerate(ensemble_test_score):\n",
    "    print(f\"- <{config['class_label_to_name'][i]:^10}> score: \\t{score * 100:5.2f} %\")\n",
    "    \n",
    "print()\n",
    "fig = plt.figure(num=1, clear=True, figsize=(3.5, 2.5), constrained_layout=True)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "im = draw_heatmap(ensemble_test_score.reshape(1, -1) * 100, row_labels=[''], \n",
    "                  col_labels=config['class_label_to_name'], ax=ax, imshow_kw={'alpha': 0.9, 'cmap': \"YlOrRd\"})\n",
    "annotate_heatmap(im, anno_format=\"{x:.2f}%\", text_colors=(\"black\", \"white\"), threshold=0.7)\n",
    "ax.set_title('Estimated Score', fontweight='bold')\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f651fe-6b38-43cd-ab7e-4aa726f41179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
