{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train Networks\n",
    "\n",
    "- Train a deep classifier for the EEG-based diagnostic classification\n",
    "    - CAUEEG-Dementia benchmark: Classification of **Normal**, **MCI**, and **Dementia** symptoms\n",
    "    - CAUEEG-Abnormal benchmark: Classification of **Normal** and **Abnormal** symptoms    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pprint\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "from train.train_script import train_script\n",
    "from datasets.caueeg_script import build_dataset_for_train\n",
    "from datasets.temple_eeg_script import build_dataset_for_tuab_train\n",
    "from models.utils import count_parameters\n",
    "\n",
    "# custom package\n",
    "from run_train import check_device_env\n",
    "from run_train import prepare_and_run_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Specify the dataset, model, and train setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "project = 'caueeg-dementia-train-size'\n",
    "data_cfg_file = 'caueeg-dementia'\n",
    "device = 'cuda:0'\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Initializing configurations using Hydra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with hydra.initialize(config_path='../config'):\n",
    "    add_configs = [f\"data={data_cfg_file}\", \n",
    "                   f\"+train.device={device}\", \n",
    "                   f\"+train.project={project}\",\n",
    "                   f\"++train.seed={seed}\",\n",
    "                   f\"++data.EKG=O\",\n",
    "                   f\"++data.awgn=0.004872735559634612\",\n",
    "                   f\"++data.awgn_age=0.03583361229344302\",\n",
    "                   f\"++data.mgn=0.09575622309480344\",\n",
    "                   f\"++data.photic=O\",\n",
    "                   f\"++data.seq_length=2000\",\n",
    "                   f\"model=1D-ResNet-18\",\n",
    "                   f\"++model.activation=gelu\",\n",
    "                   f\"++model.dropout=0.3\",\n",
    "                   f\"++model.fc_stages=3\",\n",
    "                   f\"++model.use_age=conv\",\n",
    "                   f\"++train.criterion=multi-bce\",\n",
    "                   f\"++train.lr_scheduler_type=cosine_decay_with_warmup_half\",\n",
    "                   f\"++train.mixup=0.2\",\n",
    "                   f\"++train.weight_decay=0.04394746639552375\",]\n",
    "    cfg = hydra.compose(config_name='default', overrides=add_configs)\n",
    "    \n",
    "config_base = {**OmegaConf.to_container(cfg.data), \n",
    "               **OmegaConf.to_container(cfg.train),\n",
    "               **OmegaConf.to_container(cfg.model)}\n",
    "\n",
    "check_device_env(config_base)\n",
    "pprint.pprint(config_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = None\n",
    "world_size = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat = 1\n",
    "\n",
    "for ratio in np.linspace(0.2, 0.8, num=4):\n",
    "    for r in range(repeat):\n",
    "        config = deepcopy(config_base)\n",
    "        \n",
    "        # collect some garbage\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        # fix the seed for reproducibility (a negative seed value means not fixing)\n",
    "        if config.get('seed', 0) >= 0:\n",
    "            config['seed'] = config.get('seed', 0) + r*10\n",
    "            seed = config['seed']\n",
    "            torch.manual_seed(seed)\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        # compose dataset\n",
    "        if config.get('dataset_name', None) == 'tuab':\n",
    "            train_loader, val_loader, test_loader, multicrop_test_loader = build_dataset_for_tuab_train(config)\n",
    "        else:\n",
    "            train_loader, val_loader, test_loader, multicrop_test_loader = build_dataset_for_train(config)\n",
    "            \n",
    "        # reduce the training set size\n",
    "        serial_dict_by_class = {}\n",
    "        for i, data in enumerate(train_loader.dataset):\n",
    "            class_name = data['class_name']\n",
    "            if class_name in serial_dict_by_class.keys():\n",
    "                serial_dict_by_class[class_name].append(i)\n",
    "            else:\n",
    "                serial_dict_by_class[class_name] = [i]\n",
    "        \n",
    "        keep_list = np.array([], dtype=int)\n",
    "        for k, v in serial_dict_by_class.items():\n",
    "            keep_list = np.append(keep_list, np.random.choice(np.array(v), round(len(v) * ratio)))\n",
    "        \n",
    "        data_list = []\n",
    "        for keep in keep_list:\n",
    "            data_list.append(train_loader.dataset.data_list[keep])\n",
    "        train_loader.dataset.data_list = data_list\n",
    "        \n",
    "        config['train_set_size'] = len(train_loader.dataset.data_list)\n",
    "                \n",
    "        # generate the model and update some configurations\n",
    "        model = hydra.utils.instantiate(config)\n",
    "        model = model.to(config['device'])\n",
    "        config['output_length'] = model.get_output_length()\n",
    "        config['num_params'] = count_parameters(model)\n",
    "        \n",
    "\n",
    "        # train\n",
    "        train_script(config, model, train_loader, val_loader, test_loader, multicrop_test_loader,\n",
    "                     config['preprocess_train'], config['preprocess_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
