{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aef1d0b-f084-44c6-a332-127a3d4af1fb",
   "metadata": {},
   "source": [
    "# Occlusion Sensitivity\n",
    "\n",
    "This notebook conducts an experiment for the occlusion sensitivity of our networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89b731a-e5d9-429d-9313-4d6ad242a70f",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae52098d-3075-4185-8408-a5bc3a52b31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minjae\\Desktop\\EEG_Project\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18cdea24-1a20-4989-9b69-69c05da32f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from collections import OrderedDict\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cycler import cycler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pprint\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as mtransforms\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredDirectionArrows\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_script import build_dataset_for_train\n",
    "from datasets.pipeline import EegSpectrogram\n",
    "from datasets.pipeline import eeg_collate_fn\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e54f80b1-51d1-4b23-ba5a-97750a8ab3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.0+cu117\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaa174d-f3f2-4de6-91b6-4e64ab0cd86a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "-----\n",
    "\n",
    "## Load a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ddbd12-da9a-4373-9775-020ab6a6fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    'lo88puq7',\n",
    "    'ruqd8r7g'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2119a08f-f9cc-4db4-a8f6-c7030bd08813",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7dfec22-3837-46a7-8b4d-4588300068bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat = 3\n",
    "minibatch = 1024\n",
    "crop_multiple = 1\n",
    "test_crop_multiple = 1\n",
    "save_fig = True\n",
    "target_dataset = 'train'  # train, test, val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b99490d-03bd-4bee-8bed-5253ab045b54",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ba96a8e-94b1-4ce3-9877-6f767bd6a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_score(model, sample_batched, config):\n",
    "    # compute output embedding\n",
    "    x = sample_batched['signal']\n",
    "    age = sample_batched['age']\n",
    "    output = model.compute_feature_embedding(x, age)\n",
    "    \n",
    "    if config['criterion'] == 'cross-entropy':\n",
    "        s = F.softmax(output, dim=1)\n",
    "    elif config['criterion'] == 'multi-bce':\n",
    "        s = torch.sigmoid(output)\n",
    "    elif config['criterion'] == 'svm':\n",
    "        s = output\n",
    "\n",
    "    # map depending on the loss function\n",
    "    if config['criterion'] == 'cross-entropy':\n",
    "        score = F.softmax(output, dim=1)\n",
    "    elif config['criterion'] == 'multi-bce':\n",
    "        score = torch.sigmoid(output)\n",
    "    elif config['criterion'] == 'svm':\n",
    "        score = output\n",
    "    else:\n",
    "        raise ValueError(f\"estimate_score(): cannot parse config['criterion']={config['criterion']}.\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cafa3d0-d589-47f9-b0ff-ada041b8af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_as_real_to_complex(signal):\n",
    "    N, _, H, W = signal.shape\n",
    "    C = signal.shape[1] // 2\n",
    "\n",
    "    sig_out = torch.zeros((N, C, H, W, 2))\n",
    "    sig_out[..., 0] = signal[:, :C]\n",
    "    sig_out[..., 1] = signal[:, C:]\n",
    "\n",
    "    sig_out = torch.view_as_complex(sig_out)\n",
    "    return sig_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e4876d9-9687-431e-bc8e-d6775fb51c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other settings\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # cleaner text\n",
    "\n",
    "plt.style.use('default') \n",
    "# plt.style.use('fast') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'jet' # 'jet', 'nipy_spectral', 'rainbow'\n",
    "\n",
    "# plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams.update({'font.family': 'Roboto Slab'})\n",
    "# plt.rcParams[\"font.family\"] = 'DejaVu Sans' # 'NanumGothic' # for Hangul in Windows\n",
    "plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "\n",
    "\n",
    "def draw_stft(sample, config, index=0, log_scale=False, occlusion=None, save_fig=None):\n",
    "    signal = deepcopy(sample['signal'])\n",
    "    signal_f = from_as_real_to_complex(signal)[index].abs().cpu().numpy()\n",
    "    \n",
    "    # always do not consider EKG and Photic channels\n",
    "    C = 19 # signal_f.shape[0]\n",
    "    _, H, W = signal_f.shape\n",
    "    \n",
    "    columns = 7\n",
    "    rows = round(np.ceil(C / columns))\n",
    "    \n",
    "    fig, ax = plt.subplots(rows, columns, \n",
    "                           figsize=(22.0, 9.5), constrained_layout=True)\n",
    "    normalizer = Normalize()\n",
    "    \n",
    "    for k in range(columns * rows):\n",
    "        r = k // columns\n",
    "        c = k % columns\n",
    "        \n",
    "        if k < C:\n",
    "            im = ax[r, c].imshow(np.log(signal_f[k, ::-1] + 1e-8) if log_scale else signal_f[k, ::-1],\n",
    "                                 interpolation='nearest',\n",
    "                                 extent=[0, config['seq_length']/200.0, 0, 200/2.0], \n",
    "                                 aspect=(config['seq_length']/200.0) / (200/2.0), norm=normalizer)\n",
    "            ax[r, c].set_title(config['signal_header'][k].split('-')[0], \n",
    "                               fontsize=18, fontweight='bold', color='darkred')\n",
    "            ax[r, c].set_xlabel('Time (s)', fontsize=13)\n",
    "            ax[r, c].set_ylabel('Frequency (Hz)', fontsize=13)\n",
    "            # ax[r, c].invert_yaxis()\n",
    "            \n",
    "            if occlusion and occlusion['c'] == k:\n",
    "                bb = mtransforms.Bbox([[occlusion['x'] / W * config['seq_length']/200.0, \n",
    "                                        occlusion['y'] / H * 200/2.0], \n",
    "                                       [(occlusion['x'] + occlusion['w']) / W * config['seq_length']/200.0, \n",
    "                                        (occlusion['y'] + occlusion['h']) / H * 200/2.0]])\n",
    "                fancy = FancyBboxPatch(bb.p0, bb.width, bb.height, boxstyle=\"square,pad=0\")\n",
    "                fancy.set(edgecolor=\"none\", facecolor=\"gray\", zorder=10)\n",
    "                ax[r, c].add_patch(fancy)\n",
    "            \n",
    "        elif k == C:\n",
    "            ax[r, c].axis('off')\n",
    "            axins = ax[r, c]\n",
    "        else:\n",
    "            ax[r, c].axis('off')\n",
    "        \n",
    "    fig.suptitle('Time-Frequency Representation', fontsize=20, fontweight='semibold')\n",
    "    cax = inset_axes(axins,\n",
    "                     width=\"10%\",  # width = 10% of parent_bbox width\n",
    "                     height=\"80%\",  # height : 50%\n",
    "                     loc='center',\n",
    "                     bbox_to_anchor=(0., 0., 1, 1),\n",
    "                     bbox_transform=axins.transAxes,\n",
    "                     borderpad=0,\n",
    "                     )\n",
    "    cbar = fig.colorbar(im, ax=ax.ravel().tolist(), cax=cax)\n",
    "    cbar.ax.set_xlabel('Magnitude in log-scale' if log_scale else 'Magnitude', fontsize=13) \n",
    "    if save_fig:\n",
    "        fig.savefig(os.path.join(save_fig, 'draw_stft.pdf'), transparent=True)\n",
    "    else:\n",
    "        plt.show()\n",
    "    fig.clear()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    \n",
    "def draw_stft_origin(sample, config, index=0, log_scale=False, occlusion=None, save_fig=None):\n",
    "    sample = deepcopy(sample)\n",
    "    EegSpectrogram(**config['stft_params'])(sample)\n",
    "    signal_f = from_as_real_to_complex(sample['signal'])[index].abs().cpu().numpy()\n",
    "    \n",
    "    # always do not consider EKG and Photic channels\n",
    "    C = 19 # signal_f.shape[0]\n",
    "    _, H, W = signal_f.shape\n",
    "    \n",
    "    columns = 7\n",
    "    rows = round(np.ceil(C / columns))\n",
    "    \n",
    "    fig, ax = plt.subplots(rows, columns, \n",
    "                           figsize=(22.0, 9.5), constrained_layout=True)\n",
    "    normalizer = Normalize()\n",
    "    \n",
    "    for k in range(columns * rows):\n",
    "        r = k // columns\n",
    "        c = k % columns\n",
    "        \n",
    "        if k < C:\n",
    "            im = ax[r, c].imshow(np.log(signal_f[k, ::-1] + 1e-8) if log_scale else signal_f[k, ::-1],\n",
    "                                 interpolation='nearest',\n",
    "                                 extent=[0, config['seq_length']/200.0, 0, 200/2.0], \n",
    "                                 aspect=(config['seq_length']/200.0) / (200/2.0), norm=normalizer)\n",
    "            ax[r, c].set_title(config['signal_header'][k].split('-')[0], \n",
    "                               fontsize=18, fontweight='bold', color='darkred')\n",
    "            ax[r, c].set_xlabel('Time (s)', fontsize=13)\n",
    "            ax[r, c].set_ylabel('Frequency (Hz)', fontsize=13)\n",
    "            # ax[r, c].invert_yaxis()\n",
    "            \n",
    "            if occlusion and occlusion['c'] == k:\n",
    "                bb = mtransforms.Bbox([[occlusion['x'] / W * config['seq_length']/200.0, \n",
    "                                        occlusion['y'] / H * 200/2.0], \n",
    "                                       [(occlusion['x'] + occlusion['w']) / W * config['seq_length']/200.0, \n",
    "                                        (occlusion['y'] + occlusion['h']) / H * 200/2.0]])\n",
    "                fancy = FancyBboxPatch(bb.p0, bb.width, bb.height, boxstyle=\"square,pad=0\")\n",
    "                fancy.set(edgecolor=\"none\", facecolor=\"gray\", zorder=10)\n",
    "                ax[r, c].add_patch(fancy)\n",
    "            \n",
    "        elif k == C:\n",
    "            ax[r, c].axis('off')\n",
    "            axins = ax[r, c]\n",
    "        else:\n",
    "            ax[r, c].axis('off')\n",
    "        \n",
    "    fig.suptitle('Time-Frequency Representation', fontsize=20, fontweight='semibold')\n",
    "    cax = inset_axes(axins,\n",
    "                     width=\"10%\",  # width = 10% of parent_bbox width\n",
    "                     height=\"80%\",  # height : 50%\n",
    "                     loc='center',\n",
    "                     bbox_to_anchor=(0., 0., 1, 1),\n",
    "                     bbox_transform=axins.transAxes,\n",
    "                     borderpad=0,\n",
    "                     )\n",
    "    cbar = fig.colorbar(im, ax=ax.ravel().tolist(), cax=cax)\n",
    "    cbar.ax.set_xlabel('Magnitude in log-scale' if log_scale else 'Magnitude', fontsize=13) \n",
    "    if save_fig:\n",
    "        fig.savefig(os.path.join(save_fig, 'draw_stft_origin.pdf'), transparent=True)\n",
    "    else:\n",
    "        plt.show()\n",
    "    fig.clear()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    \n",
    "def draw_occlusion_sensitivity(occlusion_score, config, suptitle=None, save_fig=None):\n",
    "    # always do not consider EKG and Photic channels\n",
    "    C, H, W = occlusion_score.shape\n",
    "    \n",
    "    columns = 7\n",
    "    rows = round(np.ceil(C / columns))\n",
    "    \n",
    "    fig, ax = plt.subplots(rows, columns, \n",
    "                           figsize=(22.0, 9.5), constrained_layout=True)\n",
    "    normalizer = Normalize()  # (0, 1)\n",
    "\n",
    "    for k in range(columns * rows):\n",
    "        r = k // columns\n",
    "        c = k % columns\n",
    "        \n",
    "        if k < C:\n",
    "            im = ax[r, c].imshow(occlusion_score[k, ::-1], interpolation='nearest',\n",
    "                                 extent=[0, config['seq_length']/200.0, 0, 200/2.0], \n",
    "                                 aspect=(config['seq_length']/200.0) / (200/2.0), norm=normalizer)\n",
    "            ax[r, c].set_title(config['signal_header'][k].split('-')[0], \n",
    "                               fontsize=18, fontweight='bold', color='darkred')\n",
    "            ax[r, c].set_xlabel('Time (s)', fontsize=13)\n",
    "            ax[r, c].set_ylabel('Frequency (Hz)', fontsize=13)\n",
    "            # ax[r, c].invert_yaxis()\n",
    "        elif k == C:\n",
    "            ax[r, c].axis('off')\n",
    "            axins = ax[r, c]\n",
    "        else:\n",
    "            ax[r, c].axis('off')\n",
    "    \n",
    "    if suptitle is None:\n",
    "        suptitle = 'Occlusion Sensitivity'\n",
    "    fig.suptitle(suptitle, fontsize=20, fontweight='semibold')\n",
    "    # colorbar\n",
    "    cax = inset_axes(axins,\n",
    "                     width=\"10%\",  # width = 10% of parent_bbox width\n",
    "                     height=\"80%\",  # height : 50%\n",
    "                     loc='center',\n",
    "                     bbox_to_anchor=(0., 0., 1, 1),\n",
    "                     bbox_transform=axins.transAxes,\n",
    "                     borderpad=0,\n",
    "                     )\n",
    "    cbar = fig.colorbar(im, ax=ax.ravel().tolist(), cax=cax)\n",
    "    cbar.ax.set_xlabel('True class score', fontsize=13)\n",
    "    if save_fig:\n",
    "        fig.savefig(save_fig, transparent=True)\n",
    "    else:\n",
    "        plt.show()\n",
    "    fig.clear()\n",
    "    plt.close(fig)\n",
    "    \n",
    "    \n",
    "def draw_occlusion_sensitivity_all_channels(occlusion_score, config, suptitle=None, save_fig=None):\n",
    "    # always do not consider EKG and Photic channels\n",
    "    H, W = occlusion_score.shape\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(6.5, 4.0), constrained_layout=True)\n",
    "    im = ax[0].imshow(occlusion_score[::-1], interpolation='nearest',\n",
    "                      extent=[0, config['seq_length']/200.0, 0, 200/2.0], \n",
    "                      aspect=(config['seq_length']/200.0) / (200/2.0))\n",
    "    ax[0].set_xlabel('Time (s)', fontsize=13)\n",
    "    ax[0].set_ylabel('Frequency (Hz)', fontsize=13)\n",
    "    \n",
    "    if suptitle is None:\n",
    "        suptitle = 'Occlusion Sensitivity (All Channels)'\n",
    "    fig.suptitle(suptitle, fontsize=20, fontweight='semibold')\n",
    "    \n",
    "    # colorbar\n",
    "    ax[1].axis('off')    \n",
    "    cax = inset_axes(ax[1],\n",
    "                     width=\"10%\",  # width = 10% of parent_bbox width\n",
    "                     height=\"80%\",  # height : 50%\n",
    "                     loc='center',\n",
    "                     bbox_to_anchor=(0., 0., 1, 1),\n",
    "                     bbox_transform=ax[1].transAxes,\n",
    "                     borderpad=0,\n",
    "                     )\n",
    "    cbar = fig.colorbar(im, ax=ax.ravel().tolist(), cax=cax, shrink=0.9)\n",
    "    cbar.ax.set_xlabel('True class score', fontsize=13) \n",
    "    if save_fig:\n",
    "        fig.savefig(save_fig, transparent=True)\n",
    "    else:\n",
    "        plt.show()\n",
    "    fig.clear()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "008b6086-c40f-4377-92a3-6ed9cd957a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_occlusion_sensitivity_map(occlusion_sensitivity):\n",
    "    coeff = np.zeros((19, H, W))\n",
    "    score = np.zeros((19, H, W))\n",
    "\n",
    "    for result in occlusion_sensitivity:\n",
    "        s = result['score']\n",
    "        c = result['c']\n",
    "        x = result['x']\n",
    "        y = result['y']\n",
    "        w = result['w']\n",
    "        h = result['h']\n",
    "\n",
    "        score[c, y:y+h, x:x+w] += s\n",
    "        coeff[c, y:y+h, x:x+w] += 1\n",
    "\n",
    "    score = score / coeff\n",
    "    return score\n",
    "\n",
    "\n",
    "def generate_occlusion_sensitivity_all_channels_map(occlusion_sensitivity):\n",
    "    coeff = np.zeros((H, W))\n",
    "    score = np.zeros((H, W))\n",
    "    ideal_score = 0.0\n",
    "    ideal_count = 0\n",
    "\n",
    "    for result in occlusion_sensitivity:\n",
    "        s = result['score']\n",
    "        x = result['x']\n",
    "        y = result['y']\n",
    "        w = result['w']\n",
    "        h = result['h']\n",
    "\n",
    "        # no occlussion case\n",
    "        if x == 0 and y == 0 and w == 0 and h == 0:\n",
    "            ideal_score += s\n",
    "            ideal_count += 1\n",
    "        else:\n",
    "            score[y:y+h, x:x+w] += s\n",
    "            coeff[y:y+h, x:x+w] += 1\n",
    "\n",
    "    score = score / coeff\n",
    "    ideal_score = ideal_score / ideal_count\n",
    "    return score, ideal_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333e085b-fadf-40c4-a37b-1913c4f8a9c6",
   "metadata": {},
   "source": [
    "## Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dca0f95-ed61-474c-9075-ae624342d270",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01300501823425293,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Outer Loop",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d895589ee6413cb26d171a7677e82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer Loop:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011000633239746094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Mid Loop",
       "rate": null,
       "total": 950,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mid Loop:   0%|          | 0/950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011999845504760742,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Mid Loop",
       "rate": null,
       "total": 950,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483c7a3c8de1496e8e8be4d13467dc30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mid Loop:   0%|          | 0/950 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model_name in model_list:\n",
    "    # load from disk\n",
    "    try:\n",
    "        path = os.path.join(r'E:\\CAUEEG\\checkpoint', model_name, 'checkpoint.pt')\n",
    "        ckpt = torch.load(path, map_location=device)\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    \n",
    "    model_state = ckpt['model_state']\n",
    "    config = ckpt['config']\n",
    "    \n",
    "    # initiate the model\n",
    "    if '_target_' in config:\n",
    "        model = hydra.utils.instantiate(config).to(device)\n",
    "    elif type(config['generator']) is str:\n",
    "        config['generator'] = getattr(models, config['generator'].split('.')[-1])\n",
    "        if 'block' in config:\n",
    "            config['block'] = getattr(models, config['block'].split('.')[-1])\n",
    "        model = config['generator'](**config).to(device)\n",
    "    else:\n",
    "        if 'block' in config:\n",
    "            if config['block'] == models.resnet_1d.BottleneckBlock1D:\n",
    "                config['block'] = 'bottleneck'\n",
    "            elif config['block'] == models.resnet_2d.Bottleneck2D:\n",
    "                config['block'] = 'bottleneck'\n",
    "            elif config['block'] == models.resnet_1d.BasicBlock1D:\n",
    "                config['block'] = 'basic'\n",
    "            elif config['block'] == models.resnet_2d.BasicBlock2D:\n",
    "                config['block'] = 'basic'\n",
    "    \n",
    "        model = config['generator'](**config).to(device)\n",
    "    \n",
    "    if config.get('ddp', False):\n",
    "        model_state_ddp = deepcopy(model_state)\n",
    "        model_state = OrderedDict()\n",
    "        for k, v in model_state_ddp.items():\n",
    "            name = k[7:]  # remove 'module.' of DataParallel/DistributedDataParallel\n",
    "            model_state[name] = v\n",
    "    \n",
    "    model.load_state_dict(model_state)\n",
    "    model.requires_grad_(False)\n",
    "    model.eval()\n",
    "\n",
    "    task = config['task']\n",
    "    config.pop('cwd', 0)\n",
    "    config['ddp'] = False\n",
    "    config['minibatch'] = 1\n",
    "    config['crop_multiple'] = crop_multiple\n",
    "    config['test_crop_multiple'] = test_crop_multiple\n",
    "    config['crop_timing_analysis'] = False\n",
    "    config['eval'] = True\n",
    "    config['device'] = device\n",
    "    H, W = config['seq_len_2d']\n",
    "    if '220419' in config['dataset_path']:\n",
    "        config['dataset_path'] = './local/dataset/caueeg-dataset/'\n",
    "    \n",
    "    _ = build_dataset_for_train(config, verbose=False)\n",
    "    train_loader = _[0]\n",
    "    val_loader = _[1]\n",
    "    test_loader = _[2]\n",
    "    multicrop_test_loader = _[3]\n",
    "    \n",
    "    if target_dataset == 'train':\n",
    "        loader = train_loader\n",
    "    elif target_dataset == 'val':\n",
    "        loader = val_loader\n",
    "    elif target_dataset == 'test':\n",
    "        loader = test_loader\n",
    "    else:\n",
    "        raise ValueError('')\n",
    "        \n",
    "    # for k in tqdm(range(repeat), desc='Outer Loop'):\n",
    "    for k in tqdm(range(3, 5), desc='Outer Loop'): #########################################################################################################\n",
    "        for ii, sample in tqdm(enumerate(loader), total=len(loader), desc='Mid Loop', leave=False):\n",
    "            sample_origin = deepcopy(sample)\n",
    "            config['preprocess_test'](sample)\n",
    "    \n",
    "            ################\n",
    "            # All Channels #\n",
    "            ################\n",
    "            occlusion_sensitivity_all_channels = []\n",
    "            occ_cycler = cycler(x=np.arange(W)) * cycler(y=np.arange(H)) * \\\n",
    "                        cycler(w=[round(W/4)]) * cycler(h=[round(H/4)])\n",
    "    \n",
    "            # no occlusion case\n",
    "            sample_batched = []\n",
    "            sb_temp = deepcopy(sample)\n",
    "            sb_temp['occlusion'] = {'x': 0, 'y': 0, 'w': 0, 'h': 0}\n",
    "            sample_batched.append(sb_temp)\n",
    "    \n",
    "            # occlusion case\n",
    "            for occ in occ_cycler:\n",
    "                # boundary condition\n",
    "                if W < occ['x'] + occ['w'] or H < occ['y'] + occ['h']:\n",
    "                    continue\n",
    "        \n",
    "                # occlude and gather minibatch\n",
    "                sb_temp = deepcopy(sample)\n",
    "                sb_temp['occlusion'] = occ\n",
    "                sb_temp['signal'][:, :, \n",
    "                                  occ['y']:occ['y'] + occ['h'], \n",
    "                                  occ['x']:occ['x'] + occ['w']] = 0\n",
    "                C = sb_temp['signal'].shape[1]\n",
    "                sample_batched.append(sb_temp)\n",
    "        \n",
    "                # gather data until it becomes minibatch size\n",
    "                if len(sample_batched) == minibatch:\n",
    "                    N = len(sample_batched)\n",
    "                    sample_batched = eeg_collate_fn(sample_batched)\n",
    "                    sample_batched['signal'] = sample_batched['signal'].reshape(N, C, H, W)\n",
    "                    sample_batched['age'] = sample_batched['age'].reshape(N)\n",
    "                    sample_batched['class_label'] = sample_batched['class_label'].reshape(N)\n",
    "                    s = estimate_score(model, sample_batched, config)\n",
    "        \n",
    "                    for i in range(N):\n",
    "                        result = {**sample_batched['occlusion'][i], \n",
    "                                  'score': s[i, sample_batched['class_label'][i]].item()}\n",
    "                        occlusion_sensitivity_all_channels.append(result)\n",
    "                    sample_batched = []\n",
    "        \n",
    "            # the rest data\n",
    "            if len(sample_batched) > 0:\n",
    "                N = len(sample_batched)\n",
    "                sample_batched = eeg_collate_fn(sample_batched)\n",
    "                sample_batched['signal'] = sample_batched['signal'].reshape(N, C, H, W)\n",
    "                sample_batched['age'] = sample_batched['age'].reshape(N)\n",
    "                sample_batched['class_label'] = sample_batched['class_label'].reshape(N)\n",
    "                s = estimate_score(model, sample_batched, config)\n",
    "        \n",
    "                for i in range(N):\n",
    "                    result = {**sample_batched['occlusion'][i], \n",
    "                              'score': s[i, sample_batched['class_label'][i]].item()}\n",
    "                    occlusion_sensitivity_all_channels.append(result)\n",
    "        \n",
    "            score, ideal_score = generate_occlusion_sensitivity_all_channels_map(occlusion_sensitivity_all_channels)\n",
    "            class_name = config['class_label_to_name'][sample[\"class_label\"][0]]\n",
    "            path = f'local/output/occlusion_exp/{task}/{target_dataset}/{class_name}/{sample[\"serial\"][0]}_{k:02d}'\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "            with open(os.path.join(path, 'occlusion_sensitivity_all_channels_map.npy'), 'wb') as f:\n",
    "                np.save(f, score)\n",
    "            with open(os.path.join(path, 'occlusion_sensitivity_all_channels_map_ideal_score.npy'), 'wb') as f:\n",
    "                np.save(f, ideal_score)\n",
    "            draw_occlusion_sensitivity_all_channels(score, config, \n",
    "                                                    save_fig=os.path.join(path, 'draw_occlusion_sensitivity_all_channels.pdf'), suptitle=f\"Ideal score: {ideal_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd41b9-bbb7-462f-a3ba-3b6a7eee4da8",
   "metadata": {},
   "source": [
    "## Post analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f8c0aa6-117f-47fc-b299-fa337c206f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for target_dataset in ['train', 'test', 'val']:\n",
    "#     for root in glob.glob(f'local/output/occlusion_exp/dementia/{target_dataset}/*'):\n",
    "#         taget_class = os.path.basename(root)\n",
    "        \n",
    "#         all_channel_count = 0\n",
    "#         count = 0\n",
    "        \n",
    "#         for file in glob.glob(os.path.join(root, '*/*.npy')):\n",
    "#             if os.path.basename(file) == 'occlusion_sensitivity_map.npy':\n",
    "#                 if count == 0:\n",
    "#                     occlusion_sensitivity_map = np.load(file)\n",
    "#                 else:\n",
    "#                     occlusion_sensitivity_map += np.load(file)\n",
    "                    \n",
    "#                 count += 1\n",
    "                \n",
    "#             elif os.path.basename(file) == 'occlusion_sensitivity_all_channels_map.npy':\n",
    "#                 if all_channel_count == 0:\n",
    "#                     occlusion_sensitivity_all_channels_map = np.load(file)\n",
    "#                 else:\n",
    "#                     occlusion_sensitivity_all_channels_map += np.load(file)\n",
    "                \n",
    "#                 all_channel_count += 1\n",
    "\n",
    "#             else:\n",
    "#                 raise FileNotFoundError('')\n",
    "    \n",
    "#         occlusion_sensitivity_all_channels_map = occlusion_sensitivity_all_channels_map / count\n",
    "#         occlusion_sensitivity_map = occlusion_sensitivity_map / count\n",
    "\n",
    "        \n",
    "#         if target_dataset == 'train':\n",
    "#             dataset_name = 'Training Set'\n",
    "#         elif target_dataset == 'val':\n",
    "#             dataset_name = 'Validation Set'\n",
    "#         elif target_dataset == 'test':\n",
    "#             dataset_name = 'Test Set'\n",
    "        \n",
    "#         # path = f'local/output/occlusion_exp/dementia/{target_dataset}/{taget_class}/'\n",
    "#         path = r'C:\\Users\\Minjae\\Desktop\\occlusion_exp/'\n",
    "#         os.makedirs(path, exist_ok=True)\n",
    "#         print(target_dataset, taget_class, count, all_channel_count, path)\n",
    "        \n",
    "#         save_path = path + f'/occlusion-exp-dementia-{target_dataset}-{taget_class}-channel-wise.pdf'\n",
    "#         draw_occlusion_sensitivity(occlusion_sensitivity_map, config, save_fig=save_path,\n",
    "#                                    # suptitle=f'Occlusion Sensitivity ({dataset_name}, {taget_class})')\n",
    "#                                    suptitle=f'')\n",
    "\n",
    "#         save_path = path + f'/occlusion-exp-dementia-{target_dataset}-{taget_class}-channel-agnostic.pdf'\n",
    "#         draw_occlusion_sensitivity_all_channels(occlusion_sensitivity_all_channels_map, config, save_fig=save_path,\n",
    "#                                                 # suptitle=f'Occlusion Sensitivity \\n(All Channels, {dataset_name}, {taget_class})')\n",
    "#                                                 suptitle=f'')\n",
    "        \n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68f617f0-ff24-47cc-b528-597f5ae86494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012000560760498047,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Outer Loop",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1f948ee3424fba9780d9c2114f36b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer Loop:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010997772216796875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Mid Loop",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mid Loop:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011000633239746094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Inner Loop",
       "rate": null,
       "total": 1494,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inner Loop:   0%|          | 0/1494 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011516094207763672,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Inner Loop",
       "rate": null,
       "total": 2004,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inner Loop:   0%|          | 0/2004 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010002613067626953,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Inner Loop",
       "rate": null,
       "total": 2202,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inner Loop:   0%|          | 0/2202 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011996269226074219,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Mid Loop",
       "rate": null,
       "total": 0,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mid Loop: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010001420974731445,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Mid Loop",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mid Loop:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012001991271972656,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Inner Loop",
       "rate": null,
       "total": 3100,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inner Loop:   0%|          | 0/3100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011296510696411133,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Inner Loop",
       "rate": null,
       "total": 4200,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inner Loop:   0%|          | 0/4200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0110015869140625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Inner Loop",
       "rate": null,
       "total": 4600,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inner Loop:   0%|          | 0/4600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010997295379638672,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Outer Loop",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0c6a011e97484f84a37fbc55a7f6ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Outer Loop:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010000228881835938,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Mid Loop",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mid Loop:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013001680374145508,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Inner Loop",
       "rate": null,
       "total": 4440,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inner Loop:   0%|          | 0/4440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011999845504760742,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Inner Loop",
       "rate": null,
       "total": 2202,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inner Loop:   0%|          | 0/2202 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012506484985351562,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Mid Loop",
       "rate": null,
       "total": 0,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mid Loop: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010999917984008789,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Mid Loop",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mid Loop:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011000394821166992,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Inner Loop",
       "rate": null,
       "total": 9000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inner Loop:   0%|          | 0/9000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010000467300415039,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 7,
       "postfix": null,
       "prefix": "Inner Loop",
       "rate": null,
       "total": 4600,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inner Loop:   0%|          | 0/4600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "for task in ['dementia', 'abnormal']:\n",
    "    for target_dataset in tqdm(['train', 'test', 'val'], desc='Outer Loop'):\n",
    "        for root in tqdm(glob.glob(f'local/output/occlusion_exp/{task}/{target_dataset}/*'), desc='Mid Loop', leave=False):\n",
    "            taget_class = os.path.basename(root)\n",
    "            \n",
    "            all_channel_count = 0\n",
    "            ideal_count = 0\n",
    "            \n",
    "            for file in tqdm(glob.glob(os.path.join(root, '*/*.npy')), 'Inner Loop', leave=False):\n",
    "                if os.path.basename(file) == 'occlusion_sensitivity_all_channels_map.npy':\n",
    "                    if all_channel_count == 0:\n",
    "                        occlusion_sensitivity_all_channels_map = np.load(file)\n",
    "                    else:\n",
    "                        occlusion_sensitivity_all_channels_map += np.load(file)\n",
    "                    all_channel_count += 1\n",
    "                    \n",
    "                elif os.path.basename(file) == 'occlusion_sensitivity_all_channels_map_ideal_score.npy':\n",
    "                    if ideal_count == 0:\n",
    "                        occlusion_sensitivity_ideal_score = np.load(file)\n",
    "                    else:\n",
    "                        occlusion_sensitivity_ideal_score += np.load(file)\n",
    "                    ideal_count += 1\n",
    "    \n",
    "                else:\n",
    "                    raise FileNotFoundError('')\n",
    "        \n",
    "            occlusion_sensitivity_all_channels_map = occlusion_sensitivity_all_channels_map / all_channel_count\n",
    "            occlusion_sensitivity_ideal_score = occlusion_sensitivity_ideal_score / ideal_count\n",
    "            \n",
    "            if target_dataset == 'train':\n",
    "                dataset_name = 'Training Set'\n",
    "            elif target_dataset == 'val':\n",
    "                dataset_name = 'Validation Set'\n",
    "            elif target_dataset == 'test':\n",
    "                dataset_name = 'Test Set'\n",
    "            \n",
    "            # path = f'local/output/occlusion_exp/{task}/{target_dataset}/{taget_class}/'\n",
    "            path = r'C:\\Users\\Minjae\\Desktop\\occlusion_exp/'\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "            save_path = path + f'/occlusion-exp-{task}-{target_dataset}-{taget_class}-channel-agnostic.pdf'\n",
    "            draw_occlusion_sensitivity_all_channels(occlusion_sensitivity_all_channels_map, config, save_fig=save_path,\n",
    "                                                    # suptitle=f'Occlusion Sensitivity \\n(All Channels, {dataset_name}, {taget_class})')\n",
    "                                                    suptitle=f'ideal score: {occlusion_sensitivity_ideal_score}')\n",
    "        \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f72601c-6325-42d0-8040-fd7fd0435e61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
