{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Finetune Masked-AutoEncoder\n",
    "\n",
    "- Finetune the deep network after pretraining the self-supervised learning framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "import pprint\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from collections import OrderedDict\n",
    "from cycler import cycler\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "# custom package\n",
    "from run_train import check_device_env\n",
    "from run_train import set_seed\n",
    "from run_train import compose_dataset\n",
    "from run_train import generate_model\n",
    "from train.ssl_train_script import ssl_train_script\n",
    "from train.train_script import train_script\n",
    "from models.utils import count_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Specify the dataset, model, and train setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_model_path = 'local/checkpoint/'\n",
    "pre_model_name = 'eg6s5fay'  # '5xlos421'\n",
    "device = 'cuda:1'\n",
    "\n",
    "############\n",
    "# Artifact #\n",
    "############\n",
    "art_config = dict()\n",
    "art_config['project'] = 'caueeg-mae-artifact'\n",
    "art_config['use_wandb'] = False\n",
    "art_config['pre_model'] = pre_model_name\n",
    "art_config['device'] = device\n",
    "\n",
    "# art_config[\"art_filter_list\"] = [9, 9, 9, 9, 9]\n",
    "art_config[\"art_dropout\"] = 0.1\n",
    "art_config[\"art_use_age\"] = \"no\"  # \"conv\", \"embedding\", \"no\"\n",
    "art_config[\"art_out_activation\"] = \"softplus\"  # \"none\", \"relu\", \"softplus\"  ######################################\n",
    "art_config[\"art_loss_type\"] = \"mse\"\n",
    "\n",
    "art_config['total_samples'] = 3.0e+6\n",
    "art_config['search_lr'] = False\n",
    "art_config['base_lr'] = 1e-4\n",
    "art_config['lr_scheduler_type'] = 'cosine_decay_with_warmup_half'\n",
    "\n",
    "art_config[\"warmup_min\"] = 150\n",
    "art_config[\"num_history\"] = 50\n",
    "art_config['save_model'] = False\n",
    "\n",
    "##################\n",
    "# Classification #\n",
    "##################\n",
    "finetune_config = dict()\n",
    "finetune_config['project'] = 'caueeg-abnormal-mae-artifact-finetune'\n",
    "finetune_config['use_wandb'] = True\n",
    "finetune_config['pre_model'] = pre_model_name\n",
    "finetune_config['device'] = device\n",
    "finetune_config[\"task\"] = \"abnormal\"\n",
    "finetune_config[\"out_dims\"] = 3\n",
    "\n",
    "# finetune_config[\"mask_ratio\"] = 0.25\n",
    "finetune_config[\"descending\"] = False  #######################################################\n",
    "finetune_config[\"global_pool\"] = True\n",
    "finetune_config[\"fc_stages\"] = 2\n",
    "finetune_config[\"dropout\"] = 0.1\n",
    "finetune_config[\"use_age\"] = \"conv\"  ##################################################\n",
    "# finetune_config[\"mixup\"] = 0.3 ###\n",
    "# finetune_config[\"crop_length\"] = 8192*4  #############################################################\n",
    "# finetune_config[\"criterion\"] = \"multi-bce\"  # \"cross-entropy\", \"multi-bce\"\n",
    "\n",
    "finetune_config[\"tuning_type\"] = \"finetune\"  # \"finetune\", \"fc_stage\"\n",
    "finetune_config[\"layer_wise_lr\"] = True\n",
    "\n",
    "finetune_config['total_samples'] = 3.0e+6  ############################################################\n",
    "# finetune_config['base_lr'] = 1e-3\n",
    "finetune_config['search_lr'] = True\n",
    "finetune_config['lr_search_steps'] = 100\n",
    "finetune_config['lr_scheduler_type'] = 'cosine_decay_with_warmup_half'\n",
    "finetune_config[\"warmup_min\"] = 200\n",
    "finetune_config[\"num_history\"] = 50\n",
    "finetune_config['save_model'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_cycler = cycler(mask_ratio=[0.3])\n",
    "finetune_cycler *= cycler(crop_length=[2560 * 2]) + cycler(minibatch=[128])\n",
    "finetune_cycler *= cycler(mixup=[0.1, 0.3])\n",
    "finetune_cycler *= cycler(total_samples=[1.0e+7, 2.0e+7])\n",
    "\n",
    "# finetune_cycler *= cycler(seed=[0, 1, 2])\n",
    "finetune_cycler *= cycler(descending=[False])\n",
    "for cyc in finetune_cycler:\n",
    "    print(cyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Uncertainty Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load pretrained configurations\n",
    "path = os.path.join(pre_model_path, pre_model_name.split(',')[-1], 'checkpoint.pt')\n",
    "try:\n",
    "    ckpt = torch.load(path, map_location=\"cpu\")\n",
    "    config = ckpt['config']\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f'- checkpoint cannot be opened: {path}')\n",
    "config[\"cwd\"] = \"\"\n",
    "\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update configuration\n",
    "for k, v in art_config.items():\n",
    "    config[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "if not config.get(\"ddp\", False):\n",
    "    pre_model_state = ckpt[\"ssl_model_state\"]\n",
    "else:\n",
    "    pre_model_state_ddp = deepcopy(ckpt[\"ssl_model_state\"])\n",
    "    pre_model_state = OrderedDict()\n",
    "    for k, v in pre_model_state_ddp.items():\n",
    "        name = k[7:]  # remove 'module.' of DataParallel/DistributedDataParallel\n",
    "        pre_model_state[name] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"ddp\"] = False\n",
    "\n",
    "# check the workstation environment and update some configurations\n",
    "check_device_env(config)\n",
    "\n",
    "# compose dataset\n",
    "train_loader, val_loader, test_loader, multicrop_test_loader = compose_dataset(config)\n",
    "\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the model\n",
    "config[\"_target_\"] = config[\"_target_\"].replace('pre', 'pre_art').replace('.mae_1d.', '.mae_1d_artifact.')\n",
    "model = generate_model(config).to(device)\n",
    "\n",
    "# load the model\n",
    "model_state = model.state_dict()\n",
    "for k, v in model_state.items():\n",
    "    if not k.startswith('art') and not k.endswith(\"pos_embed\"):\n",
    "        model_state[k] = pre_model_state[k]\n",
    "\n",
    "pre_model_state = deepcopy(model.state_dict())\n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.requires_grad_(False)\n",
    "model = model.eval()\n",
    "\n",
    "model.art_net.requires_grad_(True)\n",
    "for k, v in model._parameters.items():\n",
    "    if k.startswith(\"art\"):\n",
    "        v.requires_grad_(True)\n",
    "model.art_net = model.art_net.train()\n",
    "\n",
    "config[\"num_params\"] = count_parameters(model)\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name:100}\\t|\\t{param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# collect some garbage\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# fix the seed for reproducibility (a negative seed value means not fixing)\n",
    "set_seed(config, rank=None)\n",
    "\n",
    "# train\n",
    "ssl_train_script(\n",
    "    config,\n",
    "    model,\n",
    "    train_loader,\n",
    "    config[\"preprocess_train\"],\n",
    ")\n",
    "\n",
    "for k, v in model_state.items():\n",
    "    pre_model_state[k] = model_state[k].to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_header = [channel.split('-')[0] for i, channel in enumerate(config[\"signal_header\"])]\n",
    "fps = config.get('resample', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@plt.style.context(['ieee', 'science', 'default'])\n",
    "def draw_eeg_graph(x, pred, mask, art_out, rec_loss, num=None):\n",
    "    plt.rcParams.update({'font.family': 'Ubuntu'})\n",
    "    N, C, L = x.shape\n",
    "    _, l = mask.shape\n",
    "    patch_size = L // l\n",
    "\n",
    "    art_out = art_out.reshape(N, -1)\n",
    "    rec_loss = rec_loss.reshape(N, -1)\n",
    "\n",
    "    for n in range(N):\n",
    "        if num is not None and num <= n:\n",
    "            break\n",
    "        \n",
    "        fig = plt.figure(num=1, clear=True, figsize=(25.0, 17.0))\n",
    "        fig.subplots_adjust(hspace=0)\n",
    "        \n",
    "        for c in range(C):\n",
    "            ax = fig.add_subplot(C, 1, c + 1)\n",
    "            ax.plot(x[n, c].cpu().numpy(), lw=1, c='tab:red', label='origin')\n",
    "            ax.plot(pred[n, c].cpu().numpy(), lw=1, c='tab:blue', label='pred')\n",
    "\n",
    "            art_mid = art_out[n].median()\n",
    "            rec_mid = art_out[n].median()\n",
    "            for r in range(l):\n",
    "                if r > 0:\n",
    "                    ax.axvline(r*patch_size, color='tab:purple', alpha=0.4)\n",
    "                if mask[n, r]:\n",
    "                    ax.axvspan(r*patch_size, (r + 1)*patch_size, facecolor='tab:purple', alpha=0.2)\n",
    "\n",
    "                if c == 0:\n",
    "                    if art_mid <= art_out[n, r]:\n",
    "                        ax.annotate(f\"{art_out[n, r]:3.2f}\", \n",
    "                                    xy=((r + 0.5)*patch_size, 1), ha='center', va='bottom', color='tab:purple')\n",
    "                    else:\n",
    "                        ax.annotate(f\"{art_out[n, r]:3.2f}\", \n",
    "                                    xy=((r + 0.5)*patch_size, 1), ha='center', va='bottom')\n",
    "                    if rec_mid <= rec_loss[n, r]:\n",
    "                        ax.annotate(f\"{rec_loss[n, r]:3.2f}\", \n",
    "                                    xy=((r + 0.5)*patch_size, -1), ha='center', va='bottom', color='tab:purple')\n",
    "                    else:\n",
    "                        ax.annotate(f\"{rec_loss[n, r]:3.2f}\", \n",
    "                                    xy=((r + 0.5)*patch_size, -1), ha='center', va='bottom')\n",
    "\n",
    "            ax.set_xlim(0, L)\n",
    "            ax.set_ylabel(signal_header[c])\n",
    "            ax.set_xticks(np.arange(round(config[\"seq_length\"] / fps) + 1) * fps)\n",
    "            ax.set_xticklabels([])\n",
    "            # ax.tick_params(axis='x', width=0.1, length=0.1)\n",
    "            ax.set_yticks([0])\n",
    "            ax.set_yticklabels([])\n",
    "        \n",
    "        ax.set_xticks(np.arange(round(config[\"seq_length\"] / fps) + 1) * fps)\n",
    "        ax.set_xticklabels(np.arange(round(config[\"seq_length\"] / fps) + 1))\n",
    "        \n",
    "        ax.set_xlabel('Time (s)')\n",
    "        # fig.savefig(os.path.join(output_folder, 'signal_example.pdf'), transparent=True)\n",
    "        plt.show()\n",
    "        fig.clear()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for target_dataset in tqdm([\"val\"], desc=\"Dataset\", leave=False):\n",
    "        if target_dataset == 'train':\n",
    "            loader = train_loader\n",
    "        elif target_dataset == 'val':\n",
    "            loader = val_loader\n",
    "        elif target_dataset == 'test':\n",
    "            loader = test_loader\n",
    "        else:\n",
    "            raise ValueError('')\n",
    "                \n",
    "        for sample_batched in tqdm(loader, total=len(loader), desc='Batch', leave=False):\n",
    "            print(target_dataset)\n",
    "            config[\"preprocess_test\"](sample_batched)\n",
    "            x = sample_batched[\"signal\"]\n",
    "            age = sample_batched[\"age\"]\n",
    "\n",
    "            pred, mask = model.mask_and_reconstruct(x, age, config[\"mask_ratio\"])\n",
    "            rec_loss = model.compute_reconstruction_loss2(x, pred)\n",
    "            art_out = model.forward_artifact(x, age)\n",
    "            \n",
    "            pred_eeg = model.unpatchify(pred)\n",
    "            draw_eeg_graph(x, pred_eeg, mask, art_out, rec_loss, 2)\n",
    "\n",
    "            break\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, ckpt\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cyc in finetune_cycler:\n",
    "    # update configuration\n",
    "    for k, v in finetune_config.items():\n",
    "        config[k] = v\n",
    "    for k, v in cyc.items():\n",
    "        config[k] = v\n",
    "    config[\"ddp\"] = False\n",
    "\n",
    "    # check the workstation environment and update some configurations\n",
    "    check_device_env(config)\n",
    "    \n",
    "    # compose dataset\n",
    "    train_loader, val_loader, test_loader, multicrop_test_loader = compose_dataset(config)\n",
    "    pprint.pprint(config)\n",
    "\n",
    "    # generate the model\n",
    "    config[\"_target_\"] = config[\"_target_\"].replace('.ssl', '').replace('_pre', '')\n",
    "    model = generate_model(config).to(device)\n",
    "    \n",
    "    # load the model\n",
    "    model_state = model.state_dict()\n",
    "    for k, v in model_state.items():\n",
    "        if not k.startswith(\"fc\") and not k.endswith(\"pos_embed\"):\n",
    "            model_state[k] = pre_model_state[k]\n",
    "    \n",
    "    model.load_state_dict(model_state)\n",
    "    model.finetune_mode(config[\"tuning_type\"])\n",
    "    config[\"num_params\"] = count_parameters(model)\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name:100}\\t|\\t{param.requires_grad}\")\n",
    "\n",
    "    # collect some garbage\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    # fix the seed for reproducibility (a negative seed value means not fixing)\n",
    "    set_seed(config, rank=None)\n",
    "    \n",
    "    # train\n",
    "    train_script(\n",
    "        config,\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        multicrop_test_loader,\n",
    "        config[\"preprocess_train\"],\n",
    "        config[\"preprocess_test\"],\n",
    "    )\n",
    "\n",
    "print(\"- END -\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
