{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# EEG Data File Format Test\n",
    "\n",
    "Given the metadata generated in `01_Data_Curation1` notebook, this notebook tests some file formats to read and write the EEG dataset and decides the best one.  \n",
    "The following file formats are tested: `NumPy pickle`, `Feather`, `Parquet`, `Jay`, and `HDF5`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages and Configure Notebook Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import glob\n",
    "from openpyxl import load_workbook, Workbook, styles\n",
    "import json\n",
    "\n",
    "import pyedflib\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import pprint\n",
    "import warnings\n",
    "import ctypes\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.feather as feather\n",
    "import datatable as dt\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_dataset import *\n",
    "from datasets.caueeg_data_curation import *\n",
    "from datasets.pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.10.1+cu113\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load and Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Data file path\n",
    "original_path = r'local/dataset/01_Original_Data_220307'\n",
    "curated_path = r'local/dataset/02_Curated_Data_Temp'\n",
    "\n",
    "os.makedirs(curated_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 1390\n",
      "\n",
      "Loaded metadata (first three displayed):\n",
      "[\n",
      "    {\n",
      "        \"edfname\": \"00001809_261018\",\n",
      "        \"dx1\": \"mci_rf\",\n",
      "        \"birth\": 400602,\n",
      "        \"anomaly\": false\n",
      "    },\n",
      "    {\n",
      "        \"edfname\": \"00029426_020817\",\n",
      "        \"dx1\": \"smi\",\n",
      "        \"birth\": 601204,\n",
      "        \"anomaly\": false\n",
      "    },\n",
      "    {\n",
      "        \"edfname\": \"00047327_090718\",\n",
      "        \"dx1\": \"vascular mci\",\n",
      "        \"birth\": 241019,\n",
      "        \"anomaly\": false\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "meta_file = os.path.join(original_path, r'new_DB_list.xlsx')\n",
    "ws = load_workbook(meta_file, data_only=True)['metadata']\n",
    "\n",
    "metadata = []\n",
    "\n",
    "num = 2\n",
    "while True:\n",
    "    m = dict()\n",
    "    m['edfname'] = ws.cell(row=num, column=1).value\n",
    "    m['dx1'] = ws.cell(row=num, column=2).value\n",
    "    m['birth'] = ws.cell(row=num, column=3).value\n",
    "    m['anomaly'] = True if ws.cell(row=num, column=4).value is not None else False\n",
    "    num += 1\n",
    "    \n",
    "    # check whether the row is empty (which is EOF condition)\n",
    "    if m['edfname'] is None:\n",
    "        break\n",
    "    elif m['anomaly']:\n",
    "        continue\n",
    "        \n",
    "    # move the pivot row\n",
    "    metadata.append(m)\n",
    "    \n",
    "print('Size:', len(metadata))\n",
    "print()\n",
    "print('Loaded metadata (first three displayed):')\n",
    "print(json.dumps(metadata[:3], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2820,) 4843.0\n",
      "\n",
      "{'edfname': '00001809_261018',\n",
      " 'dx1': 'mci_rf',\n",
      " 'birth': 400602,\n",
      " 'anomaly': False}\n",
      "\n",
      "{'technician': '',\n",
      " 'recording_additional': '',\n",
      " 'patientname': '',\n",
      " 'patient_additional': '',\n",
      " 'patientcode': '',\n",
      " 'equipment': '',\n",
      " 'admincode': '',\n",
      " 'gender': '',\n",
      " 'startdate': datetime.datetime(2018, 10, 26, 15, 46, 26),\n",
      " 'birthdate': '',\n",
      " 'annotations': []}\n",
      "\n",
      "[{'label': 'Fp1-AVG',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'},\n",
      " {'label': 'F3-AVG',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'},\n",
      " {'label': 'C3-AVG',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'},\n",
      " {'label': 'P3-AVG',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'},\n",
      " {'label': 'O1-AVG',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'},\n",
      " {'label': 'Fp2-AVG',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'},\n",
      " {'label': 'F4-AVG',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'},\n",
      " {'label': 'C4-AVG',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'},\n",
      " {'label': 'P4-AVG',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'},\n",
      " {'label': 'O2-AVG',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'},\n",
      " {'label': 'F7-AVG',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'},\n",
      " {'label': 'T3-AVG',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'},\n",
      " {'label': 'T5-AVG',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'},\n",
      " {'label': 'F8-AVG',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'},\n",
      " {'label': 'T4-AVG',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'},\n",
      " {'label': 'T6-AVG',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'},\n",
      " {'label': 'FZ-AVG',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'},\n",
      " {'label': 'CZ-AVG',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'},\n",
      " {'label': 'PZ-AVG',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'},\n",
      " {'label': 'EKG',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'},\n",
      " {'label': 'Photic',\n",
      "  'dimension': 'uV',\n",
      "  'sample_rate': 200.0,\n",
      "  'physical_max': 32767.0,\n",
      "  'physical_min': -32768.0,\n",
      "  'digital_max': 32767,\n",
      "  'digital_min': -32768,\n",
      "  'prefilter': '',\n",
      "  'transducer': 'E'}]\n"
     ]
    }
   ],
   "source": [
    "m = metadata[0]\n",
    "edf_file = os.path.join(original_path, m['edfname'] + '.edf')\n",
    "signals, signal_headers, edf_header  = pyedflib.highlevel.read_edf(edf_file)\n",
    "\n",
    "refer_headers = signal_headers\n",
    "\n",
    "print(np.unique(signals.reshape(-1)).shape, signals.max() - signals.min()) # check the signal is discrete\n",
    "print()\n",
    "pprint.pp(m)\n",
    "print()\n",
    "pprint.pp(edf_header)\n",
    "print()\n",
    "pprint.pp(signal_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Arrange and Save the Data\n",
    "\n",
    "1. Remove EDF files with irregular signal header\n",
    "2. Extract EDF signal and save the data after reformatting\n",
    "3. Save all metadata as JSON and XLSX where JSON is for further use and XLSX for examination of human\n",
    "    - `metadata_debug`: Full inclusion metadata for debugging\n",
    "    - `metadata_public`: Metadata without personal information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e6f2bc30ce426489cd2b003b4591cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The age information is unknown: 00602793_300518\n",
      "- The age information is unknown: 00850537_061014\n",
      "WARNING - calculate_age() generated an unordinary age: 39\n",
      "WARNING - calculate_age() generated an unordinary age: 39\n",
      "Done.\n",
      "\n",
      "Among 1390, 1388 data were saved.\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "text = f'Delete ALL files in {curated_path}?'\n",
    "if ctypes.windll.user32.MessageBoxExW(0, text, 'Question', 4) == 6: # Yes\n",
    "    for f in glob.glob(os.path.join(curated_path, '*/*')):\n",
    "        os.remove(f)\n",
    "    for f in glob.glob(os.path.join(curated_path, '*.*')):\n",
    "        os.remove(f)\n",
    "\n",
    "os.makedirs(os.path.join(curated_path, 'signal'), exist_ok=True)\n",
    "os.makedirs(os.path.join(curated_path, 'event'), exist_ok=True)\n",
    "\n",
    "metadata_debug = []\n",
    "metadata_public = []\n",
    "fh5 = h5py.File(os.path.join(curated_path, 'signal', 'signal.h5'), 'w', \n",
    "                rdcc_nbytes =(1024**2)*15, rdcc_nslots=1e6)\n",
    "\n",
    "for m in tqdm(metadata):\n",
    "    # EDF file check\n",
    "    edf_file = os.path.join(original_path, m['edfname'] + '.edf')\n",
    "    signals, signal_headers, edf_header = pyedflib.highlevel.read_edf(edf_file)\n",
    "        \n",
    "    if refer_headers != signal_headers:\n",
    "        print('- Signal header differs from the majority:', m['edfname'])\n",
    "        continue\n",
    "        \n",
    "    # calculate age\n",
    "    age = calculate_age(birth_to_datetime(m['birth']), \n",
    "                        edf_header['startdate'])\n",
    "    \n",
    "    if age is None:\n",
    "        print('- The age information is unknown:', m['edfname'])\n",
    "        continue\n",
    "    \n",
    "    # EDF recoding events\n",
    "    event_file = os.path.join(original_path, m['edfname'] + '.xlsx')\n",
    "    wb = load_workbook(event_file, data_only=True)\n",
    "    ws = wb[wb.sheetnames[0]]\n",
    "    \n",
    "    num = 2\n",
    "    event = [] \n",
    "    \n",
    "    while True:\n",
    "        t = ws.cell(row=num, column=3).value\n",
    "        e = ws.cell(row=num, column=4).value\n",
    "        \n",
    "        if t is None:\n",
    "            break\n",
    "        \n",
    "        t = edf_header['startdate'].strftime('%Y%m%d') + t\n",
    "        t = datetime.datetime.strptime(t, '%Y%m%d %H:%M:%S.%f')\n",
    "        \n",
    "        if num == 2: \n",
    "            startTime = t\n",
    "            \n",
    "        t = int(np.floor((t - startTime).total_seconds() * 200))\n",
    "        event.append((t, e))\n",
    "        num += 1\n",
    "    \n",
    "    # metadata_debug\n",
    "    m2 = {}\n",
    "    m2['serial'] = f'{len(metadata_debug) + 1:05}'\n",
    "    m2['edfname'] = m['edfname']\n",
    "    m2['birth'] = birth_to_datetime(m['birth'])\n",
    "    m2['record'] = edf_header['startdate']\n",
    "    m2['age'] = age\n",
    "    m2['dx1'] = m['dx1']\n",
    "    m2['label'] = MultiLabel.load_from_string(m['dx1'])\n",
    "    m2['event'] = event\n",
    "    metadata_debug.append(m2)\n",
    "    \n",
    "    # metadata_public\n",
    "    m3 = {}\n",
    "    m3['serial'] = m2['serial']\n",
    "    m3['age'] = age\n",
    "    m3['label'] = m2['label']\n",
    "    metadata_public.append(m3)\n",
    "    \n",
    "    # EDF signal\n",
    "    signals = trim_trailing_zeros(signals)        # trim garbage zeros\n",
    "    signals = signals.astype('int32')\n",
    "    df = pd.DataFrame(data=signals.T, columns=[s_h['label'] for s_h in signal_headers], dtype=np.int32)\n",
    "    \n",
    "    # numpy pickle\n",
    "    np.save(os.path.join(curated_path, 'signal', m2['serial']), signals)\n",
    "    \n",
    "    # numpy memmap\n",
    "    fp = np.memmap(os.path.join(curated_path, 'signal', m2['serial'] + '.dat'), \n",
    "                   dtype='int32', mode='w+', shape=signals.shape)\n",
    "    fp[:] = signals[:]\n",
    "    fp.flush()\n",
    "    \n",
    "    # feather\n",
    "    feather.write_feather(df, os.path.join(curated_path, 'signal', m2['serial'] + '.feather'))\n",
    "    \n",
    "    # parquet\n",
    "    df.to_parquet(os.path.join(curated_path, 'signal', m2['serial']+ '.parquet'))\n",
    "    \n",
    "    # jay\n",
    "    dt.Frame(df).to_jay(os.path.join(curated_path, 'signal', m2['serial'] + '.jay'))\n",
    "    \n",
    "    # hdf5\n",
    "    # df.to_hdf(os.path.join(curated_path, 'signal', 'signal.h5') , m2['serial'])\n",
    "    fh5.create_dataset(m2['serial'], shape=signals.shape, dtype='int32', chunks=True, data=signals)\n",
    "    # rdcc_nbytes =(1024**2)*15, rdcc_nslots=1e6\n",
    "    \n",
    "    # event\n",
    "    df = pd.DataFrame(data=event, columns=['timing', 'event'])\n",
    "    with open(os.path.join(curated_path, 'event', m2['serial']) + '.json', 'w') as json_file:\n",
    "        json.dump(event, json_file, indent=4, default=serialize_json)    \n",
    "    df.to_feather(os.path.join(curated_path, 'event', m2['serial']) + '.feather')\n",
    "    \n",
    "print('Done.')\n",
    "print()\n",
    "print(f'Among {len(metadata)}, {len(metadata_public)} data were saved.')\n",
    "\n",
    "warnings.filterwarnings(action='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save metadata_public as JSON\n",
    "path = os.path.join(curated_path, 'metadata.json')\n",
    "with open(path, 'w') as json_file:\n",
    "    json.dump(metadata_public, json_file, indent=4, default=serialize_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 78,\n",
      " 'label': ['mci', 'mci_amnestic', 'mci_amnestic_rf'],\n",
      " 'serial': '00001'}\n"
     ]
    }
   ],
   "source": [
    "# load metadata_public\n",
    "meta_path = os.path.join(curated_path, 'metadata.json')\n",
    "with open(meta_path, 'r') as json_file:\n",
    "    metadata = json.load(json_file)\n",
    "\n",
    "pprint.pprint(metadata[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "-----\n",
    "\n",
    "## Data Filtering by Diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Non-Vascular Dementia, Non-Vascular MCI, Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_label_to_name: ['Normal', 'Non-vascular MCI', 'Non-vascular dementia']\n"
     ]
    }
   ],
   "source": [
    "diagnosis_filter = [\n",
    "    # Normal\n",
    "    {'type': 'Normal',\n",
    "     'include': ['normal'], \n",
    "     'exclude': []},\n",
    "    # Non-vascular MCI\n",
    "    {'type': 'Non-vascular MCI',\n",
    "     'include': ['mci'], \n",
    "     'exclude': ['mci_vascular']},\n",
    "    # Non-vascular dementia\n",
    "    {'type': 'Non-vascular dementia',\n",
    "     'include': ['dementia'], \n",
    "     'exclude': ['vd']},\n",
    "]\n",
    "\n",
    "def generate_class_label(label):\n",
    "    for c, f in enumerate(diagnosis_filter):\n",
    "        # inc = set(f['include']) & set(label) == set(f['include'])\n",
    "        inc = len(set(f['include']) & set(label)) > 0        \n",
    "        exc = len(set(f['exclude']) & set(label)) == 0\n",
    "        if  inc and exc:\n",
    "            return (c, f['type'])\n",
    "    return (-1, 'The others')\n",
    "\n",
    "class_label_to_name = [d_f['type'] for d_f in diagnosis_filter]\n",
    "print('class_label_to_name:', class_label_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- There are 458 data belonging to Normal\n",
      "- There are 350 data belonging to Non-vascular MCI\n",
      "- There are 233 data belonging to Non-vascular dementia\n"
     ]
    }
   ],
   "source": [
    "splitted_metadata = [[] for i in diagnosis_filter]\n",
    "\n",
    "for m in metadata:\n",
    "    c, n = generate_class_label(m['label'])\n",
    "    if c >= 0:\n",
    "        m['class_type'] = n\n",
    "        m['class_label'] = c\n",
    "        splitted_metadata[c].append(m)\n",
    "        \n",
    "for i, split in enumerate(splitted_metadata):\n",
    "    if len(split) == 0:\n",
    "        print(f'(Warning) Split group {i} has no data.')\n",
    "    else:\n",
    "        print(f'- There are {len(split):} data belonging to {split[0][\"class_type\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Configure the Train, Validation, and Test Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Split the filtered dataset and shuffle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size\t\t: 832\n",
      "Validation data size\t: 104\n",
      "Test data size\t\t: 105\n",
      "\n",
      " --- Recheck --- \n",
      "\n",
      "Train data label distribution\t: [366 280 186] 832\n",
      "Val data label distribution\t: [46 35 23] 104\n",
      "Test data label distribution\t: [46 35 24] 105\n"
     ]
    }
   ],
   "source": [
    "# Train : Val : Test = 8 : 1 : 1\n",
    "ratio1 = 0.8\n",
    "ratio2 = 0.1\n",
    "\n",
    "metadata_train = []\n",
    "metadata_val = []\n",
    "metadata_test = []\n",
    "\n",
    "for split in splitted_metadata:\n",
    "    random.shuffle(split)\n",
    "    \n",
    "    n1 = round(len(split) * ratio1)\n",
    "    n2 = n1 + round(len(split) * ratio2)\n",
    "\n",
    "    metadata_train.extend(split[:n1])\n",
    "    metadata_val.extend(split[n1:n2])\n",
    "    metadata_test.extend(split[n2:])\n",
    "\n",
    "random.shuffle(metadata_train)\n",
    "random.shuffle(metadata_val)\n",
    "random.shuffle(metadata_test)\n",
    "\n",
    "print('Train data size\\t\\t:', len(metadata_train))\n",
    "print('Validation data size\\t:', len(metadata_val))\n",
    "print('Test data size\\t\\t:', len(metadata_test))\n",
    "\n",
    "print('\\n', '--- Recheck ---', '\\n')\n",
    "train_class_nums = np.zeros((len(class_label_to_name)), dtype=np.int32)\n",
    "for m in metadata_train:\n",
    "    train_class_nums[m['class_label']] += 1\n",
    "\n",
    "val_class_nums = np.zeros((len(class_label_to_name)), dtype=np.int32)\n",
    "for m in metadata_val:\n",
    "    val_class_nums[m['class_label']] += 1\n",
    "\n",
    "test_class_nums = np.zeros((len(class_label_to_name)), dtype=np.int32)\n",
    "for m in metadata_test:\n",
    "    test_class_nums[m['class_label']] += 1\n",
    "\n",
    "print('Train data label distribution\\t:', train_class_nums, train_class_nums.sum())\n",
    "print('Val data label distribution\\t:', val_class_nums, val_class_nums.sum())\n",
    "print('Test data label distribution\\t:', test_class_nums, test_class_nums.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Check Signal Loading Time by Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EegDataset_np(Dataset):\n",
    "    \"\"\"EEG Dataset Class for PyTorch.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): Root path to the EDF data files.\n",
    "        metadata (list of dict): List of dictionary with metadata.\n",
    "        transform (callable, optional): Optional transform to be applied on each data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, metadata, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.metadata = metadata\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        m = self.metadata[idx]\n",
    "        fname = os.path.join(self.root_dir, 'signal', m['serial'] + '.npy')\n",
    "        signal = np.load(fname)\n",
    "        sample = {'signal': signal,\n",
    "                  'age': m['age'],\n",
    "                  'class_label': m['class_label'],\n",
    "                  'event': [],\n",
    "                  'metadata': m}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EegDataset_np_memmap(Dataset):\n",
    "    \"\"\"EEG Dataset Class for PyTorch.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): Root path to the EDF data files.\n",
    "        metadata (list of dict): List of dictionary with metadata.\n",
    "        transform (callable, optional): Optional transform to be applied on each data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, metadata, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.metadata = metadata\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        m = self.metadata[idx]\n",
    "        fname = os.path.join(self.root_dir, 'signal', m['serial'] + '.dat')\n",
    "        signal = np.memmap(fname, dtype='int32', mode='r').reshape(21, -1)\n",
    "        # signal = np.load(fname).astype('float32')\n",
    "        sample = {'signal': signal,\n",
    "                  'age': m['age'],\n",
    "                  'class_label': m['class_label'],\n",
    "                  'event': [],\n",
    "                  'metadata': m}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EegDataset_feather(Dataset):\n",
    "    \"\"\"EEG Dataset Class for PyTorch.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): Root path to the EDF data files.\n",
    "        metadata (list of dict): List of dictionary with metadata.\n",
    "        transform (callable, optional): Optional transform to be applied on each data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, metadata, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.metadata = metadata\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        m = self.metadata[idx]\n",
    "        fname = os.path.join(self.root_dir, 'signal', m['serial'] + '.feather')\n",
    "        # signal = pd.read_feather(fname).to_numpy().T\n",
    "        # signal = pd.read_feather(fname).values.T\n",
    "        signal = feather.read_feather(fname).values.T\n",
    "        sample = {'signal': signal,\n",
    "                  'age': m['age'],\n",
    "                  'class_label': m['class_label'],\n",
    "                  'event': [],\n",
    "                  'metadata': m}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EegDataset_feather2(Dataset):\n",
    "    \"\"\"EEG Dataset Class for PyTorch.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): Root path to the EDF data files.\n",
    "        metadata (list of dict): List of dictionary with metadata.\n",
    "        transform (callable, optional): Optional transform to be applied on each data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, metadata, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.metadata = metadata\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        m = self.metadata[idx]\n",
    "        fname = os.path.join(self.root_dir, 'signal', m['serial'] + '.feather')\n",
    "        df = feather.read_feather(fname)\n",
    "        signal = df.values.T\n",
    "        sample = {'signal': signal,\n",
    "                  'channel': df.columns.to_list(),\n",
    "                  'age': m['age'],\n",
    "                  'class_label': m['class_label'],\n",
    "                  'event': [],\n",
    "                  'metadata': m}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EegDataset_parquet(Dataset):\n",
    "    \"\"\"EEG Dataset Class for PyTorch.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): Root path to the EDF data files.\n",
    "        metadata (list of dict): List of dictionary with metadata.\n",
    "        transform (callable, optional): Optional transform to be applied on each data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, metadata, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.metadata = metadata\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        m = self.metadata[idx]\n",
    "        fname = os.path.join(self.root_dir, 'signal', m['serial'] + '.parquet')\n",
    "        # signal = pd.read_parquet(fname).to_numpy().T\n",
    "        signal = pd.read_parquet(fname).values.T\n",
    "        sample = {'signal': signal,\n",
    "                  'age': m['age'],\n",
    "                  'class_label': m['class_label'],\n",
    "                  'event': [],\n",
    "                  'metadata': m}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EegDataset_jay(Dataset):\n",
    "    \"\"\"EEG Dataset Class for PyTorch.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): Root path to the EDF data files.\n",
    "        metadata (list of dict): List of dictionary with metadata.\n",
    "        transform (callable, optional): Optional transform to be applied on each data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, metadata, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.metadata = metadata\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        m = self.metadata[idx]\n",
    "        fname = os.path.join(self.root_dir, 'signal', m['serial'] + '.jay')\n",
    "        signal = dt.fread(fname).to_numpy().T\n",
    "        sample = {'signal': signal,\n",
    "                  'age': m['age'],\n",
    "                  'class_label': m['class_label'],\n",
    "                  'event': [],\n",
    "                  'metadata': m}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EegDataset_h5(Dataset):\n",
    "    \"\"\"EEG Dataset Class for PyTorch.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): Root path to the EDF data files.\n",
    "        metadata (list of dict): List of dictionary with metadata.\n",
    "        transform (callable, optional): Optional transform to be applied on each data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, metadata, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.f_handle = h5py.File(os.path.join(self.root_dir, 'signal', 'signal.h5'), 'r')\n",
    "        self.metadata = metadata\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        m = self.metadata[idx]\n",
    "        #fname = os.path.join(self.root_dir, 'signal', 'signal.h5')\n",
    "        # signal = pd.read_hdf(fname, m['serial']).to_numpy().T\n",
    "        signal = self.f_handle[m['serial']][:]\n",
    "        sample = {'signal': signal,\n",
    "                  'age': m['age'],\n",
    "                  'class_label': m['class_label'],\n",
    "                  'event': [],\n",
    "                  'metadata': m}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current PyTorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "print('Current PyTorch device:', device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    num_workers = 0 # A number other than 0 causes an error\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "    \n",
    "composed = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*20, multiple=2), # 20 seconds\n",
    "    EegDropPhoticChannel(),\n",
    "    EegToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test NumPy Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 47.6 s\n",
      "Wall time: 3.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_dataset = EegDataset_np(curated_path, metadata_train, composed)\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=32, # Random crop will inflate the minibatch size\n",
    "                          shuffle=False, \n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers, \n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    sample_batched['signal'].to(device)\n",
    "    sample_batched['age'].to(device)\n",
    "    sample_batched['class_label'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ -6.,  -2.,   3.,  ...,   0.,  -2.,  -5.],\n",
      "        [ -6.,  -4.,  -1.,  ...,   3.,   2.,   0.],\n",
      "        [ -6.,  -2.,   0.,  ...,  -2.,  -3.,  -5.],\n",
      "        ...,\n",
      "        [  7.,  10.,  11.,  ...,  -6.,  -8.,  -7.],\n",
      "        [ -6.,  -7.,  -8.,  ...,   4.,   2.,   4.],\n",
      "        [-96., -15.,  35.,  ...,  38., -31.,  21.]]),\n",
      " tensor([[ -4.,  -3.,  -1.,  ...,   1.,   2.,   3.],\n",
      "        [  1.,   2.,   3.,  ...,  -5.,  -5.,  -5.],\n",
      "        [ -6.,  -5.,  -3.,  ...,  -2.,   0.,   2.],\n",
      "        ...,\n",
      "        [ -8.,  -5.,  -4.,  ...,  -8.,  -7.,  -6.],\n",
      "        [  4.,   5.,   5.,  ...,  -5.,  -3.,  -2.],\n",
      "        [-23., -10.,  82.,  ...,  30.,  12.,  78.]])]\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(train_dataset[0]['signal'])\n",
    "pprint.pprint(train_dataset[0]['signal'][0].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test NumPy Memmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10.5 s\n",
      "Wall time: 876 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_dataset = EegDataset_np_memmap(curated_path, metadata_train, composed)\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=32, # Random crop will inflate the minibatch size\n",
    "                          shuffle=False, \n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers, \n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    sample_batched['signal'].to(device)\n",
    "    sample_batched['age'].to(device)\n",
    "    sample_batched['class_label'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-49., -50., -51.,  ...,  29.,  30.,  31.],\n",
      "        [-21., -24., -25.,  ...,  -5.,  -5.,  -4.],\n",
      "        [ -2.,  -5.,  -7.,  ..., -12., -10., -10.],\n",
      "        ...,\n",
      "        [ -6.,  -7.,  -8.,  ..., -32., -32., -30.],\n",
      "        [-10.,  -8.,  -9.,  ...,   3.,   4.,   6.],\n",
      "        [ 42.,  -2.,  29.,  ..., -92., -21.,  24.]]),\n",
      " tensor([[ -2.,  -1.,  -3.,  ..., -15., -13., -13.],\n",
      "        [-14., -13., -14.,  ..., -16., -12., -13.],\n",
      "        [  5.,   5.,   6.,  ...,   2.,   3.,   4.],\n",
      "        ...,\n",
      "        [ -9.,  -8.,  -7.,  ...,  -2.,   0.,   2.],\n",
      "        [  7.,   8.,   8.,  ...,   0.,   1.,   3.],\n",
      "        [-10., -15., -45.,  ...,  86.,  14.,  45.]])]\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(train_dataset[0]['signal'])\n",
    "pprint.pprint(train_dataset[0]['signal'][0].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test Feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 55.2 s\n",
      "Wall time: 3.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_dataset = EegDataset_feather(curated_path, metadata_train, composed)\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=32, # Random crop will inflate the minibatch size\n",
    "                          shuffle=False, \n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers, \n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    sample_batched['signal'].to(device)\n",
    "    sample_batched['age'].to(device)\n",
    "    sample_batched['class_label'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ -7.,  -4.,  -3.,  ...,   4.,   5.,   5.],\n",
      "        [ 13.,  12.,   9.,  ..., -11., -11., -13.],\n",
      "        [  2.,  -2.,  -4.,  ...,   4.,   5.,   6.],\n",
      "        ...,\n",
      "        [  8.,   6.,   3.,  ...,  15.,  14.,  12.],\n",
      "        [  7.,   5.,   3.,  ...,   2.,   1.,   0.],\n",
      "        [-72., -43.,  12.,  ...,  23., -27., -93.]]),\n",
      " tensor([[  5.,   9.,  10.,  ..., -34., -34., -36.],\n",
      "        [-11., -13., -16.,  ..., -11., -10.,  -9.],\n",
      "        [  4.,   2.,   0.,  ...,  -2.,   0.,   4.],\n",
      "        ...,\n",
      "        [  4.,   3.,   1.,  ...,   0.,   0.,   2.],\n",
      "        [  2.,   1.,   1.,  ...,  -8.,  -7.,  -5.],\n",
      "        [-50., -79., -34.,  ...,  48.,  92., -12.]])]\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(train_dataset[0]['signal'])\n",
    "pprint.pprint(train_dataset[0]['signal'][0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 57.3 s\n",
      "Wall time: 3.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_dataset = EegDataset_feather2(curated_path, metadata_train, composed)\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=32, # Random crop will inflate the minibatch size\n",
    "                          shuffle=False, \n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers, \n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    sample_batched['signal'].to(device)\n",
    "    sample_batched['age'].to(device)\n",
    "    sample_batched['class_label'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  1.,  -1.,   0.,  ..., -10.,  -6.,  -5.],\n",
      "        [  5.,   3.,   7.,  ...,  -4.,  -1.,  -2.],\n",
      "        [-11.,  -9., -10.,  ...,   5.,   7.,   8.],\n",
      "        ...,\n",
      "        [  8.,  10.,  10.,  ..., -11., -10.,  -9.],\n",
      "        [  0.,   1.,   0.,  ...,   6.,   4.,   5.],\n",
      "        [-25., -43.,  -3.,  ..., -20.,   6.,  26.]]),\n",
      " tensor([[ -7.,  -6.,  -2.,  ..., -79., -78., -77.],\n",
      "        [  2.,   3.,   3.,  ..., -29., -28., -28.],\n",
      "        [ -1.,  -2.,  -2.,  ...,   1.,   3.,   3.],\n",
      "        ...,\n",
      "        [ -4.,  -5.,  -5.,  ...,   4.,   6.,   8.],\n",
      "        [ -3.,  -4.,  -5.,  ...,   6.,   8.,   8.],\n",
      "        [-64.,  71.,  91.,  ...,  68., -67., -91.]])]\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(train_dataset[0]['signal'])\n",
    "pprint.pprint(train_dataset[0]['signal'][0].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 45s\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_dataset = EegDataset_parquet(curated_path, metadata_train, composed)\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=32, # Random crop will inflate the minibatch size\n",
    "                          shuffle=False, \n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers, \n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    sample_batched['signal'].to(device)\n",
    "    sample_batched['age'].to(device)\n",
    "    sample_batched['class_label'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  6.,   1.,   1.,  ..., -18., -20., -21.],\n",
      "        [  8.,   6.,   5.,  ..., -19., -21., -22.],\n",
      "        [ -6.,  -6.,  -6.,  ...,   6.,   4.,   4.],\n",
      "        ...,\n",
      "        [  0.,   0.,   1.,  ...,   5.,   5.,   6.],\n",
      "        [ -3.,  -1.,   1.,  ...,  -2.,   0.,   0.],\n",
      "        [ -3.,  52.,  -9.,  ...,  41., -84., -54.]]),\n",
      " tensor([[  5.,   8.,  13.,  ...,  -1.,   1.,  -2.],\n",
      "        [ 12.,  14.,  16.,  ..., -13., -12., -13.],\n",
      "        [ -2.,   1.,  -2.,  ...,   4.,   4.,   5.],\n",
      "        ...,\n",
      "        [ -3.,  -3.,  -2.,  ...,  18.,  19.,  21.],\n",
      "        [  1.,  -1.,  -1.,  ...,  -1.,   0.,   1.],\n",
      "        [-73., -25.,  46.,  ...,   8., -33., -90.]])]\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(train_dataset[0]['signal'])\n",
    "pprint.pprint(train_dataset[0]['signal'][0].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test Jay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 57s\n",
      "Wall time: 7.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_dataset = EegDataset_jay(curated_path, metadata_train, composed)\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=32, # Random crop will inflate the minibatch size\n",
    "                          shuffle=False, \n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers, \n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    sample_batched['signal'].to(device)\n",
    "    sample_batched['age'].to(device)\n",
    "    sample_batched['class_label'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ -10.,  -12.,  -11.,  ...,  -12.,  -13.,  -14.],\n",
      "        [  -7.,   -7.,   -6.,  ...,   -4.,   -5.,   -6.],\n",
      "        [  -6.,   -7.,   -8.,  ...,   -6.,   -6.,   -5.],\n",
      "        ...,\n",
      "        [   9.,    9.,   10.,  ...,   11.,   11.,    9.],\n",
      "        [   6.,    6.,    6.,  ...,    5.,    4.,    5.],\n",
      "        [  46.,  -81.,  -56.,  ...,   53.,  -18., -106.]]),\n",
      " tensor([[ 35.,  25.,  17.,  ..., -41., -40., -40.],\n",
      "        [  8.,   7.,   6.,  ...,   1.,   0.,  -2.],\n",
      "        [-14., -12., -11.,  ...,   1.,   3.,   1.],\n",
      "        ...,\n",
      "        [  4.,   5.,   5.,  ...,   0.,   1.,  -1.],\n",
      "        [ -7.,  -4.,  -2.,  ...,   3.,   4.,   5.],\n",
      "        [-16., -85., -53.,  ...,   2.,  51., -36.]])]\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(train_dataset[0]['signal'])\n",
    "pprint.pprint(train_dataset[0]['signal'][0].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 45s\n",
      "Wall time: 8.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_dataset = EegDataset_h5(curated_path, metadata_train, composed)\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=32, # Random crop will inflate the minibatch size\n",
    "                          shuffle=False, \n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers, \n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    sample_batched['signal'].to(device)\n",
    "    sample_batched['age'].to(device)\n",
    "    sample_batched['class_label'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-11., -13., -12.,  ...,  -9., -13., -14.],\n",
      "        [  1.,   1.,   0.,  ...,  -7.,  -8.,  -7.],\n",
      "        [  3.,   3.,   2.,  ...,   3.,   4.,   6.],\n",
      "        ...,\n",
      "        [  5.,   3.,   2.,  ...,  -1.,   1.,   2.],\n",
      "        [  3.,   3.,   3.,  ...,   1.,   3.,   4.],\n",
      "        [  9.,  83.,  54.,  ..., -32., -58.,  20.]]),\n",
      " tensor([[-27., -27., -27.,  ..., -39., -39., -40.],\n",
      "        [ -8.,  -9.,  -9.,  ..., -16., -14., -14.],\n",
      "        [  0.,  -2.,  -2.,  ...,   2.,   2.,   4.],\n",
      "        ...,\n",
      "        [ -8.,  -8.,  -9.,  ...,  -6.,  -6.,  -6.],\n",
      "        [  2.,   3.,   4.,  ...,   8.,   9.,  10.],\n",
      "        [ -4.,  51.,  -6.,  ...,  69.,  68.,  -4.]])]\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(train_dataset[0]['signal'])\n",
    "pprint.pprint(train_dataset[0]['signal'][0].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Check Event Loading Time by Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EegDataset_event_json(Dataset):\n",
    "    \"\"\"EEG Dataset Class for PyTorch.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): Root path to the EDF data files.\n",
    "        metadata (list of dict): List of dictionary with metadata.\n",
    "        transform (callable, optional): Optional transform to be applied on each data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, metadata, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.metadata = metadata\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        m = self.metadata[idx]\n",
    "        fname = os.path.join(self.root_dir, 'event', m['serial'] + '.json')\n",
    "        with open(fname, 'r') as json_file:\n",
    "            event = json.load(json_file)        \n",
    "        sample = {'signal': np.zeros((20, 100)),\n",
    "                  'event': event,\n",
    "                  'age': m['age'],\n",
    "                  'class_label': m['class_label'],\n",
    "                  'metadata': m}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class EegDataset_event_feather(Dataset):\n",
    "    \"\"\"EEG Dataset Class for PyTorch.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): Root path to the EDF data files.\n",
    "        metadata (list of dict): List of dictionary with metadata.\n",
    "        transform (callable, optional): Optional transform to be applied on each data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, metadata, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.metadata = metadata\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        m = self.metadata[idx]\n",
    "        fname = os.path.join(self.root_dir, 'event', m['serial'] + '.feather')\n",
    "        event = pd.read_feather(fname)\n",
    "        sample = {'signal': np.zeros((20, 100)),\n",
    "                  'event': event,\n",
    "                  'age': m['age'],\n",
    "                  'class_label': m['class_label'],\n",
    "                  'metadata': m}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "composed = transforms.Compose([\n",
    "    EegToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 16.2 s\n",
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_dataset = EegDataset_event_json(curated_path, metadata_train, composed)\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=32, # Random crop will inflate the minibatch size\n",
    "                          shuffle=False, \n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers, \n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "for k in range(10):\n",
    "    for i_batch, sample_batched in enumerate(train_loader):\n",
    "        sample_batched['signal'].to(device)\n",
    "        sample_batched['age'].to(device)\n",
    "        sample_batched['class_label'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "[[0, 'Start Recording'],\n",
      " [0, 'New Montage - Montage 002'],\n",
      " [1236, 'Eyes Open'],\n",
      " [2202, 'Eyes Closed'],\n",
      " [5268, 'Eyes Open'],\n",
      " [6654, 'Eyes Closed'],\n",
      " [13332, 'Eyes Open'],\n",
      " [14466, 'Eyes Closed'],\n",
      " [19800, 'Eyes Open'],\n",
      " [20808, 'Eyes Closed'],\n",
      " [34554, 'Eyes Open'],\n",
      " [35310, 'Eyes Closed'],\n",
      " [40686, 'Eyes Open'],\n",
      " [41736, 'Eyes Closed'],\n",
      " [48246, 'Eyes Open'],\n",
      " [49338, 'Eyes Closed'],\n",
      " [58367, 'Eyes Open'],\n",
      " [59208, 'Eyes Closed'],\n",
      " [64667, 'Eyes Open'],\n",
      " [65592, 'Eyes Closed'],\n",
      " [70674, 'Eyes Open'],\n",
      " [71514, 'Eyes Closed'],\n",
      " [81468, 'Eyes Open'],\n",
      " [82350, 'Eyes Closed'],\n",
      " [88692, 'Eyes Open'],\n",
      " [89616, 'Eyes Closed'],\n",
      " [96210, 'Eyes Open'],\n",
      " [97176, 'Eyes Closed'],\n",
      " [103602, 'Eyes Open'],\n",
      " [104609, 'Eyes Closed'],\n",
      " [110994, 'Eyes Open'],\n",
      " [111918, 'Eyes Closed'],\n",
      " [116664, 'Eyes Open'],\n",
      " [117294, 'Eyes Closed'],\n",
      " [121200, 'Paused']]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(train_dataset[0]['signal'])\n",
    "pprint.pprint(train_dataset[0]['event'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test Feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 26s\n",
      "Wall time: 7.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_dataset = EegDataset_event_feather(curated_path, metadata_train, composed)\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=32, # Random crop will inflate the minibatch size\n",
    "                          shuffle=False, \n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers, \n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "for k in range(10):\n",
    "    for i_batch, sample_batched in enumerate(train_loader):\n",
    "        sample_batched['signal'].to(device)\n",
    "        sample_batched['age'].to(device)\n",
    "        sample_batched['class_label'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "    timing                      event\n",
      "0        0            Start Recording\n",
      "1        0  New Montage - Montage 002\n",
      "2     1236                  Eyes Open\n",
      "3     2202                Eyes Closed\n",
      "4     5268                  Eyes Open\n",
      "5     6654                Eyes Closed\n",
      "6    13332                  Eyes Open\n",
      "7    14466                Eyes Closed\n",
      "8    19800                  Eyes Open\n",
      "9    20808                Eyes Closed\n",
      "10   34554                  Eyes Open\n",
      "11   35310                Eyes Closed\n",
      "12   40686                  Eyes Open\n",
      "13   41736                Eyes Closed\n",
      "14   48246                  Eyes Open\n",
      "15   49338                Eyes Closed\n",
      "16   58367                  Eyes Open\n",
      "17   59208                Eyes Closed\n",
      "18   64667                  Eyes Open\n",
      "19   65592                Eyes Closed\n",
      "20   70674                  Eyes Open\n",
      "21   71514                Eyes Closed\n",
      "22   81468                  Eyes Open\n",
      "23   82350                Eyes Closed\n",
      "24   88692                  Eyes Open\n",
      "25   89616                Eyes Closed\n",
      "26   96210                  Eyes Open\n",
      "27   97176                Eyes Closed\n",
      "28  103602                  Eyes Open\n",
      "29  104609                Eyes Closed\n",
      "30  110994                  Eyes Open\n",
      "31  111918                Eyes Closed\n",
      "32  116664                  Eyes Open\n",
      "33  117294                Eyes Closed\n",
      "34  121200                     Paused\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(train_dataset[0]['signal'])\n",
    "pprint.pprint(train_dataset[0]['event'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "279px",
    "width": "378px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "356px",
    "left": "1090px",
    "top": "213px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
