{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train Networks\n",
    "\n",
    "- Train SoftMax or Multi-BCE classifier for the EEG diagnosis classification\n",
    "    - CAUEEG-task1 benchmark: Classification of **Normal** and **Abnormal** symptoms\n",
    "    - CAUEEG-task2 benchmark: Classification of **Normal**, **MCI**, and **Dementia** symptoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minjae\\Desktop\\EEG_Project\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "import pprint\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# custom package\n",
    "from run_train import check_device_env\n",
    "from run_train import prepare_and_run_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Initializing configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EKG': 'O',\n",
      " '_target_': 'models.resnet_1d.ResNet1D',\n",
      " 'activation': 'gelu',\n",
      " 'age_mean': tensor([71.1417], device='cuda:0'),\n",
      " 'age_std': tensor([9.7264], device='cuda:0'),\n",
      " 'awgn': 0.004872735559634612,\n",
      " 'awgn_age': 0.03583361229344302,\n",
      " 'base_channels': 64,\n",
      " 'base_lr': 0.00046936536527944847,\n",
      " 'block': 'basic',\n",
      " 'class_label_to_name': ['Normal', 'MCI', 'Dementia'],\n",
      " 'class_name_to_label': {'Dementia': 2, 'MCI': 1, 'Normal': 0},\n",
      " 'conv_layers': [2, 2, 2, 2],\n",
      " 'criterion': 'multi-bce',\n",
      " 'crop_multiple': 4,\n",
      " 'crop_timing_analysis': False,\n",
      " 'dataset_name': 'CAUEEG dataset',\n",
      " 'dataset_path': 'local/dataset/02_Curated_Data_220419/',\n",
      " 'ddp': False,\n",
      " 'device': device(type='cuda'),\n",
      " 'draw_result': True,\n",
      " 'dropout': 0.3,\n",
      " 'fc_stages': 3,\n",
      " 'file_format': 'memmap',\n",
      " 'in_channels': 21,\n",
      " 'input_norm': 'dataset',\n",
      " 'iterations': 390625,\n",
      " 'latency': 2000,\n",
      " 'load_event': False,\n",
      " 'lr_scheduler_type': 'cosine_decay_with_warmup_half',\n",
      " 'mgn': 0.09575622309480344,\n",
      " 'minibatch': 256,\n",
      " 'mixup': 0.2,\n",
      " 'model': '1D-ResNet-18',\n",
      " 'multi_batch_size': 32,\n",
      " 'num_history': 500,\n",
      " 'num_params': 11394051,\n",
      " 'out_dims': 3,\n",
      " 'output_length': 8,\n",
      " 'photic': 'O',\n",
      " 'preprocess_test': Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([71.1417], device='cuda:0'),std=tensor([9.7264], device='cuda:0'),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([ 0.1507,  0.0541, -0.0413,  0.0160, -0.0541,  0.1908, -0.0025, -0.0211,\n",
      "           0.0069,  0.0494,  0.0051, -0.0056, -0.0354,  0.0505, -0.0412,  0.1035,\n",
      "           0.0074, -0.0325, -0.0373, -0.0025, -0.0071], device='cuda:0'),std=tensor([45.0080, 20.2708, 11.7008, 11.5876, 15.2168, 47.7619, 19.8388, 10.5537,\n",
      "          11.6707, 15.9614, 20.6152, 14.4362, 13.6445, 21.9794, 16.9491, 14.6477,\n",
      "          19.7299, 11.4548, 11.6362, 94.2795, 68.4567], device='cuda:0'),eps=1e-08)\n",
      "),\n",
      " 'preprocess_train': Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([71.1417], device='cuda:0'),std=tensor([9.7264], device='cuda:0'),eps=1e-08)\n",
      "  (2): EegAddGaussianNoiseAge(mean=0.0,std=0.03583361229344302)\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([ 0.1507,  0.0541, -0.0413,  0.0160, -0.0541,  0.1908, -0.0025, -0.0211,\n",
      "           0.0069,  0.0494,  0.0051, -0.0056, -0.0354,  0.0505, -0.0412,  0.1035,\n",
      "           0.0074, -0.0325, -0.0373, -0.0025, -0.0071], device='cuda:0'),std=tensor([45.0080, 20.2708, 11.7008, 11.5876, 15.2168, 47.7619, 19.8388, 10.5537,\n",
      "          11.6707, 15.9614, 20.6152, 14.4362, 13.6445, 21.9794, 16.9491, 14.6477,\n",
      "          19.7299, 11.4548, 11.6362, 94.2795, 68.4567], device='cuda:0'),eps=1e-08)\n",
      "  (4): EegMultiplicativeGaussianNoise(mean=0.0,std=0.09575622309480344)\n",
      "  (5): EegAdditiveGaussianNoise(mean=0.0,std=0.004872735559634612)\n",
      "),\n",
      " 'run_mode': 'train',\n",
      " 'save_model': True,\n",
      " 'search_lr': True,\n",
      " 'search_multiplier': 1.0,\n",
      " 'seed': 0,\n",
      " 'seq_length': 2000,\n",
      " 'signal_header': ['Fp1-AVG',\n",
      "                   'F3-AVG',\n",
      "                   'C3-AVG',\n",
      "                   'P3-AVG',\n",
      "                   'O1-AVG',\n",
      "                   'Fp2-AVG',\n",
      "                   'F4-AVG',\n",
      "                   'C4-AVG',\n",
      "                   'P4-AVG',\n",
      "                   'O2-AVG',\n",
      "                   'F7-AVG',\n",
      "                   'T3-AVG',\n",
      "                   'T5-AVG',\n",
      "                   'F8-AVG',\n",
      "                   'T4-AVG',\n",
      "                   'T6-AVG',\n",
      "                   'FZ-AVG',\n",
      "                   'CZ-AVG',\n",
      "                   'PZ-AVG',\n",
      "                   'EKG',\n",
      "                   'Photic'],\n",
      " 'signal_length_limit': 10000000,\n",
      " 'signal_mean': tensor([[[ 0.1507],\n",
      "         [ 0.0541],\n",
      "         [-0.0413],\n",
      "         [ 0.0160],\n",
      "         [-0.0541],\n",
      "         [ 0.1908],\n",
      "         [-0.0025],\n",
      "         [-0.0211],\n",
      "         [ 0.0069],\n",
      "         [ 0.0494],\n",
      "         [ 0.0051],\n",
      "         [-0.0056],\n",
      "         [-0.0354],\n",
      "         [ 0.0505],\n",
      "         [-0.0412],\n",
      "         [ 0.1035],\n",
      "         [ 0.0074],\n",
      "         [-0.0325],\n",
      "         [-0.0373],\n",
      "         [-0.0025],\n",
      "         [-0.0071]]], device='cuda:0'),\n",
      " 'signal_std': tensor([[[45.0080],\n",
      "         [20.2708],\n",
      "         [11.7008],\n",
      "         [11.5876],\n",
      "         [15.2168],\n",
      "         [47.7619],\n",
      "         [19.8388],\n",
      "         [10.5537],\n",
      "         [11.6707],\n",
      "         [15.9614],\n",
      "         [20.6152],\n",
      "         [14.4362],\n",
      "         [13.6445],\n",
      "         [21.9794],\n",
      "         [16.9491],\n",
      "         [14.6477],\n",
      "         [19.7299],\n",
      "         [11.4548],\n",
      "         [11.6362],\n",
      "         [94.2795],\n",
      "         [68.4567]]], device='cuda:0'),\n",
      " 'task': 'dementia',\n",
      " 'task_description': 'Classification of [Normal], [MCI], and [Dementia] '\n",
      "                     'symptoms.',\n",
      " 'task_name': 'CAUEEG-Dementia benchmark',\n",
      " 'test_crop_multiple': 8,\n",
      " 'total_samples': 100000000.0,\n",
      " 'transform': Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=4, latency=2000, return_timing=False)\n",
      "    EegToTensor()\n",
      "),\n",
      " 'transform_multicrop': Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=8, latency=2000, return_timing=False)\n",
      "    EegToTensor()\n",
      "),\n",
      " 'use_age': 'conv',\n",
      " 'use_wandb': True,\n",
      " 'warmup_min': 3000,\n",
      " 'warmup_ratio': 0.05,\n",
      " 'warmup_steps': 19531,\n",
      " 'watch_model': False,\n",
      " 'weight_decay': 0.04394746639552375}\n"
     ]
    }
   ],
   "source": [
    "config = torch.load(r'E:\\CAUEEG\\checkpoint\\l8524nml\\checkpoint.pt')['config']\n",
    "config.pop('cwd', 0)\n",
    "\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************    Configurations for Train    ******************************\n",
      "\n",
      "{'EKG': 'O',\n",
      " '_target_': 'models.resnet_1d.ResNet1D',\n",
      " 'activation': 'gelu',\n",
      " 'age_mean': tensor([71.1417], device='cuda:0'),\n",
      " 'age_std': tensor([9.7264], device='cuda:0'),\n",
      " 'awgn': 0.004872735559634612,\n",
      " 'awgn_age': 0.03583361229344302,\n",
      " 'base_channels': 64,\n",
      " 'base_lr': 0.00046936536527944847,\n",
      " 'block': 'basic',\n",
      " 'class_label_to_name': ['Normal', 'MCI', 'Dementia'],\n",
      " 'class_name_to_label': {'Dementia': 2, 'MCI': 1, 'Normal': 0},\n",
      " 'conv_layers': [2, 2, 2, 2],\n",
      " 'criterion': 'multi-bce',\n",
      " 'crop_multiple': 4,\n",
      " 'crop_timing_analysis': False,\n",
      " 'dataset_name': 'CAUEEG dataset',\n",
      " 'dataset_path': 'local/dataset/02_Curated_Data_220419/',\n",
      " 'ddp': False,\n",
      " 'device': device(type='cuda'),\n",
      " 'draw_result': True,\n",
      " 'dropout': 0.3,\n",
      " 'fc_stages': 3,\n",
      " 'file_format': 'memmap',\n",
      " 'in_channels': 21,\n",
      " 'input_norm': 'dataset',\n",
      " 'iterations': 390625,\n",
      " 'latency': 2000,\n",
      " 'load_event': False,\n",
      " 'lr_scheduler_type': 'cosine_decay_with_warmup_half',\n",
      " 'mgn': 0.09575622309480344,\n",
      " 'minibatch': 256,\n",
      " 'mixup': 0.2,\n",
      " 'model': '1D-ResNet-18',\n",
      " 'multi_batch_size': 32,\n",
      " 'num_history': 500,\n",
      " 'num_params': 11394051,\n",
      " 'out_dims': 3,\n",
      " 'output_length': 8,\n",
      " 'photic': 'O',\n",
      " 'preprocess_test': Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([71.1417], device='cuda:0'),std=tensor([9.7264], device='cuda:0'),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([ 0.1507,  0.0541, -0.0413,  0.0160, -0.0541,  0.1908, -0.0025, -0.0211,\n",
      "           0.0069,  0.0494,  0.0051, -0.0056, -0.0354,  0.0505, -0.0412,  0.1035,\n",
      "           0.0074, -0.0325, -0.0373, -0.0025, -0.0071], device='cuda:0'),std=tensor([45.0080, 20.2708, 11.7008, 11.5876, 15.2168, 47.7619, 19.8388, 10.5537,\n",
      "          11.6707, 15.9614, 20.6152, 14.4362, 13.6445, 21.9794, 16.9491, 14.6477,\n",
      "          19.7299, 11.4548, 11.6362, 94.2795, 68.4567], device='cuda:0'),eps=1e-08)\n",
      "),\n",
      " 'preprocess_train': Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([71.1417], device='cuda:0'),std=tensor([9.7264], device='cuda:0'),eps=1e-08)\n",
      "  (2): EegAddGaussianNoiseAge(mean=0.0,std=0.03583361229344302)\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([ 0.1507,  0.0541, -0.0413,  0.0160, -0.0541,  0.1908, -0.0025, -0.0211,\n",
      "           0.0069,  0.0494,  0.0051, -0.0056, -0.0354,  0.0505, -0.0412,  0.1035,\n",
      "           0.0074, -0.0325, -0.0373, -0.0025, -0.0071], device='cuda:0'),std=tensor([45.0080, 20.2708, 11.7008, 11.5876, 15.2168, 47.7619, 19.8388, 10.5537,\n",
      "          11.6707, 15.9614, 20.6152, 14.4362, 13.6445, 21.9794, 16.9491, 14.6477,\n",
      "          19.7299, 11.4548, 11.6362, 94.2795, 68.4567], device='cuda:0'),eps=1e-08)\n",
      "  (4): EegMultiplicativeGaussianNoise(mean=0.0,std=0.09575622309480344)\n",
      "  (5): EegAdditiveGaussianNoise(mean=0.0,std=0.004872735559634612)\n",
      "),\n",
      " 'run_mode': 'train',\n",
      " 'save_model': True,\n",
      " 'search_lr': True,\n",
      " 'search_multiplier': 1.0,\n",
      " 'seed': 0,\n",
      " 'seq_length': 2000,\n",
      " 'signal_header': ['Fp1-AVG',\n",
      "                   'F3-AVG',\n",
      "                   'C3-AVG',\n",
      "                   'P3-AVG',\n",
      "                   'O1-AVG',\n",
      "                   'Fp2-AVG',\n",
      "                   'F4-AVG',\n",
      "                   'C4-AVG',\n",
      "                   'P4-AVG',\n",
      "                   'O2-AVG',\n",
      "                   'F7-AVG',\n",
      "                   'T3-AVG',\n",
      "                   'T5-AVG',\n",
      "                   'F8-AVG',\n",
      "                   'T4-AVG',\n",
      "                   'T6-AVG',\n",
      "                   'FZ-AVG',\n",
      "                   'CZ-AVG',\n",
      "                   'PZ-AVG',\n",
      "                   'EKG',\n",
      "                   'Photic'],\n",
      " 'signal_length_limit': 10000000,\n",
      " 'signal_mean': tensor([[[ 0.1507],\n",
      "         [ 0.0541],\n",
      "         [-0.0413],\n",
      "         [ 0.0160],\n",
      "         [-0.0541],\n",
      "         [ 0.1908],\n",
      "         [-0.0025],\n",
      "         [-0.0211],\n",
      "         [ 0.0069],\n",
      "         [ 0.0494],\n",
      "         [ 0.0051],\n",
      "         [-0.0056],\n",
      "         [-0.0354],\n",
      "         [ 0.0505],\n",
      "         [-0.0412],\n",
      "         [ 0.1035],\n",
      "         [ 0.0074],\n",
      "         [-0.0325],\n",
      "         [-0.0373],\n",
      "         [-0.0025],\n",
      "         [-0.0071]]], device='cuda:0'),\n",
      " 'signal_std': tensor([[[45.0080],\n",
      "         [20.2708],\n",
      "         [11.7008],\n",
      "         [11.5876],\n",
      "         [15.2168],\n",
      "         [47.7619],\n",
      "         [19.8388],\n",
      "         [10.5537],\n",
      "         [11.6707],\n",
      "         [15.9614],\n",
      "         [20.6152],\n",
      "         [14.4362],\n",
      "         [13.6445],\n",
      "         [21.9794],\n",
      "         [16.9491],\n",
      "         [14.6477],\n",
      "         [19.7299],\n",
      "         [11.4548],\n",
      "         [11.6362],\n",
      "         [94.2795],\n",
      "         [68.4567]]], device='cuda:0'),\n",
      " 'task': 'dementia',\n",
      " 'task_description': 'Classification of [Normal], [MCI], and [Dementia] symptoms.',\n",
      " 'task_name': 'CAUEEG-Dementia benchmark',\n",
      " 'test_crop_multiple': 8,\n",
      " 'total_samples': 1024,\n",
      " 'transform': Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=4, latency=2000, return_timing=False)\n",
      "    EegToTensor()\n",
      "),\n",
      " 'transform_multicrop': Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=8, latency=2000, return_timing=False)\n",
      "    EegToTensor()\n",
      "),\n",
      " 'use_age': 'conv',\n",
      " 'use_wandb': True,\n",
      " 'warmup_min': 3000,\n",
      " 'warmup_ratio': 0.05,\n",
      " 'warmup_steps': 19531,\n",
      " 'watch_model': False,\n",
      " 'weight_decay': 0.04394746639552375}\n",
      "\n",
      "********************************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mipis-mjkim\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Minjae\\Desktop\\EEG_Project\\wandb\\run-20220927_200252-2zzb7oar</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ipis-mjkim/noname/runs/2zzb7oar\" target=\"_blank\">vocal-rain-5</a></strong> to <a href=\"https://wandb.ai/ipis-mjkim/noname\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_samples\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mprepare_and_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\EEG_Project\\run_train.py:111\u001b[0m, in \u001b[0;36mprepare_and_run_train\u001b[1;34m(rank, world_size, config)\u001b[0m\n\u001b[0;32m    108\u001b[0m         model\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mload_state_dict(ckpt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# train\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m \u001b[43mtrain_script\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulticrop_test_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m             \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpreprocess_train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpreprocess_test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# cleanup\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_ddp:\n",
      "File \u001b[1;32m~\\Desktop\\EEG_Project\\train\\train_script.py:96\u001b[0m, in \u001b[0;36mtrain_script\u001b[1;34m(config, model, train_loader, val_loader, test_loader, multicrop_test_loader, preprocess_train, preprocess_test)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# search an appropriate starting learning rate if needed\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_lr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_lr\u001b[39m\u001b[38;5;124m'\u001b[39m], lr_search \u001b[38;5;241m=\u001b[39m \u001b[43mlearning_rate_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mpreprocess_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mpreprocess_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mtrials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m main_process:\n\u001b[0;32m    102\u001b[0m         draw_lr_search_record(lr_search, use_wandb\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_wandb\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\Desktop\\EEG_Project\\train\\train_script.py:44\u001b[0m, in \u001b[0;36mlearning_rate_search\u001b[1;34m(config, model, train_loader, val_loader, preprocess_train, preprocess_test, trials, steps)\u001b[0m\n\u001b[0;32m     41\u001b[0m amp_scaler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mGradScaler() \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmixed_precision\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     43\u001b[0m tr_ms \u001b[38;5;241m=\u001b[39m train_multistep \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmixup\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-12\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m train_mixup_multistep\n\u001b[1;32m---> 44\u001b[0m \u001b[43mtr_ms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamp_scaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m train_accuracy \u001b[38;5;241m=\u001b[39m check_accuracy(model, train_loader, preprocess_test, config,\n\u001b[0;32m     47\u001b[0m                                 repeat\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheck_accuracy_repeat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m     48\u001b[0m val_accuracy \u001b[38;5;241m=\u001b[39m check_accuracy(model, val_loader, preprocess_test, config,\n\u001b[0;32m     49\u001b[0m                               repeat\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcheck_accuracy_repeat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n",
      "File \u001b[1;32m~\\Desktop\\EEG_Project\\train\\train_core.py:155\u001b[0m, in \u001b[0;36mtrain_mixup_multistep\u001b[1;34m(model, loader, preprocess, optimizer, scheduler, amp_scaler, config, steps)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# train accuracy\u001b[39;00m\n\u001b[0;32m    154\u001b[0m pred \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 155\u001b[0m correct1 \u001b[38;5;241m=\u001b[39m \u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m(\u001b[49m\u001b[43my1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m correct2 \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39meq(y2)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    157\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m lam \u001b[38;5;241m*\u001b[39m correct1 \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m lam) \u001b[38;5;241m*\u001b[39m correct2\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config['total_samples'] = 1024\n",
    "prepare_and_run_train(rank=None, world_size=None, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
