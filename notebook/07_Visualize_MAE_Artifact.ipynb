{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Visualize EEG Artifacts and Masked Autoencoder's Masking Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\GitHub\\eeg_analysis\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "import pprint\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as mtransforms\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import scienceplots\n",
    "import mpl_interactions.ipyplot as iplt\n",
    "from mpl_interactions import interactive_axvline\n",
    "from mpl_interactions.controller import Controls\n",
    "import mpl_interactions\n",
    "\n",
    "# custom package\n",
    "from run_train import check_device_env\n",
    "from run_train import set_seed\n",
    "from run_train import compose_dataset\n",
    "from run_train import generate_model\n",
    "from train.train_script import train_script\n",
    "from datasets.caueeg_script import EegToTensor, EegDropChannels\n",
    "from models.utils import count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other settings\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # cleaner text\n",
    "\n",
    "plt.style.use('default') \n",
    "# ['Solarize_Light2', '_classic_test_patch', 'bmh', 'classic', 'dark_background', 'fast', \n",
    "#  'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn', 'seaborn-bright', 'seaborn-colorblind', \n",
    "#  'seaborn-dark', 'seaborn-dark-palette', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', \n",
    "#  'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', \n",
    "#  'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'tableau-colorblind10']\n",
    "\n",
    "plt.rcParams['image.interpolation'] = 'bicubic'\n",
    "plt.rcParams[\"font.family\"] = 'Roboto Slab' # 'NanumGothic' # for Hangul in Windows\n",
    "plt.style.use('classic') \n",
    "plt.style.use('default') \n",
    "plt.style.use('default') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.rcParams.update({'font.family': 'Roboto Slab'})\n",
    "plt.rcParams[\"savefig.dpi\"] = 1200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Load and modify the pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'00096': [(12, 11.6),\n",
      "           (101, 2.7),\n",
      "           (143, 2.4),\n",
      "           (201, 5.9),\n",
      "           (258, 2.0),\n",
      "           (558, 20.7)],\n",
      " '00275': [(157, 2.6), (276, 2.2), (575, 2.8)],\n",
      " '00294': [(17, 1.9), (76, 2.4)],\n",
      " '00338': [(0, 12.8), (34, 5.9)],\n",
      " '00366': [(182, 6.9),\n",
      "           (371, 1.4),\n",
      "           (388, 2.5),\n",
      "           (402, 1.8),\n",
      "           (408, 1.7),\n",
      "           (428, 0.4),\n",
      "           (519, 2.6),\n",
      "           (527, 1.9),\n",
      "           (922, 8.1)],\n",
      " '00469': [(332, 18.1), (355, 11.1), (372, 8.1)],\n",
      " '00478': [(2, 11.2), (19, 7.2), (419, 2.2), (424, 0.8), (614, 2.2)],\n",
      " '00661': [(2, 2.5), (61, 4.3), (184, 12.8), (206, 5.7), (513, 7.1)],\n",
      " '00684': [(95, 6.0), (109, 19.7)],\n",
      " '00852': [(4, 1.1), (20, 0.5), (56, 0.9), (219, 2.0), (307, 2.4), (446, 1.8)]}\n"
     ]
    }
   ],
   "source": [
    "timings_ = {\n",
    "    \"00852\": [(\"00:04\", 1.1), (\"00:20\", 0.5), (\"00:56\", 0.9), (\"03:39\", 2.0), (\"05:07\", 2.4), (\"07:26\", 1.8)],\n",
    "    \"00684\": [(\"01:35\", 6.0), (\"01:49\", 19.7)],\n",
    "    \"00096\": [(\"00:12\", 11.6), (\"01:41\", 2.7), (\"02:23\", 2.4), (\"03:21\", 5.9), (\"04:18\", 2.0), (\"09:18\", 20.7)],\n",
    "    \"00366\": [(\"03:02\", 6.9), (\"06:11\", 1.4), (\"06:28\", 2.5), (\"06:42\", 1.8), (\"06:48\", 1.7), \n",
    "              (\"07:08\", 0.4), (\"08:39\", 2.6), (\"08:47\", 1.9), (\"15:22\", 8.1)],\n",
    "    \"00478\": [(\"00:02\", 11.2), (\"00:19\", 7.2), (\"06:59\", 2.2), (\"07:04\", 0.8), (\"10:14\", 2.2)],\n",
    "    \"00275\": [(\"02:37\", 2.6), (\"04:36\", 2.2), (\"09:35\", 2.8)],\n",
    "    \"00338\": [(\"00:00\", 12.8), (\"00:34\", 5.9)],\n",
    "    \"00469\": [(\"05:32\", 18.1), (\"05:55\", 11.1), (\"06:12\", 8.1)],\n",
    "    \"00661\": [(\"00:02\", 2.5), (\"01:01\", 4.3), (\"03:04\", 12.8), (\"03:26\", 5.7), (\"08:33\", 7.1)],\n",
    "    \"00294\": [(\"00:17\", 1.9), (\"01:16\", 2.4)],\n",
    "}\n",
    "\n",
    "timings = {}\n",
    "for k, v in timings_.items():\n",
    "    timings[k] = []\n",
    "    for time, duration in v:\n",
    "        timings[k].append((int(time[:2]) * 60 + int(time[3:]), duration))\n",
    "\n",
    "pprint.pprint(timings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'boej8vuk' # boej8vuk yap6fgxc p02vsovi | 3du3h4yl bco01cyz\n",
    "target_datasets = ['val'] # ['train', 'val']\n",
    "\n",
    "use_wandb = True\n",
    "device = 'cuda:0'\n",
    "model_path = 'local/checkpoint/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.2+cu118\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EKG': 'O',\n",
      " '_target_': 'models.mae_1d_artifact.mae_1d_art_b_e768_d512',\n",
      " 'activation': 'gelu',\n",
      " 'age_mean': tensor([71.3079], device='cuda:0'),\n",
      " 'age_std': tensor([9.6942], device='cuda:0'),\n",
      " 'art_dropout': 0.1,\n",
      " 'art_loss_type': 'mse',\n",
      " 'art_out_activation': 'none',\n",
      " 'art_patch_usage': {'type': 'drop_low', 'value': 0.3},\n",
      " 'art_use_age': 'no',\n",
      " 'awgn': 0.003,\n",
      " 'awgn_age': 0.001,\n",
      " 'base_lr': 8.479608095398431e-05,\n",
      " 'class_label_to_name': ['Normal', 'MCI', 'Dementia'],\n",
      " 'class_name_to_label': {'Dementia': 2, 'MCI': 1, 'Normal': 0},\n",
      " 'criterion': 'cross-entropy',\n",
      " 'crop_length': 5120,\n",
      " 'crop_multiple': 8,\n",
      " 'crop_timing_analysis': False,\n",
      " 'cwd': '',\n",
      " 'dataset_name': 'CAUEEG dataset',\n",
      " 'dataset_path': 'local/dataset/caueeg-dataset/',\n",
      " 'ddp': False,\n",
      " 'ddp_size': 1,\n",
      " 'device': device(type='cuda', index=0),\n",
      " 'draw_result': True,\n",
      " 'dropout': 0.1,\n",
      " 'fc_stages': 2,\n",
      " 'file_format': 'memmap',\n",
      " 'global_pool': True,\n",
      " 'in_channels': 20,\n",
      " 'input_norm': 'datapoint',\n",
      " 'iterations': 7812,\n",
      " 'latency': 2000,\n",
      " 'layer_wise_lr': True,\n",
      " 'load_event': False,\n",
      " 'lr_scheduler_type': 'cosine_decay_with_warmup_half',\n",
      " 'lr_search_steps': 100,\n",
      " 'mask_ratio': 0.75,\n",
      " 'mgn': 0.003,\n",
      " 'minibatch': 128,\n",
      " 'minibatch_3090': 256,\n",
      " 'mixed_precision': True,\n",
      " 'mixup': 0.1,\n",
      " 'model': '1D-MAE-B',\n",
      " 'multi_batch_size': 16,\n",
      " 'norm_pix_loss': True,\n",
      " 'num_history': 50,\n",
      " 'num_params': 85483395,\n",
      " 'num_workers': 4,\n",
      " 'out_dims': 3,\n",
      " 'output_length': 321,\n",
      " 'patch_size': 8,\n",
      " 'photic': 'X',\n",
      " 'pre_model': 'eg6s5fay',\n",
      " 'preprocess_test': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda', index=0))\n",
      "  (1): EegResample(orig_freq=200, new_freq=100, resampling_method='sinc_interp_hann')\n",
      "  (2): EegNormalizeAge(mean=tensor([71.3079], device='cuda:0'), std=tensor([9.6942], device='cuda:0'), eps=1e-08, std_eps=tensor([9.6942], device='cuda:0'))\n",
      "  (3): EegNormalizePerSignal(eps=1e-08)\n",
      "),\n",
      " 'preprocess_train': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda', index=0))\n",
      "  (1): EegResample(orig_freq=200, new_freq=100, resampling_method='sinc_interp_hann')\n",
      "  (2): EegNormalizeAge(mean=tensor([71.3079], device='cuda:0'), std=tensor([9.6942], device='cuda:0'), eps=1e-08, std_eps=tensor([9.6942], device='cuda:0'))\n",
      "  (3): EegAddGaussianNoiseAge(mean=0.0, std=0.001)\n",
      "  (4): EegNormalizePerSignal(eps=1e-08)\n",
      "  (5): EegMultiplicativeGaussianNoise(mean=0.0, std=0.003)\n",
      "  (6): EegAdditiveGaussianNoise(mean=0.0, std=0.003)\n",
      "),\n",
      " 'project': 'caueeg-mae-artifact-finetune',\n",
      " 'resample': 100,\n",
      " 'run_mode': 'train',\n",
      " 'sampling_rate': 200,\n",
      " 'save_model': True,\n",
      " 'search_lr': True,\n",
      " 'search_multiplier': 1.0,\n",
      " 'seed': 2,\n",
      " 'seq_length': 2560,\n",
      " 'signal_header': ['Fp1-AVG',\n",
      "                   'F3-AVG',\n",
      "                   'C3-AVG',\n",
      "                   'P3-AVG',\n",
      "                   'O1-AVG',\n",
      "                   'Fp2-AVG',\n",
      "                   'F4-AVG',\n",
      "                   'C4-AVG',\n",
      "                   'P4-AVG',\n",
      "                   'O2-AVG',\n",
      "                   'F7-AVG',\n",
      "                   'T3-AVG',\n",
      "                   'T5-AVG',\n",
      "                   'F8-AVG',\n",
      "                   'T4-AVG',\n",
      "                   'T6-AVG',\n",
      "                   'FZ-AVG',\n",
      "                   'CZ-AVG',\n",
      "                   'PZ-AVG',\n",
      "                   'EKG',\n",
      "                   'Photic'],\n",
      " 'signal_length_limit': 10000000,\n",
      " 'task': 'dementia',\n",
      " 'task_description': 'Classification of [Normal], [MCI], and [Dementia] '\n",
      "                     'symptoms.',\n",
      " 'task_name': 'CAUEEG-Dementia benchmark',\n",
      " 'test_crop_multiple': 8,\n",
      " 'total_samples': 1000000.0,\n",
      " 'transform': Compose(\n",
      "    EegRandomCrop(crop_length=5120, length_limit=10000000, multiple=8, latency=2000, segment_simulation=False, return_timing=False, reject_events=False)\n",
      "    EegDropChannels(drop_index=[20])\n",
      "    EegToTensor()\n",
      "),\n",
      " 'transform_multicrop': Compose(\n",
      "    EegRandomCrop(crop_length=5120, length_limit=10000000, multiple=8, latency=2000, segment_simulation=False, return_timing=False, reject_events=False)\n",
      "    EegDropChannels(drop_index=[20])\n",
      "    EegToTensor()\n",
      "),\n",
      " 'tuning_type': 'finetune',\n",
      " 'use_age': 'conv',\n",
      " 'use_wandb': True,\n",
      " 'warmup_min': 200,\n",
      " 'warmup_ratio': 0.05,\n",
      " 'warmup_steps': 391,\n",
      " 'watch_model': False,\n",
      " 'weight_decay': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# load pretrained configurations\n",
    "path = os.path.join(model_path, model_name.split(',')[-1], 'checkpoint.pt')\n",
    "try:\n",
    "    ckpt = torch.load(path, map_location=device)\n",
    "    config = ckpt['config']\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f'- checkpoint cannot be opened: {path}')\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv1d(20, 64, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (1): BatchNorm1d(64, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): GELU(approximate='none')\n",
       "  (3): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "  (4): BatchNorm1d(64, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): GELU(approximate='none')\n",
       "  (6): Conv1d(64, 64, kernel_size=(9,), stride=(2,), padding=(4,))\n",
       "  (7): BatchNorm1d(64, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): GELU(approximate='none')\n",
       "  (9): AdaptiveAvgPool1d(output_size=1)\n",
       "  (10): Flatten(start_dim=1, end_dim=-1)\n",
       "  (11): Linear(in_features=64, out_features=32, bias=False)\n",
       "  (12): Dropout(p=0.1, inplace=False)\n",
       "  (13): BatchNorm1d(32, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): GELU(approximate='none')\n",
       "  (15): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (16): Identity()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the model\n",
    "config[\"device\"] = device\n",
    "model = generate_model(config).to(device)\n",
    "\n",
    "# load model\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "model.requires_grad_(False)\n",
    "model = model.eval()\n",
    "model.art_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Generate the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['task']\n",
    "config.pop('cwd', 0)\n",
    "config['ddp'] = False\n",
    "config['minibatch'] = 1\n",
    "config['crop_multiple'] = 1\n",
    "config['test_crop_multiple'] = 1\n",
    "config['crop_timing_analysis'] = True\n",
    "config['eval'] = True\n",
    "config['device'] = device\n",
    "\n",
    "config[\"task\"] = 'abnormal'  # annotations were written with respect to the CAUEEG-Abnormal task data\n",
    "train_loader, val_loader, test_loader, _ = compose_dataset(config)\n",
    "signal_header = [channel.split('-')[0] for i, channel in enumerate(config[\"signal_header\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'serial': ['00661'], 'age': tensor([61.]), 'symptom': [['tga']], 'class_name': ['Abnormal'], 'class_label': tensor([1]), 'signal': tensor([[[  4.,   6.,   7.,  ...,  17.,  17.,  14.],\n",
      "         [-26., -23., -21.,  ...,  14.,  16.,  16.],\n",
      "         [-11., -12., -13.,  ...,   8.,  10.,  11.],\n",
      "         ...,\n",
      "         [ -4.,  -6.,  -5.,  ...,  -5.,  -6.,  -5.],\n",
      "         [ -2.,  -3.,  -3.,  ...,   8.,   9.,   9.],\n",
      "         [  5.,   8.,   5.,  ...,  83.,  94., 108.]]]), 'crop_timing': [82381]}\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for sample in val_loader:\n",
    "        if sample[\"serial\"][0] in timings.keys():\n",
    "            print(sample)\n",
    "            ct = sample[\"crop_timing\"][0]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Transform\n",
      "Compose(\n",
      "    EegRandomCrop(crop_length=5120, length_limit=10000000, multiple=1, latency=2000, segment_simulation=False, return_timing=True, reject_events=False)\n",
      "    EegDropChannels(drop_index=[20])\n",
      "    EegToTensor()\n",
      ")\n",
      "------------------------------\n",
      "Modified Transform\n",
      "Compose(\n",
      "    EegDropChannels(drop_index=[20])\n",
      "    EegToTensor()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"Previous Transform\")\n",
    "print(val_loader.dataset.transform)\n",
    "print(\"---\" * 10)\n",
    "\n",
    "# skip the first transform (RandomCrop)\n",
    "for loader in [train_loader, val_loader, test_loader]:\n",
    "    loader.dataset.transform = torchvision.transforms.Compose([\n",
    "        *loader.dataset.transform.transforms[1:]\n",
    "    ])\n",
    "\n",
    "print(\"Modified Transform\")\n",
    "print(val_loader.dataset.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  4.,   6.,   7.,  ...,  17.,  17.,  14.],\n",
      "         [-26., -23., -21.,  ...,  14.,  16.,  16.],\n",
      "         [-11., -12., -13.,  ...,   8.,  10.,  11.],\n",
      "         ...,\n",
      "         [ -4.,  -6.,  -5.,  ...,  -5.,  -6.,  -5.],\n",
      "         [ -2.,  -3.,  -3.,  ...,   8.,   9.,   9.],\n",
      "         [  5.,   8.,   5.,  ...,  83.,  94., 108.]]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for sample in val_loader:\n",
    "        if sample[\"serial\"][0] in timings.keys():\n",
    "            print(sample[\"signal\"][:, :, ct:ct + config[\"crop_length\"]])\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Compute uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interval = 1  # speed control\n",
    "# results = {}\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for sample in val_loader:\n",
    "#         serial = sample[\"serial\"][0]\n",
    "#         if serial in timings.keys():\n",
    "#             values = timings[serial]\n",
    "#             L = sample[\"signal\"][0].shape[-1]\n",
    "#             count = torch.zeros((L,))\n",
    "#             score = torch.zeros((L,))\n",
    "\n",
    "#             for t in tqdm(range(0, L - config[\"crop_length\"], interval), desc=\"Crops\", leave=False):\n",
    "#                 s = deepcopy(sample)\n",
    "#                 s[\"signal\"] = s[\"signal\"][:, :, t:t + config[\"crop_length\"]]\n",
    "#                 config[\"preprocess_test\"](s)    \n",
    "#                 out = model.forward_artifact(s[\"signal\"], s[\"age\"]).cpu()\n",
    "                \n",
    "#                 out = torch.nn.functional.interpolate(out.reshape(1, 1, 1, -1), \n",
    "#                                                       size=(1, config[\"crop_length\"], ), mode=\"nearest\")\n",
    "#                 out = out.squeeze()\n",
    "#                 count[t:t + config[\"crop_length\"]] += 1\n",
    "#                 score[t:t + config[\"crop_length\"]] += out\n",
    "                \n",
    "#             results[serial] = score / (count + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = f'local/output/07_Visualize_MAE_Artifact_Vals_{model_name}.pt'\n",
    "# torch.save(results, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'local/output/07_Visualize_MAE_Artifact_Vals_{model_name}.pt'\n",
    "results = torch.load(path, map_location='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(['ieee', 'science', 'default']):  # science, ieee, default, fivethirtyeight\n",
    "    # plt.rcParams.update({'font.family': 'Roboto Slab'})\n",
    "    \n",
    "    for serial in results.keys():\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(25, 5), constrained_layout=True)\n",
    "\n",
    "        r = results[serial].numpy()\n",
    "        ax.plot(r)\n",
    "        sample_rate = config[\"sampling_rate\"]\n",
    "\n",
    "        for start, duration in timings[serial]:\n",
    "            bb = mtransforms.Bbox.from_bounds(x0=round(start*sample_rate), y0=0, \n",
    "                                              width=round(duration*sample_rate), height=1)\n",
    "            fancy = FancyBboxPatch(bb.p0, bb.width, bb.height, boxstyle=\"square,pad=0\")\n",
    "            fancy.set(edgecolor=\"red\", facecolor=(1, 0, 0, 0.2), zorder=10, )\n",
    "            ax.add_patch(fancy)\n",
    "        \n",
    "        x_ticks = np.arange(0, r.shape[0], sample_rate * 30)\n",
    "        x_labels = [f\"{round(tick / sample_rate)}\" for tick in x_ticks]\n",
    "        ax.set_xticks(x_ticks)\n",
    "        ax.set_xticklabels(x_labels)\n",
    "        ax.set_xlim(0, r.shape[0])\n",
    "        ax.set_ylim(0, 1.0)\n",
    "        ax.set_xlabel('Time (s)')\n",
    "        ax.set_ylabel('Estimated Uncertainty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mipympl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m target_serial \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtimings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# 0, 7\u001b[39;00m\n\u001b[0;32m      3\u001b[0m duration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4000\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf1\u001b[39m(signal, start, duration):\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "%matplotlib ipympl\n",
    "target_serial = [*timings.keys()][10]  # 0, 7\n",
    "duration = 4000\n",
    "\n",
    "def f1(signal, start, duration):\n",
    "    return signal[start: start + duration]\n",
    "    \n",
    "def f2(result, start, duration):\n",
    "    return np.tile(result[start: start + duration], (50, 1))\n",
    "\n",
    "def f3(supervised, start, duration):\n",
    "    return np.tile(supervised[start: start + duration], (50, 1))\n",
    "\n",
    "def f4(start, duration):\n",
    "    t = start\n",
    "    start_time = f\"{int((t / sample_rate) // 60):02d}:{(t / sample_rate) % 60:02.1f}\"\n",
    "    t = start + duration\n",
    "    end_time = f\"{int((t / sample_rate) // 60):02d}:{(t / sample_rate) % 60:02.1f}\"\n",
    "    return start_time + \" - \" + end_time + \" s\"\n",
    "\n",
    "def f5(signal, avg):\n",
    "    if avg:\n",
    "        signal = np.convolve(signal, np.ones(avg), 'same') / avg\n",
    "    return signal\n",
    "\n",
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "\n",
    "with plt.style.context(['ieee', 'science', 'default']):  # science, ieee, default, fivethirtyeight\n",
    "    # plt.rcParams.update({'font.family': 'Roboto Slab'})\n",
    "\n",
    "    for sample in val_loader:\n",
    "        serial = sample[\"serial\"][0]\n",
    "        if serial == target_serial:\n",
    "            signal = sample[\"signal\"][0].cpu().numpy()\n",
    "            sample_rate = config[\"sampling_rate\"]\n",
    "            C, L = signal.shape\n",
    "            r = results[serial].numpy()\n",
    "                \n",
    "            fig = plt.figure(num=1, clear=True, figsize=(30, 15))\n",
    "            fig.subplots_adjust(hspace=0)\n",
    "            fig.tight_layout()\n",
    "            gs = GridSpec(nrows=C + 8, ncols=1)\n",
    "            ctrls = Controls(start=np.arange(0, L - duration), avg=np.arange(0, 400))\n",
    "            display(ctrls)\n",
    "\n",
    "            ax = fig.add_subplot(gs[:4])\n",
    "            iplt.plot(partial(f5, signal=r), ax=ax, lw=0.6, controls=ctrls[\"avg\"])\n",
    "            for s, d in timings[serial]:\n",
    "                bb = mtransforms.Bbox.from_bounds(x0=round(s*sample_rate), y0=0, \n",
    "                                                  width=round(d*sample_rate), height=1)\n",
    "                fancy = FancyBboxPatch(bb.p0, bb.width, bb.height, boxstyle=\"square,pad=0\")\n",
    "                fancy.set(edgecolor=(1, 0, 0, 0.5), facecolor=(1, 0, 0, 0.2), zorder=30, )\n",
    "                ax.add_patch(fancy)\n",
    "            mpl_interactions.interactive_axvline(x=ctrls[\"start\"], ymin=0, ymax=1, ax=ax, \n",
    "                                                 color='purple', controls=ctrls[\"start\"], ls=\"--\")\n",
    "            mpl_interactions.interactive_axvline(x=lambda start: start + duration, ymin=0, ymax=1, ax=ax, \n",
    "                                                 color='purple', controls=ctrls[\"start\"], ls=\"--\")\n",
    "            x_ticks = np.arange(0, r.shape[0], sample_rate * 30)\n",
    "            x_labels = [f\"{round(tick / sample_rate)}\" for tick in x_ticks]\n",
    "            ax.set_xlim(0, r.shape[0])\n",
    "            ax.set_xticks(x_ticks)\n",
    "            ax.set_xticklabels(x_labels)\n",
    "            ax.set_xlabel('Time (s)')\n",
    "            ax.set_ylim(0, 1.0)\n",
    "            ax.set_yticks([0])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_ylabel(\"Artifact\")\n",
    "            \n",
    "            ax = fig.add_subplot(gs[6])\n",
    "            iplt.imshow(partial(f2, result=r, duration=duration), aspect=\"auto\",\n",
    "                        alpha=1.0, ax=ax, controls=ctrls[\"start\"], vmin=0, vmax=1)\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticks([0])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_ylabel(\"Pred\")\n",
    "\n",
    "            ax = fig.add_subplot(gs[7])\n",
    "            supervised = np.zeros_like(results[serial])\n",
    "            for s, d in timings[serial]:\n",
    "                supervised[round(s*sample_rate):round((s + d)*sample_rate)] = 1            \n",
    "            iplt.imshow(partial(f3, supervised=supervised, duration=duration), aspect=\"auto\",\n",
    "                        alpha=1.0, ax=ax, controls=ctrls[\"start\"], vmin=0, vmax=1)\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticks([0])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_ylabel(\"GT\")\n",
    "\n",
    "            for c in range(C):\n",
    "                ax = fig.add_subplot(gs[c + 8])\n",
    "                iplt.plot(partial(f1, signal=signal[c], duration=duration), \n",
    "                          ax=ax, controls=ctrls[\"start\"], lw=0.6)\n",
    "\n",
    "                ax.set_xlim(0, duration)\n",
    "                ax.set_ylabel(signal_header[c])\n",
    "                mpl_interactions.interactive_xlabel(xlabel=partial(f4, duration=duration),\n",
    "                                                    controls=ctrls[\"start\"])\n",
    "                ax.set_xticks(np.arange(round(duration / sample_rate) + 1) * sample_rate)\n",
    "                ax.set_xticklabels([])\n",
    "                # ax.tick_params(axis='x', width=0.1, length=0.1)\n",
    "                ax.set_yticks([0])\n",
    "                ax.set_yticklabels([])\n",
    "                \n",
    "            fig.suptitle(serial, fontsize=13, fontweight='semibold')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
