{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed1e2f8a-32b4-46b1-a00a-382644e90504",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# t-SNE visualization\n",
    "\n",
    "This notebook visualizes the EEG embeddings computed by the model trained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdbc4ee-d024-4025-84fb-d18dfa1410d7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df587e38-b1a9-42c8-9b50-680200a9bec7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb41bf8-1713-4228-b799-0e1c87545a16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import pprint\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_script import build_dataset_for_train\n",
    "import models\n",
    "from train.evaluate import check_accuracy\n",
    "from train.evaluate import check_accuracy_extended\n",
    "from train.evaluate import check_accuracy_extended_debug\n",
    "from train.evaluate import check_accuracy_multicrop\n",
    "from train.evaluate import check_accuracy_multicrop_extended\n",
    "from train.visualize import draw_roc_curve\n",
    "from train.visualize import draw_confusion, draw_confusion2\n",
    "from train.visualize import draw_class_wise_metrics\n",
    "from train.visualize import draw_error_table\n",
    "from train.visualize import annotate_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309eed9b-2c31-4398-a141-e1787453814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bffc0b0-30bc-4b63-908e-03a68c3da0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other settings\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # cleaner text\n",
    "\n",
    "plt.style.use('default') \n",
    "# ['Solarize_Light2', '_classic_test_patch', 'bmh', 'classic', 'dark_background', 'fast', \n",
    "#  'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn', 'seaborn-bright', 'seaborn-colorblind', \n",
    "#  'seaborn-dark', 'seaborn-dark-palette', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', \n",
    "#  'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', \n",
    "#  'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'tableau-colorblind10']\n",
    "\n",
    "plt.rcParams['image.interpolation'] = 'bicubic'\n",
    "plt.rcParams[\"font.family\"] = 'Helvetica' # 'NanumGothic' # for Hangul in Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c5390-f093-4a4c-9c72-2f16f9d42fde",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "-----\n",
    "\n",
    "## Load the configuration used during the train phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0f3c94-0bbb-42ef-ab92-df07e2964087",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model_name = 'lo88puq7'\n",
    "model_name = '1nu3jagp'  # no mixup version\n",
    "model_path = os.path.join(r'E:\\CAUEEG\\checkpoint', model_name, 'checkpoint.pt')\n",
    "\n",
    "ckpt = torch.load(model_path, map_location=device)\n",
    "print(ckpt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069adca8-f2f7-446f-ba09-87f6f5f64d8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_state = ckpt['model_state']\n",
    "config = ckpt['config']\n",
    "optimizer = ckpt['optimizer_state']\n",
    "scheduler = ckpt['scheduler_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4a490d-9f3b-42b7-a1ef-4605f5eae262",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pprint.pprint(config, width=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7877675-9feb-4175-8f54-946a29044648",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load the target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322201e6-3a07-48f9-a871-c4a44129e8f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model = config['generator'](**config).to(device)\n",
    "model = hydra.utils.instantiate(config).to(device)\n",
    "\n",
    "if config.get('ddp', False):\n",
    "    model_state_ddp = deepcopy(model_state)\n",
    "    model_state = OrderedDict()\n",
    "    for k, v in model_state_ddp.items():\n",
    "        name = k[7:] # remove 'module.' of DataParallel/DistributedDataParallel\n",
    "        model_state[name] = v\n",
    "        \n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab33f903-bbbe-49c1-9fc2-49ce8ee26cff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Evaluate the model and analyze the performance by the crop timing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d827eb6-53f2-4aa0-909c-972dcf33c6d5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427aeb6b-5fef-411c-b69a-5fb4413483ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = ckpt['config']\n",
    "\n",
    "config.pop('cwd', 0)\n",
    "config['ddp'] = False\n",
    "config['crop_timing_analysis'] = True\n",
    "config['eval'] = True\n",
    "config['crop_multiple'] = 32\n",
    "config['device'] = device\n",
    "\n",
    "target_from_last = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527fc407-9f18-4329-a551-c85ec26a0727",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1d9aa9-fbc5-4d4a-8a7f-8e8fbd4675dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if '220419' in config['dataset_path']:\n",
    "    config['dataset_path'] = './local/dataset/caueeg-dataset/'\n",
    "    \n",
    "train_loader, val_loader, test_loader, multicrop_test_loader = build_dataset_for_train(config, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3194f85f-b580-41dd-a75a-646937e51895",
   "metadata": {},
   "source": [
    "## Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf305ec-becd-4b3e-998d-649ddbb34b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = check_accuracy_extended_debug(model, test_loader, \n",
    "                                  config['preprocess_test'], config, repeat=50)\n",
    "test_acc = _[0]\n",
    "test_score = _[1]\n",
    "test_target = _[2]\n",
    "test_confusion = _[3]\n",
    "test_error_table = _[4]\n",
    "test_crop_timing = _[5]\n",
    "\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9469ef7-008c-405d-8966-840249f59344",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_roc_curve(test_score, test_target, config['class_label_to_name'], use_wandb=False)\n",
    "draw_confusion(test_confusion, config['class_label_to_name'], use_wandb=False)\n",
    "draw_class_wise_metrics(test_confusion, config['class_label_to_name'], use_wandb=False)\n",
    "draw_error_table(test_error_table, use_wandb=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dfce23-e2a8-43e7-ade1-dd29ac255f85",
   "metadata": {},
   "source": [
    "## t-SNE embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf875389-0084-4e44-98e3-eae37d63bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_embedding(model, sample_batched, preprocess, crop_multiple, target_from_last):\n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # preprocessing (this includes to-device operation)\n",
    "    preprocess(sample_batched)\n",
    "\n",
    "    # apply model on whole batch directly on device\n",
    "    x = sample_batched['signal']\n",
    "    age = sample_batched['age']\n",
    "    e = model.compute_feature_embedding(x, age, target_from_last=target_from_last)\n",
    "    y = sample_batched['class_label']\n",
    "    \n",
    "    if crop_multiple > 1:\n",
    "        # multi-crop averaging\n",
    "        if e.size(0) % crop_multiple != 0:\n",
    "            raise ValueError(f\"compute_embedding(): Real minibatch size={e.size(0)} is not multiple of \"\n",
    "                             f\"crop_multiple={crop_multiple}.\")\n",
    "\n",
    "        real_minibatch = e.size(0) // crop_multiple\n",
    "        e_ = torch.zeros((real_minibatch, e.size(1)))\n",
    "        y_ = torch.zeros((real_minibatch,), dtype=torch.int32)\n",
    "\n",
    "        for m in range(real_minibatch):\n",
    "            e_[m] = e[crop_multiple*m:crop_multiple*(m + 1)].mean(dim=0, keepdims=True)\n",
    "            y_[m] = y[crop_multiple*m]\n",
    "                \n",
    "        e = e_\n",
    "        y = y_\n",
    "    \n",
    "    return e, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168d61d3-104a-4787-ba91-bb5a92d0ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, age, y, alpha=0, use_cuda=True):\n",
    "    lam = np.random.beta(alpha, alpha) if alpha > 1e-12 else 1\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    mixed_age = lam * age + (1 - lam) * age[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, mixed_age, y_a, y_b, lam, index1\n",
    "\n",
    "def mixup_data_lam(x, age, y, lam=0.5, use_cuda=True):\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    mixed_age = lam * age + (1 - lam) * age[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, mixed_age, y_a, y_b, lam, index\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_mixup_embedding(model, sample_batched, preprocess, crop_multiple, mixup_alpha, target_from_last):\n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # preprocessing (this includes to-device operation)\n",
    "    preprocess(sample_batched)\n",
    "\n",
    "    # apply model on whole batch directly on device\n",
    "    x = sample_batched['signal']\n",
    "    age = sample_batched['age']\n",
    "    y = sample_batched['class_label']\n",
    "\n",
    "    # x, age, y1, y2, lam, mixup_index = mixup_data(x, age, y, mixup_alpha)\n",
    "    x, age, y1, y2, lam, mixup_index = mixup_data_lam(x, age, y, lam=0.5)\n",
    "    e = model.compute_feature_embedding(x, age, target_from_last=target_from_last)\n",
    "    \n",
    "    if crop_multiple > 1:\n",
    "        # multi-crop averaging\n",
    "        if e.size(0) % crop_multiple != 0:\n",
    "            raise ValueError(f\"compute_embedding(): Real minibatch size={e.size(0)} is not multiple of \"\n",
    "                             f\"crop_multiple={crop_multiple}.\")\n",
    "\n",
    "        real_minibatch = e.size(0) // crop_multiple\n",
    "        e_ = torch.zeros((real_minibatch, e.size(1)))\n",
    "\n",
    "        for m in range(real_minibatch):\n",
    "            e_[m] = e[crop_multiple*m:crop_multiple*(m + 1)].mean(dim=0, keepdims=True)\n",
    "                \n",
    "        e = e_\n",
    "    \n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d28b639-c84a-4ad3-80d7-9b862912b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [{'name': 'Train Dataset', 'loader': train_loader}, \n",
    "          {'name': 'Validation Dataset', 'loader': val_loader}, \n",
    "          {'name': 'Test Dataset', 'loader': test_loader}]\n",
    "\n",
    "for r in range(len(result)):\n",
    "    name = result[r]['name']\n",
    "    loader = result[r]['loader']\n",
    "\n",
    "    for i, sample_batched in enumerate(loader):\n",
    "        if i == 0:\n",
    "            crop_multiple = config['crop_multiple']\n",
    "            minibatch_size = loader.batch_size\n",
    "\n",
    "        # estimate\n",
    "        e, y = compute_embedding(model, sample_batched, config['preprocess_test'], crop_multiple, target_from_last=target_from_last)\n",
    "\n",
    "        if i == 0:\n",
    "            embedding = e.detach().cpu().numpy()\n",
    "            target = y.detach().cpu().numpy()\n",
    "        else:\n",
    "            embedding = np.concatenate([embedding, e.detach().cpu().numpy()], axis=0)\n",
    "            target = np.concatenate([target, y.detach().cpu().numpy()], axis=0)     \n",
    "                    \n",
    "    result[r]['embedding'] = embedding\n",
    "    result[r]['target'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a1c7ce-c99c-4bbd-8bc6-1253f568e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup_result = [{'name': 'Train Dataset', 'loader': train_loader}, \n",
    "                {'name': 'Validation Dataset', 'loader': val_loader}, \n",
    "                {'name': 'Test Dataset', 'loader': test_loader}]\n",
    "\n",
    "for r in range(len(mixup_result)):\n",
    "    name = mixup_result[r]['name']\n",
    "    loader = mixup_result[r]['loader']\n",
    "\n",
    "    for i, sample_batched in enumerate(loader):\n",
    "        if i == 0:\n",
    "            crop_multiple = config['crop_multiple']\n",
    "            minibatch_size = loader.batch_size\n",
    "\n",
    "        # estimate\n",
    "        e = compute_mixup_embedding(model, sample_batched, config['preprocess_test'], crop_multiple, \n",
    "                                    mixup_alpha=config['mixup'], target_from_last=target_from_last)\n",
    "\n",
    "        if i == 0:\n",
    "            embedding = e.detach().cpu().numpy()\n",
    "        else:\n",
    "            embedding = np.concatenate([embedding, e.detach().cpu().numpy()], axis=0)  \n",
    "                    \n",
    "    mixup_result[r]['embedding'] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b230944-8bce-468a-a560-ea8a65088a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_transform = TSNE(n_components=2, init=\"pca\", learning_rate=\"auto\", perplexity=30.0,\n",
    "                      n_iter=5000, n_iter_without_progress=500, n_jobs=2, random_state=0,)\n",
    "\n",
    "for r in range(len(result)):\n",
    "    output = tsne_transform.fit_transform( np.concatenate([result[r]['embedding'], mixup_result[r]['embedding']]))\n",
    "    result[r]['tsne_embedding'] = output[:result[r]['embedding'].shape[0]]\n",
    "    mixup_result[r]['tsne_embedding'] = output[result[r]['embedding'].shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc7238-c0d3-498d-9d94-9b20c0e0bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default') \n",
    "plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams.update({'font.family': 'Arial'})\n",
    "# plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "\n",
    "for r in range(len(result)):\n",
    "    _, ax = plt.subplots()\n",
    "    for class_name, class_label in config['class_name_to_label'].items():\n",
    "        ax.scatter(\n",
    "            result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 0],\n",
    "            result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 1],\n",
    "            label=class_name,\n",
    "            color=color_map[class_label],\n",
    "            alpha=0.8,\n",
    "            edgecolors='k',\n",
    "            zorder=2)\n",
    "    ax.scatter(\n",
    "        mixup_result[r]['tsne_embedding'][:, 0],\n",
    "        mixup_result[r]['tsne_embedding'][:, 1],\n",
    "        label='mixup',\n",
    "        color='gray',\n",
    "        alpha=0.5,\n",
    "        edgecolors='k',\n",
    "        zorder=2)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    ax.set_title(f\"t-SNE embedding of {result[r]['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb20895-2c8f-4440-a627-c33b9d34b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_out_embedding = tsne_transform.fit_transform(np.concatenate([r['embedding'] for r in result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57160e8b-0869-4757-a48d-d3d7cb772f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default') \n",
    "plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams.update({'font.family': 'Arial'})\n",
    "# plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "start_from = 0\n",
    "\n",
    "for r in range(len(result)):\n",
    "    _, ax = plt.subplots()\n",
    "    n_size = result[r]['tsne_embedding'].shape[0]\n",
    "    \n",
    "    start_from_temp = 0\n",
    "    for rr in range(len(result)):\n",
    "        n_size_temp = result[rr]['tsne_embedding'].shape[0]\n",
    "        for class_name, class_label in config['class_name_to_label'].items():\n",
    "            ax.scatter(\n",
    "                total_out_embedding[start_from_temp:start_from_temp + n_size_temp][result[rr]['target'] == class_label][:, 0],\n",
    "                total_out_embedding[start_from_temp:start_from_temp + n_size_temp][result[rr]['target'] == class_label][:, 1],\n",
    "                color=color_map[class_label],\n",
    "                alpha=0.1,\n",
    "                zorder=2)\n",
    "        start_from_temp += n_size_temp\n",
    "\n",
    "    for class_name, class_label in config['class_name_to_label'].items():\n",
    "        ax.scatter(\n",
    "            total_out_embedding[start_from:start_from + n_size][result[r]['target'] == class_label][:, 0],\n",
    "            total_out_embedding[start_from:start_from + n_size][result[r]['target'] == class_label][:, 1],\n",
    "            label=class_name,\n",
    "            color=color_map[class_label],\n",
    "            alpha=0.8,\n",
    "            edgecolors='k',\n",
    "            zorder=2)\n",
    "    start_from += n_size\n",
    "    \n",
    "    ax.set_title(f\"t-SNE embedding of {result[r]['name']}\")\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12592b74-1299-42ae-ad28-907464ca1070",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default') \n",
    "plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams.update({'font.family': 'Arial'})\n",
    "# plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "\n",
    "for r in range(len(result)):\n",
    "    _, ax = plt.subplots()\n",
    "    for k, v in result[r]['target_symptom'].items():\n",
    "        ax.scatter(\n",
    "            result[r]['tsne_embedding'][[*set(v)]][:, 0],\n",
    "            result[r]['tsne_embedding'][[*set(v)]][:, 1],\n",
    "            label=k,\n",
    "            alpha=0.8,\n",
    "            edgecolors='k',\n",
    "            zorder=2)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    ax.set_title(f\"t-SNE embedding {[*result[r]['target_symptom'].keys()]} in {result[r]['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb70bae-222b-4338-bb85-1f64378de1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default') \n",
    "plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams.update({'font.family': 'Arial'})\n",
    "# plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "start_from = 0\n",
    "\n",
    "for r in range(len(result)):\n",
    "    _, ax = plt.subplots()\n",
    "    n_size = result[r]['tsne_embedding'].shape[0]\n",
    "    \n",
    "    start_from_temp = 0\n",
    "    for rr in range(len(result)):\n",
    "        n_size_temp = result[rr]['tsne_embedding'].shape[0]\n",
    "        for class_name, class_label in config['class_name_to_label'].items():\n",
    "            ax.scatter(\n",
    "                total_out_embedding[start_from_temp:start_from_temp + n_size_temp][result[rr]['target'] == class_label][:, 0],\n",
    "                total_out_embedding[start_from_temp:start_from_temp + n_size_temp][result[rr]['target'] == class_label][:, 1],\n",
    "                color=color_map[class_label],\n",
    "                label=class_name if rr == 0 else None,\n",
    "                alpha=0.1,\n",
    "                zorder=2)\n",
    "        start_from_temp += n_size_temp\n",
    "\n",
    "    for k, v in result[r]['target_symptom'].items():\n",
    "        ax.scatter(\n",
    "            total_out_embedding[start_from:start_from + n_size][[*set(v)]][:, 0],\n",
    "            total_out_embedding[start_from:start_from + n_size][[*set(v)]][:, 1],\n",
    "            label=k,\n",
    "            alpha=0.8,\n",
    "            edgecolors='k',\n",
    "            zorder=2)\n",
    "    start_from += n_size\n",
    "    \n",
    "    ax.set_title(f\"t-SNE embedding of {result[r]['name']}\")\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b338443a-ea48-4da5-bbdf-e66d9937ef34",
   "metadata": {},
   "source": [
    "### 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7147e02a-b3bc-4bdb-93b8-d239539e5385",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_transform = TSNE(n_components=3, init=\"pca\", learning_rate=\"auto\", perplexity=200.0,\n",
    "                      n_iter=50000, n_iter_without_progress=5000, n_jobs=4, random_state=0,)\n",
    "\n",
    "for r in range(len(result)):\n",
    "    output = tsne_transform.fit_transform( np.concatenate([result[r]['embedding'], mixup_result[r]['embedding']]))\n",
    "    result[r]['tsne_embedding'] = output[:result[r]['embedding'].shape[0]]\n",
    "    mixup_result[r]['tsne_embedding'] = output[result[r]['embedding'].shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb47091-f94f-429e-bc18-5d38802280f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default') \n",
    "plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams.update({'font.family': 'Arial'})\n",
    "# plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "\n",
    "for r in range(len(result)):\n",
    "    fig = plt.figure(num=1, clear=True, figsize=(12.0, 12.0))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "    for class_name, class_label in config['class_name_to_label'].items():\n",
    "        ax.scatter(\n",
    "            xs=result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 0],\n",
    "            ys=result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 1],\n",
    "            zs=result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 2],\n",
    "            label=class_name,\n",
    "            color=color_map[class_label],\n",
    "            alpha=0.8,\n",
    "            s=40,\n",
    "            edgecolors='k',\n",
    "            # zorder=2\n",
    "        )\n",
    "    ax.scatter(\n",
    "        xs=mixup_result[r]['tsne_embedding'][:, 0],\n",
    "        ys=mixup_result[r]['tsne_embedding'][:, 1],\n",
    "        zs=mixup_result[r]['tsne_embedding'][:, 2],\n",
    "        label='mixup',\n",
    "        color='gray',\n",
    "        alpha=0.5,\n",
    "        s=40,\n",
    "        edgecolors='k',\n",
    "        # zorder=2\n",
    "    )\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    ax.set_title(f\"t-SNE embedding of {result[r]['name']}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319aae3f-7a2d-45b1-9f8c-e9bc1530aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_out_embedding = tsne_transform.fit_transform(np.concatenate([r['embedding'] for r in result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e29758-1384-4a49-b3fc-a0d1344eabac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default') \n",
    "plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams.update({'font.family': 'Arial'})\n",
    "# plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "start_from = 0\n",
    "\n",
    "for r in range(len(result)):\n",
    "    fig = plt.figure(num=1, clear=True, figsize=(12.0, 12.0))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "    n_size = result[r]['tsne_embedding'].shape[0]\n",
    "    \n",
    "    start_from_temp = 0\n",
    "    for rr in range(len(result)):\n",
    "        n_size_temp = result[rr]['tsne_embedding'].shape[0]\n",
    "        for class_name, class_label in config['class_name_to_label'].items():\n",
    "            ax.scatter(\n",
    "                total_out_embedding[start_from_temp:start_from_temp + n_size_temp][result[rr]['target'] == class_label][:, 0],\n",
    "                total_out_embedding[start_from_temp:start_from_temp + n_size_temp][result[rr]['target'] == class_label][:, 1],\n",
    "                total_out_embedding[start_from_temp:start_from_temp + n_size_temp][result[rr]['target'] == class_label][:, 2],\n",
    "                color=color_map[class_label],\n",
    "                alpha=0.1,\n",
    "                s=40,\n",
    "                zorder=2)\n",
    "        start_from_temp += n_size_temp\n",
    "\n",
    "    for class_name, class_label in config['class_name_to_label'].items():\n",
    "        ax.scatter(\n",
    "            total_out_embedding[start_from:start_from + n_size][result[r]['target'] == class_label][:, 0],\n",
    "            total_out_embedding[start_from:start_from + n_size][result[r]['target'] == class_label][:, 1],\n",
    "            total_out_embedding[start_from:start_from + n_size][result[r]['target'] == class_label][:, 2],\n",
    "            label=class_name,\n",
    "            color=color_map[class_label],\n",
    "            alpha=0.8,\n",
    "            s=40,\n",
    "            edgecolors='k',\n",
    "            zorder=2)\n",
    "    start_from += n_size\n",
    "    \n",
    "    ax.set_title(f\"t-SNE embedding of {result[r]['name']}\")\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1cb845-c820-4682-b6a0-a2b6df0db3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default') \n",
    "plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams.update({'font.family': 'Arial'})\n",
    "# plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "\n",
    "for r in range(len(result)):\n",
    "    fig = plt.figure(num=1, clear=True, figsize=(12.0, 12.0))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "    for k, v in result[r]['target_symptom'].items():\n",
    "        ax.scatter(\n",
    "            result[r]['tsne_embedding'][[*set(v)]][:, 0],\n",
    "            result[r]['tsne_embedding'][[*set(v)]][:, 1],\n",
    "            result[r]['tsne_embedding'][[*set(v)]][:, 2],\n",
    "            label=k,\n",
    "            s=40,\n",
    "            alpha=0.8,\n",
    "            edgecolors='k',\n",
    "            zorder=2)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    ax.set_title(f\"t-SNE embedding {[*result[r]['target_symptom'].keys()]} in {result[r]['name']}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9fa0fb-e62d-4e1c-8075-6d05f8bfd02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default') \n",
    "plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams.update({'font.family': 'Arial'})\n",
    "# plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "start_from = 0\n",
    "\n",
    "for r in range(len(result)):\n",
    "    fig = plt.figure(num=1, clear=True, figsize=(12.0, 12.0))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "    n_size = result[r]['tsne_embedding'].shape[0]\n",
    "    \n",
    "    start_from_temp = 0\n",
    "    for rr in range(len(result)):\n",
    "        n_size_temp = result[rr]['tsne_embedding'].shape[0]\n",
    "        for class_name, class_label in config['class_name_to_label'].items():\n",
    "            ax.scatter(\n",
    "                total_out_embedding[start_from_temp:start_from_temp + n_size_temp][result[rr]['target'] == class_label][:, 0],\n",
    "                total_out_embedding[start_from_temp:start_from_temp + n_size_temp][result[rr]['target'] == class_label][:, 1],\n",
    "                total_out_embedding[start_from_temp:start_from_temp + n_size_temp][result[rr]['target'] == class_label][:, 2],\n",
    "                color=color_map[class_label],\n",
    "                label=class_name if rr == 0 else None,\n",
    "                s=40,\n",
    "                alpha=0.1,\n",
    "                zorder=2)\n",
    "        start_from_temp += n_size_temp\n",
    "\n",
    "    for k, v in result[r]['target_symptom'].items():\n",
    "        ax.scatter(\n",
    "            total_out_embedding[start_from:start_from + n_size][[*set(v)]][:, 0],\n",
    "            total_out_embedding[start_from:start_from + n_size][[*set(v)]][:, 1],\n",
    "            total_out_embedding[start_from:start_from + n_size][[*set(v)]][:, 2],\n",
    "            label=k,\n",
    "            s=40,\n",
    "            alpha=0.8,\n",
    "            edgecolors='k',\n",
    "            zorder=2)\n",
    "    start_from += n_size\n",
    "    \n",
    "    ax.set_title(f\"t-SNE embedding of {result[r]['name']}\")\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52626dc8-251d-445d-8851-f270206d1977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b00f55-ec49-4677-a01f-da597329ca3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fae016-748f-4d4e-acad-92826c9cfc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfddec9-503c-49e2-8a59-8ca2e0c1187a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d9e7b49-eb04-44e4-83fa-924c09e8b6cf",
   "metadata": {},
   "source": [
    "## Same data and different augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985ebef9-fb8f-4c58-9e17-b0909eaa6a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_time_result = []\n",
    "for t in range(4):\n",
    "    time_result = [{'name': 'Train Dataset', 'loader': train_loader}, \n",
    "                   {'name': 'Validation Dataset', 'loader': val_loader}, \n",
    "                   {'name': 'Test Dataset', 'loader': test_loader}]\n",
    "\n",
    "    for r in range(len(time_result)):\n",
    "        target_symptom = {'mci_amnestic_ef': [], 'mci_amnestic_rf': []}\n",
    "        name = time_result[r]['name']\n",
    "        loader = time_result[r]['loader']\n",
    "\n",
    "        for i, sample_batched in enumerate(loader):\n",
    "            if i == 0:\n",
    "                crop_multiple = config['crop_multiple']\n",
    "                minibatch_size = loader.batch_size\n",
    "\n",
    "            # estimate\n",
    "            e, y = compute_embedding(model, sample_batched, config['preprocess_test'], crop_multiple, \n",
    "                                     target_from_last=target_from_last)\n",
    "\n",
    "            if i == 0:\n",
    "                embedding = e.detach().cpu().numpy()\n",
    "                target = y.detach().cpu().numpy()\n",
    "            else:\n",
    "                embedding = np.concatenate([embedding, e.detach().cpu().numpy()], axis=0)\n",
    "                target = np.concatenate([target, y.detach().cpu().numpy()], axis=0)\n",
    "\n",
    "        time_result[r]['embedding'] = embedding\n",
    "        time_result[r]['target'] = target\n",
    "        time_result[r]['target_symptom'] = target_symptom\n",
    "    \n",
    "    multi_time_result.append(time_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e35b13-a90f-4445-bb4c-cec921478a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_transform = TSNE(n_components=2, init=\"pca\", learning_rate=\"auto\", perplexity=80.0,\n",
    "                      n_iter=15000, n_iter_without_progress=1000, n_jobs=2, random_state=0,)\n",
    "\n",
    "multi_time_total_out_embedding = []\n",
    "\n",
    "for time_result in multi_time_result:\n",
    "    for r in time_result:\n",
    "        multi_time_total_out_embedding.append(r['embedding'])\n",
    "\n",
    "multi_time_total_out_embedding = tsne_transform.fit_transform(np.concatenate(multi_time_total_out_embedding))\n",
    "print(multi_time_total_out_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda69b3-52f7-461f-ba34-b4c6f8da1432",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default') \n",
    "plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams.update({'font.family': 'Arial'})\n",
    "# plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "\n",
    "color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "start_from = 0\n",
    "for rr in range(len(time_result)):\n",
    "    n_size = time_result[rr]['embedding'].shape[0]\n",
    "    for class_name, class_label in config['class_name_to_label'].items():\n",
    "        ax.scatter(\n",
    "            multi_time_total_out_embedding[start_from:start_from + n_size][time_result[rr]['target'] == class_label][:, 0],\n",
    "            multi_time_total_out_embedding[start_from:start_from + n_size][time_result[rr]['target'] == class_label][:, 1],\n",
    "            color=color_map[class_label],\n",
    "            alpha=0.05,\n",
    "            edgecolors='k',\n",
    "            zorder=2)\n",
    "    start_from += n_size\n",
    "\n",
    "start_from = 0\n",
    "for time_result in multi_time_result:\n",
    "    for rr in range(len(time_result)):\n",
    "        n_size = time_result[rr]['embedding'].shape[0]\n",
    "        for class_name, class_label in config['class_name_to_label'].items():\n",
    "            ax.scatter(\n",
    "                multi_time_total_out_embedding[start_from:start_from + n_size][time_result[rr]['target'] == class_label][3, 0],\n",
    "                multi_time_total_out_embedding[start_from:start_from + n_size][time_result[rr]['target'] == class_label][3, 1],\n",
    "                color=color_map[class_label],\n",
    "                alpha=0.5,\n",
    "                edgecolors='k',\n",
    "                zorder=2)\n",
    "        start_from += n_size\n",
    "    \n",
    "ax.set_title(f\"t-SNE embedding by different augmentation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
