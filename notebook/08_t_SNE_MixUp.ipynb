{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed1e2f8a-32b4-46b1-a00a-382644e90504",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# t-SNE visualization\n",
    "\n",
    "This notebook visualizes the EEG embeddings computed by the model trained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdbc4ee-d024-4025-84fb-d18dfa1410d7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df587e38-b1a9-42c8-9b50-680200a9bec7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minjae\\Desktop\\EEG_Project\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb41bf8-1713-4228-b799-0e1c87545a16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import pprint\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_script import build_dataset_for_train\n",
    "import models\n",
    "from train.evaluate import check_accuracy\n",
    "from train.evaluate import check_accuracy_extended\n",
    "from train.evaluate import check_accuracy_extended_debug\n",
    "from train.evaluate import check_accuracy_multicrop\n",
    "from train.evaluate import check_accuracy_multicrop_extended\n",
    "from train.visualize import draw_roc_curve\n",
    "from train.visualize import draw_confusion, draw_confusion2\n",
    "from train.visualize import draw_class_wise_metrics\n",
    "from train.visualize import draw_error_table\n",
    "from train.visualize import annotate_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "309eed9b-2c31-4398-a141-e1787453814a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.0+cu117\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bffc0b0-30bc-4b63-908e-03a68c3da0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other settings\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # cleaner text\n",
    "\n",
    "plt.style.use('default') \n",
    "# ['Solarize_Light2', '_classic_test_patch', 'bmh', 'classic', 'dark_background', 'fast', \n",
    "#  'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn', 'seaborn-bright', 'seaborn-colorblind', \n",
    "#  'seaborn-dark', 'seaborn-dark-palette', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', \n",
    "#  'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', \n",
    "#  'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'tableau-colorblind10']\n",
    "\n",
    "plt.rcParams['image.interpolation'] = 'bicubic'\n",
    "plt.rcParams[\"font.family\"] = 'Helvetica' # 'NanumGothic' # for Hangul in Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c5390-f093-4a4c-9c72-2f16f9d42fde",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "-----\n",
    "\n",
    "## Load the configuration used during the train phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a0f3c94-0bbb-42ef-ab92-df07e2964087",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model_state', 'config', 'optimizer_state', 'scheduler_state'])\n"
     ]
    }
   ],
   "source": [
    "# VGG\n",
    "# model_name = 'lo88puq7'  # mixup o, awgn o\n",
    "# model_name = '1nu3jagp'  # mixup x, awgn x\n",
    "# model_name = '1mwdhqbz'  # mixup x, awgn x, dropout x\n",
    "\n",
    "# ResNet\n",
    "# model_name = 'l8524nml'  # mixup o, awgn o\n",
    "model_name = 'ph0mix3b'    # mixup x, awgn o, dropout x\n",
    "# model_name = '2apj72km'  # mixup x, awgn o\n",
    "# model_name = '2k8xomy6'  # mixup x, awgn x\n",
    "\n",
    "\n",
    "model_path = os.path.join(r'E:\\CAUEEG\\checkpoint', model_name, 'checkpoint.pt')\n",
    "mix_repeat = 3\n",
    "\n",
    "save_fig = True\n",
    "output_folder = './local/output/mixup_tsne'\n",
    "\n",
    "ckpt = torch.load(model_path, map_location=device)\n",
    "print(ckpt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "069adca8-f2f7-446f-ba09-87f6f5f64d8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_state = ckpt['model_state']\n",
    "config = ckpt['config']\n",
    "optimizer = ckpt['optimizer_state']\n",
    "scheduler = ckpt['scheduler_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca4a490d-9f3b-42b7-a1ef-4605f5eae262",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EKG': 'O',\n",
      " '_target_': 'models.resnet_1d.ResNet1D',\n",
      " 'activation': 'gelu',\n",
      " 'age_mean': tensor([71.2768], device='cuda:0'),\n",
      " 'age_std': tensor([9.7251], device='cuda:0'),\n",
      " 'awgn': 0,\n",
      " 'awgn_age': 0,\n",
      " 'base_channels': 64,\n",
      " 'base_lr': 0.00033918432381593736,\n",
      " 'block': 'basic',\n",
      " 'class_label_to_name': ['Normal', 'MCI', 'Dementia'],\n",
      " 'class_name_to_label': {'Dementia': 2, 'MCI': 1, 'Normal': 0},\n",
      " 'conv_layers': [2, 2, 2, 2],\n",
      " 'criterion': 'multi-bce',\n",
      " 'crop_multiple': 4,\n",
      " 'crop_timing_analysis': False,\n",
      " 'cwd': 'C:\\\\Users\\\\Minjae\\\\Desktop\\\\EEG_Project',\n",
      " 'dataset_name': 'CAUEEG dataset',\n",
      " 'dataset_path': 'local/dataset/02_Curated_Data_220419/',\n",
      " 'ddp': False,\n",
      " 'device': device(type='cuda'),\n",
      " 'draw_result': True,\n",
      " 'dropout': 0,\n",
      " 'fc_stages': 3,\n",
      " 'file_format': 'memmap',\n",
      " 'in_channels': 21,\n",
      " 'input_norm': 'dataset',\n",
      " 'iterations': 195312,\n",
      " 'latency': 2000,\n",
      " 'load_event': False,\n",
      " 'lr_scheduler_type': 'cosine_decay_with_warmup_half',\n",
      " 'mgn': 0,\n",
      " 'minibatch': 512,\n",
      " 'mixup': 0,\n",
      " 'model': '1D-ResNet-18',\n",
      " 'multi_batch_size': 64,\n",
      " 'num_history': 500,\n",
      " 'num_params': 11394051,\n",
      " 'out_dims': 3,\n",
      " 'output_length': 8,\n",
      " 'photic': 'O',\n",
      " 'preprocess_test': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda'))\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2768], device='cuda:0'), std=tensor([9.7251], device='cuda:0'), eps=1e-08, std_eps=tensor([9.7251], device='cuda:0'))\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([[[ 0.0423],\n",
      "           [-0.0214],\n",
      "           [-0.0237],\n",
      "           [ 0.0370],\n",
      "           [ 0.0544],\n",
      "           [ 0.1645],\n",
      "           [ 0.0481],\n",
      "           [ 0.0047],\n",
      "           [ 0.0140],\n",
      "           [ 0.0288],\n",
      "           [-0.0025],\n",
      "           [-0.0005],\n",
      "           [ 0.0262],\n",
      "           [-0.0635],\n",
      "           [-0.0125],\n",
      "           [-0.0060],\n",
      "           [ 0.0212],\n",
      "           [-0.0593],\n",
      "           [-0.0409],\n",
      "           [ 0.0075],\n",
      "           [-0.0098]]], device='cuda:0'), std=tensor([[[44.7590],\n",
      "           [20.5848],\n",
      "           [11.9388],\n",
      "           [11.9315],\n",
      "           [15.8824],\n",
      "           [47.9627],\n",
      "           [20.0782],\n",
      "           [10.7304],\n",
      "           [11.7056],\n",
      "           [15.9134],\n",
      "           [20.9704],\n",
      "           [14.6276],\n",
      "           [14.0635],\n",
      "           [22.1878],\n",
      "           [16.9503],\n",
      "           [15.1123],\n",
      "           [19.6405],\n",
      "           [11.6111],\n",
      "           [11.8943],\n",
      "           [93.4007],\n",
      "           [69.3012]]], device='cuda:0'), eps=1e-08, std_eps=tensor([[[44.7590],\n",
      "           [20.5848],\n",
      "           [11.9388],\n",
      "           [11.9315],\n",
      "           [15.8824],\n",
      "           [47.9627],\n",
      "           [20.0782],\n",
      "           [10.7304],\n",
      "           [11.7056],\n",
      "           [15.9134],\n",
      "           [20.9704],\n",
      "           [14.6276],\n",
      "           [14.0635],\n",
      "           [22.1878],\n",
      "           [16.9503],\n",
      "           [15.1123],\n",
      "           [19.6405],\n",
      "           [11.6111],\n",
      "           [11.8943],\n",
      "           [93.4007],\n",
      "           [69.3012]]], device='cuda:0'))\n",
      "),\n",
      " 'preprocess_train': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda'))\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2768], device='cuda:0'), std=tensor([9.7251], device='cuda:0'), eps=1e-08, std_eps=tensor([9.7251], device='cuda:0'))\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([[[ 0.0423],\n",
      "           [-0.0214],\n",
      "           [-0.0237],\n",
      "           [ 0.0370],\n",
      "           [ 0.0544],\n",
      "           [ 0.1645],\n",
      "           [ 0.0481],\n",
      "           [ 0.0047],\n",
      "           [ 0.0140],\n",
      "           [ 0.0288],\n",
      "           [-0.0025],\n",
      "           [-0.0005],\n",
      "           [ 0.0262],\n",
      "           [-0.0635],\n",
      "           [-0.0125],\n",
      "           [-0.0060],\n",
      "           [ 0.0212],\n",
      "           [-0.0593],\n",
      "           [-0.0409],\n",
      "           [ 0.0075],\n",
      "           [-0.0098]]], device='cuda:0'), std=tensor([[[44.7590],\n",
      "           [20.5848],\n",
      "           [11.9388],\n",
      "           [11.9315],\n",
      "           [15.8824],\n",
      "           [47.9627],\n",
      "           [20.0782],\n",
      "           [10.7304],\n",
      "           [11.7056],\n",
      "           [15.9134],\n",
      "           [20.9704],\n",
      "           [14.6276],\n",
      "           [14.0635],\n",
      "           [22.1878],\n",
      "           [16.9503],\n",
      "           [15.1123],\n",
      "           [19.6405],\n",
      "           [11.6111],\n",
      "           [11.8943],\n",
      "           [93.4007],\n",
      "           [69.3012]]], device='cuda:0'), eps=1e-08, std_eps=tensor([[[44.7590],\n",
      "           [20.5848],\n",
      "           [11.9388],\n",
      "           [11.9315],\n",
      "           [15.8824],\n",
      "           [47.9627],\n",
      "           [20.0782],\n",
      "           [10.7304],\n",
      "           [11.7056],\n",
      "           [15.9134],\n",
      "           [20.9704],\n",
      "           [14.6276],\n",
      "           [14.0635],\n",
      "           [22.1878],\n",
      "           [16.9503],\n",
      "           [15.1123],\n",
      "           [19.6405],\n",
      "           [11.6111],\n",
      "           [11.8943],\n",
      "           [93.4007],\n",
      "           [69.3012]]], device='cuda:0'))\n",
      "),\n",
      " 'project': 'caueeg-task2-ablation',\n",
      " 'run_mode': 'train',\n",
      " 'save_model': True,\n",
      " 'search_lr': True,\n",
      " 'search_multiplier': 1.0,\n",
      " 'seed': 1,\n",
      " 'seq_length': 2000,\n",
      " 'signal_header': ['Fp1-AVG', 'F3-AVG', 'C3-AVG', 'P3-AVG', 'O1-AVG', 'Fp2-AVG', 'F4-AVG', 'C4-AVG', 'P4-AVG', 'O2-AVG', 'F7-AVG', 'T3-AVG', 'T5-AVG', 'F8-AVG', 'T4-AVG', 'T6-AVG', 'FZ-AVG', 'CZ-AVG', 'PZ-AVG', 'EKG', 'Photic'],\n",
      " 'signal_length_limit': 10000000,\n",
      " 'signal_mean': tensor([[[ 0.0423],\n",
      "         [-0.0214],\n",
      "         [-0.0237],\n",
      "         [ 0.0370],\n",
      "         [ 0.0544],\n",
      "         [ 0.1645],\n",
      "         [ 0.0481],\n",
      "         [ 0.0047],\n",
      "         [ 0.0140],\n",
      "         [ 0.0288],\n",
      "         [-0.0025],\n",
      "         [-0.0005],\n",
      "         [ 0.0262],\n",
      "         [-0.0635],\n",
      "         [-0.0125],\n",
      "         [-0.0060],\n",
      "         [ 0.0212],\n",
      "         [-0.0593],\n",
      "         [-0.0409],\n",
      "         [ 0.0075],\n",
      "         [-0.0098]]], device='cuda:0'),\n",
      " 'signal_std': tensor([[[44.7590],\n",
      "         [20.5848],\n",
      "         [11.9388],\n",
      "         [11.9315],\n",
      "         [15.8824],\n",
      "         [47.9627],\n",
      "         [20.0782],\n",
      "         [10.7304],\n",
      "         [11.7056],\n",
      "         [15.9134],\n",
      "         [20.9704],\n",
      "         [14.6276],\n",
      "         [14.0635],\n",
      "         [22.1878],\n",
      "         [16.9503],\n",
      "         [15.1123],\n",
      "         [19.6405],\n",
      "         [11.6111],\n",
      "         [11.8943],\n",
      "         [93.4007],\n",
      "         [69.3012]]], device='cuda:0'),\n",
      " 'task': 'dementia',\n",
      " 'task_description': 'Classification of [Normal], [MCI], and [Dementia] symptoms.',\n",
      " 'task_name': 'CAUEEG-Dementia benchmark',\n",
      " 'test_crop_multiple': 8,\n",
      " 'total_samples': 100000000.0,\n",
      " 'transform': Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=4, latency=2000, segment_simulation=False, return_timing=False)\n",
      "    EegToTensor()\n",
      "),\n",
      " 'transform_multicrop': Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=8, latency=2000, segment_simulation=False, return_timing=False)\n",
      "    EegToTensor()\n",
      "),\n",
      " 'use_age': 'conv',\n",
      " 'use_wandb': True,\n",
      " 'warmup_min': 3000,\n",
      " 'warmup_ratio': 0.05,\n",
      " 'warmup_steps': 9766,\n",
      " 'watch_model': False,\n",
      " 'weight_decay': 0.04394746639552375}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(config, width=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7877675-9feb-4175-8f54-946a29044648",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load the target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "322201e6-3a07-48f9-a871-c4a44129e8f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = config['generator'](**config).to(device)\n",
    "model = hydra.utils.instantiate(config).to(device)\n",
    "\n",
    "if config.get('ddp', False):\n",
    "    model_state_ddp = deepcopy(model_state)\n",
    "    model_state = OrderedDict()\n",
    "    for k, v in model_state_ddp.items():\n",
    "        name = k[7:] # remove 'module.' of DataParallel/DistributedDataParallel\n",
    "        model_state[name] = v\n",
    "        \n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab33f903-bbbe-49c1-9fc2-49ce8ee26cff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Evaluate the model and analyze the performance by the crop timing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d827eb6-53f2-4aa0-909c-972dcf33c6d5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "427aeb6b-5fef-411c-b69a-5fb4413483ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = ckpt['config']\n",
    "\n",
    "config.pop('cwd', 0)\n",
    "config['ddp'] = False\n",
    "config['crop_timing_analysis'] = True\n",
    "config['eval'] = True\n",
    "config['crop_multiple'] = 32\n",
    "config['device'] = device\n",
    "\n",
    "target_from_last = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527fc407-9f18-4329-a551-c85ec26a0727",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b1d9aa9-fbc5-4d4a-8a7f-8e8fbd4675dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform: Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=32, latency=2000, segment_simulation=False, return_timing=True, reject_events=False)\n",
      "    EegDropChannels(drop_index=[])\n",
      "    EegToTensor()\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "transform_multicrop: Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=8, latency=2000, segment_simulation=False, return_timing=True, reject_events=False)\n",
      "    EegDropChannels(drop_index=[])\n",
      "    EegToTensor()\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "task config:\n",
      "{'class_label_to_name': ['Normal', 'MCI', 'Dementia'],\n",
      " 'class_name_to_label': {'Dementia': 2, 'MCI': 1, 'Normal': 0},\n",
      " 'task_description': 'Classification of [Normal], [MCI], and [Dementia] '\n",
      "                     'symptoms.',\n",
      " 'task_name': 'CAUEEG-Dementia benchmark'}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "train_dataset[0].keys():\n",
      "dict_keys(['serial', 'age', 'symptom', 'class_name', 'class_label', 'signal', 'crop_timing'])\n",
      "train signal shape: torch.Size([21, 2000])\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "val_dataset[0].keys():\n",
      "dict_keys(['serial', 'age', 'symptom', 'class_name', 'class_label', 'signal', 'crop_timing'])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_dataset[0].keys():\n",
      "dict_keys(['serial', 'age', 'symptom', 'class_name', 'class_label', 'signal', 'crop_timing'])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_dataset[0].keys():\n",
      "dict_keys(['serial', 'age', 'symptom', 'class_name', 'class_label', 'signal', 'crop_timing'])\n",
      "test signal shape: torch.Size([21, 2000])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "preprocess_train: Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda'))\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2768], device='cuda:0'), std=tensor([9.7251], device='cuda:0'), eps=1e-08, std_eps=tensor([9.7251], device='cuda:0'))\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([[[ 0.0423],\n",
      "           [-0.0214],\n",
      "           [-0.0237],\n",
      "           [ 0.0370],\n",
      "           [ 0.0544],\n",
      "           [ 0.1645],\n",
      "           [ 0.0481],\n",
      "           [ 0.0047],\n",
      "           [ 0.0140],\n",
      "           [ 0.0288],\n",
      "           [-0.0025],\n",
      "           [-0.0005],\n",
      "           [ 0.0262],\n",
      "           [-0.0635],\n",
      "           [-0.0125],\n",
      "           [-0.0060],\n",
      "           [ 0.0212],\n",
      "           [-0.0593],\n",
      "           [-0.0409],\n",
      "           [ 0.0075],\n",
      "           [-0.0098]]], device='cuda:0'), std=tensor([[[44.7590],\n",
      "           [20.5848],\n",
      "           [11.9388],\n",
      "           [11.9315],\n",
      "           [15.8824],\n",
      "           [47.9627],\n",
      "           [20.0782],\n",
      "           [10.7304],\n",
      "           [11.7056],\n",
      "           [15.9134],\n",
      "           [20.9704],\n",
      "           [14.6276],\n",
      "           [14.0635],\n",
      "           [22.1878],\n",
      "           [16.9503],\n",
      "           [15.1123],\n",
      "           [19.6405],\n",
      "           [11.6111],\n",
      "           [11.8943],\n",
      "           [93.4007],\n",
      "           [69.3012]]], device='cuda:0'), eps=1e-08, std_eps=tensor([[[44.7590],\n",
      "           [20.5848],\n",
      "           [11.9388],\n",
      "           [11.9315],\n",
      "           [15.8824],\n",
      "           [47.9627],\n",
      "           [20.0782],\n",
      "           [10.7304],\n",
      "           [11.7056],\n",
      "           [15.9134],\n",
      "           [20.9704],\n",
      "           [14.6276],\n",
      "           [14.0635],\n",
      "           [22.1878],\n",
      "           [16.9503],\n",
      "           [15.1123],\n",
      "           [19.6405],\n",
      "           [11.6111],\n",
      "           [11.8943],\n",
      "           [93.4007],\n",
      "           [69.3012]]], device='cuda:0'))\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "preprocess_test: Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda'))\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2768], device='cuda:0'), std=tensor([9.7251], device='cuda:0'), eps=1e-08, std_eps=tensor([9.7251], device='cuda:0'))\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([[[ 0.0423],\n",
      "           [-0.0214],\n",
      "           [-0.0237],\n",
      "           [ 0.0370],\n",
      "           [ 0.0544],\n",
      "           [ 0.1645],\n",
      "           [ 0.0481],\n",
      "           [ 0.0047],\n",
      "           [ 0.0140],\n",
      "           [ 0.0288],\n",
      "           [-0.0025],\n",
      "           [-0.0005],\n",
      "           [ 0.0262],\n",
      "           [-0.0635],\n",
      "           [-0.0125],\n",
      "           [-0.0060],\n",
      "           [ 0.0212],\n",
      "           [-0.0593],\n",
      "           [-0.0409],\n",
      "           [ 0.0075],\n",
      "           [-0.0098]]], device='cuda:0'), std=tensor([[[44.7590],\n",
      "           [20.5848],\n",
      "           [11.9388],\n",
      "           [11.9315],\n",
      "           [15.8824],\n",
      "           [47.9627],\n",
      "           [20.0782],\n",
      "           [10.7304],\n",
      "           [11.7056],\n",
      "           [15.9134],\n",
      "           [20.9704],\n",
      "           [14.6276],\n",
      "           [14.0635],\n",
      "           [22.1878],\n",
      "           [16.9503],\n",
      "           [15.1123],\n",
      "           [19.6405],\n",
      "           [11.6111],\n",
      "           [11.8943],\n",
      "           [93.4007],\n",
      "           [69.3012]]], device='cuda:0'), eps=1e-08, std_eps=tensor([[[44.7590],\n",
      "           [20.5848],\n",
      "           [11.9388],\n",
      "           [11.9315],\n",
      "           [15.8824],\n",
      "           [47.9627],\n",
      "           [20.0782],\n",
      "           [10.7304],\n",
      "           [11.7056],\n",
      "           [15.9134],\n",
      "           [20.9704],\n",
      "           [14.6276],\n",
      "           [14.0635],\n",
      "           [22.1878],\n",
      "           [16.9503],\n",
      "           [15.1123],\n",
      "           [19.6405],\n",
      "           [11.6111],\n",
      "           [11.8943],\n",
      "           [93.4007],\n",
      "           [69.3012]]], device='cuda:0'))\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "0 torch.Size([512, 21, 2000]) torch.Size([512]) torch.Size([512])\n",
      "1 torch.Size([512, 21, 2000]) torch.Size([512]) torch.Size([512])\n",
      "2 torch.Size([512, 21, 2000]) torch.Size([512]) torch.Size([512])\n",
      "3 torch.Size([512, 21, 2000]) torch.Size([512]) torch.Size([512])\n",
      "4 torch.Size([512, 21, 2000]) torch.Size([512]) torch.Size([512])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if '220419' in config['dataset_path']:\n",
    "    config['dataset_path'] = './local/dataset/caueeg-dataset/'\n",
    "    \n",
    "train_loader, val_loader, test_loader, multicrop_test_loader = build_dataset_for_train(config, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3194f85f-b580-41dd-a75a-646937e51895",
   "metadata": {},
   "source": [
    "## Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cf305ec-becd-4b3e-998d-649ddbb34b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = check_accuracy_extended_debug(model, test_loader, \n",
    "#                                   config['preprocess_test'], config, repeat=50)\n",
    "# test_acc = _[0]\n",
    "# test_score = _[1]\n",
    "# test_target = _[2]\n",
    "# test_confusion = _[3]\n",
    "# test_error_table = _[4]\n",
    "# test_crop_timing = _[5]\n",
    "\n",
    "# print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9469ef7-008c-405d-8966-840249f59344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_roc_curve(test_score, test_target, config['class_label_to_name'], use_wandb=False)\n",
    "# draw_confusion(test_confusion, config['class_label_to_name'], use_wandb=False)\n",
    "# draw_class_wise_metrics(test_confusion, config['class_label_to_name'], use_wandb=False)\n",
    "# draw_error_table(test_error_table, use_wandb=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dfce23-e2a8-43e7-ade1-dd29ac255f85",
   "metadata": {},
   "source": [
    "## t-SNE embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf875389-0084-4e44-98e3-eae37d63bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_embedding(model, sample_batched, preprocess, crop_multiple, target_from_last):\n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # preprocessing (this includes to-device operation)\n",
    "    preprocess(sample_batched)\n",
    "\n",
    "    # apply model on whole batch directly on device\n",
    "    x = sample_batched['signal']\n",
    "    age = sample_batched['age']\n",
    "    e = model.compute_feature_embedding(x, age, target_from_last=target_from_last)\n",
    "    y = sample_batched['class_label']\n",
    "    \n",
    "    if crop_multiple > 1:\n",
    "        # multi-crop averaging\n",
    "        if e.size(0) % crop_multiple != 0:\n",
    "            raise ValueError(f\"compute_embedding(): Real minibatch size={e.size(0)} is not multiple of \"\n",
    "                             f\"crop_multiple={crop_multiple}.\")\n",
    "\n",
    "        real_minibatch = e.size(0) // crop_multiple\n",
    "        e_ = torch.zeros((real_minibatch, e.size(1)))\n",
    "        y_ = torch.zeros((real_minibatch,), dtype=torch.int32)\n",
    "\n",
    "        for m in range(real_minibatch):\n",
    "            e_[m] = e[crop_multiple*m:crop_multiple*(m + 1)].mean(dim=0, keepdims=True)\n",
    "            y_[m] = y[crop_multiple*m]\n",
    "                \n",
    "        e = e_\n",
    "        y = y_\n",
    "    \n",
    "    return e, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "168d61d3-104a-4787-ba91-bb5a92d0ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, age, y, alpha=0, use_cuda=True):\n",
    "    lam = np.random.beta(alpha, alpha) if alpha > 1e-12 else 1\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    mixed_age = lam * age + (1 - lam) * age[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, mixed_age, y_a, y_b, lam, index1\n",
    "\n",
    "def mixup_data_lam(x, age, y, lam=0.5, use_cuda=True):\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    mixed_age = lam * age + (1 - lam) * age[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, mixed_age, y_a, y_b, lam, index\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_mixup_embedding(model, sample_batched, preprocess, crop_multiple, mixup_alpha, target_from_last):\n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # preprocessing (this includes to-device operation)\n",
    "    preprocess(sample_batched)\n",
    "\n",
    "    # apply model on whole batch directly on device\n",
    "    x = sample_batched['signal']\n",
    "    age = sample_batched['age']\n",
    "    y = sample_batched['class_label']\n",
    "\n",
    "    # x, age, y1, y2, lam, mixup_index = mixup_data(x, age, y, mixup_alpha)\n",
    "    x, age, y1, y2, lam, mixup_index = mixup_data_lam(x, age, y, lam=0.5)\n",
    "    e = model.compute_feature_embedding(x, age, target_from_last=target_from_last)\n",
    "    y = torch.concatenate((y1.unsqueeze(dim=-1), y2.unsqueeze(dim=-1)), axis=-1)\n",
    "    \n",
    "    if crop_multiple > 1:\n",
    "        # multi-crop averaging\n",
    "        if e.size(0) % crop_multiple != 0:\n",
    "            raise ValueError(f\"compute_embedding(): Real minibatch size={e.size(0)} is not multiple of \"\n",
    "                             f\"crop_multiple={crop_multiple}.\")\n",
    "\n",
    "        real_minibatch = e.size(0) // crop_multiple\n",
    "        e_ = torch.zeros((real_minibatch, e.size(1)))\n",
    "        y_ = torch.zeros((real_minibatch, y.size(1)), dtype=torch.int32)\n",
    "\n",
    "        for m in range(real_minibatch):\n",
    "            e_[m] = e[crop_multiple*m:crop_multiple*(m + 1)].mean(dim=0, keepdims=True)\n",
    "            y_[m] = y[crop_multiple*m]\n",
    "                \n",
    "        e = e_\n",
    "        y = y_\n",
    "    \n",
    "    return e, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d28b639-c84a-4ad3-80d7-9b862912b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [{'name': 'Train Dataset', 'loader': train_loader}]\n",
    "\n",
    "for r in range(len(result)):\n",
    "    name = result[r]['name']\n",
    "    loader = result[r]['loader']\n",
    "\n",
    "    for i, sample_batched in enumerate(loader):\n",
    "        if i == 0:\n",
    "            crop_multiple = config['crop_multiple']\n",
    "            minibatch_size = loader.batch_size\n",
    "\n",
    "        # estimate\n",
    "        e, y = compute_embedding(model, sample_batched, config['preprocess_test'], crop_multiple, target_from_last=target_from_last)\n",
    "\n",
    "        if i == 0:\n",
    "            embedding = e.detach().cpu().numpy()\n",
    "            target = y.detach().cpu().numpy()\n",
    "        else:\n",
    "            embedding = np.concatenate([embedding, e.detach().cpu().numpy()], axis=0)\n",
    "            target = np.concatenate([target, y.detach().cpu().numpy()], axis=0)     \n",
    "                    \n",
    "    result[r]['embedding'] = embedding\n",
    "    result[r]['target'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2a1c7ce-c99c-4bbd-8bc6-1253f568e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixup_result = [{'name': 'Train Dataset', 'loader': train_loader}]\n",
    "\n",
    "for r in range(len(mixup_result)):\n",
    "    name = mixup_result[r]['name']\n",
    "    loader = mixup_result[r]['loader']\n",
    "\n",
    "    for m in range(mix_repeat):\n",
    "        for i, sample_batched in enumerate(loader):\n",
    "            if i == 0:\n",
    "                crop_multiple = config['crop_multiple']\n",
    "                minibatch_size = loader.batch_size\n",
    "    \n",
    "            # estimate\n",
    "            e, y = compute_mixup_embedding(model, sample_batched, config['preprocess_test'], crop_multiple, \n",
    "                                           mixup_alpha=config['mixup'], target_from_last=target_from_last)\n",
    "    \n",
    "            if m == 0 and i == 0:\n",
    "                embedding = e.detach().cpu().numpy()\n",
    "                target = y.detach().cpu().numpy()\n",
    "            else:\n",
    "                embedding = np.concatenate([embedding, e.detach().cpu().numpy()], axis=0)  \n",
    "                target = np.concatenate([target, y.detach().cpu().numpy()], axis=0)     \n",
    "                    \n",
    "    mixup_result[r]['embedding'] = embedding\n",
    "    mixup_result[r]['target'] = target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9672d5-d7a1-4f9d-9086-ab0be26be030",
   "metadata": {},
   "source": [
    "## Draw 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b230944-8bce-468a-a560-ea8a65088a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne_transform = TSNE(n_components=2, init=\"pca\", learning_rate=\"auto\", perplexity=50,\n",
    "#                       n_iter=10000, n_iter_without_progress=1000, n_jobs=2, random_state=0,)\n",
    "\n",
    "# for r in range(len(result)):\n",
    "#     output = tsne_transform.fit_transform( np.concatenate([result[r]['embedding'], mixup_result[r]['embedding']]))\n",
    "#     result[r]['tsne_embedding'] = output[:result[r]['embedding'].shape[0]]\n",
    "#     mixup_result[r]['tsne_embedding'] = output[result[r]['embedding'].shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3bc7238-c0d3-498d-9d94-9b20c0e0bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use('default') \n",
    "# plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "# plt.rcParams.update({'font.size': 16})\n",
    "# plt.rcParams.update({'font.family': 'Roboto Slab'})\n",
    "# # plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "# color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "\n",
    "# for r in range(len(result)):\n",
    "#     _, ax = plt.subplots()\n",
    "#     for class_name, class_label in config['class_name_to_label'].items():\n",
    "#         ax.scatter(\n",
    "#             result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 0],\n",
    "#             result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 1],\n",
    "#             label=class_name,\n",
    "#             color=color_map[class_label],\n",
    "#             alpha=0.8,\n",
    "#             edgecolors='k',\n",
    "#             zorder=2)\n",
    "#     ax.set_xticklabels([])\n",
    "#     ax.set_yticklabels([])\n",
    "#     ax.legend(bbox_to_anchor=(1.04, 1), loc='center left', borderaxespad=0.)\n",
    "#     ax.set_title(f\"t-SNE embedding of {result[r]['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6572655d-d120-4659-865b-bd0b12f081d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use('default') \n",
    "# plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "# plt.rcParams.update({'font.size': 16})\n",
    "# plt.rcParams.update({'font.family': 'Roboto Slab'})\n",
    "# # plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "# color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "# color_map2 = [['tab:green', 'tab:brown', 'tab:blue'], \n",
    "#               ['gray', 'tab:orange', 'tab:pink'], \n",
    "#               ['gray', 'gray', 'tab:red']]\n",
    "\n",
    "# for r in range(len(result)):\n",
    "#     _, ax = plt.subplots()\n",
    "#     for class_name, class_label in config['class_name_to_label'].items():\n",
    "#         ax.scatter(\n",
    "#             result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 0],\n",
    "#             result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 1],\n",
    "#             label=class_name,\n",
    "#             color=color_map[class_label],\n",
    "#             alpha=0.2,\n",
    "#             zorder=2)\n",
    "\n",
    "#     for class_name, class_label in config['class_name_to_label'].items():        \n",
    "#         for class_name2, class_label2 in config['class_name_to_label'].items():\n",
    "#             if class_label2 <= class_label:\n",
    "#                 continue\n",
    "#             mixup_idx = np.all(mixup_result[r]['target'] == [class_label, class_label2], axis=-1)\n",
    "#             mixup_idx = mixup_idx | np.all(mixup_result[r]['target'] == [class_label2, class_label], axis=-1)\n",
    "#             ax.scatter(\n",
    "#                 mixup_result[r]['tsne_embedding'][mixup_idx][:, 0],\n",
    "#                 mixup_result[r]['tsne_embedding'][mixup_idx][:, 1],\n",
    "#                 label=f\"mixup of {class_name} and {class_name2}\",\n",
    "#                 color=color_map2[class_label][class_label2],\n",
    "#                 alpha=0.8,\n",
    "#                 edgecolors='k',\n",
    "#                 zorder=2)\n",
    "\n",
    "#     ax.legend(bbox_to_anchor=(1.04, 1), loc='center left', borderaxespad=0.)\n",
    "#     ax.set_xticklabels([])\n",
    "#     ax.set_yticklabels([])\n",
    "#     ax.set_title(f\"t-SNE embedding of {result[r]['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a25d4ffa-a66b-4edb-856e-9d44a9c02fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use('default') \n",
    "# plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "# plt.rcParams.update({'font.size': 16})\n",
    "# plt.rcParams.update({'font.family': 'Roboto Slab'})\n",
    "# plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "# color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "# color_map2 = [['tab:green', 'tab:brown', 'tab:blue'], \n",
    "#               ['gray', 'tab:orange', 'tab:pink'], \n",
    "#               ['gray', 'gray', 'tab:red']]\n",
    "\n",
    "\n",
    "# for n_iter in [7000]:\n",
    "#     for perplexity in [25, 50, 100, 200, 300]:\n",
    "#         tsne_transform = TSNE(n_components=2, init=\"pca\", learning_rate=\"auto\", perplexity=perplexity,\n",
    "#                               n_iter=n_iter, n_iter_without_progress=1000, n_jobs=2, random_state=0,)\n",
    "        \n",
    "#         for r in range(len(result)):\n",
    "#             output = tsne_transform.fit_transform(np.concatenate([result[r]['embedding'], mixup_result[r]['embedding']]))\n",
    "#             result[r]['tsne_embedding'] = output[:result[r]['embedding'].shape[0]]\n",
    "#             mixup_result[r]['tsne_embedding'] = output[result[r]['embedding'].shape[0]:]\n",
    "            \n",
    "#         for r in range(len(result)):\n",
    "#             fig, ax = plt.subplots()\n",
    "#             for class_name, class_label in config['class_name_to_label'].items():\n",
    "#                 ax.scatter(\n",
    "#                     result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 0],\n",
    "#                     result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 1],\n",
    "#                     label=class_name,\n",
    "#                     color=color_map[class_label],\n",
    "#                     alpha=0.8,\n",
    "#                     edgecolors='k',\n",
    "#                     zorder=2)\n",
    "#             ax.set_xticklabels([])\n",
    "#             ax.set_yticklabels([])\n",
    "#             ax.legend(bbox_to_anchor=(1.04, 0.5), loc='center left', borderaxespad=0.)\n",
    "#             if save_fig:\n",
    "#                 for ext in ['pdf', 'jpg', 'svg']:\n",
    "#                     os.makedirs(os.path.join(output_folder, model_name, ext), exist_ok=True)\n",
    "#                     fig.savefig(os.path.join(output_folder, model_name, ext, f\"dim2_per{perplexity:03}_iter{n_iter:05}_ori.{ext}\"), \n",
    "#                                 transparent=True, bbox_inches='tight')\n",
    "#             else:\n",
    "#                 plt.show()\n",
    "#             fig.clear()\n",
    "#             plt.close(fig)\n",
    "            \n",
    "#         for r in range(len(result)):\n",
    "#             fig, ax = plt.subplots()\n",
    "#             for class_name, class_label in config['class_name_to_label'].items():\n",
    "#                 ax.scatter(\n",
    "#                     result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 0],\n",
    "#                     result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 1],\n",
    "#                     label=class_name,\n",
    "#                     color=color_map[class_label],\n",
    "#                     alpha=0.2,\n",
    "#                     zorder=2)        \n",
    "                \n",
    "#             for class_name, class_label in config['class_name_to_label'].items():        \n",
    "#                 for class_name2, class_label2 in config['class_name_to_label'].items():\n",
    "#                     if class_label2 <= class_label:\n",
    "#                         continue\n",
    "#                     mixup_idx = np.all(mixup_result[r]['target'] == [class_label, class_label2], axis=-1)\n",
    "#                     mixup_idx = mixup_idx | np.all(mixup_result[r]['target'] == [class_label2, class_label], axis=-1)\n",
    "#                     ax.scatter(\n",
    "#                         mixup_result[r]['tsne_embedding'][mixup_idx][:, 0],\n",
    "#                         mixup_result[r]['tsne_embedding'][mixup_idx][:, 1],\n",
    "#                         label=f\"mixup of {class_name} and {class_name2}\",\n",
    "#                         color=color_map2[class_label][class_label2],\n",
    "#                         alpha=0.8,\n",
    "#                         edgecolors='k',\n",
    "#                         zorder=2)\n",
    "        \n",
    "#             ax.set_xticklabels([])\n",
    "#             ax.set_yticklabels([])\n",
    "#             ax.legend(bbox_to_anchor=(1.04, 0.5), loc='center left', borderaxespad=0.)\n",
    "#             if save_fig:\n",
    "#                 for ext in ['pdf', 'jpg', 'svg']:\n",
    "#                     os.makedirs(os.path.join(output_folder, model_name, ext), exist_ok=True)\n",
    "#                     fig.savefig(os.path.join(output_folder, model_name, ext, f\"dim2_per{perplexity:03}_iter{n_iter:05}.{ext}\"), \n",
    "#                                 transparent=True, bbox_inches='tight')\n",
    "#             else:\n",
    "#                 plt.show()\n",
    "#             fig.clear()\n",
    "#             plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b50bfd7-3d49-4bf4-95dc-fa923d9c5328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use('default') \n",
    "# plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "# plt.rcParams.update({'font.size': 16})\n",
    "# plt.rcParams.update({'font.family': 'Roboto Slab'})\n",
    "# plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "# color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "# color_map2 = [['tab:green', 'tab:brown', 'tab:blue'], \n",
    "#               ['gray', 'tab:orange', 'tab:pink'], \n",
    "#               ['gray', 'gray', 'tab:red']]\n",
    "\n",
    "\n",
    "# for n_iter in [7000]:\n",
    "#     for perplexity in [25, 50, 100, 200, 300]:\n",
    "#         tsne_transform = TSNE(n_components=2, init=\"pca\", learning_rate=\"auto\", perplexity=perplexity,\n",
    "#                               n_iter=n_iter, n_iter_without_progress=1000, n_jobs=2, random_state=0,)\n",
    "        \n",
    "#         for r in range(len(result)):\n",
    "#             N = result[r]['embedding'].shape[0]\n",
    "#             output = tsne_transform.fit_transform( np.concatenate([result[r]['embedding'], \n",
    "#                                                                    mixup_result[r]['embedding'][:N]]))\n",
    "#             result[r]['tsne_embedding'] = output[:result[r]['embedding'].shape[0]]\n",
    "#             mixup_result[r]['tsne_embedding'] = output[result[r]['embedding'].shape[0]:]\n",
    "\n",
    "#         for r in range(len(result)):\n",
    "#             fig, ax = plt.subplots()\n",
    "#             for class_name, class_label in config['class_name_to_label'].items():\n",
    "#                 ax.scatter(\n",
    "#                     result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 0],\n",
    "#                     result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 1],\n",
    "#                     label=class_name,\n",
    "#                     color=color_map[class_label],\n",
    "#                     alpha=0.8,\n",
    "#                     edgecolors='k',\n",
    "#                     zorder=2)\n",
    "#             ax.set_xticklabels([])\n",
    "#             ax.set_yticklabels([])\n",
    "#             ax.legend(bbox_to_anchor=(1.04, 0.5), loc='center left', borderaxespad=0.)\n",
    "#             if save_fig:\n",
    "#                 for ext in ['pdf', 'jpg', 'svg']:\n",
    "#                     os.makedirs(os.path.join(output_folder, model_name, ext), exist_ok=True)\n",
    "#                     fig.savefig(os.path.join(output_folder, model_name, ext, f\"dim2_per{perplexity:03}_iter{n_iter:05}_ori.{ext}\"), \n",
    "#                                 transparent=True, bbox_inches='tight')\n",
    "#             else:\n",
    "#                 plt.show()\n",
    "#             fig.clear()\n",
    "#             plt.close(fig)\n",
    "            \n",
    "#         for r in range(len(result)):\n",
    "#             fig, ax = plt.subplots()\n",
    "#             for class_name, class_label in config['class_name_to_label'].items():\n",
    "#                 ax.scatter(\n",
    "#                     result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 0],\n",
    "#                     result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 1],\n",
    "#                     label=class_name,\n",
    "#                     color=color_map[class_label],\n",
    "#                     alpha=0.2,\n",
    "#                     zorder=2)\n",
    "        \n",
    "#             N = result[r]['embedding'].shape[0]\n",
    "#             for class_name, class_label in config['class_name_to_label'].items():        \n",
    "#                 for class_name2, class_label2 in config['class_name_to_label'].items():\n",
    "#                     if class_label2 < class_label:\n",
    "#                         continue\n",
    "#                     mixup_idx = np.all(mixup_result[r]['target'] == [class_label, class_label2], axis=-1)\n",
    "#                     mixup_idx = mixup_idx | np.all(mixup_result[r]['target'] == [class_label2, class_label], axis=-1)\n",
    "#                     ax.scatter(\n",
    "#                         mixup_result[r]['tsne_embedding'][mixup_idx[:N]][:, 0],\n",
    "#                         mixup_result[r]['tsne_embedding'][mixup_idx[:N]][:, 1],\n",
    "#                         label=f\"mixup of {class_name} and {class_name2}\",\n",
    "#                         color=color_map2[class_label][class_label2],\n",
    "#                         alpha=0.8,\n",
    "#                         edgecolors='k',\n",
    "#                         zorder=2)\n",
    "        \n",
    "#             ax.set_xticklabels([])\n",
    "#             ax.set_yticklabels([])\n",
    "#             ax.legend(bbox_to_anchor=(1.04, 0.5), loc='center left', borderaxespad=0.)\n",
    "#             if save_fig:\n",
    "#                 for ext in ['pdf', 'jpg', 'svg']:\n",
    "#                     os.makedirs(os.path.join(output_folder, model_name, ext), exist_ok=True)\n",
    "#                     fig.savefig(os.path.join(output_folder, model_name, ext, f\"dim2_per{perplexity:03}_iter{n_iter:05}_1Epoch.{ext}\"), \n",
    "#                                 transparent=True, bbox_inches='tight')\n",
    "#             else:\n",
    "#                 plt.show()\n",
    "#             fig.clear()\n",
    "#             plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b338443a-ea48-4da5-bbdf-e66d9937ef34",
   "metadata": {},
   "source": [
    "## Draw 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce418a79-2756-47b7-99d0-f5aae47d60c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minjae\\anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:991: FutureWarning:\n",
      "\n",
      "The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plt.style.use('default') \n",
    "plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams.update({'font.family': 'Roboto Slab'})\n",
    "plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "color_map2 = [['tab:green', 'tab:brown', 'tab:blue'], \n",
    "              ['gray', 'tab:orange', 'tab:pink'], \n",
    "              ['gray', 'gray', 'tab:red']]\n",
    "\n",
    "\n",
    "for n_iter in [10000]:\n",
    "    for perplexity in [100]: # [50, 70, 100, 150, 200]:\n",
    "        tsne_transform = TSNE(n_components=3, init=\"pca\", learning_rate=\"auto\", perplexity=perplexity,\n",
    "                              n_iter=n_iter, n_iter_without_progress=2000, n_jobs=4, random_state=0,)\n",
    "        \n",
    "        for r in range(len(result)):\n",
    "            output = tsne_transform.fit_transform( np.concatenate([result[r]['embedding'], mixup_result[r]['embedding']]))\n",
    "            result[r]['tsne_embedding'] = output[:result[r]['embedding'].shape[0]]\n",
    "            mixup_result[r]['tsne_embedding'] = output[result[r]['embedding'].shape[0]:]\n",
    "\n",
    "        for r in range(len(result)):\n",
    "            fig = plt.figure(num=1, clear=True, figsize=(12.0, 12.0))\n",
    "            ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "            for class_name, class_label in config['class_name_to_label'].items():\n",
    "                ax.scatter(\n",
    "                    xs=result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 0],\n",
    "                    ys=result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 1],\n",
    "                    zs=result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 2],\n",
    "                    label=class_name,\n",
    "                    color=color_map[class_label],\n",
    "                    alpha=0.8,\n",
    "                    s=40,\n",
    "                    # zorder=2\n",
    "                )\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_zticklabels([])\n",
    "            ax.legend(bbox_to_anchor=(1.04, 0.5), loc='center left', borderaxespad=0.)\n",
    "            if save_fig:\n",
    "                for ext in ['pdf', 'jpg', 'svg']:\n",
    "                    os.makedirs(os.path.join(output_folder, model_name, ext), exist_ok=True)\n",
    "                    fig.savefig(os.path.join(output_folder, model_name, ext, f\"dim3_per{perplexity:03}_iter{n_iter:05}_ori.{ext}\"), \n",
    "                                transparent=True, bbox_inches='tight')\n",
    "            else:\n",
    "                plt.show()\n",
    "            fig.clear()\n",
    "            plt.close(fig)\n",
    "            \n",
    "        for r in range(len(result)):\n",
    "            fig = plt.figure(num=1, clear=True, figsize=(12.0, 12.0))\n",
    "            ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "            for class_name, class_label in config['class_name_to_label'].items():\n",
    "                ax.scatter(\n",
    "                    xs=result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 0],\n",
    "                    ys=result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 1],\n",
    "                    zs=result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 2],\n",
    "                    label=class_name,\n",
    "                    color=color_map[class_label],\n",
    "                    alpha=0.2,\n",
    "                    s=40,\n",
    "                    # zorder=2\n",
    "                )\n",
    "        \n",
    "            for class_name, class_label in config['class_name_to_label'].items():        \n",
    "                for class_name2, class_label2 in config['class_name_to_label'].items():\n",
    "                    if class_label2 <= class_label:\n",
    "                        continue\n",
    "                    mixup_idx = np.all(mixup_result[r]['target'] == [class_label, class_label2], axis=-1)\n",
    "                    mixup_idx = mixup_idx | np.all(mixup_result[r]['target'] == [class_label2, class_label], axis=-1)\n",
    "                    ax.scatter(\n",
    "                        xs=mixup_result[r]['tsne_embedding'][mixup_idx][:, 0],\n",
    "                        ys=mixup_result[r]['tsne_embedding'][mixup_idx][:, 1],\n",
    "                        zs=mixup_result[r]['tsne_embedding'][mixup_idx][:, 2],\n",
    "                        label=f\"mixup of {class_name} and {class_name2}\",\n",
    "                        color=color_map2[class_label][class_label2],\n",
    "                        alpha=0.8,\n",
    "                        s=40,\n",
    "                        edgecolors='k',\n",
    "                        # zorder=2\n",
    "                    )\n",
    "        \n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_zticklabels([])\n",
    "            ax.legend(bbox_to_anchor=(1.04, 0.5), loc='center left', borderaxespad=0.)\n",
    "            if save_fig:\n",
    "                for ext in ['pdf', 'jpg', 'svg']:\n",
    "                    os.makedirs(os.path.join(output_folder, model_name, ext), exist_ok=True)\n",
    "                    fig.savefig(os.path.join(output_folder, model_name, ext, f\"dim3_per{perplexity:03}_iter{n_iter:05}.{ext}\"), \n",
    "                                transparent=True, bbox_inches='tight')\n",
    "            else:\n",
    "                plt.show()\n",
    "            fig.clear()\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5b00f55-ec49-4677-a01f-da597329ca3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minjae\\anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:991: FutureWarning:\n",
      "\n",
      "The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plt.style.use('default') \n",
    "plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams.update({'font.family': 'Roboto Slab'})\n",
    "plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "color_map2 = [['tab:green', 'tab:brown', 'tab:blue'], \n",
    "              ['gray', 'tab:orange', 'tab:pink'], \n",
    "              ['gray', 'gray', 'tab:red']]\n",
    "\n",
    "\n",
    "for n_iter in [10000]:\n",
    "    for perplexity in [100]: # [50, 70, 100, 150, 200]:\n",
    "        tsne_transform = TSNE(n_components=3, init=\"pca\", learning_rate=\"auto\", perplexity=perplexity,\n",
    "                              n_iter=n_iter, n_iter_without_progress=2000, n_jobs=4, random_state=0,)\n",
    "        \n",
    "        for r in range(len(result)):\n",
    "            N = result[r]['embedding'].shape[0]\n",
    "            output = tsne_transform.fit_transform( np.concatenate([result[r]['embedding'], \n",
    "                                                                   mixup_result[r]['embedding'][:N]]))\n",
    "            result[r]['tsne_embedding'] = output[:result[r]['embedding'].shape[0]]\n",
    "            mixup_result[r]['tsne_embedding'] = output[result[r]['embedding'].shape[0]:]\n",
    "\n",
    "        for r in range(len(result)):\n",
    "            fig = plt.figure(num=1, clear=True, figsize=(12.0, 12.0))\n",
    "            ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "            for class_name, class_label in config['class_name_to_label'].items():\n",
    "                ax.scatter(\n",
    "                    xs=result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 0],\n",
    "                    ys=result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 1],\n",
    "                    zs=result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 2],\n",
    "                    label=class_name,\n",
    "                    color=color_map[class_label],\n",
    "                    alpha=0.8,\n",
    "                    s=40,\n",
    "                    # zorder=2\n",
    "                )\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_zticklabels([])\n",
    "            ax.legend(bbox_to_anchor=(1.04, 0.5), loc='center left', borderaxespad=0.)\n",
    "            if save_fig:\n",
    "                for ext in ['pdf', 'jpg', 'svg']:\n",
    "                    os.makedirs(os.path.join(output_folder, model_name, ext), exist_ok=True)\n",
    "                    fig.savefig(os.path.join(output_folder, model_name, ext, f\"dim3_per{perplexity:03}_iter{n_iter:05}_ori.{ext}\"), \n",
    "                                transparent=True, bbox_inches='tight')\n",
    "            else:\n",
    "                plt.show()\n",
    "            fig.clear()\n",
    "            plt.close(fig)\n",
    "            \n",
    "        for r in range(len(result)):\n",
    "            fig = plt.figure(num=1, clear=True, figsize=(12.0, 12.0))\n",
    "            ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "            for class_name, class_label in config['class_name_to_label'].items():\n",
    "                ax.scatter(\n",
    "                    xs=result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 0],\n",
    "                    ys=result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 1],\n",
    "                    zs=result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 2],\n",
    "                    label=class_name,\n",
    "                    color=color_map[class_label],\n",
    "                    alpha=0.2,\n",
    "                    s=40,\n",
    "                    # zorder=2\n",
    "                )\n",
    "        \n",
    "            N = result[r]['embedding'].shape[0]\n",
    "            for class_name, class_label in config['class_name_to_label'].items():        \n",
    "                for class_name2, class_label2 in config['class_name_to_label'].items():\n",
    "                    if class_label2 < class_label:\n",
    "                        continue\n",
    "                    mixup_idx = np.all(mixup_result[r]['target'] == [class_label, class_label2], axis=-1)\n",
    "                    mixup_idx = mixup_idx | np.all(mixup_result[r]['target'] == [class_label2, class_label], axis=-1)\n",
    "                    ax.scatter(\n",
    "                        xs=mixup_result[r]['tsne_embedding'][mixup_idx[:N]][:, 0],\n",
    "                        ys=mixup_result[r]['tsne_embedding'][mixup_idx[:N]][:, 1],\n",
    "                        zs=mixup_result[r]['tsne_embedding'][mixup_idx[:N]][:, 2],\n",
    "                        label=f\"mixup of {class_name} and {class_name2}\",\n",
    "                        color=color_map2[class_label][class_label2],\n",
    "                        alpha=0.8,\n",
    "                        s=40,\n",
    "                        edgecolors='k',\n",
    "                        # zorder=2\n",
    "                    )\n",
    "        \n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_zticklabels([])\n",
    "            ax.legend(bbox_to_anchor=(1.04, 0.5), loc='center left', borderaxespad=0.)\n",
    "            if save_fig:\n",
    "                for ext in ['pdf', 'jpg', 'svg']:\n",
    "                    os.makedirs(os.path.join(output_folder, model_name, ext), exist_ok=True)\n",
    "                    fig.savefig(os.path.join(output_folder, model_name, ext, f\"dim3_per{perplexity:03}_iter{n_iter:05}_1Epoch.{ext}\"), \n",
    "                                transparent=True, bbox_inches='tight')\n",
    "            else:\n",
    "                plt.show()\n",
    "            fig.clear()\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aec2ea-0bfe-4852-bcf4-d3201439ae18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
