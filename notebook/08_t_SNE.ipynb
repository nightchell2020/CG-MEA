{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed1e2f8a-32b4-46b1-a00a-382644e90504",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# t-SNE visualization\n",
    "\n",
    "This notebook visualizes the trained EEG embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdbc4ee-d024-4025-84fb-d18dfa1410d7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df587e38-b1a9-42c8-9b50-680200a9bec7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb41bf8-1713-4228-b799-0e1c87545a16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import pprint\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_script import build_dataset_for_train\n",
    "import models\n",
    "from train.evaluate import check_accuracy\n",
    "from train.evaluate import check_accuracy_extended\n",
    "from train.evaluate import check_accuracy_extended_debug\n",
    "from train.evaluate import check_accuracy_multicrop\n",
    "from train.evaluate import check_accuracy_multicrop_extended\n",
    "from train.visualize import draw_roc_curve\n",
    "from train.visualize import draw_confusion\n",
    "from train.visualize import draw_class_wise_metrics\n",
    "from train.visualize import draw_error_table\n",
    "from train.visualize import annotate_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309eed9b-2c31-4398-a141-e1787453814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bffc0b0-30bc-4b63-908e-03a68c3da0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other settings\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # cleaner text\n",
    "\n",
    "plt.style.use('default') \n",
    "# ['Solarize_Light2', '_classic_test_patch', 'bmh', 'classic', 'dark_background', 'fast', \n",
    "#  'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn', 'seaborn-bright', 'seaborn-colorblind', \n",
    "#  'seaborn-dark', 'seaborn-dark-palette', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', \n",
    "#  'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', \n",
    "#  'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'tableau-colorblind10']\n",
    "\n",
    "plt.rcParams['image.interpolation'] = 'bicubic'\n",
    "plt.rcParams[\"font.family\"] = 'Helvetica' # 'NanumGothic' # for Hangul in Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c5390-f093-4a4c-9c72-2f16f9d42fde",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "-----\n",
    "\n",
    "## Load the configuration used during the train phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0f3c94-0bbb-42ef-ab92-df07e2964087",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'amzr0uzt'\n",
    "model_path = os.path.join(r'E:\\CAUEEG\\checkpoint', model_name, 'checkpoint.pt')\n",
    "\n",
    "ckpt = torch.load(model_path, map_location=device)\n",
    "print(ckpt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069adca8-f2f7-446f-ba09-87f6f5f64d8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_state = ckpt['model_state']\n",
    "config = ckpt['config']\n",
    "optimizer = ckpt['optimizer_state']\n",
    "scheduler = ckpt['scheduler_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4a490d-9f3b-42b7-a1ef-4605f5eae262",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pprint.pprint(config, width=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7877675-9feb-4175-8f54-946a29044648",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load the target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322201e6-3a07-48f9-a871-c4a44129e8f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model = config['generator'](**config).to(device)\n",
    "model = hydra.utils.instantiate(config).to(device)\n",
    "\n",
    "if config.get('ddp', False):\n",
    "    model_state_ddp = deepcopy(model_state)\n",
    "    model_state = OrderedDict()\n",
    "    for k, v in model_state_ddp.items():\n",
    "        name = k[7:] # remove 'module.' of DataParallel/DistributedDataParallel\n",
    "        model_state[name] = v\n",
    "        \n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab33f903-bbbe-49c1-9fc2-49ce8ee26cff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Evaluate the model and analyze the performance by the crop timing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d827eb6-53f2-4aa0-909c-972dcf33c6d5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427aeb6b-5fef-411c-b69a-5fb4413483ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = ckpt['config']\n",
    "\n",
    "config.pop('cwd', 0)\n",
    "config['ddp'] = False\n",
    "config['crop_timing_analysis'] = True\n",
    "config['eval'] = True\n",
    "config['crop_multiple'] = 64\n",
    "config['device'] = device\n",
    "\n",
    "target_from_last = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527fc407-9f18-4329-a551-c85ec26a0727",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1d9aa9-fbc5-4d4a-8a7f-8e8fbd4675dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, multicrop_test_loader = build_dataset_for_train(config, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf875389-0084-4e44-98e3-eae37d63bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_embedding(model, sample_batched, preprocess, crop_multiple, target_from_last):\n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # preprocessing (this includes to-device operation)\n",
    "    preprocess(sample_batched)\n",
    "\n",
    "    # apply model on whole batch directly on device\n",
    "    x = sample_batched['signal']\n",
    "    age = sample_batched['age']\n",
    "    e = model.compute_feature_embedding(x, age, target_from_last=target_from_last)\n",
    "    y = sample_batched['class_label']\n",
    "    \n",
    "    if crop_multiple > 1:\n",
    "        # multi-crop averaging\n",
    "        if e.size(0) % crop_multiple != 0:\n",
    "            raise ValueError(f\"compute_embedding(): Real minibatch size={e.size(0)} is not multiple of \"\n",
    "                             f\"crop_multiple={crop_multiple}.\")\n",
    "\n",
    "        real_minibatch = e.size(0) // crop_multiple\n",
    "        e_ = torch.zeros((real_minibatch, e.size(1)))\n",
    "        y_ = torch.zeros((real_minibatch,), dtype=torch.int32)\n",
    "\n",
    "        for m in range(real_minibatch):\n",
    "            e_[m] = e[crop_multiple*m:crop_multiple*(m + 1)].mean(dim=0, keepdims=True)\n",
    "            y_[m] = y[crop_multiple*m]\n",
    "                \n",
    "        e = e_\n",
    "        y = y_\n",
    "    \n",
    "    return e, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d28b639-c84a-4ad3-80d7-9b862912b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [{'name': 'Train Dataset', \n",
    "           'loader': train_loader}, \n",
    "          {'name': 'Validation Dataset', \n",
    "           'loader': val_loader}, \n",
    "          {'name': 'Test Dataset', \n",
    "           'loader': test_loader}]\n",
    "\n",
    "for r in range(len(result)):\n",
    "    target_symptom = {'mci_amnestic_ef': [], 'mci_amnestic_rf': []}\n",
    "    name = result[r]['name']\n",
    "    loader = result[r]['loader']\n",
    "\n",
    "    for i, sample_batched in enumerate(loader):\n",
    "        if i == 0:\n",
    "            crop_multiple = config['crop_multiple']\n",
    "            minibatch_size = loader.batch_size\n",
    "\n",
    "        # estimate\n",
    "        e, y = compute_embedding(model, sample_batched, config['preprocess_test'], crop_multiple, target_from_last=target_from_last)\n",
    "\n",
    "        if i == 0:\n",
    "            embedding = e.detach().cpu().numpy()\n",
    "            target = y.detach().cpu().numpy()\n",
    "        else:\n",
    "            embedding = np.concatenate([embedding, e.detach().cpu().numpy()], axis=0)\n",
    "            target = np.concatenate([target, y.detach().cpu().numpy()], axis=0)\n",
    "\n",
    "        for s in range(0, len(sample_batched['symptom']), crop_multiple):\n",
    "            symp = sample_batched['symptom'][s]        \n",
    "            for k in target_symptom.keys():\n",
    "                if k in symp:\n",
    "                    target_symptom[k].append((s // crop_multiple) + (i * minibatch_size))\n",
    "                    \n",
    "    result[r]['embedding'] = embedding\n",
    "    result[r]['target'] = target\n",
    "    result[r]['target_symptom'] = target_symptom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b230944-8bce-468a-a560-ea8a65088a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_transform = TSNE(n_components=2, init=\"pca\", learning_rate=\"auto\", perplexity=50.0,\n",
    "                      n_iter=5000, n_iter_without_progress=500, n_jobs=2, random_state=0,)\n",
    "\n",
    "for r in range(len(result)):\n",
    "    result[r]['tsne_embedding'] = tsne_transform.fit_transform(result[r]['embedding'])\n",
    "    print(result[r]['name'], '-', result[r]['tsne_embedding'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc7238-c0d3-498d-9d94-9b20c0e0bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default') \n",
    "plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams.update({'font.family': 'Arial'})\n",
    "# plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "\n",
    "for r in range(len(result)):\n",
    "    _, ax = plt.subplots()\n",
    "    for class_name, class_label in config['class_name_to_label'].items():\n",
    "        ax.scatter(\n",
    "            result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 0],\n",
    "            result[r]['tsne_embedding'][result[r]['target'] == class_label][:, 1],\n",
    "            label=class_name,\n",
    "            color=color_map[class_label],\n",
    "            alpha=0.8,\n",
    "            edgecolors='k',\n",
    "            zorder=2)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    ax.set_title(f\"t-SNE embedding of {result[r]['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb20895-2c8f-4440-a627-c33b9d34b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_out_embedding = tsne_transform.fit_transform(np.concatenate([r['embedding'] for r in result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57160e8b-0869-4757-a48d-d3d7cb772f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default') \n",
    "plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams.update({'font.family': 'Arial'})\n",
    "# plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "start_from = 0\n",
    "\n",
    "for r in range(len(result)):\n",
    "    _, ax = plt.subplots()\n",
    "    n_size = result[r]['tsne_embedding'].shape[0]\n",
    "    \n",
    "    start_from_temp = 0\n",
    "    for rr in range(len(result)):\n",
    "        n_size_temp = result[rr]['tsne_embedding'].shape[0]\n",
    "        for class_name, class_label in config['class_name_to_label'].items():\n",
    "            ax.scatter(\n",
    "                total_out_embedding[start_from_temp:start_from_temp + n_size_temp][result[rr]['target'] == class_label][:, 0],\n",
    "                total_out_embedding[start_from_temp:start_from_temp + n_size_temp][result[rr]['target'] == class_label][:, 1],\n",
    "                color=color_map[class_label],\n",
    "                alpha=0.1,\n",
    "                zorder=2)\n",
    "        start_from_temp += n_size_temp\n",
    "\n",
    "    for class_name, class_label in config['class_name_to_label'].items():\n",
    "        ax.scatter(\n",
    "            total_out_embedding[start_from:start_from + n_size][result[r]['target'] == class_label][:, 0],\n",
    "            total_out_embedding[start_from:start_from + n_size][result[r]['target'] == class_label][:, 1],\n",
    "            label=class_name,\n",
    "            color=color_map[class_label],\n",
    "            alpha=0.8,\n",
    "            edgecolors='k',\n",
    "            zorder=2)\n",
    "    start_from += n_size\n",
    "    \n",
    "    ax.set_title(f\"t-SNE embedding of {result[r]['name']}\")\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12592b74-1299-42ae-ad28-907464ca1070",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default') \n",
    "plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams.update({'font.family': 'Arial'})\n",
    "# plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "\n",
    "for r in range(len(result)):\n",
    "    _, ax = plt.subplots()\n",
    "    for k, v in result[r]['target_symptom'].items():\n",
    "        ax.scatter(\n",
    "            result[r]['tsne_embedding'][[*set(v)]][:, 0],\n",
    "            result[r]['tsne_embedding'][[*set(v)]][:, 1],\n",
    "            label=k,\n",
    "            alpha=0.8,\n",
    "            edgecolors='k',\n",
    "            zorder=2)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    ax.set_title(f\"t-SNE embedding {[*result[r]['target_symptom'].keys()]} in {result[r]['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb70bae-222b-4338-bb85-1f64378de1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default') \n",
    "plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams.update({'font.family': 'Arial'})\n",
    "# plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "start_from = 0\n",
    "\n",
    "for r in range(len(result)):\n",
    "    _, ax = plt.subplots()\n",
    "    n_size = result[r]['tsne_embedding'].shape[0]\n",
    "    \n",
    "    start_from_temp = 0\n",
    "    for rr in range(len(result)):\n",
    "        n_size_temp = result[rr]['tsne_embedding'].shape[0]\n",
    "        for class_name, class_label in config['class_name_to_label'].items():\n",
    "            ax.scatter(\n",
    "                total_out_embedding[start_from_temp:start_from_temp + n_size_temp][result[rr]['target'] == class_label][:, 0],\n",
    "                total_out_embedding[start_from_temp:start_from_temp + n_size_temp][result[rr]['target'] == class_label][:, 1],\n",
    "                color=color_map[class_label],\n",
    "                label=class_name if rr == 0 else None,\n",
    "                alpha=0.1,\n",
    "                zorder=2)\n",
    "        start_from_temp += n_size_temp\n",
    "\n",
    "    for k, v in result[r]['target_symptom'].items():\n",
    "        ax.scatter(\n",
    "            total_out_embedding[start_from:start_from + n_size][[*set(v)]][:, 0],\n",
    "            total_out_embedding[start_from:start_from + n_size][[*set(v)]][:, 1],\n",
    "            label=k,\n",
    "            alpha=0.8,\n",
    "            edgecolors='k',\n",
    "            zorder=2)\n",
    "    start_from += n_size\n",
    "    \n",
    "    ax.set_title(f\"t-SNE embedding of {result[r]['name']}\")\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af27d2b-2040-4e57-9a59-81fdbaa75b43",
   "metadata": {},
   "source": [
    "## Extra Symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e83d53-c608-4437-b358-41fe29256cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "serial_set = set()\n",
    "for loader in [train_loader, val_loader, test_loader]:    \n",
    "    for sample_batched in loader:\n",
    "        serial_set.update(sample_batched['serial'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6121e2-b929-4a8e-a86f-1423105daa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets.caueeg_dataset import CauEegDataset\n",
    "from datasets.pipeline import eeg_collate_fn\n",
    "\n",
    "dataset_path = os.path.join(config['cwd'], config['dataset_path']) if 'cwd' in config.keys() else config['dataset_path']\n",
    "\n",
    "with open(os.path.join(dataset_path, 'annotation.json'), 'r') as json_file:\n",
    "    annotation_ = json.load(json_file)\n",
    "\n",
    "annotation = deepcopy(annotation_)\n",
    "annotation['data'] = [data for data in annotation['data'] if data['serial'] not in serial_set]\n",
    "\n",
    "print(len(annotation_['data']))\n",
    "print(len(serial_set))\n",
    "print(len(annotation['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8c6118-90da-41ee-b462-0ff1db64a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_eeg_dataset = CauEegDataset(dataset_path, annotation['data'],\n",
    "                                  load_event=config['load_event'],\n",
    "                                  file_format=config['file_format'],\n",
    "                                  transform=config['transform'])\n",
    "\n",
    "print(len(extra_eeg_dataset))\n",
    "\n",
    "extra_loader = DataLoader(extra_eeg_dataset,\n",
    "                          batch_size=4,\n",
    "                          shuffle=False,\n",
    "                          drop_last=False,\n",
    "                          num_workers=0,\n",
    "                          pin_memory=True,\n",
    "                          collate_fn=eeg_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff46fc4a-3cde-4e2b-8370-da7d1b2db996",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_symptom = {}\n",
    "extra_result = {}\n",
    "\n",
    "for i, sample_batched in enumerate(extra_loader):\n",
    "    if i == 0:\n",
    "        crop_multiple = config['crop_multiple']\n",
    "        minibatch_size = extra_loader.batch_size\n",
    "    sample_batched['class_label'] = torch.zeros((len(sample_batched['symptom'])))\n",
    "    \n",
    "    # estimate\n",
    "    e, _ = compute_embedding(model, sample_batched, config['preprocess_test'], crop_multiple, target_from_last=target_from_last)\n",
    "        \n",
    "    if i == 0:\n",
    "        embedding = e.detach().cpu().numpy()\n",
    "    else:\n",
    "        embedding = np.concatenate([embedding, e.detach().cpu().numpy()], axis=0)\n",
    "    \n",
    "    for s in range(0, len(sample_batched['symptom']), crop_multiple):\n",
    "        symp = ', '.join(sample_batched['symptom'][s])\n",
    "        \n",
    "        if symp in extra_symptom.keys():\n",
    "            extra_symptom[symp].append((s // crop_multiple) + i * minibatch_size)\n",
    "        else:\n",
    "            extra_symptom[symp] = [(s // crop_multiple) + (i * minibatch_size)]\n",
    "    \n",
    "    extra_result['embedding'] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3549214-11a8-404b-b018-a53b5da4832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_transform = TSNE(n_components=2, init=\"pca\", learning_rate=\"auto\", perplexity=70.0,\n",
    "                      n_iter=5000, n_iter_without_progress=500, n_jobs=2, random_state=0,)\n",
    "\n",
    "extra_result['tsne_embedding'] = tsne_transform.fit_transform(extra_result['embedding'])\n",
    "print(extra_result['tsne_embedding'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7a0ed-9cfd-42c8-9c15-ec8fad056863",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "for k, v in extra_symptom.items():\n",
    "    ax.scatter(\n",
    "        extra_result['tsne_embedding'][[*set(v)]][:, 0],\n",
    "        extra_result['tsne_embedding'][[*set(v)]][:, 1],\n",
    "        label=k,\n",
    "        alpha=0.5,\n",
    "        zorder=2)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea28d01-d05f-43bd-ad45-81af8b3132cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_total_out_embedding = tsne_transform.fit_transform(np.concatenate([r['embedding'] for r in result] + [extra_result['embedding']], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e70189-dc33-4f04-a0c5-fbea7a06f9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map1 = ['tab:green', 'tab:orange', 'tab:red']\n",
    "\n",
    "for i, k, in enumerate(sorted(extra_symptom.keys())):\n",
    "    v = extra_symptom[k]\n",
    "    \n",
    "    fig = plt.figure(num=1, clear=True, figsize=(6.0, 6.0))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    start_from_temp = 0\n",
    "    for rr in range(len(result)):\n",
    "        n_size_temp = result[rr]['tsne_embedding'].shape[0]\n",
    "        for class_name, class_label in config['class_name_to_label'].items():\n",
    "            ax.scatter(\n",
    "                extra_total_out_embedding[start_from_temp:start_from_temp + n_size_temp][result[rr]['target'] == class_label][:, 0],\n",
    "                extra_total_out_embedding[start_from_temp:start_from_temp + n_size_temp][result[rr]['target'] == class_label][:, 1],\n",
    "                color=color_map[class_label],\n",
    "                label=class_name if rr == 0 else None,\n",
    "                alpha=0.1,\n",
    "                zorder=2)\n",
    "        start_from_temp += n_size_temp\n",
    "        \n",
    "    ax.scatter(\n",
    "        extra_total_out_embedding[start_from_temp:][[*set(v)]][:, 0],\n",
    "        extra_total_out_embedding[start_from_temp:][[*set(v)]][:, 1],\n",
    "        label=k,\n",
    "        color=plt.cm.tab10(i),\n",
    "        edgecolors='k',\n",
    "        alpha=0.8,\n",
    "        s=50,\n",
    "        zorder=2)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "    plt.show()\n",
    "    fig.clear()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c29a59-27e0-45c5-80c6-584d327dbd8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ed62cb-3a21-4b7c-a719-eeff3ad3549a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
