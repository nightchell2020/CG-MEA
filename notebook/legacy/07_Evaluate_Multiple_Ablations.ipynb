{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74515d5-5f25-477b-9a97-ed1f9b6d4c51",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluate\n",
    "\n",
    "This notebook evaluates the network trained previous notebooks and analyzes the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a2666f-6b4b-4748-9dca-2884347a1f0f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df587e38-b1a9-42c8-9b50-680200a9bec7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minjae\\Desktop\\EEG_Project\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb41bf8-1713-4228-b799-0e1c87545a16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "import pprint\n",
    "import wandb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_script import build_dataset_for_train\n",
    "from datasets.caueeg_script import load_caueeg_task_split\n",
    "from datasets.pipeline import eeg_collate_fn\n",
    "import models\n",
    "from train.evaluate import check_accuracy\n",
    "from train.evaluate import check_accuracy_extended\n",
    "from train.evaluate import check_accuracy_extended_debug\n",
    "from train.evaluate import check_accuracy_multicrop\n",
    "from train.evaluate import check_accuracy_multicrop_extended\n",
    "from train.evaluate import calculate_class_wise_metrics\n",
    "from train.visualize import draw_roc_curve\n",
    "from train.visualize import draw_confusion\n",
    "from train.visualize import draw_class_wise_metrics\n",
    "from train.visualize import draw_error_table\n",
    "from train.visualize import annotate_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10e3f39-ed55-422c-b47f-376691cbeed6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.12.1+cu113\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a62fa4-aa53-49d5-8ab4-2e2aaf7b65d1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "-----\n",
    "\n",
    "## List up the models to check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d3404e-be31-4a63-ac4b-214868fe0cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['l8524nml',\n",
      " 'dejxbfxu',\n",
      " '3874otvp',\n",
      " '2bw00w05',\n",
      " '2k8xomy6',\n",
      " '2452kedi',\n",
      " '3c9rbdxu',\n",
      " '2h30v12p',\n",
      " '1242j086',\n",
      " '30ek7z1x',\n",
      " '2apj72km',\n",
      " '2d7mttdu',\n",
      " '2615y2jm',\n",
      " '3jmkkwbc',\n",
      " '1nq1zwxk',\n",
      " '2s1700lg',\n",
      " '3pg95uf1',\n",
      " '86s3czvy',\n",
      " '1o7cz2rs',\n",
      " '52v2mp7f',\n",
      " '3t0s53ki',\n",
      " '1cmzq9xq',\n",
      " '2z7is3m0',\n",
      " '13i117jq',\n",
      " '3cy4eb97',\n",
      " 'ph0mix3b',\n",
      " 'cygczhuk',\n",
      " 'gma3iwco',\n",
      " '1xhv4ae6']\n"
     ]
    }
   ],
   "source": [
    "model_names = [\n",
    "'l8524nml',\n",
    "'dejxbfxu',\n",
    "'3874otvp',\n",
    "'2bw00w05',\n",
    "'2k8xomy6',\n",
    "'2452kedi',\n",
    "'3c9rbdxu',\n",
    "'2h30v12p',\n",
    "'1242j086',\n",
    "'30ek7z1x',\n",
    "'2apj72km',\n",
    "'2d7mttdu',\n",
    "'2615y2jm',\n",
    "'3jmkkwbc',\n",
    "'1nq1zwxk',\n",
    "'2s1700lg',\n",
    "'3pg95uf1',\n",
    "'86s3czvy',\n",
    "'1o7cz2rs',\n",
    "'52v2mp7f',\n",
    "'3t0s53ki',\n",
    "'1cmzq9xq',\n",
    "'2z7is3m0',\n",
    "'13i117jq',\n",
    "'3cy4eb97',\n",
    "'ph0mix3b',\n",
    "'cygczhuk',\n",
    "'gma3iwco',\n",
    "'1xhv4ae6',\n",
    "]\n",
    "model_pool = []\n",
    "\n",
    "for model_name in model_names:\n",
    "    path = os.path.join(r'E:\\CAUEEG\\checkpoint', model_name, 'checkpoint.pt')\n",
    "    try:\n",
    "        ckpt = torch.load(path, map_location=device)\n",
    "        model_pool.append({'name': model_name, 'path': path})\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'- checkpoint cannot be opened: {path}')\n",
    "        \n",
    "pprint.pprint([model_dict['name'] for model_dict in model_pool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f2ac6e-cbb1-432d-8118-193285405ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pool = []\n",
    "\n",
    "# api = wandb.Api()\n",
    "# runs = api.runs('ipis-mjkim/caueeg-task2-ablation')\n",
    "\n",
    "# for run in runs:\n",
    "#     path = os.path.join(r'E:\\CAUEEG\\checkpoint', run.name, 'checkpoint.pt')\n",
    "#     try:\n",
    "#         ckpt = torch.load(path, map_location=device)\n",
    "#         model_pool.append({'name': run.name, 'path': path})\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         print(f'- {run.name}\\'s checkpoint cannot be opened: {path}')\n",
    "        \n",
    "# pprint.pprint([model_dict['name'] for model_dict in model_pool])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00973b7-d2ba-4e54-a4ac-86879c1fe89f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dfec22-3837-46a7-8b4d-4588300068bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_repeat = 200\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e25ca9a-48ee-4c0d-8e06-616a84e59527",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Load and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee4f853-3cad-4b01-8ee8-44ac9e49adbe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- checking for l8524nml 1D-ResNet-18 ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m multicrop_val_loader \u001b[38;5;241m=\u001b[39m DataLoader(multicrop_val_dataset,\n\u001b[0;32m     71\u001b[0m                                    batch_size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     72\u001b[0m                                    shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m                                    pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     76\u001b[0m                                    collate_fn\u001b[38;5;241m=\u001b[39meeg_collate_fn)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# train accuracy\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpreprocess_test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepeat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m model_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_acc\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# val accuracy\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Desktop\\EEG_Project\\train\\evaluate.py:93\u001b[0m, in \u001b[0;36mcheck_accuracy\u001b[1;34m(model, loader, preprocess, config, repeat)\u001b[0m\n\u001b[0;32m     90\u001b[0m correct, total \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(repeat):\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sample_batched \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;66;03m# estimate\u001b[39;00m\n\u001b[0;32m     95\u001b[0m         s \u001b[38;5;241m=\u001b[39m estimate_score(model, sample_batched, preprocess, config)\n\u001b[0;32m     96\u001b[0m         y \u001b[38;5;241m=\u001b[39m sample_batched[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\EEG_Project\\datasets\\pipeline.py:424\u001b[0m, in \u001b[0;36meeg_collate_fn\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    421\u001b[0m             \u001b[38;5;28;01melif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrop_timing\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    422\u001b[0m                 batched_sample[k] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39msample[k]]\n\u001b[1;32m--> 424\u001b[0m batched_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msignal\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_sample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msignal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    425\u001b[0m batched_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(batched_sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_label\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batched_sample\u001b[38;5;241m.\u001b[39mkeys():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for model_dict in model_pool:\n",
    "    # load and parse the checkpoint\n",
    "    ckpt = torch.load(model_dict['path'], map_location=device)\n",
    "    model_state = ckpt['model_state']\n",
    "    config = ckpt['config']\n",
    "    optimizer = ckpt['optimizer_state']\n",
    "    scheduler = ckpt['scheduler_state']\n",
    "    \n",
    "    print('- checking for', model_dict['name'], config['model'], '...')\n",
    "    \n",
    "    # initiate the model\n",
    "    if '_target_' in config:\n",
    "        model = hydra.utils.instantiate(config).to(device)\n",
    "    elif type(config['generator']) is str:\n",
    "        config['generator'] = getattr(models, config['generator'].split('.')[-1])\n",
    "        if 'block' in config:\n",
    "            config['block'] = getattr(models, config['block'].split('.')[-1])\n",
    "        model = config['generator'](**config).to(device)\n",
    "    else:\n",
    "        if 'block' in config:\n",
    "            if config['block'] == models.resnet_1d.BottleneckBlock1D:\n",
    "                config['block'] = 'bottleneck'\n",
    "            elif config['block'] == models.resnet_2d.Bottleneck2D:\n",
    "                config['block'] = 'bottleneck'\n",
    "            elif config['block'] == models.resnet_1d.BasicBlock1D:\n",
    "                config['block'] = 'basic'\n",
    "            elif config['block'] == models.resnet_2d.BasicBlock2D:\n",
    "                config['block'] = 'basic'\n",
    "                \n",
    "        model = config['generator'](**config).to(device)\n",
    "    \n",
    "    if config.get('ddp', False):\n",
    "        model_state_ddp = deepcopy(model_state)\n",
    "        model_state = OrderedDict()\n",
    "        for k, v in model_state_ddp.items():\n",
    "            name = k[7:]  # remove 'module.' of DataParallel/DistributedDataParallel\n",
    "            model_state[name] = v\n",
    "    \n",
    "    model.load_state_dict(model_state)\n",
    "    \n",
    "    # reconfigure\n",
    "    config.pop('cwd', 0)\n",
    "    config['ddp'] = False\n",
    "    config['crop_timing_analysis'] = False\n",
    "    config['eval'] = True\n",
    "    config['device'] = device\n",
    "    config['run_mode'] = 'eval'\n",
    "    \n",
    "    repeat = round(base_repeat / config['crop_multiple'])\n",
    "    model_dict['repeat'] = repeat\n",
    "    model_dict['crop_multiple'] = config['crop_multiple']\n",
    "    model_dict['test_crop_multiple'] = config['test_crop_multiple']    \n",
    "    \n",
    "    # build dataset\n",
    "    _ = build_dataset_for_train(config, verbose=verbose)\n",
    "    train_loader = _[0]\n",
    "    val_loader = _[1]\n",
    "    test_loader = _[2]\n",
    "    multicrop_test_loader = _[3]\n",
    "    _, multicrop_val_dataset = load_caueeg_task_split(dataset_path=config['dataset_path'],\n",
    "                                                      task=config['task'],\n",
    "                                                      split='val',\n",
    "                                                      load_event=config['load_event'],\n",
    "                                                      file_format=config['file_format'],\n",
    "                                                      transform=config['transform_multicrop'],\n",
    "                                                      verbose=verbose)\n",
    "    multicrop_val_loader = DataLoader(multicrop_val_dataset,\n",
    "                                       batch_size=config['multi_batch_size'],\n",
    "                                       shuffle=False,\n",
    "                                       drop_last=False,\n",
    "                                       num_workers=0,\n",
    "                                       pin_memory=True,\n",
    "                                       collate_fn=eeg_collate_fn)\n",
    "    \n",
    "    # train accuracy\n",
    "    train_acc = check_accuracy(model, train_loader, \n",
    "                               config['preprocess_test'], config, repeat=repeat)\n",
    "    model_dict['Train Accuracy'] = train_acc\n",
    "    \n",
    "    # val accuracy\n",
    "    val_acc = check_accuracy(model, val_loader, \n",
    "                             config['preprocess_test'], config, repeat=repeat)\n",
    "    model_dict['Validation Accuracy'] = val_acc\n",
    "\n",
    "    # Multi-crop val accuracy\n",
    "    _ = check_accuracy_multicrop_extended(model, multicrop_val_loader, \n",
    "                                          config['preprocess_test'], config, repeat=repeat)\n",
    "    model_dict['Multi-Crop Val Throughput'] = _[4]\n",
    "    model_dict['Multi-Crop Val Accuracy'] = _[0]\n",
    "    multi_val_class_wise_metrics = calculate_class_wise_metrics(_[3])\n",
    "    \n",
    "    for k, v in multi_val_class_wise_metrics.items():\n",
    "        for c in range(config['out_dims']):\n",
    "            c_name = config['class_label_to_name'][c]\n",
    "            model_dict[f'Multi-Crop Val {k} ({c_name})'] = multi_val_class_wise_metrics[k][c]\n",
    "    \n",
    "    \n",
    "    # Test accuracy\n",
    "    _ = check_accuracy_extended(model, test_loader, \n",
    "                                config['preprocess_test'], config, repeat=repeat)\n",
    "    model_dict['Test Throughput'] = _[4]\n",
    "    model_dict['Test Accuracy'] = _[0]\n",
    "\n",
    "    # Multi-crop test accuracy\n",
    "    _ = check_accuracy_multicrop_extended(model, multicrop_test_loader, \n",
    "                                          config['preprocess_test'], config, repeat=repeat)  \n",
    "    model_dict['Multi-Crop Test Throughput'] = _[4]\n",
    "    model_dict['Multi-Crop Test Accuracy'] = _[0]\n",
    "    multi_test_class_wise_metrics = calculate_class_wise_metrics(_[3])\n",
    "    \n",
    "    for k, v in multi_test_class_wise_metrics.items():\n",
    "        for c in range(config['out_dims']):\n",
    "            c_name = config['class_label_to_name'][c]\n",
    "            model_dict[f'Multi-Crop Test {k} ({c_name})'] = multi_test_class_wise_metrics[k][c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23811ac5-4a94-4d8a-b4fb-68161557a87d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pprint.pprint(model_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1509c9-3449-47b1-9a8c-1aa3dacf2606",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_dict in model_pool:\n",
    "    # load and parse the checkpoint\n",
    "    ckpt = torch.load(model_dict['path'], map_location=device)\n",
    "    model_state = ckpt['model_state']\n",
    "    config = ckpt['config']\n",
    "        \n",
    "    model_dict['model'] = config['model']\n",
    "    model_dict['num_params'] = config.get('num_params', '???')\n",
    "    model_dict['model size (MiB)'] = sys.getsizeof(pickle.dumps(model_state)) / (1024 * 1024)\n",
    "    # torch.save(model_state, 'temptemptemp.pt')\n",
    "    \n",
    "    model_dict['seq_length'] = config['seq_length']\n",
    "    model_dict['use_age'] = config['use_age']\n",
    "    model_dict['photic'] = config['photic']\n",
    "    model_dict['EKG'] = config['EKG']\n",
    "\n",
    "    model_dict['awgn'] = config.get('awgn', 0)\n",
    "    model_dict['awgn_age'] = config.get('awgn_age', 0)\n",
    "    model_dict['mgn'] = config.get('mgn', 0)\n",
    "    model_dict['mixup'] = config.get('mixup', 0)\n",
    "    model_dict['dropout'] = config.get('dropout', 0)\n",
    "    model_dict['weight_decay'] = config.get('weight_decay', '???')\n",
    "    model_dict['fc_stages'] = config.get('fc_stages', 1)\n",
    "    \n",
    "    model_dict['minibatch'] = round(config['minibatch'])\n",
    "    model_dict['total_samples'] = round(config.get('total_samples', config['iterations'] * config['minibatch']))\n",
    "    model_dict['base_lr'] = config.get('base_lr', config.get('LR', '???'))\n",
    "    model_dict['lr_scheduler_type'] = config.get('lr_scheduler_type', 'constant_with_decay')\n",
    "    model_dict['warmup_steps'] = config.get('warmup_steps', '???')\n",
    "    model_dict['seed'] = config.get('seed', '???')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ae7d8-ac60-42ad-b852-c38d3d52987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfabea6-e56f-4f29-8027-cb290a3d2d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_pool).to_csv('local/output/caueeg-task2-ablations-summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046bc5e-8b28-4c2c-941a-490a809b57dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
