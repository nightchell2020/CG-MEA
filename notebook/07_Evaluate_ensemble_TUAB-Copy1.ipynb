{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74515d5-5f25-477b-9a97-ed1f9b6d4c51",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluate Ensemble\n",
    "\n",
    "This notebook combines the classification results of some models via logit-ensembling way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a2666f-6b4b-4748-9dca-2884347a1f0f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df587e38-b1a9-42c8-9b50-680200a9bec7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\GitHub\\eeg_analysis\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb41bf8-1713-4228-b799-0e1c87545a16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "import pprint\n",
    "import wandb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# custom package\n",
    "from datasets.temple_eeg_script import build_dataset_for_tuab_train\n",
    "import models\n",
    "from train.evaluate import check_accuracy\n",
    "from train.evaluate import check_accuracy_extended\n",
    "from train.evaluate import check_accuracy_extended_debug\n",
    "from train.evaluate import check_accuracy_multicrop\n",
    "from train.evaluate import check_accuracy_multicrop_extended\n",
    "from train.evaluate import calculate_confusion_matrix\n",
    "from train.evaluate import calculate_confusion_matrix2\n",
    "from train.evaluate import calculate_class_wise_metrics\n",
    "from train.visualize import draw_roc_curve\n",
    "from train.visualize import draw_confusion, draw_confusion2\n",
    "from train.visualize import draw_class_wise_metrics\n",
    "from train.visualize import draw_error_table\n",
    "from train.visualize import annotate_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d10e3f39-ed55-422c-b47f-376691cbeed6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.2+cu118\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a62fa4-aa53-49d5-8ab4-2e2aaf7b65d1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "-----\n",
    "\n",
    "## List up the models to check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06d3404e-be31-4a63-ac4b-214868fe0cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D-MAE-B\n",
      "1D-MAE-B\n",
      "1D-MAE-B\n",
      "1D-MAE-B\n",
      "1D-MAE-B\n",
      "1D-MAE-B\n",
      "1D-MAE-B\n",
      "['767ogu61',\n",
      " '767ogu61',\n",
      " '767ogu61',\n",
      " '767ogu61',\n",
      " '767ogu61',\n",
      " '767ogu61',\n",
      " '767ogu61']\n"
     ]
    }
   ],
   "source": [
    "model_names = [\n",
    "    # '1id6fh8l',  # 2D-ResNeXt-50\n",
    "    # '1ixy3mpa',  # 1D-ResNet-50\n",
    "    # '2c9d9csx',  # 2D-Wide-ResNet-50\n",
    "    # '2pot34fr',  # 2D-VGG-19\n",
    "    # '3u3bx062',  # 1D-ResNeXt-50\n",
    "    # '21xq2ksd',  # 2D-ResNet-18\n",
    "    # '28fb1p9d',  # 1D-ResNeXt-50\n",
    "    # '36eo4dey',  # 2D-VGG-19\n",
    "    # '36riftdk',  # 1D-ResNeXt-50\n",
    "    # '92vum19n',  # 1D-ResNet-18\n",
    "    # 'l25884ae',  # 1D-ResNet-18\n",
    "    # 'ql56npap',  # 2D-VGG-19\n",
    "    # 'to3gp1w8',  # 1D-ResNeXt-50\n",
    "]\n",
    "\n",
    "model_names = ['767ogu61', '767ogu61', '767ogu61', '767ogu61', '767ogu61', '767ogu61', '767ogu61']\n",
    "\n",
    "model_pool = []\n",
    "\n",
    "for model_name in model_names:\n",
    "    path = os.path.join(r\"local/checkpoint/\", model_name, 'checkpoint.pt')\n",
    "    try:\n",
    "        ckpt = torch.load(path, map_location=device)\n",
    "        print(ckpt['config']['model'])\n",
    "        model_pool.append({'name': model_name, 'path': path})\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'- checkpoint cannot be opened: {path}')\n",
    "        \n",
    "pprint.pprint([model_dict['name'] for model_dict in model_pool])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00973b7-d2ba-4e54-a4ac-86879c1fe89f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7dfec22-3837-46a7-8b4d-4588300068bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'exp-tuab-multiple-767ogu61'\n",
    "eval_ensemble = False\n",
    "\n",
    "base_repeat = 32 # 800\n",
    "crop_multiple = 32\n",
    "test_crop_multiple = 32\n",
    "minibatch = 512\n",
    "\n",
    "verbose = False\n",
    "save_fig = False\n",
    "\n",
    "eval_train = False\n",
    "eval_val = False\n",
    "eval_test = True\n",
    "eval_test_multi = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ea3cfe6-4211-485d-a169-396f52e7d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval_ensemble:\n",
    "    task += '-ensem'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e25ca9a-48ee-4c0d-8e06-616a84e59527",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Evaluate each model and accumulate the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bee4f853-3cad-4b01-8ee8-44ac9e49adbe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- checking for 767ogu61 1D-MAE-B ...\n",
      "- checking for 767ogu61 1D-MAE-B ...\n",
      "- checking for 767ogu61 1D-MAE-B ...\n",
      "- checking for 767ogu61 1D-MAE-B ...\n",
      "- checking for 767ogu61 1D-MAE-B ...\n",
      "- checking for 767ogu61 1D-MAE-B ...\n",
      "- checking for 767ogu61 1D-MAE-B ...\n",
      "==== Finished ====\n"
     ]
    }
   ],
   "source": [
    "for k, model_dict in enumerate(model_pool):\n",
    "    if 'Ensemble' == model_pool[-1]['name']:\n",
    "        model_pool.remove(model_pool[-1])     \n",
    "    \n",
    "    # load and parse the checkpoint\n",
    "    ckpt = torch.load(model_dict['path'], map_location=device)\n",
    "    model_state = ckpt['model_state']\n",
    "    config = ckpt['config']\n",
    "    \n",
    "    model_dict['model'] = config['model']\n",
    "    model_dict['num_params'] = config.get('num_params', '???')\n",
    "    model_dict['model size (MiB)'] = sys.getsizeof(pickle.dumps(model_state)) / (1024 * 1024)\n",
    "    \n",
    "    config['dataset_path'] = './local/dataset/tuab/'    \n",
    "    config['run_mode'] = 'eval'\n",
    "    \n",
    "    model_dict['seq_length'] = config['seq_length']\n",
    "    model_dict['use_age'] = config['use_age']\n",
    "    model_dict['EKG'] = config['EKG']\n",
    "\n",
    "    model_dict['awgn'] = config.get('awgn', 0)\n",
    "    model_dict['awgn_age'] = config.get('awgn_age', 0)\n",
    "    model_dict['mgn'] = config.get('mgn', 0)\n",
    "    model_dict['mixup'] = config.get('mixup', 0)\n",
    "    model_dict['dropout'] = config.get('dropout', 0)\n",
    "    model_dict['weight_decay'] = config.get('weight_decay', '???')\n",
    "    model_dict['fc_stages'] = config.get('fc_stages', 1)\n",
    "    model_dict['activation'] = config.get('activation', 0)\n",
    "\n",
    "    model_dict['minibatch'] = round(config['minibatch'])\n",
    "    model_dict['total_samples'] = round(config.get('total_samples', config['iterations'] * config['minibatch']))\n",
    "    model_dict['base_lr'] = config.get('base_lr', config.get('LR', '???'))\n",
    "    model_dict['lr_scheduler_type'] = config.get('lr_scheduler_type', 'constant_with_decay')\n",
    "    model_dict['warmup_steps'] = config.get('warmup_steps', '???')\n",
    "    model_dict['seed'] = config.get('seed', '???')\n",
    "\n",
    "    if k == 0:\n",
    "        model_dict['art_patch_usage'] = {'type': 'drop_low', 'value': 0.3}\n",
    "    elif k == 1:\n",
    "        model_dict['art_patch_usage'] = {'type': 'drop_high', 'value': 0.3}\n",
    "    elif k == 2:\n",
    "        model_dict['art_patch_usage'] = {'type': 'drop_ends', 'value': 0.3}\n",
    "    elif k == 3:\n",
    "        model_dict['art_patch_usage'] = {'type': 'drop_low', 'value': 0.15}\n",
    "    elif k == 4:\n",
    "        model_dict['art_patch_usage'] = {'type': 'drop_high', 'value': 0.15}\n",
    "    elif k == 5:\n",
    "        model_dict['art_patch_usage'] = {'type': 'drop_ends', 'value': 0.15}\n",
    "    else:\n",
    "        model_dict['art_patch_usage'] = {'type': 'drop_low', 'value': 0.0}    \n",
    "    \n",
    "    print('- checking for', model_dict['name'], config['model'], '...')\n",
    "    \n",
    "    # initiate the model\n",
    "    if '_target_' in config:\n",
    "        model = hydra.utils.instantiate(config).to(device)\n",
    "    elif type(config['generator']) is str:\n",
    "        config['generator'] = getattr(models, config['generator'].split('.')[-1])\n",
    "        if 'block' in config:\n",
    "            config['block'] = getattr(models, config['block'].split('.')[-1])\n",
    "        model = config['generator'](**config).to(device)\n",
    "    else:\n",
    "        if 'block' in config:\n",
    "            if config['block'] == models.resnet_1d.BottleneckBlock1D:\n",
    "                config['block'] = 'bottleneck'\n",
    "            elif config['block'] == models.resnet_2d.Bottleneck2D:\n",
    "                config['block'] = 'bottleneck'\n",
    "            elif config['block'] == models.resnet_1d.BasicBlock1D:\n",
    "                config['block'] = 'basic'\n",
    "            elif config['block'] == models.resnet_2d.BasicBlock2D:\n",
    "                config['block'] = 'basic'\n",
    "                \n",
    "        model = config['generator'](**config).to(device)\n",
    "    \n",
    "    if config.get('ddp', False):\n",
    "        model_state_ddp = deepcopy(model_state)\n",
    "        model_state = OrderedDict()\n",
    "        for k, v in model_state_ddp.items():\n",
    "            name = k[7:]  # remove 'module.' of DataParallel/DistributedDataParallel\n",
    "            model_state[name] = v\n",
    "    \n",
    "    model.load_state_dict(model_state)\n",
    "    \n",
    "    # reconfigure and update\n",
    "    config.pop('cwd', 0)\n",
    "    config['ddp'] = False\n",
    "    config['crop_multiple'] = crop_multiple\n",
    "    config['test_crop_multiple'] = test_crop_multiple\n",
    "    config['minibatch'] = minibatch  \n",
    "    config['crop_timing_analysis'] = False\n",
    "    config['eval'] = True\n",
    "    config['device'] = device\n",
    "\n",
    "    repeat = round(base_repeat / crop_multiple)\n",
    "    model_dict['repeat'] = repeat\n",
    "    model_dict['crop_multiple'] = crop_multiple\n",
    "    model_dict['test_crop_multiple'] = test_crop_multiple\n",
    "    \n",
    "    # build dataset\n",
    "    _ = build_dataset_for_tuab_train(config, verbose=verbose)\n",
    "    train_loader = _[0]\n",
    "    val_loader = _[1]\n",
    "    test_loader = _[2]\n",
    "    multicrop_test_loader = _[3]\n",
    "    \n",
    "    # warm-up stage\n",
    "    _ = check_accuracy_extended(model, test_loader, \n",
    "                                config['preprocess_test'], config, repeat=1)\n",
    "    \n",
    "    # train accuracy\n",
    "    if eval_train:\n",
    "        train_acc = check_accuracy(model, train_loader, \n",
    "                                   config['preprocess_test'], config, repeat=repeat)\n",
    "        model_dict['Train Accuracy'] = train_acc\n",
    "    \n",
    "    # val accuracy\n",
    "    if eval_val:\n",
    "        val_acc = check_accuracy(model, val_loader, \n",
    "                                 config['preprocess_test'], config, repeat=repeat)\n",
    "        model_dict['Validation Accuracy'] = val_acc\n",
    "    \n",
    "    # Test accuracy\n",
    "    if eval_test:\n",
    "        _ = check_accuracy_extended(model, test_loader, \n",
    "                                    config['preprocess_test'], config, repeat=repeat)\n",
    "        model_dict['Test Throughput'] = _[4]\n",
    "        model_dict['Test Accuracy'] = _[0]\n",
    "        model_dict['Test Score'] = _[1]\n",
    "        model_dict['Test Target'] = _[2]\n",
    "        \n",
    "        pred =  model_dict['Test Score'].argmax(axis=-1)\n",
    "        target = model_dict['Test Target']\n",
    "        test_confusion = calculate_confusion_matrix2(pred, target, model_dict['Test Score'].shape[-1], \n",
    "                                                     len(test_loader.dataset)) \n",
    "        test_class_wise_metrics = calculate_class_wise_metrics(test_confusion.sum(axis=0))\n",
    "\n",
    "        for k, v in test_class_wise_metrics.items():\n",
    "            for c in range(config['out_dims']):\n",
    "                c_name = config['class_label_to_name'][c]\n",
    "                model_dict[f'{k} ({c_name})'] = test_class_wise_metrics[k][c]\n",
    "            \n",
    "        if save_fig:\n",
    "            draw_roc_curve(model_dict['Test Score'], \n",
    "                           model_dict['Test Target'], \n",
    "                           config['class_label_to_name'], \n",
    "                           use_wandb=False, \n",
    "                           save_path=f'local/output/imgs/{model_dict[\"name\"]}-ROC.pdf')\n",
    "\n",
    "            draw_confusion(test_confusion.sum(axis=0), \n",
    "                           config['class_label_to_name'], \n",
    "                           use_wandb=False, \n",
    "                           save_path=f'local/output/imgs/{model_dict[\"name\"]}-confusion.pdf')\n",
    "\n",
    "            draw_confusion2(test_confusion.mean(axis=0), \n",
    "                            test_confusion.std(axis=0), \n",
    "                            config['class_label_to_name'], \n",
    "                            use_wandb=False, \n",
    "                            save_path=f'local/output/imgs/{model_dict[\"name\"]}-confusion2.pdf')\n",
    "\n",
    "            draw_class_wise_metrics(test_confusion.sum(axis=0), \n",
    "                                    config['class_label_to_name'], \n",
    "                                    use_wandb=False, \n",
    "                                    save_path=f'local/output/imgs/{model_dict[\"name\"]}-class-wise.pdf')\n",
    "    # Multi-crop test accuracy\n",
    "    if eval_test_multi:\n",
    "        _ = check_accuracy_multicrop_extended(model, multicrop_test_loader, \n",
    "                                              config['preprocess_test'], config, repeat=repeat)\n",
    "        model_dict['Multi-Crop Test Throughput'] = _[4]\n",
    "        model_dict['Multi-Crop Test Accuracy'] = _[0]\n",
    "        model_dict['Multi-Crop Test Score'] = _[1]\n",
    "        model_dict['Multi-Crop Test Target'] = _[2]\n",
    "        \n",
    "        pred =  model_dict['Multi-Crop Test Score'].argmax(axis=-1)\n",
    "        target = model_dict['Multi-Crop Test Target']\n",
    "        multi_test_confusion = calculate_confusion_matrix2(pred, target, model_dict['Test Score'].shape[-1], \n",
    "                                                           len(test_loader.dataset)) \n",
    "        multi_test_class_wise_metrics = calculate_class_wise_metrics(multi_test_confusion.sum(axis=0))\n",
    "\n",
    "        for k, v in multi_test_class_wise_metrics.items():\n",
    "            for c in range(config['out_dims']):\n",
    "                c_name = config['class_label_to_name'][c]\n",
    "                model_dict[f'Multi-Crop {k} ({c_name})'] = multi_test_class_wise_metrics[k][c]\n",
    "\n",
    "        if save_fig:\n",
    "            draw_roc_curve(model_dict['Multi-Crop Test Score'], \n",
    "                           model_dict['Multi-Crop Test Target'], \n",
    "                           config['class_label_to_name'], \n",
    "                           use_wandb=False, \n",
    "                           save_path=f'local/output/imgs/{model_dict[\"name\"]}-roc-tta.pdf')\n",
    "\n",
    "            draw_confusion(multi_test_confusion.sum(axis=0), \n",
    "                           config['class_label_to_name'], \n",
    "                           use_wandb=False, \n",
    "                           save_path=f'local/output/imgs/{model_dict[\"name\"]}-confusion-tta.pdf')\n",
    "            \n",
    "            draw_confusion2(multi_test_confusion.mean(axis=0), \n",
    "                            multi_test_confusion.std(axis=0), \n",
    "                            config['class_label_to_name'], \n",
    "                            use_wandb=False, \n",
    "                            save_path=f'local/output/imgs/{model_dict[\"name\"]}-confusion2-tta.pdf')\n",
    "\n",
    "            draw_class_wise_metrics(multi_test_confusion.sum(axis=0), \n",
    "                                    config['class_label_to_name'], \n",
    "                                    use_wandb=False, \n",
    "                                    save_path=f'local/output/imgs/{model_dict[\"name\"]}-class-wise-tta.pdf') \n",
    "            \n",
    "print('==== Finished ====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b58f9d7d-eb8d-46f5-9035-00d7cdf300c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pool_backup = deepcopy(model_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f20c63-6d13-47a3-b6d5-8cbf89b5b25e",
   "metadata": {},
   "source": [
    "## Conduct ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3343a302-6361-49db-b31e-68f5b43f98b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if eval_ensemble:\n",
    "#     if 'Ensemble' == model_pool[-1]['name']:\n",
    "#         model_pool.remove(model_pool[-1])     \n",
    "\n",
    "#     # conduct ensembling\n",
    "#     if eval_test:\n",
    "#         ensem_test_score = np.zeros_like(model_pool[0]['Test Score'])\n",
    "#         ensem_test_latency = 0\n",
    "\n",
    "#     if eval_test_multi:\n",
    "#         ensem_multi_test_score = np.zeros_like(model_pool[0]['Multi-Crop Test Score'])\n",
    "#         ensem_multi_test_latency = 0\n",
    "\n",
    "#     ensem_params = 0\n",
    "#     ensem_model_size = 0\n",
    "\n",
    "#     for model_dict in model_pool:        \n",
    "#         ensem_params += model_dict['num_params']\n",
    "#         ensem_model_size += model_dict['model size (MiB)']\n",
    "\n",
    "#         if eval_test:\n",
    "#             ensem_test_score += model_dict['Test Score'] / len(model_pool)\n",
    "#             ensem_test_latency += 1 / model_dict['Test Throughput']\n",
    "\n",
    "#         if eval_test_multi:\n",
    "#             ensem_multi_test_score += model_dict['Multi-Crop Test Score'] / len(model_pool)\n",
    "#             ensem_multi_test_latency += 1 / model_dict['Multi-Crop Test Throughput']\n",
    "            \n",
    "#     # test accuracy\n",
    "#     if eval_test:\n",
    "#         # confusion matrix\n",
    "#         pred = ensem_test_score.argmax(axis=-1)\n",
    "#         target = model_pool[0]['Test Target']\n",
    "#         ensem_test_acc = 100.0 * (pred.squeeze() == target).sum() / pred.shape[0]\n",
    "\n",
    "#         ensem_test_confusion = calculate_confusion_matrix2(pred, target, ensem_test_score.shape[-1], \n",
    "#                                                            len(test_loader.dataset))\n",
    "#         ensem_test_class_wise_metrics = calculate_class_wise_metrics(ensem_test_confusion.sum(axis=0))\n",
    "\n",
    "#         # draw\n",
    "#         save_path = f'local/output/imgs/{task}-ensemble-confusion.pdf' if save_fig else None\n",
    "#         draw_confusion(ensem_test_confusion.sum(axis=0), config['class_label_to_name'], \n",
    "#                        normalize=True, use_wandb=False, save_path=save_path)\n",
    "\n",
    "#         save_path = f'local/output/imgs/{task}-ensemble-confusion2.pdf' if save_fig else None\n",
    "#         draw_confusion2(ensem_test_confusion.mean(axis=0), ensem_test_confusion.std(axis=0), \n",
    "#                         config['class_label_to_name'], use_wandb=False, save_path=save_path)\n",
    "\n",
    "#         save_path = f'local/output/imgs/{task}-ensemble-roc.pdf' if save_fig else None\n",
    "#         draw_roc_curve(ensem_test_score, model_pool[0]['Test Target'], config['class_label_to_name'], \n",
    "#                        use_wandb=False, save_path=save_path)\n",
    "\n",
    "#         save_path = f'local/output/imgs/{task}-ensemble-class-wise.pdf' if save_fig else None\n",
    "#         draw_class_wise_metrics(ensem_test_confusion.sum(axis=0), config['class_label_to_name'], \n",
    "#                             use_wandb=False, save_path=save_path, percent=True)\n",
    "        \n",
    "#     # multi-crop accuracy\n",
    "#     if eval_test_multi:\n",
    "#         # confusion matrix\n",
    "#         pred = ensem_multi_test_score.argmax(axis=-1)\n",
    "#         target = model_pool[0]['Multi-Crop Test Target']\n",
    "#         ensem_multi_test_acc = 100.0 * (pred.squeeze() == target).sum() / pred.shape[0]\n",
    "\n",
    "#         ensem_multi_test_confusion = calculate_confusion_matrix2(pred, target, ensem_multi_test_score.shape[-1], \n",
    "#                                                                  len(test_loader.dataset))\n",
    "#         ensem_multi_test_class_wise_metrics = calculate_class_wise_metrics(ensem_multi_test_confusion.sum(axis=0))\n",
    "\n",
    "#         # draw\n",
    "#         save_path = f'local/output/imgs/{task}-ensemble-confusion-tta.pdf' if save_fig else None\n",
    "#         draw_confusion(ensem_multi_test_confusion.sum(axis=0), config['class_label_to_name'], \n",
    "#                        normalize=True, use_wandb=False, save_path=save_path)\n",
    "\n",
    "#         save_path = f'local/output/imgs/{task}-ensemble-confusion-tta2.pdf' if save_fig else None\n",
    "#         draw_confusion2(ensem_multi_test_confusion.mean(axis=0), ensem_multi_test_confusion.std(axis=0), \n",
    "#                         config['class_label_to_name'], use_wandb=False, save_path=save_path)\n",
    "\n",
    "#         save_path = f'local/output/imgs/{task}-ensemble-roc-tta.pdf' if save_fig else None\n",
    "#         draw_roc_curve(ensem_multi_test_score, model_pool[0]['Multi-Crop Test Target'], config['class_label_to_name'], \n",
    "#                        use_wandb=False, save_path=save_path)\n",
    "\n",
    "#         save_path = f'local/output/imgs/{task}-ensemble-class-wise-tta.pdf' if save_fig else None\n",
    "#         draw_class_wise_metrics(ensem_multi_test_confusion.sum(axis=0), config['class_label_to_name'], \n",
    "#                                 use_wandb=False, save_path=save_path, percent=True)\n",
    "        \n",
    "#     # summarize the ensemble results\n",
    "#     ensem_dict = {}\n",
    "\n",
    "#     ensem_dict['name'] = 'Ensemble'\n",
    "#     ensem_dict['num_params'] = ensem_params\n",
    "#     ensem_dict['model size (MiB)'] = ensem_model_size\n",
    "\n",
    "#     if eval_test:\n",
    "#         ensem_dict['Test Throughput'] = 1 / ensem_test_latency\n",
    "#         ensem_dict['Test Accuracy'] = ensem_test_acc\n",
    "\n",
    "#         for k, v in ensem_test_class_wise_metrics.items():\n",
    "#             for c in range(config['out_dims']):\n",
    "#                 c_name = config['class_label_to_name'][c]\n",
    "#                 ensem_dict[f'{k} ({c_name})'] = ensem_test_class_wise_metrics[k][c]\n",
    "\n",
    "#     if eval_test_multi:\n",
    "#         ensem_dict['Multi-Crop Test Throughput'] = 1 / ensem_multi_test_latency\n",
    "#         ensem_dict['Multi-Crop Test Accuracy'] = ensem_multi_test_acc\n",
    "\n",
    "#         for k, v in ensem_multi_test_class_wise_metrics.items():\n",
    "#             for c in range(config['out_dims']):\n",
    "#                 c_name = config['class_label_to_name'][c]\n",
    "#                 ensem_dict[f'Multi-Crop {k} ({c_name})'] = ensem_multi_test_class_wise_metrics[k][c]\n",
    "\n",
    "#     model_pool.append(ensem_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab2c2d4f-7fcc-4f0c-b456-4bd6eda98c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pool_frame = deepcopy(model_pool)\n",
    "\n",
    "# for model_dict in model_pool_frame:\n",
    "#     model_dict.pop('Test Score', None)\n",
    "#     model_dict.pop('Test Target', None)\n",
    "#     model_dict.pop('Multi-Crop Test Score', None)\n",
    "#     model_dict.pop('Multi-Crop Test Target', None)\n",
    "    \n",
    "# pd.DataFrame(model_pool_frame).to_csv(f'local/output/{task}.csv')\n",
    "# pd.DataFrame(model_pool_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf323d3-646f-41ec-a114-b44f843a5d49",
   "metadata": {},
   "source": [
    "## Ensemble conbinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75058791-8705-4bbb-9cc7-ea21d71d06ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00464c8104da4893a9ed39feac88fd9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from tqdm.auto import tqdm\n",
    "sample_list = deepcopy(model_names)\n",
    "list_combinations = list()\n",
    "\n",
    "for n in range(2, len(sample_list)):\n",
    "    list_combinations += list(combinations(sample_list, n))\n",
    "\n",
    "results = []\n",
    "\n",
    "for combination in tqdm(list_combinations):\n",
    "    model_pool = []\n",
    "    for model_dict in model_pool_backup:\n",
    "        if model_dict['name'] in combination:\n",
    "            model_pool.append(model_dict)\n",
    "\n",
    "    if eval_ensemble:\n",
    "        if 'Ensemble' == model_pool[-1]['name']:\n",
    "            model_pool.remove(model_pool[-1])     \n",
    "    \n",
    "        # conduct ensembling\n",
    "        if eval_test:\n",
    "            ensem_test_score = np.zeros_like(model_pool[0]['Test Score'])\n",
    "            ensem_test_latency = 0\n",
    "    \n",
    "        if eval_test_multi:\n",
    "            ensem_multi_test_score = np.zeros_like(model_pool[0]['Multi-Crop Test Score'])\n",
    "            ensem_multi_test_latency = 0\n",
    "    \n",
    "        ensem_params = 0\n",
    "        ensem_model_size = 0\n",
    "    \n",
    "        for model_dict in model_pool:        \n",
    "            ensem_params += model_dict['num_params']\n",
    "            ensem_model_size += model_dict['model size (MiB)']\n",
    "    \n",
    "            if eval_test:\n",
    "                ensem_test_score += model_dict['Test Score'] / len(model_pool)\n",
    "                ensem_test_latency += 1 / model_dict['Test Throughput']\n",
    "    \n",
    "            if eval_test_multi:\n",
    "                ensem_multi_test_score += model_dict['Multi-Crop Test Score'] / len(model_pool)\n",
    "                ensem_multi_test_latency += 1 / model_dict['Multi-Crop Test Throughput']\n",
    "                \n",
    "        # test accuracy\n",
    "        if eval_test:\n",
    "            # confusion matrix\n",
    "            pred = ensem_test_score.argmax(axis=-1)\n",
    "            target = model_pool[0]['Test Target']\n",
    "            ensem_test_acc = 100.0 * (pred.squeeze() == target).sum() / pred.shape[0]\n",
    "    \n",
    "            ensem_test_confusion = calculate_confusion_matrix2(pred, target, ensem_test_score.shape[-1], \n",
    "                                                               len(test_loader.dataset))\n",
    "            ensem_test_class_wise_metrics = calculate_class_wise_metrics(ensem_test_confusion.sum(axis=0))\n",
    "            \n",
    "        # multi-crop accuracy\n",
    "        if eval_test_multi:\n",
    "            # confusion matrix\n",
    "            pred = ensem_multi_test_score.argmax(axis=-1)\n",
    "            target = model_pool[0]['Multi-Crop Test Target']\n",
    "            ensem_multi_test_acc = 100.0 * (pred.squeeze() == target).sum() / pred.shape[0]\n",
    "    \n",
    "            ensem_multi_test_confusion = calculate_confusion_matrix2(pred, target, ensem_multi_test_score.shape[-1], \n",
    "                                                                     len(test_loader.dataset))\n",
    "            ensem_multi_test_class_wise_metrics = calculate_class_wise_metrics(ensem_multi_test_confusion.sum(axis=0))\n",
    "            \n",
    "        # summarize the ensemble results\n",
    "        ensem_dict = {}\n",
    "    \n",
    "        ensem_dict['name'] = 'Ensemble'\n",
    "        ensem_dict['num_params'] = ensem_params\n",
    "        ensem_dict['model size (MiB)'] = ensem_model_size\n",
    "    \n",
    "        if eval_test:\n",
    "            ensem_dict['Test Throughput'] = 1 / ensem_test_latency\n",
    "            ensem_dict['Test Accuracy'] = ensem_test_acc\n",
    "    \n",
    "            for k, v in ensem_test_class_wise_metrics.items():\n",
    "                for c in range(config['out_dims']):\n",
    "                    c_name = config['class_label_to_name'][c]\n",
    "                    ensem_dict[f'{k} ({c_name})'] = ensem_test_class_wise_metrics[k][c]\n",
    "    \n",
    "        if eval_test_multi:\n",
    "            ensem_dict['Multi-Crop Test Throughput'] = 1 / ensem_multi_test_latency\n",
    "            ensem_dict['Multi-Crop Test Accuracy'] = ensem_multi_test_acc\n",
    "    \n",
    "            for k, v in ensem_multi_test_class_wise_metrics.items():\n",
    "                for c in range(config['out_dims']):\n",
    "                    c_name = config['class_label_to_name'][c]\n",
    "                    ensem_dict[f'Multi-Crop {k} ({c_name})'] = ensem_multi_test_class_wise_metrics[k][c]\n",
    "    \n",
    "        model_pool.append(ensem_dict)\n",
    "    results.append({\n",
    "        'Combination': combination,\n",
    "        'Test Accuracy': model_pool[-1]['Test Accuracy'],\n",
    "        'Multi-Crop Test Accuracy': model_pool[-1]['Multi-Crop Test Accuracy']   \n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a3191a2-192c-4d58-87f2-468f1956c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pool_comb = deepcopy(model_pool_backup)\n",
    "sorted_results = sorted(results, key=lambda x: x['Multi-Crop Test Accuracy'])\n",
    "for k in range(10):\n",
    "    ensemble = sorted_results[-1 - k]\n",
    "\n",
    "    ensem_dict = {}\n",
    "    ensem_dict['name'] = ensemble['Combination']\n",
    "    ensem_dict['Test Accuracy'] = ensemble['Test Accuracy']\n",
    "    ensem_dict['Multi-Crop Test Accuracy'] = ensemble['Multi-Crop Test Accuracy']\n",
    "    model_pool_comb.append(ensem_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85f973f6-b799-4ba5-9258-9eee4f2f88ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>model</th>\n",
       "      <th>num_params</th>\n",
       "      <th>model size (MiB)</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>use_age</th>\n",
       "      <th>EKG</th>\n",
       "      <th>awgn</th>\n",
       "      <th>awgn_age</th>\n",
       "      <th>...</th>\n",
       "      <th>Multi-Crop Accuracy (Normal)</th>\n",
       "      <th>Multi-Crop Accuracy (Abnormal)</th>\n",
       "      <th>Multi-Crop Sensitivity (Normal)</th>\n",
       "      <th>Multi-Crop Sensitivity (Abnormal)</th>\n",
       "      <th>Multi-Crop Specificity (Normal)</th>\n",
       "      <th>Multi-Crop Specificity (Abnormal)</th>\n",
       "      <th>Multi-Crop Precision (Normal)</th>\n",
       "      <th>Multi-Crop Precision (Abnormal)</th>\n",
       "      <th>Multi-Crop F1-score (Normal)</th>\n",
       "      <th>Multi-Crop F1-score (Abnormal)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>767ogu61</td>\n",
       "      <td>local/checkpoint/767ogu61\\checkpoint.pt</td>\n",
       "      <td>1D-MAE-B</td>\n",
       "      <td>85722626.0</td>\n",
       "      <td>327.803819</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>no</td>\n",
       "      <td>O</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.893082</td>\n",
       "      <td>0.854701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>767ogu61</td>\n",
       "      <td>local/checkpoint/767ogu61\\checkpoint.pt</td>\n",
       "      <td>1D-MAE-B</td>\n",
       "      <td>85722626.0</td>\n",
       "      <td>327.803819</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>no</td>\n",
       "      <td>O</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.894410</td>\n",
       "      <td>0.852174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>767ogu61</td>\n",
       "      <td>local/checkpoint/767ogu61\\checkpoint.pt</td>\n",
       "      <td>1D-MAE-B</td>\n",
       "      <td>85722626.0</td>\n",
       "      <td>327.803819</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>no</td>\n",
       "      <td>O</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.897196</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>767ogu61</td>\n",
       "      <td>local/checkpoint/767ogu61\\checkpoint.pt</td>\n",
       "      <td>1D-MAE-B</td>\n",
       "      <td>85722626.0</td>\n",
       "      <td>327.803819</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>no</td>\n",
       "      <td>O</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.839080</td>\n",
       "      <td>0.960784</td>\n",
       "      <td>0.901235</td>\n",
       "      <td>0.859649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>767ogu61</td>\n",
       "      <td>local/checkpoint/767ogu61\\checkpoint.pt</td>\n",
       "      <td>1D-MAE-B</td>\n",
       "      <td>85722626.0</td>\n",
       "      <td>327.803819</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>no</td>\n",
       "      <td>O</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862319</td>\n",
       "      <td>0.862319</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.825581</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.881988</td>\n",
       "      <td>0.834783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>767ogu61</td>\n",
       "      <td>local/checkpoint/767ogu61\\checkpoint.pt</td>\n",
       "      <td>1D-MAE-B</td>\n",
       "      <td>85722626.0</td>\n",
       "      <td>327.803819</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>no</td>\n",
       "      <td>O</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.862069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>767ogu61</td>\n",
       "      <td>local/checkpoint/767ogu61\\checkpoint.pt</td>\n",
       "      <td>1D-MAE-B</td>\n",
       "      <td>85722626.0</td>\n",
       "      <td>327.803819</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>no</td>\n",
       "      <td>O</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.769841</td>\n",
       "      <td>0.769841</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.950980</td>\n",
       "      <td>0.895062</td>\n",
       "      <td>0.850877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(767ogu61, 767ogu61, 767ogu61, 767ogu61, 767og...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(767ogu61, 767ogu61, 767ogu61, 767ogu61, 767og...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(767ogu61, 767ogu61, 767ogu61, 767ogu61, 767og...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(767ogu61, 767ogu61, 767ogu61, 767ogu61, 767og...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(767ogu61, 767ogu61, 767ogu61, 767ogu61, 767og...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(767ogu61, 767ogu61, 767ogu61, 767ogu61, 767og...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(767ogu61, 767ogu61, 767ogu61, 767ogu61, 767og...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(767ogu61, 767ogu61, 767ogu61, 767ogu61, 767og...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(767ogu61, 767ogu61, 767ogu61, 767ogu61, 767og...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(767ogu61, 767ogu61, 767ogu61, 767ogu61, 767og...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  \\\n",
       "0                                            767ogu61   \n",
       "1                                            767ogu61   \n",
       "2                                            767ogu61   \n",
       "3                                            767ogu61   \n",
       "4                                            767ogu61   \n",
       "5                                            767ogu61   \n",
       "6                                            767ogu61   \n",
       "7   (767ogu61, 767ogu61, 767ogu61, 767ogu61, 767og...   \n",
       "8   (767ogu61, 767ogu61, 767ogu61, 767ogu61, 767og...   \n",
       "9   (767ogu61, 767ogu61, 767ogu61, 767ogu61, 767og...   \n",
       "10  (767ogu61, 767ogu61, 767ogu61, 767ogu61, 767og...   \n",
       "11  (767ogu61, 767ogu61, 767ogu61, 767ogu61, 767og...   \n",
       "12  (767ogu61, 767ogu61, 767ogu61, 767ogu61, 767og...   \n",
       "13  (767ogu61, 767ogu61, 767ogu61, 767ogu61, 767og...   \n",
       "14  (767ogu61, 767ogu61, 767ogu61, 767ogu61, 767og...   \n",
       "15  (767ogu61, 767ogu61, 767ogu61, 767ogu61, 767og...   \n",
       "16  (767ogu61, 767ogu61, 767ogu61, 767ogu61, 767og...   \n",
       "\n",
       "                                       path     model  num_params  \\\n",
       "0   local/checkpoint/767ogu61\\checkpoint.pt  1D-MAE-B  85722626.0   \n",
       "1   local/checkpoint/767ogu61\\checkpoint.pt  1D-MAE-B  85722626.0   \n",
       "2   local/checkpoint/767ogu61\\checkpoint.pt  1D-MAE-B  85722626.0   \n",
       "3   local/checkpoint/767ogu61\\checkpoint.pt  1D-MAE-B  85722626.0   \n",
       "4   local/checkpoint/767ogu61\\checkpoint.pt  1D-MAE-B  85722626.0   \n",
       "5   local/checkpoint/767ogu61\\checkpoint.pt  1D-MAE-B  85722626.0   \n",
       "6   local/checkpoint/767ogu61\\checkpoint.pt  1D-MAE-B  85722626.0   \n",
       "7                                       NaN       NaN         NaN   \n",
       "8                                       NaN       NaN         NaN   \n",
       "9                                       NaN       NaN         NaN   \n",
       "10                                      NaN       NaN         NaN   \n",
       "11                                      NaN       NaN         NaN   \n",
       "12                                      NaN       NaN         NaN   \n",
       "13                                      NaN       NaN         NaN   \n",
       "14                                      NaN       NaN         NaN   \n",
       "15                                      NaN       NaN         NaN   \n",
       "16                                      NaN       NaN         NaN   \n",
       "\n",
       "    model size (MiB)  seq_length use_age  EKG   awgn  awgn_age  ...  \\\n",
       "0         327.803819      2048.0      no    O  0.003     0.001  ...   \n",
       "1         327.803819      2048.0      no    O  0.003     0.001  ...   \n",
       "2         327.803819      2048.0      no    O  0.003     0.001  ...   \n",
       "3         327.803819      2048.0      no    O  0.003     0.001  ...   \n",
       "4         327.803819      2048.0      no    O  0.003     0.001  ...   \n",
       "5         327.803819      2048.0      no    O  0.003     0.001  ...   \n",
       "6         327.803819      2048.0      no    O  0.003     0.001  ...   \n",
       "7                NaN         NaN     NaN  NaN    NaN       NaN  ...   \n",
       "8                NaN         NaN     NaN  NaN    NaN       NaN  ...   \n",
       "9                NaN         NaN     NaN  NaN    NaN       NaN  ...   \n",
       "10               NaN         NaN     NaN  NaN    NaN       NaN  ...   \n",
       "11               NaN         NaN     NaN  NaN    NaN       NaN  ...   \n",
       "12               NaN         NaN     NaN  NaN    NaN       NaN  ...   \n",
       "13               NaN         NaN     NaN  NaN    NaN       NaN  ...   \n",
       "14               NaN         NaN     NaN  NaN    NaN       NaN  ...   \n",
       "15               NaN         NaN     NaN  NaN    NaN       NaN  ...   \n",
       "16               NaN         NaN     NaN  NaN    NaN       NaN  ...   \n",
       "\n",
       "    Multi-Crop Accuracy (Normal)  Multi-Crop Accuracy (Abnormal)  \\\n",
       "0                       0.876812                        0.876812   \n",
       "1                       0.876812                        0.876812   \n",
       "2                       0.880435                        0.880435   \n",
       "3                       0.884058                        0.884058   \n",
       "4                       0.862319                        0.862319   \n",
       "5                       0.884058                        0.884058   \n",
       "6                       0.876812                        0.876812   \n",
       "7                            NaN                             NaN   \n",
       "8                            NaN                             NaN   \n",
       "9                            NaN                             NaN   \n",
       "10                           NaN                             NaN   \n",
       "11                           NaN                             NaN   \n",
       "12                           NaN                             NaN   \n",
       "13                           NaN                             NaN   \n",
       "14                           NaN                             NaN   \n",
       "15                           NaN                             NaN   \n",
       "16                           NaN                             NaN   \n",
       "\n",
       "    Multi-Crop Sensitivity (Normal)  Multi-Crop Sensitivity (Abnormal)  \\\n",
       "0                          0.946667                           0.793651   \n",
       "1                          0.960000                           0.777778   \n",
       "2                          0.960000                           0.785714   \n",
       "3                          0.973333                           0.777778   \n",
       "4                          0.946667                           0.761905   \n",
       "5                          0.960000                           0.793651   \n",
       "6                          0.966667                           0.769841   \n",
       "7                               NaN                                NaN   \n",
       "8                               NaN                                NaN   \n",
       "9                               NaN                                NaN   \n",
       "10                              NaN                                NaN   \n",
       "11                              NaN                                NaN   \n",
       "12                              NaN                                NaN   \n",
       "13                              NaN                                NaN   \n",
       "14                              NaN                                NaN   \n",
       "15                              NaN                                NaN   \n",
       "16                              NaN                                NaN   \n",
       "\n",
       "    Multi-Crop Specificity (Normal) Multi-Crop Specificity (Abnormal)  \\\n",
       "0                          0.793651                          0.946667   \n",
       "1                          0.777778                          0.960000   \n",
       "2                          0.785714                          0.960000   \n",
       "3                          0.777778                          0.973333   \n",
       "4                          0.761905                          0.946667   \n",
       "5                          0.793651                          0.960000   \n",
       "6                          0.769841                          0.966667   \n",
       "7                               NaN                               NaN   \n",
       "8                               NaN                               NaN   \n",
       "9                               NaN                               NaN   \n",
       "10                              NaN                               NaN   \n",
       "11                              NaN                               NaN   \n",
       "12                              NaN                               NaN   \n",
       "13                              NaN                               NaN   \n",
       "14                              NaN                               NaN   \n",
       "15                              NaN                               NaN   \n",
       "16                              NaN                               NaN   \n",
       "\n",
       "    Multi-Crop Precision (Normal)  Multi-Crop Precision (Abnormal)  \\\n",
       "0                        0.845238                         0.925926   \n",
       "1                        0.837209                         0.942308   \n",
       "2                        0.842105                         0.942857   \n",
       "3                        0.839080                         0.960784   \n",
       "4                        0.825581                         0.923077   \n",
       "5                        0.847059                         0.943396   \n",
       "6                        0.833333                         0.950980   \n",
       "7                             NaN                              NaN   \n",
       "8                             NaN                              NaN   \n",
       "9                             NaN                              NaN   \n",
       "10                            NaN                              NaN   \n",
       "11                            NaN                              NaN   \n",
       "12                            NaN                              NaN   \n",
       "13                            NaN                              NaN   \n",
       "14                            NaN                              NaN   \n",
       "15                            NaN                              NaN   \n",
       "16                            NaN                              NaN   \n",
       "\n",
       "    Multi-Crop F1-score (Normal) Multi-Crop F1-score (Abnormal)  \n",
       "0                       0.893082                       0.854701  \n",
       "1                       0.894410                       0.852174  \n",
       "2                       0.897196                       0.857143  \n",
       "3                       0.901235                       0.859649  \n",
       "4                       0.881988                       0.834783  \n",
       "5                       0.900000                       0.862069  \n",
       "6                       0.895062                       0.850877  \n",
       "7                            NaN                            NaN  \n",
       "8                            NaN                            NaN  \n",
       "9                            NaN                            NaN  \n",
       "10                           NaN                            NaN  \n",
       "11                           NaN                            NaN  \n",
       "12                           NaN                            NaN  \n",
       "13                           NaN                            NaN  \n",
       "14                           NaN                            NaN  \n",
       "15                           NaN                            NaN  \n",
       "16                           NaN                            NaN  \n",
       "\n",
       "[17 rows x 50 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pool_frame = deepcopy(model_pool_comb)\n",
    "\n",
    "for model_dict in model_pool_frame:\n",
    "    model_dict.pop('Test Score', None)\n",
    "    model_dict.pop('Test Target', None)\n",
    "    model_dict.pop('Multi-Crop Test Score', None)\n",
    "    model_dict.pop('Multi-Crop Test Target', None)\n",
    "    \n",
    "pd.DataFrame(model_pool_frame).to_csv(f'local/output/{task}-comb.csv')\n",
    "pd.DataFrame(model_pool_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df9ad5a-1ffc-4c7f-bc15-a5b653cee4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363676a0-9e70-42a2-b265-a4b8a180e634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb1560-98ee-4410-af0f-66440a651d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a015df-bac9-483a-8a93-3db1d43926e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedcc8cd-c793-4314-b50d-2d556f1e9490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e7ce67-3406-4e54-893f-0e69bcca2b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b18fd432-14fc-4771-a203-3e705537685a",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f749f-ac27-4ff7-9fe0-f274f1a6b662",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
