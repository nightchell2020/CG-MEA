{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74515d5-5f25-477b-9a97-ed1f9b6d4c51",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluate Ensemble\n",
    "\n",
    "This notebook combines the classification results of some models via logit-ensembling way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a2666f-6b4b-4748-9dca-2884347a1f0f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df587e38-b1a9-42c8-9b50-680200a9bec7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minjae\\Desktop\\EEG_Project\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb41bf8-1713-4228-b799-0e1c87545a16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "import pprint\n",
    "import wandb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_script import build_dataset_for_train\n",
    "import models\n",
    "from train.evaluate import check_accuracy\n",
    "from train.evaluate import check_accuracy_extended\n",
    "from train.evaluate import check_accuracy_extended_debug\n",
    "from train.evaluate import check_accuracy_multicrop\n",
    "from train.evaluate import check_accuracy_multicrop_extended\n",
    "from train.evaluate import calculate_confusion_matrix\n",
    "from train.evaluate import calculate_confusion_matrix2\n",
    "from train.evaluate import calculate_class_wise_metrics\n",
    "from train.visualize import draw_roc_curve\n",
    "from train.visualize import draw_confusion, draw_confusion2\n",
    "from train.visualize import draw_class_wise_metrics\n",
    "from train.visualize import draw_error_table\n",
    "from train.visualize import annotate_heatmap\n",
    "from train.visualize import draw_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d10e3f39-ed55-422c-b47f-376691cbeed6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.0+cu117\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a62fa4-aa53-49d5-8ab4-2e2aaf7b65d1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "-----\n",
    "\n",
    "## List up the models to check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06d3404e-be31-4a63-ac4b-214868fe0cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D-VGG-19\n",
      "1D-ResNet-18\n",
      "1D-ResNet-50\n",
      "1D-ResNeXt-50\n",
      "2D-VGG-19\n",
      "2D-ResNet-18\n",
      "2D-ResNet-50\n",
      "2D-ResNeXt-50\n",
      "2D-ViT-B-16\n",
      "['1vc80n1f',\n",
      " 'l8524nml',\n",
      " 'gvqyvmrj',\n",
      " 'v301o425',\n",
      " 'lo88puq7',\n",
      " 'xci5svkl',\n",
      " 'syrx7bmk',\n",
      " '1sl7ipca',\n",
      " 'gjkysllw']\n"
     ]
    }
   ],
   "source": [
    "model_names = [\n",
    "    '1vc80n1f',  # 1D-VGG-19 \n",
    "    'l8524nml',  # 1D-ResNet-18   // 2s1700lg, l8524nml\n",
    "    'gvqyvmrj',  # 1D-ResNet-50 \n",
    "    'v301o425',  # 1D-ResNeXt-50 \n",
    "    'lo88puq7',  # 2D-VGG-19\n",
    "    'xci5svkl',  # 2D-ResNet-18 \n",
    "    'syrx7bmk',  # 2D-ResNet-50 \n",
    "    '1sl7ipca',  # 2D-ResNeXt-50 \n",
    "    'gjkysllw',  # 2D-ViT-B-16 \n",
    "]\n",
    "\n",
    "# model_names = [\n",
    "#     'nemy8ikm',  # 1D-VGG-19\n",
    "#     '4439k9pg',  # 1D-ResNet-18\n",
    "#     'q1hhkmik',  # 1D-ResNet-50\n",
    "#     'tp7qn5hd',  # 1D-ResNeXt-50 \n",
    "#     'ruqd8r7g',  # 2D-VGG-19\n",
    "#     'dn10a6bv',  # 2D-ResNet-18\n",
    "#     'atbhqdgg',  # 2D-ResNet-50\n",
    "#     '0svudowu',  # 2D-ResNeXt-50\n",
    "#     '1cdws3t5',  # 2D-ViT-B-16\n",
    "# ]\n",
    "\n",
    "model_pool = []\n",
    "\n",
    "for model_name in model_names:\n",
    "    path = os.path.join(r'E:\\CAUEEG\\checkpoint', model_name, 'checkpoint.pt')\n",
    "    try:\n",
    "        ckpt = torch.load(path, map_location=device)\n",
    "        print(ckpt['config']['model'])\n",
    "        model_pool.append({'name': model_name, 'path': path})\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'- checkpoint cannot be opened: {path}')\n",
    "        \n",
    "pprint.pprint([model_dict['name'] for model_dict in model_pool])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00973b7-d2ba-4e54-a4ac-86879c1fe89f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7dfec22-3837-46a7-8b4d-4588300068bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'cross-correlation'\n",
    "no_patient_overlap = False\n",
    "eval_ensemble = True\n",
    "\n",
    "base_repeat = 800 # 800\n",
    "crop_multiple = 8\n",
    "test_crop_multiple = 8\n",
    "\n",
    "verbose = False\n",
    "\n",
    "eval_train = False\n",
    "eval_val = True\n",
    "eval_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e74efead-1462-415c-aff4-d9712ac6a599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_score_epoch(model, loader, preprocess, config, repeat=1):\n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    N = len(loader.dataset)\n",
    "    C = len(config['class_label_to_name'])\n",
    "    \n",
    "    crop_multiple = config['crop_multiple']\n",
    "    \n",
    "    embeddings = torch.zeros((repeat, N, C), device=device)\n",
    "    \n",
    "    for k in range(repeat):\n",
    "        for i, sample_batched in enumerate(loader):\n",
    "            preprocess(sample_batched)\n",
    "            x = sample_batched['signal']\n",
    "            age = sample_batched['age']\n",
    "\n",
    "            output = model.compute_feature_embedding(x, age, target_from_last=0)\n",
    "            current_minibatch = x.shape[0]\n",
    "            \n",
    "            for m in range(current_minibatch // crop_multiple):\n",
    "                ind1 = m*crop_multiple\n",
    "                ind2 = (m + 1)*crop_multiple\n",
    "                ind3 = (config['minibatch'] // crop_multiple)*i + m\n",
    "                embeddings[k, ind3] = output[ind1:ind2].mean(dim=0, keepdim=True)\n",
    "                \n",
    "    return embeddings.mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e25ca9a-48ee-4c0d-8e06-616a84e59527",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Evaluate each model and accumulate the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee4f853-3cad-4b01-8ee8-44ac9e49adbe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for model_dict in model_pool:\n",
    "    # load and parse the checkpoint\n",
    "    ckpt = torch.load(model_dict['path'], map_location=device)\n",
    "    model_state = ckpt['model_state']\n",
    "    config = ckpt['config']\n",
    "    \n",
    "    model_dict['task'] = config['task']\n",
    "    model_dict['model'] = config['model']\n",
    "    \n",
    "    if '220419' in config['dataset_path']:\n",
    "        config['dataset_path'] = './local/dataset/caueeg-dataset/'\n",
    "    config['run_mode'] = 'eval'\n",
    "    \n",
    "    print('- checking for', model_dict['name'], config['model'], '...')\n",
    "    \n",
    "    # initiate the model\n",
    "    if '_target_' in config:\n",
    "        model = hydra.utils.instantiate(config).to(device)\n",
    "    elif type(config['generator']) is str:\n",
    "        config['generator'] = getattr(models, config['generator'].split('.')[-1])\n",
    "        if 'block' in config:\n",
    "            config['block'] = getattr(models, config['block'].split('.')[-1])\n",
    "        model = config['generator'](**config).to(device)\n",
    "    else:\n",
    "        if 'block' in config:\n",
    "            if config['block'] == models.resnet_1d.BottleneckBlock1D:\n",
    "                config['block'] = 'bottleneck'\n",
    "            elif config['block'] == models.resnet_2d.Bottleneck2D:\n",
    "                config['block'] = 'bottleneck'\n",
    "            elif config['block'] == models.resnet_1d.BasicBlock1D:\n",
    "                config['block'] = 'basic'\n",
    "            elif config['block'] == models.resnet_2d.BasicBlock2D:\n",
    "                config['block'] = 'basic'\n",
    "                \n",
    "        model = config['generator'](**config).to(device)\n",
    "    \n",
    "    if config.get('ddp', False):\n",
    "        model_state_ddp = deepcopy(model_state)\n",
    "        model_state = OrderedDict()\n",
    "        for k, v in model_state_ddp.items():\n",
    "            name = k[7:]  # remove 'module.' of DataParallel/DistributedDataParallel\n",
    "            model_state[name] = v\n",
    "    \n",
    "    model.load_state_dict(model_state)\n",
    "    \n",
    "    # reconfigure and update\n",
    "    config.pop('cwd', 0)\n",
    "    config['ddp'] = False\n",
    "    config['crop_multiple'] = crop_multiple\n",
    "    config['test_crop_multiple'] = test_crop_multiple  # do not use\n",
    "    config['crop_timing_analysis'] = False\n",
    "    config['eval'] = True\n",
    "    config['device'] = device\n",
    "\n",
    "    repeat = round(base_repeat / crop_multiple)\n",
    "    \n",
    "    # build dataset\n",
    "    _ = build_dataset_for_train(config, verbose=verbose)\n",
    "    train_loader = _[0]\n",
    "    val_loader = _[1]\n",
    "    test_loader = _[2]\n",
    "    \n",
    "    \n",
    "    path = f\"local/output/cross-correlation/{model_dict['name']}\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    # train accuracy\n",
    "    if eval_train:\n",
    "        train_embeddings = estimate_score_epoch(model, train_loader, \n",
    "                                                config['preprocess_test'], config, repeat=repeat)\n",
    "        torch.save(train_embeddings, os.path.join(path, 'train_embeddings.pt'))\n",
    "\n",
    "    # val accuracy\n",
    "    if eval_val:\n",
    "        val_embeddings = estimate_score_epoch(model, val_loader, \n",
    "                                              config['preprocess_test'], config, repeat=repeat)\n",
    "        torch.save(val_embeddings, os.path.join(path, 'val_embeddings.pt'))\n",
    "    \n",
    "    # Test accuracy\n",
    "    if eval_test:\n",
    "        test_embeddings = estimate_score_epoch(model, test_loader, \n",
    "                                               config['preprocess_test'], config, repeat=repeat)\n",
    "        torch.save(test_embeddings, os.path.join(path, 'test_embeddings.pt'))\n",
    "\n",
    "\n",
    "print('==== Finished ====')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8846b3-ef36-44a1-bef5-290bb841f0a5",
   "metadata": {},
   "source": [
    "## Calculate Cross-Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95b299cf-519d-4af7-b510-ebbd6ca41c7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model_dict in model_pool:\n",
    "    # load and parse the checkpoint\n",
    "    ckpt = torch.load(model_dict['path'], map_location=device)\n",
    "    model_state = ckpt['model_state']\n",
    "    config = ckpt['config']\n",
    "    \n",
    "    model_dict['task'] = config['task']\n",
    "    model_dict['model'] = config['model']\n",
    "    \n",
    "    if 'ViT' in model_dict['model']:\n",
    "        model_dict['model'] = model_dict['model'].replace('2D-ViT', 'ViT')\n",
    "\n",
    "    if '220419' in config['dataset_path']:\n",
    "        config['dataset_path'] = './local/dataset/caueeg-dataset/'\n",
    "    config['run_mode'] = 'eval'\n",
    "\n",
    "    \n",
    "    path = f\"local/output/cross-correlation/{model_dict['name']}\"\n",
    "    if eval_train:\n",
    "        model_dict['train_embeddings'] = torch.load(os.path.join(path, 'train_embeddings.pt')).cpu().numpy()\n",
    "                \n",
    "    if eval_val:\n",
    "        model_dict['val_embeddings'] = torch.load(os.path.join(path, 'val_embeddings.pt')).cpu().numpy()\n",
    "        \n",
    "    if eval_test:\n",
    "        model_dict['test_embeddings'] = torch.load(os.path.join(path, 'test_embeddings.pt')).cpu().numpy()\n",
    "        \n",
    "        \n",
    "    if 'ViT' in model_dict['model']:\n",
    "        model_dict['model'].replace('2D-ViT', 'ViT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "090dafc2-66e4-4236-a1d9-016e80efc056",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if eval_ensemble:\n",
    "    model_dict = {'name': 'Ensemble', 'model': 'Ensemble'}\n",
    "    if eval_train:\n",
    "        model_dict['train_embeddings'] = np.mean([md['train_embeddings'] for md in model_pool], axis=0)\n",
    "    if eval_val:\n",
    "        model_dict['val_embeddings'] = np.mean([md['val_embeddings'] for md in model_pool], axis=0)\n",
    "    if eval_test:\n",
    "        model_dict['test_embeddings'] = np.mean([md['test_embeddings'] for md in model_pool], axis=0)\n",
    "        \n",
    "    model_pool.append(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cf20ba7-616f-422c-997a-970579ee6247",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "def pearson_correlation(model_dict, target_embeddings):\n",
    "    result = np.zeros((len(model_dict), len(model_dict)))\n",
    "    C = model_dict[0][target_embeddings].shape[1]\n",
    "    \n",
    "    for i, md_1 in enumerate(model_dict):\n",
    "        for k, md_2 in enumerate(model_dict):\n",
    "            summation = 0.0\n",
    "            for c in range(C):\n",
    "                summation += pearsonr(md_1[target_embeddings][:, c], \n",
    "                                      md_2[target_embeddings][:, c])[0]\n",
    "            result[i, k] = summation / C\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74ccc913-a8ca-4735-b3ec-922d0a049574",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cosine_correlation(model_dict, target_embeddings):\n",
    "    result = np.zeros((len(model_dict), len(model_dict)))\n",
    "    C = model_dict[0][target_embeddings].shape[1]\n",
    "    \n",
    "    \n",
    "    for i, md_1 in enumerate(model_dict):\n",
    "        for k, md_2 in enumerate(model_dict):\n",
    "            cos_sim = cosine_similarity(md_1[target_embeddings], \n",
    "                                        md_2[target_embeddings])\n",
    "            result[i, k] = np.mean(cos_sim)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a0b548b-3414-419b-9bc4-91d63027700b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Other settings\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # cleaner text\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use('default') \n",
    "# ['Solarize_Light2', '_classic_test_patch', 'bmh', 'classic', 'dark_background', 'fast', \n",
    "#  'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn', 'seaborn-bright', 'seaborn-colorblind', \n",
    "#  'seaborn-dark', 'seaborn-dark-palette', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', \n",
    "#  'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', \n",
    "#  'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'tableau-colorblind10']\n",
    "\n",
    "plt.rcParams['image.interpolation'] = 'bicubic'\n",
    "plt.rcParams[\"font.family\"] = 'Roboto Slab' # 'NanumGothic' # for Hangul in Windows\n",
    "plt.style.use('classic') \n",
    "plt.style.use('default') \n",
    "plt.style.use('default') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.rcParams.update({'font.family': 'Roboto Slab'})\n",
    "plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "\n",
    "def draw_correlation(correlation, model_names, title='', save_path=None):\n",
    "    with plt.style.context(['science', 'default']):  # science, ieee, default, fivethirtyeight\n",
    "        plt.rcParams[\"font.family\"] = 'Roboto Slab' # 'NanumGothic' # for Hangul in Windows\n",
    "        plt.rcParams.update({\"font.size\": 16})\n",
    "        plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "\n",
    "        H = len(model_names) + 0.5\n",
    "        W = len(model_names) + 0.5\n",
    "        \n",
    "        fig = plt.figure(num=1, clear=True, figsize=(W, H), constrained_layout=True)\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "        data = correlation\n",
    "        im = draw_heatmap(\n",
    "            data,\n",
    "            model_names,\n",
    "            model_names,\n",
    "            ax=ax,\n",
    "            # imshow_kw={\"alpha\": 0.9, \"cmap\": \"YlOrRd\"},  # jet, YlOrRd, RdPu\n",
    "            imshow_kw={\"alpha\": 0.9, \"cmap\": \"coolwarm\"},  # jet, YlOrRd, RdPu\n",
    "            draw_cbar=False,\n",
    "            cbar_label=\"\",\n",
    "            cbar_kw={},\n",
    "        )\n",
    "        annotate_heatmap(im, anno_format=\"{x:.2f}\", text_colors=(\"black\", \"white\"), threshold=0.9)\n",
    "\n",
    "        ax.set_title(title)\n",
    "        # ax.set_xlabel(\"Model\")\n",
    "        # ax.set_ylabel(\"Model\")        \n",
    "\n",
    "        # save\n",
    "        if save_path:\n",
    "            fig.savefig(save_path, transparent=True)\n",
    "\n",
    "        if save_path is None:\n",
    "            plt.show()\n",
    "\n",
    "        # fig.clear()\n",
    "        plt.close(fig)\n",
    "        \n",
    "        \n",
    "def draw_correlation_mean(correlation, model_names, title='', save_path=None):\n",
    "    with plt.style.context(['science', 'default']):  # science, ieee, default, fivethirtyeight\n",
    "        plt.rcParams[\"font.family\"] = 'Roboto Slab' # 'NanumGothic' # for Hangul in Windows\n",
    "        plt.rcParams.update({\"font.size\": 16})\n",
    "        plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "\n",
    "        H = 2.5\n",
    "        W = len(model_names) + 0.5\n",
    "        \n",
    "        fig = plt.figure(num=1, clear=True, figsize=(W, H), constrained_layout=True)\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "        data = correlation\n",
    "        im = draw_heatmap(\n",
    "            data,\n",
    "            ['Average'],\n",
    "            model_names,\n",
    "            ax=ax,\n",
    "            # imshow_kw={\"alpha\": 0.9, \"cmap\": \"YlOrRd\"},  # jet, YlOrRd, RdPu\n",
    "            imshow_kw={\"alpha\": 0.9, \"cmap\": \"coolwarm\"},  # jet, YlOrRd, RdPu\n",
    "            draw_cbar=False,\n",
    "            cbar_label=\"\",\n",
    "            cbar_kw={},\n",
    "        )\n",
    "        annotate_heatmap(im, anno_format=\"{x:.2f}\", text_colors=(\"black\", \"white\"), threshold=0.9)\n",
    "\n",
    "        ax.set_title(title)\n",
    "        # ax.set_xlabel(\"Model\")\n",
    "        # ax.set_ylabel(\"Model\")        \n",
    "\n",
    "        # save\n",
    "        if save_path:\n",
    "            fig.savefig(save_path, transparent=True)\n",
    "\n",
    "        if save_path is None:\n",
    "            plt.show()\n",
    "\n",
    "        # fig.clear()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f88d1c2-3fb3-4011-8293-fe6ee48e4501",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pearson_result = pearson_correlation(model_pool, 'val_embeddings')\n",
    "\n",
    "save_path = f\"./local/output/{task}\"\n",
    "\n",
    "draw_correlation(pearson_result, [md['model'] for md in model_pool], \n",
    "                 save_path=os.path.join(save_path, f\"{model_pool[0]['task']}-val.pdf\"))\n",
    "                 \n",
    "draw_correlation_mean(pearson_result.mean(axis=0, keepdims=True), [md['model'] for md in model_pool], \n",
    "                      save_path=os.path.join(save_path, f\"{model_pool[0]['task']}-val-mean.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef90e0c7-42ee-4a2f-938a-4c33d1127d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D-VGG-19\n",
      "1D-ResNet-18\n",
      "1D-ResNet-50\n",
      "1D-ResNeXt-50\n",
      "(476, 3)\n"
     ]
    }
   ],
   "source": [
    "model_1d_aggregation = {'name': '1D', 'model': '1D'}\n",
    "\n",
    "val_embeddings = np.zeros((4, *model_pool[0]['val_embeddings'].shape))\n",
    "for i in range(4):\n",
    "    print(model_pool[i]['model'])\n",
    "    val_embeddings[i] = model_pool[i]['val_embeddings']\n",
    "    \n",
    "model_1d_aggregation['val_embeddings'] = val_embeddings.reshape(-1, model_pool[0]['val_embeddings'].shape[1])\n",
    "print( model_1d_aggregation['val_embeddings'].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c616ea51-b935-428e-b6ce-2c01c61f6769",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D-VGG-19\n",
      "2D-ResNet-18\n",
      "2D-ResNet-50\n",
      "2D-ResNeXt-50\n",
      "(476, 3)\n"
     ]
    }
   ],
   "source": [
    "model_2d_aggregation = {'name': '1D', 'model': '1D'}\n",
    "\n",
    "val_embeddings = np.zeros((4, *model_pool[0]['val_embeddings'].shape))\n",
    "for k in range(4):\n",
    "    i = k + 4\n",
    "    print(model_pool[i]['model'])\n",
    "    val_embeddings[k] = model_pool[i]['val_embeddings']\n",
    "    \n",
    "model_2d_aggregation['val_embeddings'] = val_embeddings.reshape(-1, model_pool[0]['val_embeddings'].shape[1])\n",
    "print( model_2d_aggregation['val_embeddings'].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3cb9d030-489e-437e-b5ca-82782b1aa039",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.42392487],\n",
       "       [0.42392487, 1.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_correlation([model_1d_aggregation, model_2d_aggregation], 'val_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f56d6-c4cc-434e-a662-90cf49ec9b6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cosine_result = cosine_correlation(model_pool, 'val_embeddings')\n",
    "\n",
    "# draw_correlation(cosine_result, [md['model'] for md in model_pool])\n",
    "# draw_correlation_mean(cosine_result.mean(axis=0, keepdims=True), [md['model'] for md in model_pool])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18fd432-14fc-4771-a203-3e705537685a",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f749f-ac27-4ff7-9fe0-f274f1a6b662",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
