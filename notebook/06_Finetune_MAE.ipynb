{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Finetune Masked-AutoEncoder\n",
    "\n",
    "- Finetune the deep network after pretraining the self-supervised learning framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "import pprint\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "# custom package\n",
    "from run_train import check_device_env\n",
    "from run_train import set_seed\n",
    "from run_train import compose_dataset\n",
    "from run_train import generate_model\n",
    "from train.ssl_train_script import ssl_train_script\n",
    "from train.train_script import train_script\n",
    "from models.utils import count_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Specify the dataset, model, and train setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_model_path = 'local/checkpoint/'\n",
    "pre_model_name = '2ew55ua4'\n",
    "\n",
    "use_wandb = False\n",
    "project = 'caueeg-mae'\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Load and modify the pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load pretrained configurations\n",
    "path = os.path.join(pre_model_path, pre_model_name.split(',')[-1], 'checkpoint.pt')\n",
    "try:\n",
    "    ckpt = torch.load(path, map_location=device)\n",
    "    config = ckpt['config']\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f'- checkpoint cannot be opened: {path}')\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model = deepcopy(model)\n",
    "pre_model_state = pre_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training configuration\n",
    "config['project'] = project\n",
    "config['use_wandb'] = use_wandb\n",
    "config['pre_model'] = pre_model_name\n",
    "config['device'] = device\n",
    "\n",
    "config['total_samples'] = 5.0e+5\n",
    "config['search_lr'] = False\n",
    "config['base_lr'] = 1e-3\n",
    "config['lr_scheduler_type'] = 'cosine_decay_with_warmup_half'\n",
    "\n",
    "config[\"warmup_min\"] = 200   \n",
    "\n",
    "# model\n",
    "config[\"tuning_type\"] = \"finetune\"  # \"finetune\", \"fc_stage\"\n",
    "config[\"layer_wise_lr\"] = True\n",
    "\n",
    "config[\"out_dims\"] = 3\n",
    "config[\"task\"] = \"dementia\"\n",
    "config[\"use_age\"] = 'fc'\n",
    "config[\"fc_stages\"] = 3\n",
    "config[\"global_pool\"] = True\n",
    "config[\"dropout\"] = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the workstation environment and update some configurations\n",
    "check_device_env(config)\n",
    "\n",
    "# compose dataset\n",
    "train_loader, val_loader, test_loader, multicrop_test_loader = compose_dataset(config)\n",
    "\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the model\n",
    "config[\"_target_\"] = config[\"_target_\"].replace('.ssl', '').replace('_pre', '')\n",
    "model = generate_model(config).to(device)\n",
    "\n",
    "# load the model\n",
    "model_state = model.state_dict()\n",
    "for k, v in model_state.items():\n",
    "    if not k.startswith('fc') and not k.endswith(\"pos_embed\")::\n",
    "        model_state[k] = pre_model_state[k]\n",
    "\n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.finetune_mode(config[\"tuning_type\"])\n",
    "config[\"num_params\"] = count_parameters(model)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name:100}\\t|\\t{param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect some garbage\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# fix the seed for reproducibility (a negative seed value means not fixing)\n",
    "set_seed(config, rank=None)\n",
    "\n",
    "# train\n",
    "train_script(\n",
    "    config,\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    multicrop_test_loader,\n",
    "    config[\"preprocess_train\"],\n",
    "    config[\"preprocess_test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
