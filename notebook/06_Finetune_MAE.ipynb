{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Finetune Masked-AutoEncoder\n",
    "\n",
    "- Finetune the deep network after pretraining the self-supervised learning framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\GitHub\\eeg_analysis\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "import pprint\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "# custom package\n",
    "from run_train import check_device_env\n",
    "from run_train import set_seed\n",
    "from run_train import compose_dataset\n",
    "from run_train import generate_model\n",
    "from train.ssl_train_script import ssl_train_script\n",
    "from train.train_script import train_script\n",
    "from models.utils import count_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Specify the dataset, model, and train setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_model_path = 'local/checkpoint/'\n",
    "pre_model_name = '2ew55ua4'\n",
    "\n",
    "use_wandb = False\n",
    "project = 'caueeg-mae'\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.0+cu117\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Load and modify the pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EKG': 'X',\n",
      " '_target_': 'models.ssl.mae.mae_pre_b_e768_d512',\n",
      " 'activation': 'gelu',\n",
      " 'age_mean': tensor([71.1417], device='cuda:0'),\n",
      " 'age_std': tensor([9.7264], device='cuda:0'),\n",
      " 'awgn': 0.01,\n",
      " 'awgn_age': 0.001,\n",
      " 'base_lr': 0.00012226453861270155,\n",
      " 'class_label_to_name': ['Normal', 'MCI', 'Dementia'],\n",
      " 'class_name_to_label': {'Dementia': 2, 'MCI': 1, 'Normal': 0},\n",
      " 'criterion': 'cross-entropy',\n",
      " 'crop_length': 4096,\n",
      " 'crop_multiple': 4,\n",
      " 'crop_timing_analysis': False,\n",
      " 'cwd': 'D:\\\\GitHub\\\\eeg_analysis',\n",
      " 'dataset_name': 'CAUEEG dataset',\n",
      " 'dataset_path': 'local/dataset/caueeg-dataset/',\n",
      " 'ddp': False,\n",
      " 'device': device(type='cuda'),\n",
      " 'draw_result': True,\n",
      " 'file_format': 'memmap',\n",
      " 'in_channels': 19,\n",
      " 'input_norm': 'datapoint',\n",
      " 'iterations': 390625,\n",
      " 'latency': 2000,\n",
      " 'load_event': False,\n",
      " 'lr_scheduler_type': 'cosine_decay_with_warmup_half',\n",
      " 'mask_ratio': 0.5,\n",
      " 'mgn': 0.01,\n",
      " 'minibatch': 256,\n",
      " 'minibatch_3090': 256,\n",
      " 'mixup': 0.0,\n",
      " 'multi_batch_size': 32,\n",
      " 'norm_pix_loss': False,\n",
      " 'num_history': 500,\n",
      " 'num_params': 126396288,\n",
      " 'out_dims': 3,\n",
      " 'output_length': 17,\n",
      " 'patch_size': 128,\n",
      " 'photic': 'X',\n",
      " 'preprocess_test': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda'))\n",
      "  (1): EegResample(orig_freq=200, new_freq=100, resampling_method='sinc_interp_hann')\n",
      "  (2): EegNormalizeAge(mean=tensor([71.1417], device='cuda:0'), std=tensor([9.7264], device='cuda:0'), eps=1e-08, std_eps=tensor([9.7264], device='cuda:0'))\n",
      "  (3): EegNormalizePerSignal(eps=1e-08)\n",
      "),\n",
      " 'preprocess_train': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda'))\n",
      "  (1): EegResample(orig_freq=200, new_freq=100, resampling_method='sinc_interp_hann')\n",
      "  (2): EegNormalizeAge(mean=tensor([71.1417], device='cuda:0'), std=tensor([9.7264], device='cuda:0'), eps=1e-08, std_eps=tensor([9.7264], device='cuda:0'))\n",
      "  (3): EegAddGaussianNoiseAge(mean=0.0, std=0.001)\n",
      "  (4): EegNormalizePerSignal(eps=1e-08)\n",
      "  (5): EegMultiplicativeGaussianNoise(mean=0.0, std=0.01)\n",
      "  (6): EegAdditiveGaussianNoise(mean=0.0, std=0.01)\n",
      "),\n",
      " 'project': 'caueeg-mae',\n",
      " 'resample': 100,\n",
      " 'run_mode': 'train',\n",
      " 'save_model': True,\n",
      " 'search_lr': True,\n",
      " 'search_multiplier': 1.0,\n",
      " 'seed': 0,\n",
      " 'seq_length': 2048,\n",
      " 'signal_header': ['Fp1-AVG',\n",
      "                   'F3-AVG',\n",
      "                   'C3-AVG',\n",
      "                   'P3-AVG',\n",
      "                   'O1-AVG',\n",
      "                   'Fp2-AVG',\n",
      "                   'F4-AVG',\n",
      "                   'C4-AVG',\n",
      "                   'P4-AVG',\n",
      "                   'O2-AVG',\n",
      "                   'F7-AVG',\n",
      "                   'T3-AVG',\n",
      "                   'T5-AVG',\n",
      "                   'F8-AVG',\n",
      "                   'T4-AVG',\n",
      "                   'T6-AVG',\n",
      "                   'FZ-AVG',\n",
      "                   'CZ-AVG',\n",
      "                   'PZ-AVG',\n",
      "                   'EKG',\n",
      "                   'Photic'],\n",
      " 'signal_length_limit': 10000000,\n",
      " 'task': 'dementia',\n",
      " 'task_description': 'Classification of [Normal], [MCI], and [Dementia] '\n",
      "                     'symptoms.',\n",
      " 'task_name': 'CAUEEG-Dementia benchmark',\n",
      " 'test_crop_multiple': 8,\n",
      " 'total_samples': 100000000.0,\n",
      " 'transform': Compose(\n",
      "    EegRandomCrop(crop_length=4096, length_limit=10000000, multiple=4, latency=2000, segment_simulation=False, return_timing=False, reject_events=False)\n",
      "    EegDropChannels(drop_index=[19, 20])\n",
      "    EegToTensor()\n",
      "),\n",
      " 'transform_multicrop': Compose(\n",
      "    EegRandomCrop(crop_length=4096, length_limit=10000000, multiple=8, latency=2000, segment_simulation=False, return_timing=False, reject_events=False)\n",
      "    EegDropChannels(drop_index=[19, 20])\n",
      "    EegToTensor()\n",
      "),\n",
      " 'use_age': 'no',\n",
      " 'use_wandb': True,\n",
      " 'warmup_min': 3000,\n",
      " 'warmup_ratio': 0.05,\n",
      " 'warmup_steps': 19531,\n",
      " 'watch_model': False,\n",
      " 'weight_decay': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# load pretrained configurations\n",
    "path = os.path.join(pre_model_path, pre_model_name.split(',')[-1], 'checkpoint.pt')\n",
    "try:\n",
    "    ckpt = torch.load(path, map_location=device)\n",
    "    config = ckpt['config']\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f'- checkpoint cannot be opened: {path}')\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model = deepcopy(model)\n",
    "pre_model_state = pre_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training configuration\n",
    "config['project'] = project\n",
    "config['use_wandb'] = use_wandb\n",
    "config['pre_model'] = pre_model_name\n",
    "config['device'] = device\n",
    "\n",
    "config['total_samples'] = 5.0e+5\n",
    "config['search_lr'] = False\n",
    "config['base_lr'] = 1e-3\n",
    "config['lr_scheduler_type'] = 'cosine_decay_with_warmup_half'\n",
    "\n",
    "config[\"warmup_min\"] = 200   \n",
    "\n",
    "# model\n",
    "tuning_type = \"finetune\"  # \"finetune\", \"fc_stage\", \"layer-wise finetune\"\n",
    "\n",
    "config[\"out_dims\"] = 3\n",
    "config[\"task\"] = \"dementia\"\n",
    "config[\"use_age\"] = 'fc'\n",
    "config[\"fc_stages\"] = 3\n",
    "config[\"global_pool\"] = True\n",
    "config[\"dropout\"] = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the model\n",
    "config[\"_target_\"] = config[\"_target_\"].replace('.ssl', '').replace('_pre', '')\n",
    "model = generate_model(config).to(device)\n",
    "\n",
    "# load the model\n",
    "model_state = model.state_dict()\n",
    "for k, v in model_state.items():\n",
    "    if not k.startswith('fc'):\n",
    "        model_state[k] = pre_model_state[k]\n",
    "\n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if tuning_type == \"fc_stage\":\n",
    "    model.requires_grad_(False)\n",
    "    model = model.eval()    \n",
    "    model.fc_stage.requires_grad_(True)\n",
    "    model.fc_stage.train()\n",
    "elif tuning_type == \"finetune\":\n",
    "    model.requires_grad_(True)\n",
    "    model = model.train()    \n",
    "    model.art_net.requires_grad_(False)\n",
    "    model.art_net = model.art_net.eval()\n",
    "elif tuning_type == \"layer-wise finetune\":\n",
    "    model.requires_grad_(True)\n",
    "    model = model.train()    \n",
    "    model.art_net.requires_grad_(False)\n",
    "    model.art_net = model.art_net.eval()\n",
    "\n",
    "config[\"num_params\"] = count_parameters(model)\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name:100}\\t|\\t{param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the workstation environment and update some configurations\n",
    "check_device_env(config)\n",
    "\n",
    "# collect some garbage\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# fix the seed for reproducibility (a negative seed value means not fixing)\n",
    "set_seed(config, rank=None)\n",
    "\n",
    "# compose dataset\n",
    "train_loader, val_loader, test_loader, multicrop_test_loader = compose_dataset(config)\n",
    "\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_script(\n",
    "    config,\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    multicrop_test_loader,\n",
    "    config[\"preprocess_train\"],\n",
    "    config[\"preprocess_test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
