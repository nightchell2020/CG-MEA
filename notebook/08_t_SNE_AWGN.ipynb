{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed1e2f8a-32b4-46b1-a00a-382644e90504",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# t-SNE visualization\n",
    "\n",
    "This notebook visualizes the EEG embeddings computed by the model trained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdbc4ee-d024-4025-84fb-d18dfa1410d7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df587e38-b1a9-42c8-9b50-680200a9bec7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minjae\\Desktop\\EEG_Project\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb41bf8-1713-4228-b799-0e1c87545a16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import pprint\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_script import build_dataset_for_train\n",
    "import models\n",
    "from train.evaluate import check_accuracy\n",
    "from train.evaluate import check_accuracy_extended\n",
    "from train.evaluate import check_accuracy_extended_debug\n",
    "from train.evaluate import check_accuracy_multicrop\n",
    "from train.evaluate import check_accuracy_multicrop_extended\n",
    "from train.visualize import draw_roc_curve\n",
    "from train.visualize import draw_confusion, draw_confusion2\n",
    "from train.visualize import draw_class_wise_metrics\n",
    "from train.visualize import draw_error_table\n",
    "from train.visualize import annotate_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "309eed9b-2c31-4398-a141-e1787453814a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.0+cu117\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bffc0b0-30bc-4b63-908e-03a68c3da0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other settings\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # cleaner text\n",
    "\n",
    "plt.style.use('default') \n",
    "# ['Solarize_Light2', '_classic_test_patch', 'bmh', 'classic', 'dark_background', 'fast', \n",
    "#  'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn', 'seaborn-bright', 'seaborn-colorblind', \n",
    "#  'seaborn-dark', 'seaborn-dark-palette', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', \n",
    "#  'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', \n",
    "#  'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'tableau-colorblind10']\n",
    "\n",
    "plt.rcParams['image.interpolation'] = 'bicubic'\n",
    "plt.rcParams[\"font.family\"] = 'Helvetica' # 'NanumGothic' # for Hangul in Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c5390-f093-4a4c-9c72-2f16f9d42fde",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "-----\n",
    "\n",
    "## Load the configuration used during the train phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a0f3c94-0bbb-42ef-ab92-df07e2964087",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# VGG\n",
    "# model_name_1 = 'lo88puq7'  # mixup o, awgn o\n",
    "# model_name_2 = '1nu3jagp'  # mixup x, awgn x\n",
    "# model_name_2 = '1mwdhqbz' # mixup x, awgn x, dropout x\n",
    "# model_name_2 = '2r88ber7' # mixup o, awgn x\n",
    "\n",
    "# ResNet\n",
    "# model_name_1 = 'l8524nml'  # mixup o, awgn o\n",
    "# model_name_2 = 'ph0mix3b'  # mixup x, awgn o, dropout x\n",
    "\n",
    "# ResNet \n",
    "model_name_1 = '2apj72km'  # mixup x, awgn o\n",
    "model_name_2 = '2k8xomy6'  # mixup x, awgn x\n",
    "\n",
    "\n",
    "repeat = 3\n",
    "save_fig = True\n",
    "output_folder = './local/output/awgn_tsne'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "069adca8-f2f7-446f-ba09-87f6f5f64d8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EKG': 'O',\n",
      " '_target_': 'models.resnet_1d.ResNet1D',\n",
      " 'activation': 'gelu',\n",
      " 'age_mean': tensor([71.1417], device='cuda:0'),\n",
      " 'age_std': tensor([9.7840], device='cuda:0'),\n",
      " 'awgn': 0.004872735559634612,\n",
      " 'awgn_age': 0.03583361229344302,\n",
      " 'base_channels': 64,\n",
      " 'base_lr': 0.00033918432381593736,\n",
      " 'block': 'basic',\n",
      " 'class_label_to_name': ['Normal', 'MCI', 'Dementia'],\n",
      " 'class_name_to_label': {'Dementia': 2, 'MCI': 1, 'Normal': 0},\n",
      " 'conv_layers': [2, 2, 2, 2],\n",
      " 'criterion': 'multi-bce',\n",
      " 'crop_multiple': 4,\n",
      " 'crop_timing_analysis': False,\n",
      " 'cwd': 'C:\\\\Users\\\\Minjae\\\\Desktop\\\\EEG_Project',\n",
      " 'dataset_name': 'CAUEEG dataset',\n",
      " 'dataset_path': 'local/dataset/02_Curated_Data_220419/',\n",
      " 'ddp': False,\n",
      " 'device': device(type='cuda'),\n",
      " 'draw_result': True,\n",
      " 'dropout': 0.3,\n",
      " 'fc_stages': 3,\n",
      " 'file_format': 'memmap',\n",
      " 'in_channels': 21,\n",
      " 'input_norm': 'dataset',\n",
      " 'iterations': 195312,\n",
      " 'latency': 2000,\n",
      " 'load_event': False,\n",
      " 'lr_scheduler_type': 'cosine_decay_with_warmup_half',\n",
      " 'mgn': 0.09575622309480344,\n",
      " 'minibatch': 512,\n",
      " 'mixup': 0,\n",
      " 'model': '1D-ResNet-18',\n",
      " 'multi_batch_size': 64,\n",
      " 'num_history': 500,\n",
      " 'num_params': 11394051,\n",
      " 'out_dims': 3,\n",
      " 'output_length': 8,\n",
      " 'photic': 'O',\n",
      " 'preprocess_test': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda'))\n",
      "  (1): EegNormalizeAge(mean=tensor([71.1417], device='cuda:0'), std=tensor([9.7840], device='cuda:0'), eps=1e-08, std_eps=tensor([9.7840], device='cuda:0'))\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([[[ 0.1507],\n",
      "           [ 0.0541],\n",
      "           [-0.0413],\n",
      "           [ 0.0160],\n",
      "           [-0.0541],\n",
      "           [ 0.1908],\n",
      "           [-0.0025],\n",
      "           [-0.0211],\n",
      "           [ 0.0069],\n",
      "           [ 0.0494],\n",
      "           [ 0.0051],\n",
      "           [-0.0056],\n",
      "           [-0.0354],\n",
      "           [ 0.0505],\n",
      "           [-0.0412],\n",
      "           [ 0.1035],\n",
      "           [ 0.0074],\n",
      "           [-0.0325],\n",
      "           [-0.0373],\n",
      "           [-0.0025],\n",
      "           [-0.0071]]], device='cuda:0'), std=tensor([[[45.0080],\n",
      "           [20.2708],\n",
      "           [11.7008],\n",
      "           [11.5876],\n",
      "           [15.2168],\n",
      "           [47.7619],\n",
      "           [19.8388],\n",
      "           [10.5537],\n",
      "           [11.6707],\n",
      "           [15.9614],\n",
      "           [20.6152],\n",
      "           [14.4362],\n",
      "           [13.6445],\n",
      "           [21.9794],\n",
      "           [16.9491],\n",
      "           [14.6477],\n",
      "           [19.7299],\n",
      "           [11.4548],\n",
      "           [11.6362],\n",
      "           [94.2795],\n",
      "           [68.4567]]], device='cuda:0'), eps=1e-08, std_eps=tensor([[[45.0080],\n",
      "           [20.2708],\n",
      "           [11.7008],\n",
      "           [11.5876],\n",
      "           [15.2168],\n",
      "           [47.7619],\n",
      "           [19.8388],\n",
      "           [10.5537],\n",
      "           [11.6707],\n",
      "           [15.9614],\n",
      "           [20.6152],\n",
      "           [14.4362],\n",
      "           [13.6445],\n",
      "           [21.9794],\n",
      "           [16.9491],\n",
      "           [14.6477],\n",
      "           [19.7299],\n",
      "           [11.4548],\n",
      "           [11.6362],\n",
      "           [94.2795],\n",
      "           [68.4567]]], device='cuda:0'))\n",
      "),\n",
      " 'preprocess_train': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda'))\n",
      "  (1): EegNormalizeAge(mean=tensor([71.1417], device='cuda:0'), std=tensor([9.7840], device='cuda:0'), eps=1e-08, std_eps=tensor([9.7840], device='cuda:0'))\n",
      "  (2): EegAddGaussianNoiseAge(mean=0.0, std=0.03583361229344302)\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([[[ 0.1507],\n",
      "           [ 0.0541],\n",
      "           [-0.0413],\n",
      "           [ 0.0160],\n",
      "           [-0.0541],\n",
      "           [ 0.1908],\n",
      "           [-0.0025],\n",
      "           [-0.0211],\n",
      "           [ 0.0069],\n",
      "           [ 0.0494],\n",
      "           [ 0.0051],\n",
      "           [-0.0056],\n",
      "           [-0.0354],\n",
      "           [ 0.0505],\n",
      "           [-0.0412],\n",
      "           [ 0.1035],\n",
      "           [ 0.0074],\n",
      "           [-0.0325],\n",
      "           [-0.0373],\n",
      "           [-0.0025],\n",
      "           [-0.0071]]], device='cuda:0'), std=tensor([[[45.0080],\n",
      "           [20.2708],\n",
      "           [11.7008],\n",
      "           [11.5876],\n",
      "           [15.2168],\n",
      "           [47.7619],\n",
      "           [19.8388],\n",
      "           [10.5537],\n",
      "           [11.6707],\n",
      "           [15.9614],\n",
      "           [20.6152],\n",
      "           [14.4362],\n",
      "           [13.6445],\n",
      "           [21.9794],\n",
      "           [16.9491],\n",
      "           [14.6477],\n",
      "           [19.7299],\n",
      "           [11.4548],\n",
      "           [11.6362],\n",
      "           [94.2795],\n",
      "           [68.4567]]], device='cuda:0'), eps=1e-08, std_eps=tensor([[[45.0080],\n",
      "           [20.2708],\n",
      "           [11.7008],\n",
      "           [11.5876],\n",
      "           [15.2168],\n",
      "           [47.7619],\n",
      "           [19.8388],\n",
      "           [10.5537],\n",
      "           [11.6707],\n",
      "           [15.9614],\n",
      "           [20.6152],\n",
      "           [14.4362],\n",
      "           [13.6445],\n",
      "           [21.9794],\n",
      "           [16.9491],\n",
      "           [14.6477],\n",
      "           [19.7299],\n",
      "           [11.4548],\n",
      "           [11.6362],\n",
      "           [94.2795],\n",
      "           [68.4567]]], device='cuda:0'))\n",
      "  (4): EegMultiplicativeGaussianNoise(mean=0.0, std=0.09575622309480344)\n",
      "  (5): EegAdditiveGaussianNoise(mean=0.0, std=0.004872735559634612)\n",
      "),\n",
      " 'project': 'caueeg-task2-ablation',\n",
      " 'run_mode': 'train',\n",
      " 'save_model': True,\n",
      " 'search_lr': True,\n",
      " 'search_multiplier': 1.0,\n",
      " 'seed': 0,\n",
      " 'seq_length': 2000,\n",
      " 'signal_header': ['Fp1-AVG', 'F3-AVG', 'C3-AVG', 'P3-AVG', 'O1-AVG', 'Fp2-AVG', 'F4-AVG', 'C4-AVG', 'P4-AVG', 'O2-AVG', 'F7-AVG', 'T3-AVG', 'T5-AVG', 'F8-AVG', 'T4-AVG', 'T6-AVG', 'FZ-AVG', 'CZ-AVG', 'PZ-AVG', 'EKG', 'Photic'],\n",
      " 'signal_length_limit': 10000000,\n",
      " 'signal_mean': tensor([[[ 0.1507],\n",
      "         [ 0.0541],\n",
      "         [-0.0413],\n",
      "         [ 0.0160],\n",
      "         [-0.0541],\n",
      "         [ 0.1908],\n",
      "         [-0.0025],\n",
      "         [-0.0211],\n",
      "         [ 0.0069],\n",
      "         [ 0.0494],\n",
      "         [ 0.0051],\n",
      "         [-0.0056],\n",
      "         [-0.0354],\n",
      "         [ 0.0505],\n",
      "         [-0.0412],\n",
      "         [ 0.1035],\n",
      "         [ 0.0074],\n",
      "         [-0.0325],\n",
      "         [-0.0373],\n",
      "         [-0.0025],\n",
      "         [-0.0071]]], device='cuda:0'),\n",
      " 'signal_std': tensor([[[45.0080],\n",
      "         [20.2708],\n",
      "         [11.7008],\n",
      "         [11.5876],\n",
      "         [15.2168],\n",
      "         [47.7619],\n",
      "         [19.8388],\n",
      "         [10.5537],\n",
      "         [11.6707],\n",
      "         [15.9614],\n",
      "         [20.6152],\n",
      "         [14.4362],\n",
      "         [13.6445],\n",
      "         [21.9794],\n",
      "         [16.9491],\n",
      "         [14.6477],\n",
      "         [19.7299],\n",
      "         [11.4548],\n",
      "         [11.6362],\n",
      "         [94.2795],\n",
      "         [68.4567]]], device='cuda:0'),\n",
      " 'task': 'dementia',\n",
      " 'task_description': 'Classification of [Normal], [MCI], and [Dementia] symptoms.',\n",
      " 'task_name': 'CAUEEG-Dementia benchmark',\n",
      " 'test_crop_multiple': 8,\n",
      " 'total_samples': 100000000.0,\n",
      " 'transform': Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=4, latency=2000, segment_simulation=False, return_timing=False)\n",
      "    EegToTensor()\n",
      "),\n",
      " 'transform_multicrop': Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=8, latency=2000, segment_simulation=False, return_timing=False)\n",
      "    EegToTensor()\n",
      "),\n",
      " 'use_age': 'conv',\n",
      " 'use_wandb': True,\n",
      " 'warmup_min': 3000,\n",
      " 'warmup_ratio': 0.05,\n",
      " 'warmup_steps': 9766,\n",
      " 'watch_model': False,\n",
      " 'weight_decay': 0.04394746639552375}\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load(os.path.join(r'E:\\CAUEEG\\checkpoint', model_name_1, 'checkpoint.pt'), map_location=device)\n",
    "# print(ckpt.keys())\n",
    "\n",
    "config_1 = ckpt['config']\n",
    "model_1 = hydra.utils.instantiate(config_1).to(device)\n",
    "\n",
    "model_state_1 = ckpt['model_state']\n",
    "if config_1.get('ddp', False):\n",
    "    model_state_1_ddp = deepcopy(model_state_1)\n",
    "    model_state_1 = OrderedDict()\n",
    "    for k, v in model_state_1_ddp.items():\n",
    "        name = k[7:] # remove 'module.' of DataParallel/DistributedDataParallel\n",
    "        model_state_1[name] = v\n",
    "        \n",
    "model_1.load_state_dict(model_state_1)\n",
    "pprint.pprint(config_1, width=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca4a490d-9f3b-42b7-a1ef-4605f5eae262",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EKG': 'O',\n",
      " '_target_': 'models.resnet_1d.ResNet1D',\n",
      " 'activation': 'gelu',\n",
      " 'age_mean': tensor([71.1417], device='cuda:0'),\n",
      " 'age_std': tensor([9.7840], device='cuda:0'),\n",
      " 'awgn': 0,\n",
      " 'awgn_age': 0,\n",
      " 'base_channels': 64,\n",
      " 'base_lr': 0.00033918432381593736,\n",
      " 'block': 'basic',\n",
      " 'class_label_to_name': ['Normal', 'MCI', 'Dementia'],\n",
      " 'class_name_to_label': {'Dementia': 2, 'MCI': 1, 'Normal': 0},\n",
      " 'conv_layers': [2, 2, 2, 2],\n",
      " 'criterion': 'multi-bce',\n",
      " 'crop_multiple': 4,\n",
      " 'crop_timing_analysis': False,\n",
      " 'cwd': '/home/imkbsz/workspace/eeg_analysis',\n",
      " 'dataset_name': 'CAUEEG dataset',\n",
      " 'dataset_path': 'local/dataset/02_Curated_Data_220419/',\n",
      " 'ddp': False,\n",
      " 'device': device(type='cuda'),\n",
      " 'draw_result': True,\n",
      " 'dropout': 0.3,\n",
      " 'fc_stages': 3,\n",
      " 'file_format': 'memmap',\n",
      " 'in_channels': 21,\n",
      " 'input_norm': 'dataset',\n",
      " 'iterations': 195312,\n",
      " 'latency': 2000,\n",
      " 'load_event': False,\n",
      " 'lr_scheduler_type': 'cosine_decay_with_warmup_half',\n",
      " 'mgn': 0,\n",
      " 'minibatch': 512,\n",
      " 'mixup': 0,\n",
      " 'model': '1D-ResNet-18',\n",
      " 'multi_batch_size': 64,\n",
      " 'num_history': 500,\n",
      " 'num_params': 11394051,\n",
      " 'out_dims': 3,\n",
      " 'output_length': 8,\n",
      " 'photic': 'O',\n",
      " 'preprocess_test': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda'))\n",
      "  (1): EegNormalizeAge(mean=tensor([71.1417], device='cuda:0'), std=tensor([9.7840], device='cuda:0'), eps=1e-08, std_eps=tensor([9.7840], device='cuda:0'))\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([[[ 0.1507],\n",
      "           [ 0.0541],\n",
      "           [-0.0413],\n",
      "           [ 0.0160],\n",
      "           [-0.0541],\n",
      "           [ 0.1908],\n",
      "           [-0.0025],\n",
      "           [-0.0211],\n",
      "           [ 0.0069],\n",
      "           [ 0.0494],\n",
      "           [ 0.0051],\n",
      "           [-0.0056],\n",
      "           [-0.0354],\n",
      "           [ 0.0505],\n",
      "           [-0.0412],\n",
      "           [ 0.1035],\n",
      "           [ 0.0074],\n",
      "           [-0.0325],\n",
      "           [-0.0373],\n",
      "           [-0.0025],\n",
      "           [-0.0071]]], device='cuda:0'), std=tensor([[[45.0080],\n",
      "           [20.2708],\n",
      "           [11.7008],\n",
      "           [11.5876],\n",
      "           [15.2168],\n",
      "           [47.7619],\n",
      "           [19.8388],\n",
      "           [10.5537],\n",
      "           [11.6707],\n",
      "           [15.9614],\n",
      "           [20.6152],\n",
      "           [14.4362],\n",
      "           [13.6445],\n",
      "           [21.9794],\n",
      "           [16.9491],\n",
      "           [14.6477],\n",
      "           [19.7299],\n",
      "           [11.4548],\n",
      "           [11.6362],\n",
      "           [94.2795],\n",
      "           [68.4567]]], device='cuda:0'), eps=1e-08, std_eps=tensor([[[45.0080],\n",
      "           [20.2708],\n",
      "           [11.7008],\n",
      "           [11.5876],\n",
      "           [15.2168],\n",
      "           [47.7619],\n",
      "           [19.8388],\n",
      "           [10.5537],\n",
      "           [11.6707],\n",
      "           [15.9614],\n",
      "           [20.6152],\n",
      "           [14.4362],\n",
      "           [13.6445],\n",
      "           [21.9794],\n",
      "           [16.9491],\n",
      "           [14.6477],\n",
      "           [19.7299],\n",
      "           [11.4548],\n",
      "           [11.6362],\n",
      "           [94.2795],\n",
      "           [68.4567]]], device='cuda:0'))\n",
      "),\n",
      " 'preprocess_train': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda'))\n",
      "  (1): EegNormalizeAge(mean=tensor([71.1417], device='cuda:0'), std=tensor([9.7840], device='cuda:0'), eps=1e-08, std_eps=tensor([9.7840], device='cuda:0'))\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([[[ 0.1507],\n",
      "           [ 0.0541],\n",
      "           [-0.0413],\n",
      "           [ 0.0160],\n",
      "           [-0.0541],\n",
      "           [ 0.1908],\n",
      "           [-0.0025],\n",
      "           [-0.0211],\n",
      "           [ 0.0069],\n",
      "           [ 0.0494],\n",
      "           [ 0.0051],\n",
      "           [-0.0056],\n",
      "           [-0.0354],\n",
      "           [ 0.0505],\n",
      "           [-0.0412],\n",
      "           [ 0.1035],\n",
      "           [ 0.0074],\n",
      "           [-0.0325],\n",
      "           [-0.0373],\n",
      "           [-0.0025],\n",
      "           [-0.0071]]], device='cuda:0'), std=tensor([[[45.0080],\n",
      "           [20.2708],\n",
      "           [11.7008],\n",
      "           [11.5876],\n",
      "           [15.2168],\n",
      "           [47.7619],\n",
      "           [19.8388],\n",
      "           [10.5537],\n",
      "           [11.6707],\n",
      "           [15.9614],\n",
      "           [20.6152],\n",
      "           [14.4362],\n",
      "           [13.6445],\n",
      "           [21.9794],\n",
      "           [16.9491],\n",
      "           [14.6477],\n",
      "           [19.7299],\n",
      "           [11.4548],\n",
      "           [11.6362],\n",
      "           [94.2795],\n",
      "           [68.4567]]], device='cuda:0'), eps=1e-08, std_eps=tensor([[[45.0080],\n",
      "           [20.2708],\n",
      "           [11.7008],\n",
      "           [11.5876],\n",
      "           [15.2168],\n",
      "           [47.7619],\n",
      "           [19.8388],\n",
      "           [10.5537],\n",
      "           [11.6707],\n",
      "           [15.9614],\n",
      "           [20.6152],\n",
      "           [14.4362],\n",
      "           [13.6445],\n",
      "           [21.9794],\n",
      "           [16.9491],\n",
      "           [14.6477],\n",
      "           [19.7299],\n",
      "           [11.4548],\n",
      "           [11.6362],\n",
      "           [94.2795],\n",
      "           [68.4567]]], device='cuda:0'))\n",
      "),\n",
      " 'project': 'caueeg-task2-ablation',\n",
      " 'run_mode': 'train',\n",
      " 'save_model': True,\n",
      " 'search_lr': True,\n",
      " 'search_multiplier': 1.0,\n",
      " 'seed': 0,\n",
      " 'seq_length': 2000,\n",
      " 'signal_header': ['Fp1-AVG', 'F3-AVG', 'C3-AVG', 'P3-AVG', 'O1-AVG', 'Fp2-AVG', 'F4-AVG', 'C4-AVG', 'P4-AVG', 'O2-AVG', 'F7-AVG', 'T3-AVG', 'T5-AVG', 'F8-AVG', 'T4-AVG', 'T6-AVG', 'FZ-AVG', 'CZ-AVG', 'PZ-AVG', 'EKG', 'Photic'],\n",
      " 'signal_length_limit': 10000000,\n",
      " 'signal_mean': tensor([[[ 0.1507],\n",
      "         [ 0.0541],\n",
      "         [-0.0413],\n",
      "         [ 0.0160],\n",
      "         [-0.0541],\n",
      "         [ 0.1908],\n",
      "         [-0.0025],\n",
      "         [-0.0211],\n",
      "         [ 0.0069],\n",
      "         [ 0.0494],\n",
      "         [ 0.0051],\n",
      "         [-0.0056],\n",
      "         [-0.0354],\n",
      "         [ 0.0505],\n",
      "         [-0.0412],\n",
      "         [ 0.1035],\n",
      "         [ 0.0074],\n",
      "         [-0.0325],\n",
      "         [-0.0373],\n",
      "         [-0.0025],\n",
      "         [-0.0071]]], device='cuda:0'),\n",
      " 'signal_std': tensor([[[45.0080],\n",
      "         [20.2708],\n",
      "         [11.7008],\n",
      "         [11.5876],\n",
      "         [15.2168],\n",
      "         [47.7619],\n",
      "         [19.8388],\n",
      "         [10.5537],\n",
      "         [11.6707],\n",
      "         [15.9614],\n",
      "         [20.6152],\n",
      "         [14.4362],\n",
      "         [13.6445],\n",
      "         [21.9794],\n",
      "         [16.9491],\n",
      "         [14.6477],\n",
      "         [19.7299],\n",
      "         [11.4548],\n",
      "         [11.6362],\n",
      "         [94.2795],\n",
      "         [68.4567]]], device='cuda:0'),\n",
      " 'task': 'dementia',\n",
      " 'task_description': 'Classification of [Normal], [MCI], and [Dementia] symptoms.',\n",
      " 'task_name': 'CAUEEG-Dementia benchmark',\n",
      " 'test_crop_multiple': 8,\n",
      " 'total_samples': 100000000.0,\n",
      " 'transform': Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=4, latency=2000, segment_simulation=False, return_timing=False)\n",
      "    EegToTensor()\n",
      "),\n",
      " 'transform_multicrop': Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=8, latency=2000, segment_simulation=False, return_timing=False)\n",
      "    EegToTensor()\n",
      "),\n",
      " 'use_age': 'conv',\n",
      " 'use_wandb': True,\n",
      " 'warmup_min': 3000,\n",
      " 'warmup_ratio': 0.05,\n",
      " 'warmup_steps': 9766,\n",
      " 'watch_model': False,\n",
      " 'weight_decay': 0.04394746639552375}\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load(os.path.join(r'E:\\CAUEEG\\checkpoint', model_name_2, 'checkpoint.pt'), map_location=device)\n",
    "# print(ckpt.keys())\n",
    "\n",
    "config_2 = ckpt['config']\n",
    "model_2 = hydra.utils.instantiate(config_2).to(device)\n",
    "\n",
    "model_state_2 = ckpt['model_state']\n",
    "if config_2.get('ddp', False):\n",
    "    model_state_2_ddp = deepcopy(model_state_2)\n",
    "    model_state_2 = OrderedDict()\n",
    "    for k, v in model_state_2_ddp.items():\n",
    "        name = k[7:] # remove 'module.' of DataParallel/DistributedDataParallel\n",
    "        model_state_2[name] = v\n",
    "        \n",
    "model_2.load_state_dict(model_state_2)\n",
    "pprint.pprint(config_2, width=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d827eb6-53f2-4aa0-909c-972dcf33c6d5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "427aeb6b-5fef-411c-b69a-5fb4413483ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config_1.pop('cwd', 0)\n",
    "config_1['ddp'] = False\n",
    "config_1['crop_timing_analysis'] = True\n",
    "config_1['eval'] = True\n",
    "config_1['crop_multiple'] = 32\n",
    "config_1['device'] = device\n",
    "\n",
    "config_2.pop('cwd', 0)\n",
    "config_2['ddp'] = False\n",
    "config_2['crop_timing_analysis'] = True\n",
    "config_2['eval'] = True\n",
    "config_2['crop_multiple'] = 32\n",
    "config_2['device'] = device\n",
    "\n",
    "target_from_last = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527fc407-9f18-4329-a551-c85ec26a0727",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b1d9aa9-fbc5-4d4a-8a7f-8e8fbd4675dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform: Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=32, latency=2000, segment_simulation=False, return_timing=True, reject_events=False)\n",
      "    EegDropChannels(drop_index=[])\n",
      "    EegToTensor()\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "transform_multicrop: Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=10000000, multiple=8, latency=2000, segment_simulation=False, return_timing=True, reject_events=False)\n",
      "    EegDropChannels(drop_index=[])\n",
      "    EegToTensor()\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "task config:\n",
      "{'class_label_to_name': ['Normal', 'MCI', 'Dementia'],\n",
      " 'class_name_to_label': {'Dementia': 2, 'MCI': 1, 'Normal': 0},\n",
      " 'task_description': 'Classification of [Normal], [MCI], and [Dementia] '\n",
      "                     'symptoms.',\n",
      " 'task_name': 'CAUEEG-Dementia benchmark'}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "train_dataset[0].keys():\n",
      "dict_keys(['serial', 'age', 'symptom', 'class_name', 'class_label', 'signal', 'crop_timing'])\n",
      "train signal shape: torch.Size([21, 2000])\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "val_dataset[0].keys():\n",
      "dict_keys(['serial', 'age', 'symptom', 'class_name', 'class_label', 'signal', 'crop_timing'])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_dataset[0].keys():\n",
      "dict_keys(['serial', 'age', 'symptom', 'class_name', 'class_label', 'signal', 'crop_timing'])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_dataset[0].keys():\n",
      "dict_keys(['serial', 'age', 'symptom', 'class_name', 'class_label', 'signal', 'crop_timing'])\n",
      "test signal shape: torch.Size([21, 2000])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "preprocess_train: Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda'))\n",
      "  (1): EegNormalizeAge(mean=tensor([71.1417], device='cuda:0'), std=tensor([9.7840], device='cuda:0'), eps=1e-08, std_eps=tensor([9.7840], device='cuda:0'))\n",
      "  (2): EegAddGaussianNoiseAge(mean=0.0, std=0.03583361229344302)\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([[[ 0.1507],\n",
      "           [ 0.0541],\n",
      "           [-0.0413],\n",
      "           [ 0.0160],\n",
      "           [-0.0541],\n",
      "           [ 0.1908],\n",
      "           [-0.0025],\n",
      "           [-0.0211],\n",
      "           [ 0.0069],\n",
      "           [ 0.0494],\n",
      "           [ 0.0051],\n",
      "           [-0.0056],\n",
      "           [-0.0354],\n",
      "           [ 0.0505],\n",
      "           [-0.0412],\n",
      "           [ 0.1035],\n",
      "           [ 0.0074],\n",
      "           [-0.0325],\n",
      "           [-0.0373],\n",
      "           [-0.0025],\n",
      "           [-0.0071]]], device='cuda:0'), std=tensor([[[45.0080],\n",
      "           [20.2708],\n",
      "           [11.7008],\n",
      "           [11.5876],\n",
      "           [15.2168],\n",
      "           [47.7619],\n",
      "           [19.8388],\n",
      "           [10.5537],\n",
      "           [11.6707],\n",
      "           [15.9614],\n",
      "           [20.6152],\n",
      "           [14.4362],\n",
      "           [13.6445],\n",
      "           [21.9794],\n",
      "           [16.9491],\n",
      "           [14.6477],\n",
      "           [19.7299],\n",
      "           [11.4548],\n",
      "           [11.6362],\n",
      "           [94.2795],\n",
      "           [68.4567]]], device='cuda:0'), eps=1e-08, std_eps=tensor([[[45.0080],\n",
      "           [20.2708],\n",
      "           [11.7008],\n",
      "           [11.5876],\n",
      "           [15.2168],\n",
      "           [47.7619],\n",
      "           [19.8388],\n",
      "           [10.5537],\n",
      "           [11.6707],\n",
      "           [15.9614],\n",
      "           [20.6152],\n",
      "           [14.4362],\n",
      "           [13.6445],\n",
      "           [21.9794],\n",
      "           [16.9491],\n",
      "           [14.6477],\n",
      "           [19.7299],\n",
      "           [11.4548],\n",
      "           [11.6362],\n",
      "           [94.2795],\n",
      "           [68.4567]]], device='cuda:0'))\n",
      "  (4): EegMultiplicativeGaussianNoise(mean=0.0, std=0.09575622309480344)\n",
      "  (5): EegAdditiveGaussianNoise(mean=0.0, std=0.004872735559634612)\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "preprocess_test: Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda'))\n",
      "  (1): EegNormalizeAge(mean=tensor([71.1417], device='cuda:0'), std=tensor([9.7840], device='cuda:0'), eps=1e-08, std_eps=tensor([9.7840], device='cuda:0'))\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([[[ 0.1507],\n",
      "           [ 0.0541],\n",
      "           [-0.0413],\n",
      "           [ 0.0160],\n",
      "           [-0.0541],\n",
      "           [ 0.1908],\n",
      "           [-0.0025],\n",
      "           [-0.0211],\n",
      "           [ 0.0069],\n",
      "           [ 0.0494],\n",
      "           [ 0.0051],\n",
      "           [-0.0056],\n",
      "           [-0.0354],\n",
      "           [ 0.0505],\n",
      "           [-0.0412],\n",
      "           [ 0.1035],\n",
      "           [ 0.0074],\n",
      "           [-0.0325],\n",
      "           [-0.0373],\n",
      "           [-0.0025],\n",
      "           [-0.0071]]], device='cuda:0'), std=tensor([[[45.0080],\n",
      "           [20.2708],\n",
      "           [11.7008],\n",
      "           [11.5876],\n",
      "           [15.2168],\n",
      "           [47.7619],\n",
      "           [19.8388],\n",
      "           [10.5537],\n",
      "           [11.6707],\n",
      "           [15.9614],\n",
      "           [20.6152],\n",
      "           [14.4362],\n",
      "           [13.6445],\n",
      "           [21.9794],\n",
      "           [16.9491],\n",
      "           [14.6477],\n",
      "           [19.7299],\n",
      "           [11.4548],\n",
      "           [11.6362],\n",
      "           [94.2795],\n",
      "           [68.4567]]], device='cuda:0'), eps=1e-08, std_eps=tensor([[[45.0080],\n",
      "           [20.2708],\n",
      "           [11.7008],\n",
      "           [11.5876],\n",
      "           [15.2168],\n",
      "           [47.7619],\n",
      "           [19.8388],\n",
      "           [10.5537],\n",
      "           [11.6707],\n",
      "           [15.9614],\n",
      "           [20.6152],\n",
      "           [14.4362],\n",
      "           [13.6445],\n",
      "           [21.9794],\n",
      "           [16.9491],\n",
      "           [14.6477],\n",
      "           [19.7299],\n",
      "           [11.4548],\n",
      "           [11.6362],\n",
      "           [94.2795],\n",
      "           [68.4567]]], device='cuda:0'))\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "0 torch.Size([512, 21, 2000]) torch.Size([512]) torch.Size([512])\n",
      "1 torch.Size([512, 21, 2000]) torch.Size([512]) torch.Size([512])\n",
      "2 torch.Size([512, 21, 2000]) torch.Size([512]) torch.Size([512])\n",
      "3 torch.Size([512, 21, 2000]) torch.Size([512]) torch.Size([512])\n",
      "4 torch.Size([512, 21, 2000]) torch.Size([512]) torch.Size([512])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if '220419' in config_1['dataset_path']:\n",
    "    config_1['dataset_path'] = './local/dataset/caueeg-dataset/'\n",
    "if '220419' in config_2['dataset_path']:\n",
    "    config_2['dataset_path'] = './local/dataset/caueeg-dataset/'\n",
    "\n",
    "train_loader, val_loader, test_loader, multicrop_test_loader = build_dataset_for_train(deepcopy(config_1), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abaa1cae-7a0b-4c01-bea1-1c905c785b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.pipeline.EegToDevice'>\n",
      "<class 'datasets.pipeline.EegNormalizeAge'>\n",
      "<class 'datasets.pipeline.EegAddGaussianNoiseAge'>\n",
      "<class 'datasets.pipeline.EegNormalizeMeanStd'>\n",
      "<class 'datasets.pipeline.EegMultiplicativeGaussianNoise'>\n",
      "<class 'datasets.pipeline.EegAdditiveGaussianNoise'>\n",
      "---\n",
      "<class 'datasets.pipeline.EegToDevice'>\n",
      "<class 'datasets.pipeline.EegNormalizeAge'>\n",
      "<class 'datasets.pipeline.EegNormalizeMeanStd'>\n",
      "---\n",
      "<class 'datasets.pipeline.EegToDevice'>\n",
      "<class 'datasets.pipeline.EegNormalizeAge'>\n",
      "<class 'datasets.pipeline.EegAddGaussianNoiseAge'>\n",
      "<class 'datasets.pipeline.EegNormalizeMeanStd'>\n",
      "<class 'datasets.pipeline.EegMultiplicativeGaussianNoise'>\n",
      "<class 'datasets.pipeline.EegAdditiveGaussianNoise'>\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(config_1['preprocess_train'])):\n",
    "    print(config_1['preprocess_train'][i].__class__)\n",
    "    \n",
    "print('---')\n",
    "\n",
    "for i in range(len(config_2['preprocess_train'])):\n",
    "    print(config_2['preprocess_train'][i].__class__)\n",
    "    \n",
    "print('---')\n",
    "\n",
    "if model_name_1 == 'lo88puq7':\n",
    "    config_2['preprocess_train_noisy'] = torch.nn.Sequential(*[config_2['preprocess_train'][0], config_2['preprocess_train'][1], \n",
    "                                                               config_1['preprocess_train'][2], \n",
    "                                                               config_2['preprocess_train'][2],\n",
    "                                                               config_1['preprocess_train'][4], config_1['preprocess_train'][5],\n",
    "                                                               config_2['preprocess_train'][3], config_2['preprocess_train'][4]])\n",
    "elif model_name_1 == 'l8524nml':\n",
    "    config_2['preprocess_train_noisy'] = torch.nn.Sequential(*[config_2['preprocess_train'][0], config_2['preprocess_train'][1], \n",
    "                                                               config_1['preprocess_train'][2], \n",
    "                                                               config_2['preprocess_train'][2],\n",
    "                                                               config_1['preprocess_train'][4], config_1['preprocess_train'][5]])\n",
    "elif model_name_1 == '2apj72km':    \n",
    "    config_2['preprocess_train_noisy'] = torch.nn.Sequential(*[config_2['preprocess_train'][0], config_2['preprocess_train'][1], \n",
    "                                                               config_1['preprocess_train'][2], \n",
    "                                                               config_2['preprocess_train'][2],\n",
    "                                                               config_1['preprocess_train'][4], config_1['preprocess_train'][5]])\n",
    "\n",
    "for i in range(len(config_2['preprocess_train_noisy'])):\n",
    "    print(config_2['preprocess_train_noisy'][i].__class__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3194f85f-b580-41dd-a75a-646937e51895",
   "metadata": {},
   "source": [
    "## Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cf305ec-becd-4b3e-998d-649ddbb34b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "63.42690677966102\n",
      "100.0\n",
      "63.32097457627118\n",
      "100.0\n",
      "63.029661016949156\n"
     ]
    }
   ],
   "source": [
    "_ = check_accuracy(model_1, train_loader, \n",
    "                   config_1['preprocess_test'], config_1, repeat=1)\n",
    "print(_)\n",
    "\n",
    "_ = check_accuracy(model_1, test_loader, \n",
    "                   config_1['preprocess_test'], config_1, repeat=3)\n",
    "print(_)\n",
    "\n",
    "_ = check_accuracy(model_1, train_loader, \n",
    "                   config_1['preprocess_train'], config_1, repeat=1)\n",
    "print(_)\n",
    "\n",
    "_ = check_accuracy(model_1, test_loader, \n",
    "                   config_1['preprocess_train'], config_1, repeat=3)\n",
    "print(_)\n",
    "\n",
    "_ = check_accuracy(model_1, train_loader, \n",
    "                   config_2['preprocess_train_noisy'], config_1, repeat=1)\n",
    "print(_)\n",
    "\n",
    "_ = check_accuracy(model_1, test_loader, \n",
    "                   config_2['preprocess_train_noisy'], config_1, repeat=3)\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e226632-1382-4d43-8307-9eb74e79021e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "62.82662429378531\n",
      "100.0\n",
      "63.24152542372882\n",
      "100.0\n",
      "62.976694915254235\n"
     ]
    }
   ],
   "source": [
    "_ = check_accuracy(model_2, train_loader, \n",
    "                   config_2['preprocess_test'], config_2, repeat=1)\n",
    "print(_)\n",
    "\n",
    "_ = check_accuracy(model_2, test_loader, \n",
    "                   config_2['preprocess_test'], config_2, repeat=3)\n",
    "print(_)\n",
    "\n",
    "_ = check_accuracy(model_2, train_loader, \n",
    "                   config_2['preprocess_train'], config_2, repeat=1)\n",
    "print(_)\n",
    "\n",
    "_ = check_accuracy(model_2, test_loader, \n",
    "                   config_2['preprocess_train'], config_2, repeat=3)\n",
    "print(_)\n",
    "\n",
    "_ = check_accuracy(model_2, train_loader, \n",
    "                   config_2['preprocess_train_noisy'], config_2, repeat=1)\n",
    "print(_)\n",
    "\n",
    "_ = check_accuracy(model_2, test_loader, \n",
    "                   config_2['preprocess_train_noisy'], config_2, repeat=3)\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76707ff8-e734-4c8e-a1e7-17636ca3e334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "63.356285310734464\n",
      "100.0\n",
      "63.04731638418079\n"
     ]
    }
   ],
   "source": [
    "_ = check_accuracy(model_2, train_loader, \n",
    "                   config_1['preprocess_test'], config_2, repeat=1)\n",
    "print(_)\n",
    "\n",
    "_ = check_accuracy(model_2, test_loader, \n",
    "                   config_1['preprocess_test'], config_2, repeat=3)\n",
    "print(_)\n",
    "\n",
    "_ = check_accuracy(model_2, train_loader, \n",
    "                   config_1['preprocess_train'], config_2, repeat=1)\n",
    "print(_)\n",
    "\n",
    "_ = check_accuracy(model_2, test_loader, \n",
    "                   config_1['preprocess_train'], config_2, repeat=3)\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dfce23-e2a8-43e7-ade1-dd29ac255f85",
   "metadata": {},
   "source": [
    "## t-SNE embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf875389-0084-4e44-98e3-eae37d63bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_embedding(model, sample_batched, preprocess, crop_multiple, target_from_last):\n",
    "    # evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # preprocessing (this includes to-device operation)\n",
    "    preprocess(sample_batched)\n",
    "\n",
    "    # apply model on whole batch directly on device\n",
    "    x = sample_batched['signal']\n",
    "    age = sample_batched['age']\n",
    "    e = model.compute_feature_embedding(x, age, target_from_last=target_from_last)\n",
    "    y = sample_batched['class_label']\n",
    "    \n",
    "    if crop_multiple > 1:\n",
    "        # multi-crop averaging\n",
    "        if e.size(0) % crop_multiple != 0:\n",
    "            raise ValueError(f\"compute_embedding(): Real minibatch size={e.size(0)} is not multiple of \"\n",
    "                             f\"crop_multiple={crop_multiple}.\")\n",
    "\n",
    "        real_minibatch = e.size(0) // crop_multiple\n",
    "        e_ = torch.zeros((real_minibatch, e.size(1)))\n",
    "        y_ = torch.zeros((real_minibatch,), dtype=torch.int32)\n",
    "\n",
    "        for m in range(real_minibatch):\n",
    "            e_[m] = e[crop_multiple*m:crop_multiple*(m + 1)].mean(dim=0, keepdims=True)\n",
    "            y_[m] = y[crop_multiple*m]\n",
    "                \n",
    "        e = e_\n",
    "        y = y_\n",
    "    \n",
    "    return e, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d28b639-c84a-4ad3-80d7-9b862912b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = [{'name': 'Train Dataset', 'loader': train_loader}]\n",
    "\n",
    "for r in range(len(result_1)):\n",
    "    name = result_1[r]['name']\n",
    "    loader = result_1[r]['loader']\n",
    "\n",
    "    for i, sample_batched in enumerate(loader):\n",
    "        if i == 0:\n",
    "            crop_multiple = config_1['crop_multiple']\n",
    "            minibatch_size = loader.batch_size\n",
    "\n",
    "        # estimate\n",
    "        e, y = compute_embedding(model_1, deepcopy(sample_batched), config_1['preprocess_test'], \n",
    "                                 crop_multiple, target_from_last=target_from_last)\n",
    "        if i == 0:\n",
    "            embedding = e.detach().cpu().numpy()\n",
    "            target = y.detach().cpu().numpy()\n",
    "        else:\n",
    "            embedding = np.concatenate([embedding, e.detach().cpu().numpy()], axis=0)\n",
    "            target = np.concatenate([target, y.detach().cpu().numpy()], axis=0)     \n",
    "\n",
    "        for m in range(repeat):\n",
    "            e_noisy, y_noisy = compute_embedding(model_1, deepcopy(sample_batched), config_1['preprocess_train'], \n",
    "                                                 crop_multiple, target_from_last=target_from_last)\n",
    "            if m == 0 and i == 0:\n",
    "                embedding_noisy = e_noisy.detach().cpu().numpy()\n",
    "                target_noisy = y_noisy.detach().cpu().numpy()\n",
    "            else:\n",
    "                embedding_noisy = np.concatenate([embedding_noisy, e_noisy.detach().cpu().numpy()], axis=0)\n",
    "                target_noisy = np.concatenate([target_noisy, y_noisy.detach().cpu().numpy()], axis=0)\n",
    "\n",
    "    result_1[r]['embedding'] = embedding\n",
    "    result_1[r]['target'] = target\n",
    "    result_1[r]['embedding_noisy'] = embedding_noisy\n",
    "    result_1[r]['target_noisy'] = target_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7703da53-2a0f-4dd9-ba73-f96be3db8880",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_2 = [{'name': 'Train Dataset', 'loader': train_loader}]\n",
    "\n",
    "for r in range(len(result_2)):\n",
    "    name = result_2[r]['name']\n",
    "    loader = result_2[r]['loader']\n",
    "\n",
    "    for i, sample_batched in enumerate(loader):\n",
    "        if i == 0:\n",
    "            crop_multiple = config_2['crop_multiple']\n",
    "            minibatch_size = loader.batch_size\n",
    "\n",
    "        # estimate\n",
    "        e, y = compute_embedding(model_2, deepcopy(sample_batched), config_2['preprocess_test'], \n",
    "                                 crop_multiple, target_from_last=target_from_last)\n",
    "        if i == 0:\n",
    "            embedding = e.detach().cpu().numpy()\n",
    "            target = y.detach().cpu().numpy()\n",
    "        else:\n",
    "            embedding = np.concatenate([embedding, e.detach().cpu().numpy()], axis=0)\n",
    "            target = np.concatenate([target, y.detach().cpu().numpy()], axis=0)     \n",
    "\n",
    "        for m in range(repeat):\n",
    "            e_noisy, y_noisy = compute_embedding(model_2, deepcopy(sample_batched), config_2['preprocess_train_noisy'], \n",
    "                                                 crop_multiple, target_from_last=target_from_last)\n",
    "            if m == 0 and i == 0:\n",
    "                embedding_noisy = e_noisy.detach().cpu().numpy()\n",
    "                target_noisy = y_noisy.detach().cpu().numpy()\n",
    "            else:\n",
    "                embedding_noisy = np.concatenate([embedding_noisy, e_noisy.detach().cpu().numpy()], axis=0)\n",
    "                target_noisy = np.concatenate([target_noisy, y_noisy.detach().cpu().numpy()], axis=0)\n",
    "\n",
    "    result_2[r]['embedding'] = embedding\n",
    "    result_2[r]['target'] = target\n",
    "    result_2[r]['embedding_noisy'] = embedding_noisy\n",
    "    result_2[r]['target_noisy'] = target_noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9672d5-d7a1-4f9d-9086-ab0be26be030",
   "metadata": {},
   "source": [
    "## Draw 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a25d4ffa-a66b-4edb-856e-9d44a9c02fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use('default') \n",
    "# plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "# plt.rcParams.update({'font.size': 16})\n",
    "# plt.rcParams.update({'font.family': 'Roboto Slab'})\n",
    "# plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "# color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "# color_map2 = [['tab:green', 'tab:brown', 'tab:blue'], \n",
    "#               ['gray', 'tab:orange', 'tab:pink'], \n",
    "#               ['gray', 'gray', 'tab:red']]\n",
    "\n",
    "\n",
    "# for n_iter in [7000]:\n",
    "#     for perplexity in [25, 50, 100, 200, 300]:\n",
    "#         tsne_transform = TSNE(n_components=2, init=\"pca\", learning_rate=\"auto\", perplexity=perplexity,\n",
    "#                               n_iter=n_iter, n_iter_without_progress=1000, n_jobs=2, random_state=0,)\n",
    "        \n",
    "#         for r in range(len(result_1)):\n",
    "#             output = tsne_transform.fit_transform(np.concatenate([result_1[r]['embedding'], result_1[r]['embedding_noisy']]))\n",
    "#             result_1[r]['tsne_embedding'] = output[:result_1[r]['embedding'].shape[0]]\n",
    "#             result_1[r]['tsne_embedding_noisy'] = output[result_1[r]['embedding'].shape[0]:]\n",
    "            \n",
    "#         for r in range(len(result_1)):\n",
    "#             fig, ax = plt.subplots()\n",
    "#             for class_name, class_label in config_1['class_name_to_label'].items():\n",
    "#                 ax.scatter(\n",
    "#                     result_1[r]['tsne_embedding'][result_1[r]['target'] == class_label][:, 0],\n",
    "#                     result_1[r]['tsne_embedding'][result_1[r]['target'] == class_label][:, 1],\n",
    "#                     label=class_name,\n",
    "#                     color=color_map[class_label],\n",
    "#                     alpha=0.8,\n",
    "#                     edgecolors='k',                    \n",
    "#                     zorder=2)\n",
    "#             ax.set_xticklabels([])\n",
    "#             ax.set_yticklabels([])\n",
    "#             ax.legend(bbox_to_anchor=(1.04, 0.5), loc='center left', borderaxespad=0.)\n",
    "#             if save_fig:\n",
    "#                 for ext in ['pdf', 'jpg', 'svg']:\n",
    "#                     os.makedirs(os.path.join(output_folder, model_name_1, ext), exist_ok=True)\n",
    "#                     fig.savefig(os.path.join(output_folder, model_name_1, ext, f\"dim2_per{perplexity:03}_iter{n_iter:05}_ori.{ext}\"), \n",
    "#                                 transparent=True, bbox_inches='tight')\n",
    "#             else:\n",
    "#                 plt.show()\n",
    "#             fig.clear()\n",
    "#             plt.close(fig)\n",
    "            \n",
    "#         for r in range(len(result_1)):\n",
    "#             fig, ax = plt.subplots()\n",
    "#             for class_name, class_label in config_1['class_name_to_label'].items():\n",
    "#                 ax.scatter(\n",
    "#                     result_1[r]['tsne_embedding'][result_1[r]['target'] == class_label][:, 0],\n",
    "#                     result_1[r]['tsne_embedding'][result_1[r]['target'] == class_label][:, 1],\n",
    "#                     label=class_name,\n",
    "#                     color=color_map[class_label],\n",
    "#                     alpha=0.2,\n",
    "#                     zorder=2)        \n",
    "#                 ax.scatter(\n",
    "#                     result_1[r]['tsne_embedding_noisy'][result_1[r]['target_noisy'] == class_label][:, 0],\n",
    "#                     result_1[r]['tsne_embedding_noisy'][result_1[r]['target_noisy'] == class_label][:, 1],\n",
    "#                     label=class_name + ' (noisy)',\n",
    "#                     color=color_map[class_label],\n",
    "#                     alpha=0.8,\n",
    "#                     edgecolors='k',\n",
    "#                     zorder=2)               \n",
    "#             ax.set_xticklabels([])\n",
    "#             ax.set_yticklabels([])\n",
    "#             ax.legend(bbox_to_anchor=(1.04, 0.5), loc='center left', borderaxespad=0.)\n",
    "#             if save_fig:\n",
    "#                 for ext in ['pdf', 'jpg', 'svg']:\n",
    "#                     os.makedirs(os.path.join(output_folder, model_name_1, ext), exist_ok=True)\n",
    "#                     fig.savefig(os.path.join(output_folder, model_name_1, ext, f\"dim2_per{perplexity:03}_iter{n_iter:05}.{ext}\"), \n",
    "#                                 transparent=True, bbox_inches='tight')\n",
    "#             else:\n",
    "#                 plt.show()\n",
    "#             fig.clear()\n",
    "#             plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d1f1aa5-d511-4595-b817-5c3fc9fce2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use('default') \n",
    "# plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "# plt.rcParams.update({'font.size': 16})\n",
    "# plt.rcParams.update({'font.family': 'Roboto Slab'})\n",
    "# plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "# color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "# color_map2 = [['tab:green', 'tab:brown', 'tab:blue'], \n",
    "#               ['gray', 'tab:orange', 'tab:pink'], \n",
    "#               ['gray', 'gray', 'tab:red']]\n",
    "\n",
    "\n",
    "# for n_iter in [7000]:\n",
    "#     for perplexity in [25, 50, 100, 200, 300]:\n",
    "#         tsne_transform = TSNE(n_components=2, init=\"pca\", learning_rate=\"auto\", perplexity=perplexity,\n",
    "#                               n_iter=n_iter, n_iter_without_progress=1000, n_jobs=2, random_state=0,)\n",
    "        \n",
    "#         for r in range(len(result_2)):\n",
    "#             output = tsne_transform.fit_transform(np.concatenate([result_2[r]['embedding'], result_2[r]['embedding_noisy']]))\n",
    "#             result_2[r]['tsne_embedding'] = output[:result_2[r]['embedding'].shape[0]]\n",
    "#             result_2[r]['tsne_embedding_noisy'] = output[result_2[r]['embedding'].shape[0]:]\n",
    "            \n",
    "#         for r in range(len(result_2)):\n",
    "#             fig, ax = plt.subplots()\n",
    "#             for class_name, class_label in config_2['class_name_to_label'].items():\n",
    "#                 ax.scatter(\n",
    "#                     result_2[r]['tsne_embedding'][result_2[r]['target'] == class_label][:, 0],\n",
    "#                     result_2[r]['tsne_embedding'][result_2[r]['target'] == class_label][:, 1],\n",
    "#                     label=class_name,\n",
    "#                     color=color_map[class_label],\n",
    "#                     alpha=0.8,\n",
    "#                     edgecolors='k',                    \n",
    "#                     zorder=2)\n",
    "#             ax.set_xticklabels([])\n",
    "#             ax.set_yticklabels([])\n",
    "#             ax.legend(bbox_to_anchor=(1.04, 0.5), loc='center left', borderaxespad=0.)\n",
    "#             if save_fig:\n",
    "#                 for ext in ['pdf', 'jpg', 'svg']:\n",
    "#                     os.makedirs(os.path.join(output_folder, model_name_2, ext), exist_ok=True)\n",
    "#                     fig.savefig(os.path.join(output_folder, model_name_2, ext, f\"dim2_per{perplexity:03}_iter{n_iter:05}_ori.{ext}\"), \n",
    "#                                 transparent=True, bbox_inches='tight')\n",
    "#             else:\n",
    "#                 plt.show()\n",
    "#             fig.clear()\n",
    "#             plt.close(fig)\n",
    "            \n",
    "#         for r in range(len(result_2)):\n",
    "#             fig, ax = plt.subplots()\n",
    "#             for class_name, class_label in config_2['class_name_to_label'].items():\n",
    "#                 ax.scatter(\n",
    "#                     result_2[r]['tsne_embedding'][result_2[r]['target'] == class_label][:, 0],\n",
    "#                     result_2[r]['tsne_embedding'][result_2[r]['target'] == class_label][:, 1],\n",
    "#                     label=class_name,\n",
    "#                     color=color_map[class_label],\n",
    "#                     alpha=0.2,\n",
    "#                     zorder=2)        \n",
    "#                 ax.scatter(\n",
    "#                     result_2[r]['tsne_embedding_noisy'][result_2[r]['target_noisy'] == class_label][:, 0],\n",
    "#                     result_2[r]['tsne_embedding_noisy'][result_2[r]['target_noisy'] == class_label][:, 1],\n",
    "#                     label=class_name + ' (noisy)',\n",
    "#                     color=color_map[class_label],\n",
    "#                     alpha=0.8,\n",
    "#                     edgecolors='k',\n",
    "#                     zorder=2)               \n",
    "#             ax.set_xticklabels([])\n",
    "#             ax.set_yticklabels([])\n",
    "#             ax.legend(bbox_to_anchor=(1.04, 0.5), loc='center left', borderaxespad=0.)\n",
    "#             if save_fig:\n",
    "#                 for ext in ['pdf', 'jpg', 'svg']:\n",
    "#                     os.makedirs(os.path.join(output_folder, model_name_2, ext), exist_ok=True)\n",
    "#                     fig.savefig(os.path.join(output_folder, model_name_2, ext, f\"dim2_per{perplexity:03}_iter{n_iter:05}.{ext}\"), \n",
    "#                                 transparent=True, bbox_inches='tight')\n",
    "#             else:\n",
    "#                 plt.show()\n",
    "#             fig.clear()\n",
    "#             plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b338443a-ea48-4da5-bbdf-e66d9937ef34",
   "metadata": {},
   "source": [
    "## Draw 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "644d24ae-c70b-4ea5-bf09-9855a239bc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minjae\\anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:991: FutureWarning:\n",
      "\n",
      "The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plt.style.use('default') \n",
    "plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams.update({'font.family': 'Roboto Slab'})\n",
    "plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "color_map2 = [['tab:green', 'tab:brown', 'tab:blue'], \n",
    "              ['gray', 'tab:orange', 'tab:pink'], \n",
    "              ['gray', 'gray', 'tab:red']]\n",
    "\n",
    "\n",
    "for n_iter in [10000]:\n",
    "    for perplexity in [200]:# [50, 70, 100, 150, 200]:\n",
    "        tsne_transform = TSNE(n_components=3, init=\"pca\", learning_rate=\"auto\", perplexity=perplexity,\n",
    "                              n_iter=n_iter, n_iter_without_progress=1000, n_jobs=2, random_state=0,)\n",
    "        \n",
    "        for r in range(len(result_1)):\n",
    "            output = tsne_transform.fit_transform(result_1[r]['embedding'])\n",
    "            result_1[r]['tsne_embedding'] = output[:result_1[r]['embedding'].shape[0]]\n",
    "            \n",
    "        for r in range(len(result_1)):\n",
    "            fig = plt.figure(num=1, clear=True, figsize=(12.0, 12.0))\n",
    "            ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "            for class_name, class_label in config_1['class_name_to_label'].items():\n",
    "                ax.scatter(\n",
    "                    xs=result_1[r]['tsne_embedding'][result_1[r]['target'] == class_label][:, 0],\n",
    "                    ys=result_1[r]['tsne_embedding'][result_1[r]['target'] == class_label][:, 1],\n",
    "                    zs=result_1[r]['tsne_embedding'][result_1[r]['target'] == class_label][:, 2],\n",
    "                    label=class_name,\n",
    "                    color=color_map[class_label],\n",
    "                    alpha=0.8,\n",
    "                    s=40,\n",
    "                    # zorder=2\n",
    "                )\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_zticklabels([])\n",
    "            ax.legend(bbox_to_anchor=(1.04, 0.5), loc='center left', borderaxespad=0.)\n",
    "            if save_fig:\n",
    "                for ext in ['pdf', 'jpg', 'svg']:\n",
    "                    os.makedirs(os.path.join(output_folder, model_name_1, ext), exist_ok=True)\n",
    "                    fig.savefig(os.path.join(output_folder, model_name_1, ext, f\"dim3_per{perplexity:03}_iter{n_iter:05}_ori0.{ext}\"), \n",
    "                                transparent=True, bbox_inches='tight')\n",
    "            else:\n",
    "                plt.show()\n",
    "            fig.clear()\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce418a79-2756-47b7-99d0-f5aae47d60c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minjae\\anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:991: FutureWarning:\n",
      "\n",
      "The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plt.style.use('default') \n",
    "plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams.update({'font.family': 'Roboto Slab'})\n",
    "plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "color_map2 = [['tab:green', 'tab:brown', 'tab:blue'], \n",
    "              ['gray', 'tab:orange', 'tab:pink'], \n",
    "              ['gray', 'gray', 'tab:red']]\n",
    "\n",
    "\n",
    "for n_iter in [10000]:\n",
    "    for perplexity in [200]:# [50, 70, 100, 150, 200]:\n",
    "        tsne_transform = TSNE(n_components=3, init=\"pca\", learning_rate=\"auto\", perplexity=perplexity,\n",
    "                              n_iter=n_iter, n_iter_without_progress=1000, n_jobs=2, random_state=0,)\n",
    "        \n",
    "        for r in range(len(result_1)):\n",
    "            output = tsne_transform.fit_transform(np.concatenate([result_1[r]['embedding'], result_1[r]['embedding_noisy']]))\n",
    "            result_1[r]['tsne_embedding'] = output[:result_1[r]['embedding'].shape[0]]\n",
    "            result_1[r]['tsne_embedding_noisy'] = output[result_1[r]['embedding'].shape[0]:]\n",
    "            \n",
    "        for r in range(len(result_1)):\n",
    "            fig = plt.figure(num=1, clear=True, figsize=(12.0, 12.0))\n",
    "            ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "            for class_name, class_label in config_1['class_name_to_label'].items():\n",
    "                ax.scatter(\n",
    "                    xs=result_1[r]['tsne_embedding'][result_1[r]['target'] == class_label][:, 0],\n",
    "                    ys=result_1[r]['tsne_embedding'][result_1[r]['target'] == class_label][:, 1],\n",
    "                    zs=result_1[r]['tsne_embedding'][result_1[r]['target'] == class_label][:, 2],\n",
    "                    label=class_name,\n",
    "                    color=color_map[class_label],\n",
    "                    alpha=0.8,\n",
    "                    s=40,\n",
    "                    # zorder=2\n",
    "                )\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_zticklabels([])\n",
    "            ax.legend(bbox_to_anchor=(1.04, 0.5), loc='center left', borderaxespad=0.)\n",
    "            if save_fig:\n",
    "                for ext in ['pdf', 'jpg', 'svg']:\n",
    "                    os.makedirs(os.path.join(output_folder, model_name_1, ext), exist_ok=True)\n",
    "                    fig.savefig(os.path.join(output_folder, model_name_1, ext, f\"dim3_per{perplexity:03}_iter{n_iter:05}_ori.{ext}\"), \n",
    "                                transparent=True, bbox_inches='tight')\n",
    "            else:\n",
    "                plt.show()\n",
    "            fig.clear()\n",
    "            plt.close(fig)\n",
    "            \n",
    "        for r in range(len(result_1)):\n",
    "            fig = plt.figure(num=1, clear=True, figsize=(12.0, 12.0))\n",
    "            ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "            for class_name, class_label in config_1['class_name_to_label'].items():\n",
    "                ax.scatter(\n",
    "                    xs=result_1[r]['tsne_embedding'][result_1[r]['target'] == class_label][:, 0],\n",
    "                    ys=result_1[r]['tsne_embedding'][result_1[r]['target'] == class_label][:, 1],\n",
    "                    zs=result_1[r]['tsne_embedding'][result_1[r]['target'] == class_label][:, 2],\n",
    "                    label=class_name,\n",
    "                    color=color_map[class_label],\n",
    "                    alpha=0.2,\n",
    "                    s=40,\n",
    "                    # zorder=2\n",
    "                )       \n",
    "                ax.scatter(\n",
    "                    xs=result_1[r]['tsne_embedding_noisy'][result_1[r]['target_noisy'] == class_label][:, 0],\n",
    "                    ys=result_1[r]['tsne_embedding_noisy'][result_1[r]['target_noisy'] == class_label][:, 1],\n",
    "                    zs=result_1[r]['tsne_embedding_noisy'][result_1[r]['target_noisy'] == class_label][:, 2],\n",
    "                    label=class_name + ' (noisy)',\n",
    "                    color=color_map[class_label],\n",
    "                    alpha=0.8,\n",
    "                    s=40,\n",
    "                    # zorder=2\n",
    "                )      \n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_zticklabels([])\n",
    "            ax.legend(bbox_to_anchor=(1.04, 0.5), loc='center left', borderaxespad=0.)\n",
    "            if save_fig:\n",
    "                for ext in ['pdf', 'jpg', 'svg']:\n",
    "                    os.makedirs(os.path.join(output_folder, model_name_1, ext), exist_ok=True)\n",
    "                    fig.savefig(os.path.join(output_folder, model_name_1, ext, f\"dim3_per{perplexity:03}_iter{n_iter:05}.{ext}\"), \n",
    "                                transparent=True, bbox_inches='tight')\n",
    "            else:\n",
    "                plt.show()\n",
    "            fig.clear()\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1efd7d6c-7e34-4ebd-8b4b-eab414b64581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minjae\\anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:991: FutureWarning:\n",
      "\n",
      "The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plt.style.use('default') \n",
    "plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams.update({'font.family': 'Roboto Slab'})\n",
    "plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "color_map2 = [['tab:green', 'tab:brown', 'tab:blue'], \n",
    "              ['gray', 'tab:orange', 'tab:pink'], \n",
    "              ['gray', 'gray', 'tab:red']]\n",
    "\n",
    "\n",
    "for n_iter in [10000]:\n",
    "    for perplexity in [200]:# [50, 70, 100, 150, 200]:\n",
    "        tsne_transform = TSNE(n_components=3, init=\"pca\", learning_rate=\"auto\", perplexity=perplexity,\n",
    "                              n_iter=n_iter, n_iter_without_progress=1000, n_jobs=2, random_state=0,)\n",
    "        \n",
    "        for r in range(len(result_2)):\n",
    "            output = tsne_transform.fit_transform(result_2[r]['embedding'])\n",
    "            result_2[r]['tsne_embedding'] = output[:result_2[r]['embedding'].shape[0]]\n",
    "            \n",
    "        for r in range(len(result_2)):\n",
    "            fig = plt.figure(num=1, clear=True, figsize=(12.0, 12.0))\n",
    "            ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "            for class_name, class_label in config_2['class_name_to_label'].items():\n",
    "                ax.scatter(\n",
    "                    xs=result_2[r]['tsne_embedding'][result_2[r]['target'] == class_label][:, 0],\n",
    "                    ys=result_2[r]['tsne_embedding'][result_2[r]['target'] == class_label][:, 1],\n",
    "                    zs=result_2[r]['tsne_embedding'][result_2[r]['target'] == class_label][:, 2],\n",
    "                    label=class_name,\n",
    "                    color=color_map[class_label],\n",
    "                    alpha=0.8,\n",
    "                    s=40,\n",
    "                    # zorder=2\n",
    "                )\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_zticklabels([])\n",
    "            ax.legend(bbox_to_anchor=(1.04, 0.5), loc='center left', borderaxespad=0.)\n",
    "            if save_fig:\n",
    "                for ext in ['pdf', 'jpg', 'svg']:\n",
    "                    os.makedirs(os.path.join(output_folder, model_name_2, ext), exist_ok=True)\n",
    "                    fig.savefig(os.path.join(output_folder, model_name_2, ext, f\"dim3_per{perplexity:03}_iter{n_iter:05}_ori0.{ext}\"), \n",
    "                                transparent=True, bbox_inches='tight')\n",
    "            else:\n",
    "                plt.show()\n",
    "            fig.clear()\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5b00f55-ec49-4677-a01f-da597329ca3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minjae\\anaconda3\\envs\\eeg\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:991: FutureWarning:\n",
      "\n",
      "The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plt.style.use('default') \n",
    "plt.style.use('fivethirtyeight') # default, ggplot, fivethirtyeight, bmh, dark_background, classic\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams.update({'font.family': 'Roboto Slab'})\n",
    "plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "color_map = ['tab:green', 'tab:orange', 'tab:red']\n",
    "color_map2 = [['tab:green', 'tab:brown', 'tab:blue'], \n",
    "              ['gray', 'tab:orange', 'tab:pink'], \n",
    "              ['gray', 'gray', 'tab:red']]\n",
    "\n",
    "\n",
    "for n_iter in [10000]:\n",
    "    for perplexity in [200]: # [50, 70, 100, 150, 200]:\n",
    "        tsne_transform = TSNE(n_components=3, init=\"pca\", learning_rate=\"auto\", perplexity=perplexity,\n",
    "                              n_iter=n_iter, n_iter_without_progress=1000, n_jobs=2, random_state=0,)\n",
    "        \n",
    "        for r in range(len(result_2)):\n",
    "            output = tsne_transform.fit_transform(np.concatenate([result_2[r]['embedding'], result_2[r]['embedding_noisy']]))\n",
    "            result_2[r]['tsne_embedding'] = output[:result_2[r]['embedding'].shape[0]]\n",
    "            result_2[r]['tsne_embedding_noisy'] = output[result_2[r]['embedding'].shape[0]:]\n",
    "            \n",
    "        for r in range(len(result_2)):\n",
    "            fig = plt.figure(num=1, clear=True, figsize=(12.0, 12.0))\n",
    "            ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "            for class_name, class_label in config_2['class_name_to_label'].items():\n",
    "                ax.scatter(\n",
    "                    xs=result_2[r]['tsne_embedding'][result_2[r]['target'] == class_label][:, 0],\n",
    "                    ys=result_2[r]['tsne_embedding'][result_2[r]['target'] == class_label][:, 1],\n",
    "                    zs=result_2[r]['tsne_embedding'][result_2[r]['target'] == class_label][:, 2],\n",
    "                    label=class_name,\n",
    "                    color=color_map[class_label],\n",
    "                    alpha=0.8,\n",
    "                    s=40,\n",
    "                    # zorder=2\n",
    "                )\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_zticklabels([])\n",
    "            ax.legend(bbox_to_anchor=(1.04, 0.5), loc='center left', borderaxespad=0.)\n",
    "            if save_fig:\n",
    "                for ext in ['pdf', 'jpg', 'svg']:\n",
    "                    os.makedirs(os.path.join(output_folder, model_name_2, ext), exist_ok=True)\n",
    "                    fig.savefig(os.path.join(output_folder, model_name_2, ext, f\"dim3_per{perplexity:03}_iter{n_iter:05}_ori.{ext}\"), \n",
    "                                transparent=True, bbox_inches='tight')\n",
    "            else:\n",
    "                plt.show()\n",
    "            fig.clear()\n",
    "            plt.close(fig)\n",
    "            \n",
    "        for r in range(len(result_2)):\n",
    "            fig = plt.figure(num=1, clear=True, figsize=(12.0, 12.0))\n",
    "            ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "            for class_name, class_label in config_2['class_name_to_label'].items():\n",
    "                ax.scatter(\n",
    "                    xs=result_2[r]['tsne_embedding'][result_2[r]['target'] == class_label][:, 0],\n",
    "                    ys=result_2[r]['tsne_embedding'][result_2[r]['target'] == class_label][:, 1],\n",
    "                    zs=result_2[r]['tsne_embedding'][result_2[r]['target'] == class_label][:, 2],\n",
    "                    label=class_name,\n",
    "                    color=color_map[class_label],\n",
    "                    alpha=0.2,\n",
    "                    s=40,\n",
    "                    # zorder=2\n",
    "                )       \n",
    "                ax.scatter(\n",
    "                    xs=result_2[r]['tsne_embedding_noisy'][result_2[r]['target_noisy'] == class_label][:, 0],\n",
    "                    ys=result_2[r]['tsne_embedding_noisy'][result_2[r]['target_noisy'] == class_label][:, 1],\n",
    "                    zs=result_2[r]['tsne_embedding_noisy'][result_2[r]['target_noisy'] == class_label][:, 2],\n",
    "                    label=class_name + ' (noisy)',\n",
    "                    color=color_map[class_label],\n",
    "                    alpha=0.8,\n",
    "                    s=40,\n",
    "                    # zorder=2\n",
    "                )      \n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "            ax.set_zticklabels([])\n",
    "            ax.legend(bbox_to_anchor=(1.04, 0.5), loc='center left', borderaxespad=0.)\n",
    "            if save_fig:\n",
    "                for ext in ['pdf', 'jpg', 'svg']:\n",
    "                    os.makedirs(os.path.join(output_folder, model_name_2, ext), exist_ok=True)\n",
    "                    fig.savefig(os.path.join(output_folder, model_name_2, ext, f\"dim3_per{perplexity:03}_iter{n_iter:05}.{ext}\"), \n",
    "                                transparent=True, bbox_inches='tight')\n",
    "            else:\n",
    "                plt.show()\n",
    "            fig.clear()\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fae016-748f-4d4e-acad-92826c9cfc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e6ee2-4acd-4776-9f43-bdba669d195d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
