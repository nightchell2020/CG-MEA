{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Finetune Self-Supervision\n",
    "\n",
    "- Finetune the deep network after pretraining the self-supervised learning framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/imkbsz/workspace/eeg_analysis\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "import pprint\n",
    "import torch\n",
    "\n",
    "# custom package\n",
    "from run_train import check_device_env\n",
    "from run_train import set_seed\n",
    "from run_train import compose_dataset\n",
    "from train.train_script import train_script\n",
    "from models.utils import count_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Specify the dataset, model, and train setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_model_path = 'local/checkpoint/'\n",
    "pre_model_name = 'jjqcw8r9'\n",
    "finetune = 'finetune'\n",
    "\n",
    "project = 'caueeg-ssl-finetune'\n",
    "use_wandb = True\n",
    "device = 'cuda:3'\n",
    "\n",
    "crop_multiple = 8\n",
    "total_samples = 3.0e+6\n",
    "reset_minibatch = False\n",
    "search_lr = True   ##########\n",
    "base_lr = 1e-3  #########\n",
    "warmup_min = 300 # None\n",
    "lr_scheduler_type = 'cosine_decay_with_warmup_half'  # 'consine_decay_with_warmup_half', 'linear_decay_with_warmup'\n",
    "\n",
    "mixup = 0.1    ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.11.0\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Load and modify the pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EKG': 'O',\n",
      " '_ssl_target_': 'models.ssl.byol.BYOL',\n",
      " '_target_': 'models.vit.vit_b_8',\n",
      " 'activation': 'gelu',\n",
      " 'age_mean': tensor([71.2164], device='cuda:3'),\n",
      " 'age_std': tensor([9.6946], device='cuda:3'),\n",
      " 'attention_dropout': 0.1,\n",
      " 'awgn': 0.05,\n",
      " 'awgn_age': 0.001,\n",
      " 'base_lr': 0.1,\n",
      " 'channel_dropout': 0.2,\n",
      " 'class_label_to_name': ['Normal', 'MCI', 'Dementia'],\n",
      " 'class_name_to_label': {'Dementia': 2, 'MCI': 1, 'Normal': 0},\n",
      " 'clip_grad_norm': 1.0,\n",
      " 'criterion': 'cross-entropy',\n",
      " 'crop_multiple': 2,\n",
      " 'crop_timing_analysis': False,\n",
      " 'cwd': '/home/imkbsz/workspace/eeg_analysis',\n",
      " 'dataset_name': 'CAUEEG dataset',\n",
      " 'dataset_path': 'local/dataset/caueeg-dataset/',\n",
      " 'ddp': False,\n",
      " 'device': device(type='cuda'),\n",
      " 'draw_result': True,\n",
      " 'dropout': 0.1,\n",
      " 'embedding_layer': 2,\n",
      " 'fc_stages': 2,\n",
      " 'file_format': 'memmap',\n",
      " 'in_channels': 40,\n",
      " 'input_norm': 'datapoint',\n",
      " 'iterations': 520833,\n",
      " 'latency': 2000,\n",
      " 'load_event': False,\n",
      " 'lr_scheduler_type': 'cosine_decay_with_warmup_half',\n",
      " 'mgn': 0.05,\n",
      " 'minibatch': 192,\n",
      " 'minibatch_3090': 192,\n",
      " 'mixup': 0.0,\n",
      " 'mlp_hidden_size': 4096,\n",
      " 'model': '2D-ViT-B-8',\n",
      " 'multi_batch_size': 24,\n",
      " 'num_history': 500,\n",
      " 'num_params': 88565763,\n",
      " 'out_dims': 3,\n",
      " 'output_length': 82,\n",
      " 'photic': 'X',\n",
      " 'preprocess_test': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda'))\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2164], device='cuda:3'), std=tensor([9.6946], device='cuda:3'), eps=1e-08, std_eps=tensor([9.6946], device='cuda:3'))\n",
      "  (2): EegNormalizePerSignal(eps=1e-08)\n",
      "  (3): EegSpectrogram(n_fft=179, complex_mode='as_real', stft_kwargs={'hop_length': 45})\n",
      "  (4): EegNormalizePerSignal(eps=1e-08)\n",
      "),\n",
      " 'preprocess_train': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda'))\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2164], device='cuda:3'), std=tensor([9.6946], device='cuda:3'), eps=1e-08, std_eps=tensor([9.6946], device='cuda:3'))\n",
      "  (2): EegAddGaussianNoiseAge(mean=0.0, std=0.001)\n",
      "  (3): EegNormalizePerSignal(eps=1e-08)\n",
      "  (4): EegChannelDropOut(p=0.2)\n",
      "  (5): EegMultiplicativeGaussianNoise(mean=0.0, std=0.05)\n",
      "  (6): EegAdditiveGaussianNoise(mean=0.0, std=0.05)\n",
      "  (7): EegSpectrogram(n_fft=179, complex_mode='as_real', stft_kwargs={'hop_length': 45})\n",
      "  (8): EegNormalizePerSignal(eps=1e-08)\n",
      "),\n",
      " 'project': 'caueeg-ssl',\n",
      " 'projection_size': 256,\n",
      " 'run_mode': 'train',\n",
      " 'save_model': True,\n",
      " 'search_lr': False,\n",
      " 'search_multiplier': 1.0,\n",
      " 'seed': 0,\n",
      " 'seq_len_2d': (90, 89),\n",
      " 'seq_length': 4000,\n",
      " 'signal_header': ['Fp1-AVG',\n",
      "                   'F3-AVG',\n",
      "                   'C3-AVG',\n",
      "                   'P3-AVG',\n",
      "                   'O1-AVG',\n",
      "                   'Fp2-AVG',\n",
      "                   'F4-AVG',\n",
      "                   'C4-AVG',\n",
      "                   'P4-AVG',\n",
      "                   'O2-AVG',\n",
      "                   'F7-AVG',\n",
      "                   'T3-AVG',\n",
      "                   'T5-AVG',\n",
      "                   'F8-AVG',\n",
      "                   'T4-AVG',\n",
      "                   'T6-AVG',\n",
      "                   'FZ-AVG',\n",
      "                   'CZ-AVG',\n",
      "                   'PZ-AVG',\n",
      "                   'EKG',\n",
      "                   'Photic'],\n",
      " 'signal_length_limit': 10000000,\n",
      " 'stft_params': {'hop_length': 45, 'n_fft': 179},\n",
      " 'target_ema': 0.99,\n",
      " 'task': 'dementia',\n",
      " 'task_description': 'Classification of [Normal], [MCI], and [Dementia] '\n",
      "                     'symptoms.',\n",
      " 'task_name': 'CAUEEG-Dementia benchmark',\n",
      " 'test_crop_multiple': 8,\n",
      " 'total_samples': 100000000.0,\n",
      " 'transform': Compose(\n",
      "    EegRandomCrop(crop_length=4000, length_limit=10000000, multiple=2, latency=2000, segment_simulation=False, return_timing=False, reject_events=False)\n",
      "    EegDropChannels(drop_index=[20])\n",
      "    EegToTensor()\n",
      "),\n",
      " 'transform_multicrop': Compose(\n",
      "    EegRandomCrop(crop_length=4000, length_limit=10000000, multiple=8, latency=2000, segment_simulation=False, return_timing=False, reject_events=False)\n",
      "    EegDropChannels(drop_index=[20])\n",
      "    EegToTensor()\n",
      "),\n",
      " 'use_age': 'conv',\n",
      " 'use_wandb': True,\n",
      " 'warmup_min': 3000,\n",
      " 'warmup_ratio': 0.05,\n",
      " 'warmup_steps': 26042,\n",
      " 'watch_model': False,\n",
      " 'weight_decay': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# load pretrained configurations\n",
    "path = os.path.join(pre_model_path, pre_model_name.split(',')[-1], 'checkpoint.pt')\n",
    "try:\n",
    "    ckpt = torch.load(path, map_location=device)\n",
    "    config = ckpt['config']\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f'- checkpoint cannot be opened: {path}')\n",
    "\n",
    "# initiate the model\n",
    "model = hydra.utils.instantiate(config).to(device)\n",
    "    \n",
    "# initiate SSL model and load model state\n",
    "ssl_config = deepcopy(config)\n",
    "ssl_config['_target_'] = ssl_config['_ssl_target_']\n",
    "ssl_model = hydra.utils.instantiate(ssl_config, model).to(device)\n",
    "\n",
    "if ckpt[\"config\"][\"ddp\"] == ssl_config[\"ddp\"]:\n",
    "    ssl_model.load_state_dict(ckpt[\"ssl_model_state\"])\n",
    "elif ckpt[\"config\"][\"ddp\"]:\n",
    "    ssl_model_state_ddp = deepcopy(ckpt[\"ssl_model_state\"])\n",
    "    ssl_model_state = OrderedDict()\n",
    "    for k, v in ssl_model_state_ddp.items():\n",
    "        name = k[7:]  # remove 'module.' of DataParallel/DistributedDataParallel\n",
    "        ssl_model_state[name] = v\n",
    "    ssl_model.load_state_dict(ssl_model_state)\n",
    "else:\n",
    "    ssl_model.module.load_state_dict(ckpt[\"ssl_model_state\"])    \n",
    "\n",
    "model_state = deepcopy(ssl_model.backbone.state_dict())\n",
    "del ssl_config, ssl_model\n",
    "\n",
    "# load\n",
    "model.load_state_dict(model_state)\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Not implemented!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     model\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot implemented!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Not implemented!"
     ]
    }
   ],
   "source": [
    "# define finetuning range   \n",
    "if finetune == 'fc_stage':\n",
    "    model.requires_grad_(False)\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'fc_stage' in name:\n",
    "            param.requires_grad_(True)\n",
    "        elif 'heads' in name:\n",
    "            param.requires_grad_(True)\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{str(param.requires_grad):^15}\\t{name}\")\n",
    "elif finetune == 'whole':\n",
    "    model.requires_grad_(True)\n",
    "elif finetune == 'reset':\n",
    "    model = model = hydra.utils.instantiate(config).to(device)\n",
    "    model.requires_grad_(True)\n",
    "else:\n",
    "    raise NotImplementedError('Not implemented!')\n",
    "    \n",
    "# TODO: Need to think about the DropOut and Batch/LayerNorms statistics\n",
    "# eval/train mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modify configuration\n",
    "config['project'] = project\n",
    "config['use_wandb'] = use_wandb\n",
    "config['pre_model'] = pre_model_name\n",
    "config['finetune'] = finetune\n",
    "config['device'] = device\n",
    "\n",
    "config['crop_multiple'] = crop_multiple\n",
    "config['total_samples'] = total_samples\n",
    "if reset_minibatch: \n",
    "    config.pop('minibatch')\n",
    "config['search_lr'] = search_lr\n",
    "config['base_lr'] = base_lr\n",
    "config['lr_scheduler_type'] = lr_scheduler_type\n",
    "\n",
    "config[\"output_length\"] = model.get_output_length()\n",
    "config[\"num_params\"] = count_parameters(model)\n",
    "if warmup_min:\n",
    "    config[\"warmup_min\"] = warmup_min\n",
    "\n",
    "config['mixup'] = mixup\n",
    "    \n",
    "# remove unused keywords\n",
    "config.pop('_ssl_target_', None)\n",
    "config.pop('embedding_layer', None)\n",
    "config.pop('mlp_hidden_size', None)\n",
    "config.pop('projection_size', None)\n",
    "config.pop('warmup_steps', None)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the workstation environment and update some configurations\n",
    "check_device_env(config)\n",
    "\n",
    "# collect some garbage\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# fix the seed for reproducibility (a negative seed value means not fixing)\n",
    "set_seed(config, rank=None)\n",
    "\n",
    "# compose dataset\n",
    "train_loader, val_loader, test_loader, multicrop_test_loader = compose_dataset(config)\n",
    "\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train\n",
    "train_script(\n",
    "    config,\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    multicrop_test_loader,\n",
    "    config[\"preprocess_train\"],\n",
    "    config[\"preprocess_test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
