{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Finetune Self-Supervision\n",
    "\n",
    "- Finetune the deep network after pretraining the self-supervised learning framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/imkbsz/workspace/eeg_analysis\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "import pprint\n",
    "import torch\n",
    "\n",
    "# custom package\n",
    "from run_train import check_device_env\n",
    "from run_train import set_seed\n",
    "from run_train import compose_dataset\n",
    "from train.train_script import train_script\n",
    "from models.utils import count_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Specify the dataset, model, and train setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_model_path = 'local/checkpoint/'\n",
    "pre_model_name = '6tv8k95u'\n",
    "finetune = 'whole'\n",
    "\n",
    "project = 'caueeg-ssl-finetune-abnormal'\n",
    "use_wandb = True\n",
    "device = 'cuda:0'\n",
    "\n",
    "crop_multiple = 8\n",
    "total_samples = 1.0e+6\n",
    "reset_minibatch = False\n",
    "search_lr = True   ##########\n",
    "base_lr = 1e-3  #########\n",
    "warmup_min = 300 # None\n",
    "lr_scheduler_type = 'cosine_decay_with_warmup_half'  # 'consine_decay_with_warmup_half', 'linear_decay_with_warmup'\n",
    "\n",
    "mixup = 0.0    ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.11.0\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Load and modify the pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EKG': 'O',\n",
      " '_ssl_target_': 'models.ssl.byol.BYOL',\n",
      " '_target_': 'models.resnet_2d.ResNet2D',\n",
      " 'activation': 'mish',\n",
      " 'age_mean': tensor([71.2670], device='cuda:0'),\n",
      " 'age_std': tensor([9.3919], device='cuda:0'),\n",
      " 'awgn': 0.05,\n",
      " 'awgn_age': 0.001,\n",
      " 'base_channels': 64,\n",
      " 'base_lr': 0.1,\n",
      " 'block': 'bottleneck',\n",
      " 'channel_dropout': 0.1,\n",
      " 'class_label_to_name': ['Normal', 'MCI', 'Dementia'],\n",
      " 'class_name_to_label': {'Dementia': 2, 'MCI': 1, 'Normal': 0},\n",
      " 'conv_layers': [3, 4, 6, 3],\n",
      " 'criterion': 'multi-bce',\n",
      " 'crop_multiple': 2,\n",
      " 'crop_timing_analysis': False,\n",
      " 'dataset_name': 'CAUEEG dataset',\n",
      " 'dataset_path': 'local/dataset/caueeg-dataset/',\n",
      " 'ddp': False,\n",
      " 'device': device(type='cuda', index=3),\n",
      " 'draw_result': True,\n",
      " 'dropout': 0.1,\n",
      " 'embedding_layer': 3,\n",
      " 'fc_stages': 3,\n",
      " 'file_format': 'memmap',\n",
      " 'in_channels': 40,\n",
      " 'input_norm': 'datapoint',\n",
      " 'iterations': 3125000,\n",
      " 'latency': 2000,\n",
      " 'load_event': False,\n",
      " 'lr_scheduler_type': 'cosine_decay_with_warmup_half',\n",
      " 'mgn': 0.05,\n",
      " 'minibatch': 32,\n",
      " 'minibatch_3090': 32,\n",
      " 'mixup': 0.0,\n",
      " 'mlp_hidden_size': 4096,\n",
      " 'model': '2D-ResNet-50',\n",
      " 'multi_batch_size': 4,\n",
      " 'num_history': 500,\n",
      " 'num_params': 26251139,\n",
      " 'out_dims': 3,\n",
      " 'output_length': 5,\n",
      " 'photic': 'X',\n",
      " 'preprocess_test': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda', index=3))\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2670], device='cuda:0'), std=tensor([9.3919], device='cuda:0'), eps=1e-08, std_eps=tensor([9.3919], device='cuda:0'))\n",
      "  (2): EegNormalizePerSignal(eps=1e-08)\n",
      "  (3): EegSpectrogram(n_fft=155, complex_mode='as_real', stft_kwargs={'hop_length': 39})\n",
      "  (4): EegNormalizePerSignal(eps=1e-08)\n",
      "),\n",
      " 'preprocess_train': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda', index=3))\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2670], device='cuda:0'), std=tensor([9.3919], device='cuda:0'), eps=1e-08, std_eps=tensor([9.3919], device='cuda:0'))\n",
      "  (2): EegAddGaussianNoiseAge(mean=0.0, std=0.001)\n",
      "  (3): EegNormalizePerSignal(eps=1e-08)\n",
      "  (4): EegChannelDropOut(p=0.1)\n",
      "  (5): EegMultiplicativeGaussianNoise(mean=0.0, std=0.05)\n",
      "  (6): EegAdditiveGaussianNoise(mean=0.0, std=0.05)\n",
      "  (7): EegSpectrogram(n_fft=155, complex_mode='as_real', stft_kwargs={'hop_length': 39})\n",
      "  (8): EegNormalizePerSignal(eps=1e-08)\n",
      "),\n",
      " 'project': 'caueeg-ssl',\n",
      " 'projection_size': 256,\n",
      " 'run_mode': 'train',\n",
      " 'save_model': True,\n",
      " 'search_lr': False,\n",
      " 'search_multiplier': 1.0,\n",
      " 'seed': 0,\n",
      " 'seq_len_2d': (78, 77),\n",
      " 'seq_length': 3000,\n",
      " 'signal_header': ['Fp1-AVG',\n",
      "                   'F3-AVG',\n",
      "                   'C3-AVG',\n",
      "                   'P3-AVG',\n",
      "                   'O1-AVG',\n",
      "                   'Fp2-AVG',\n",
      "                   'F4-AVG',\n",
      "                   'C4-AVG',\n",
      "                   'P4-AVG',\n",
      "                   'O2-AVG',\n",
      "                   'F7-AVG',\n",
      "                   'T3-AVG',\n",
      "                   'T5-AVG',\n",
      "                   'F8-AVG',\n",
      "                   'T4-AVG',\n",
      "                   'T6-AVG',\n",
      "                   'FZ-AVG',\n",
      "                   'CZ-AVG',\n",
      "                   'PZ-AVG',\n",
      "                   'EKG',\n",
      "                   'Photic'],\n",
      " 'signal_length_limit': 10000000,\n",
      " 'stft_params': {'hop_length': 39, 'n_fft': 155},\n",
      " 'target_ema': 0.99,\n",
      " 'task': 'dementia',\n",
      " 'task_description': 'Classification of [Normal], [MCI], and [Dementia] '\n",
      "                     'symptoms.',\n",
      " 'task_name': 'CAUEEG-Dementia benchmark',\n",
      " 'test_crop_multiple': 8,\n",
      " 'total_samples': 100000000.0,\n",
      " 'transform': Compose(\n",
      "    EegRandomCrop(crop_length=3000, length_limit=10000000, multiple=2, latency=2000, segment_simulation=False, return_timing=False, reject_events=False)\n",
      "    EegDropChannels(drop_index=[20])\n",
      "    EegToTensor()\n",
      "),\n",
      " 'transform_multicrop': Compose(\n",
      "    EegRandomCrop(crop_length=3000, length_limit=10000000, multiple=8, latency=2000, segment_simulation=False, return_timing=False, reject_events=False)\n",
      "    EegDropChannels(drop_index=[20])\n",
      "    EegToTensor()\n",
      "),\n",
      " 'use_age': 'fc',\n",
      " 'use_wandb': True,\n",
      " 'warmup_min': 3000,\n",
      " 'warmup_ratio': 0.05,\n",
      " 'warmup_steps': 156250,\n",
      " 'watch_model': False,\n",
      " 'weight_decay': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# load pretrained configurations\n",
    "path = os.path.join(pre_model_path, pre_model_name.split(',')[-1], 'checkpoint.pt')\n",
    "try:\n",
    "    ckpt = torch.load(path, map_location=device)\n",
    "    config = ckpt['config']\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f'- checkpoint cannot be opened: {path}')\n",
    "\n",
    "# initiate the model\n",
    "model = hydra.utils.instantiate(config).to(device)\n",
    "    \n",
    "# initiate SSL model and load model state\n",
    "ssl_config = deepcopy(config)\n",
    "ssl_config['_target_'] = ssl_config['_ssl_target_']\n",
    "ssl_model = hydra.utils.instantiate(ssl_config, model).to(device)\n",
    "\n",
    "if ckpt[\"config\"][\"ddp\"] == ssl_config[\"ddp\"]:\n",
    "    ssl_model.load_state_dict(ckpt[\"ssl_model_state\"])\n",
    "elif ckpt[\"config\"][\"ddp\"]:\n",
    "    ssl_model_state_ddp = deepcopy(ckpt[\"ssl_model_state\"])\n",
    "    ssl_model_state = OrderedDict()\n",
    "    for k, v in ssl_model_state_ddp.items():\n",
    "        name = k[7:]  # remove 'module.' of DataParallel/DistributedDataParallel\n",
    "        ssl_model_state[name] = v\n",
    "    ssl_model.load_state_dict(ssl_model_state)\n",
    "else:\n",
    "    ssl_model.module.load_state_dict(ckpt[\"ssl_model_state\"])    \n",
    "\n",
    "model_state = deepcopy(ssl_model.backbone.state_dict())\n",
    "del ssl_config, ssl_model\n",
    "\n",
    "# load\n",
    "model.load_state_dict(model_state)\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modify configuration\n",
    "config['project'] = project\n",
    "config['use_wandb'] = use_wandb\n",
    "config['pre_model'] = pre_model_name\n",
    "config['finetune'] = finetune\n",
    "config['device'] = device\n",
    "config['task'] = 'abnormal'\n",
    "config['out_dims'] = 2\n",
    "\n",
    "config['crop_multiple'] = crop_multiple\n",
    "config['total_samples'] = total_samples\n",
    "if reset_minibatch: \n",
    "    config.pop('minibatch')\n",
    "config['search_lr'] = search_lr\n",
    "config['base_lr'] = base_lr\n",
    "config['lr_scheduler_type'] = lr_scheduler_type\n",
    "\n",
    "config[\"output_length\"] = model.get_output_length()\n",
    "config[\"num_params\"] = count_parameters(model)\n",
    "if warmup_min:\n",
    "    config[\"warmup_min\"] = warmup_min\n",
    "\n",
    "config['mixup'] = mixup\n",
    "    \n",
    "# remove unused keywords\n",
    "config.pop('_ssl_target_', None)\n",
    "config.pop('embedding_layer', None)\n",
    "config.pop('mlp_hidden_size', None)\n",
    "config.pop('projection_size', None)\n",
    "config.pop('warmup_steps', None)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = hydra.utils.instantiate(config).to(device)\n",
    "model.fc_stage = deepcopy(model2.fc_stage)\n",
    "del model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define finetuning range   \n",
    "if finetune == 'fc_stage':\n",
    "    model.requires_grad_(False)\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'fc_stage' in name:\n",
    "            param.requires_grad_(True)\n",
    "        elif 'heads' in name:\n",
    "            param.requires_grad_(True)\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{str(param.requires_grad):^15}\\t{name}\")\n",
    "elif finetune == 'whole':\n",
    "    model.requires_grad_(True)\n",
    "elif finetune == 'reset':\n",
    "    model = model = hydra.utils.instantiate(config).to(device)\n",
    "    model.requires_grad_(True)\n",
    "else:\n",
    "    raise NotImplementedError('Not implemented!')\n",
    "    \n",
    "# TODO: Need to think about the DropOut and Batch/LayerNorms statistics\n",
    "# eval/train mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EKG': 'O',\n",
      " '_target_': 'models.resnet_2d.ResNet2D',\n",
      " 'activation': 'mish',\n",
      " 'age_mean': tensor([71.2670], device='cuda:0'),\n",
      " 'age_std': tensor([9.3919], device='cuda:0'),\n",
      " 'awgn': 0.05,\n",
      " 'awgn_age': 0.001,\n",
      " 'base_channels': 64,\n",
      " 'base_lr': 0.001,\n",
      " 'block': 'bottleneck',\n",
      " 'channel_dropout': 0.1,\n",
      " 'class_label_to_name': ['Normal', 'Abnormal'],\n",
      " 'class_name_to_label': {'Abnormal': 1, 'Normal': 0},\n",
      " 'conv_layers': [3, 4, 6, 3],\n",
      " 'criterion': 'multi-bce',\n",
      " 'crop_multiple': 8,\n",
      " 'crop_timing_analysis': False,\n",
      " 'dataset_name': 'CAUEEG dataset',\n",
      " 'dataset_path': 'local/dataset/caueeg-dataset/',\n",
      " 'ddp': False,\n",
      " 'device': device(type='cuda', index=0),\n",
      " 'draw_result': True,\n",
      " 'dropout': 0.1,\n",
      " 'fc_stages': 3,\n",
      " 'file_format': 'memmap',\n",
      " 'finetune': 'whole',\n",
      " 'in_channels': 40,\n",
      " 'input_norm': 'datapoint',\n",
      " 'iterations': 3125000,\n",
      " 'latency': 2000,\n",
      " 'load_event': False,\n",
      " 'lr_scheduler_type': 'cosine_decay_with_warmup_half',\n",
      " 'mgn': 0.05,\n",
      " 'minibatch': 32,\n",
      " 'minibatch_3090': 32,\n",
      " 'mixup': 0.0,\n",
      " 'model': '2D-ResNet-50',\n",
      " 'multi_batch_size': 4,\n",
      " 'num_history': 500,\n",
      " 'num_params': 26251139,\n",
      " 'out_dims': 2,\n",
      " 'output_length': 5,\n",
      " 'photic': 'X',\n",
      " 'pre_model': '6tv8k95u',\n",
      " 'preprocess_test': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda', index=0))\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2670], device='cuda:0'), std=tensor([9.3919], device='cuda:0'), eps=1e-08, std_eps=tensor([9.3919], device='cuda:0'))\n",
      "  (2): EegNormalizePerSignal(eps=1e-08)\n",
      "  (3): EegSpectrogram(n_fft=155, complex_mode='as_real', stft_kwargs={'hop_length': 39})\n",
      "  (4): EegNormalizePerSignal(eps=1e-08)\n",
      "),\n",
      " 'preprocess_train': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda', index=0))\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2670], device='cuda:0'), std=tensor([9.3919], device='cuda:0'), eps=1e-08, std_eps=tensor([9.3919], device='cuda:0'))\n",
      "  (2): EegAddGaussianNoiseAge(mean=0.0, std=0.001)\n",
      "  (3): EegNormalizePerSignal(eps=1e-08)\n",
      "  (4): EegChannelDropOut(p=0.1)\n",
      "  (5): EegMultiplicativeGaussianNoise(mean=0.0, std=0.05)\n",
      "  (6): EegAdditiveGaussianNoise(mean=0.0, std=0.05)\n",
      "  (7): EegSpectrogram(n_fft=155, complex_mode='as_real', stft_kwargs={'hop_length': 39})\n",
      "  (8): EegNormalizePerSignal(eps=1e-08)\n",
      "),\n",
      " 'project': 'caueeg-ssl-finetune-abnormal',\n",
      " 'run_mode': 'train',\n",
      " 'save_model': True,\n",
      " 'search_lr': True,\n",
      " 'search_multiplier': 1.0,\n",
      " 'seed': 0,\n",
      " 'seq_len_2d': (78, 77),\n",
      " 'seq_length': 3000,\n",
      " 'signal_header': ['Fp1-AVG',\n",
      "                   'F3-AVG',\n",
      "                   'C3-AVG',\n",
      "                   'P3-AVG',\n",
      "                   'O1-AVG',\n",
      "                   'Fp2-AVG',\n",
      "                   'F4-AVG',\n",
      "                   'C4-AVG',\n",
      "                   'P4-AVG',\n",
      "                   'O2-AVG',\n",
      "                   'F7-AVG',\n",
      "                   'T3-AVG',\n",
      "                   'T5-AVG',\n",
      "                   'F8-AVG',\n",
      "                   'T4-AVG',\n",
      "                   'T6-AVG',\n",
      "                   'FZ-AVG',\n",
      "                   'CZ-AVG',\n",
      "                   'PZ-AVG',\n",
      "                   'EKG',\n",
      "                   'Photic'],\n",
      " 'signal_length_limit': 10000000,\n",
      " 'stft_params': {'hop_length': 39, 'n_fft': 155},\n",
      " 'target_ema': 0.99,\n",
      " 'task': 'abnormal',\n",
      " 'task_description': 'Classification of [Normal] and [Abnormal] symptoms',\n",
      " 'task_name': 'CAUEEG-Abnormal benchmark',\n",
      " 'test_crop_multiple': 8,\n",
      " 'total_samples': 1000000.0,\n",
      " 'transform': Compose(\n",
      "    EegRandomCrop(crop_length=3000, length_limit=10000000, multiple=8, latency=2000, segment_simulation=False, return_timing=False, reject_events=False)\n",
      "    EegDropChannels(drop_index=[20])\n",
      "    EegToTensor()\n",
      "),\n",
      " 'transform_multicrop': Compose(\n",
      "    EegRandomCrop(crop_length=3000, length_limit=10000000, multiple=8, latency=2000, segment_simulation=False, return_timing=False, reject_events=False)\n",
      "    EegDropChannels(drop_index=[20])\n",
      "    EegToTensor()\n",
      "),\n",
      " 'use_age': 'fc',\n",
      " 'use_wandb': True,\n",
      " 'warmup_min': 300,\n",
      " 'warmup_ratio': 0.05,\n",
      " 'watch_model': False,\n",
      " 'weight_decay': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# check the workstation environment and update some configurations\n",
    "check_device_env(config)\n",
    "\n",
    "# collect some garbage\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# fix the seed for reproducibility (a negative seed value means not fixing)\n",
    "set_seed(config, rank=None)\n",
    "\n",
    "# compose dataset\n",
    "train_loader, val_loader, test_loader, multicrop_test_loader = compose_dataset(config)\n",
    "\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************    Configurations for Train    ******************************\n",
      "\n",
      "{'EKG': 'O',\n",
      " '_target_': 'models.resnet_2d.ResNet2D',\n",
      " 'activation': 'mish',\n",
      " 'age_mean': tensor([71.2670], device='cuda:0'),\n",
      " 'age_std': tensor([9.3919], device='cuda:0'),\n",
      " 'awgn': 0.05,\n",
      " 'awgn_age': 0.001,\n",
      " 'base_channels': 64,\n",
      " 'base_lr': 0.001,\n",
      " 'block': 'bottleneck',\n",
      " 'channel_dropout': 0.1,\n",
      " 'class_label_to_name': ['Normal', 'Abnormal'],\n",
      " 'class_name_to_label': {'Abnormal': 1, 'Normal': 0},\n",
      " 'conv_layers': [3, 4, 6, 3],\n",
      " 'criterion': 'multi-bce',\n",
      " 'crop_multiple': 8,\n",
      " 'crop_timing_analysis': False,\n",
      " 'dataset_name': 'CAUEEG dataset',\n",
      " 'dataset_path': 'local/dataset/caueeg-dataset/',\n",
      " 'ddp': False,\n",
      " 'device': device(type='cuda', index=0),\n",
      " 'draw_result': True,\n",
      " 'dropout': 0.1,\n",
      " 'fc_stages': 3,\n",
      " 'file_format': 'memmap',\n",
      " 'finetune': 'whole',\n",
      " 'in_channels': 40,\n",
      " 'input_norm': 'datapoint',\n",
      " 'iterations': 3125000,\n",
      " 'latency': 2000,\n",
      " 'load_event': False,\n",
      " 'lr_scheduler_type': 'cosine_decay_with_warmup_half',\n",
      " 'mgn': 0.05,\n",
      " 'minibatch': 32,\n",
      " 'minibatch_3090': 32,\n",
      " 'mixup': 0.0,\n",
      " 'model': '2D-ResNet-50',\n",
      " 'multi_batch_size': 4,\n",
      " 'num_history': 500,\n",
      " 'num_params': 26251139,\n",
      " 'out_dims': 2,\n",
      " 'output_length': 5,\n",
      " 'photic': 'X',\n",
      " 'pre_model': '6tv8k95u',\n",
      " 'preprocess_test': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda', index=0))\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2670], device='cuda:0'), std=tensor([9.3919], device='cuda:0'), eps=1e-08, std_eps=tensor([9.3919], device='cuda:0'))\n",
      "  (2): EegNormalizePerSignal(eps=1e-08)\n",
      "  (3): EegSpectrogram(n_fft=155, complex_mode='as_real', stft_kwargs={'hop_length': 39})\n",
      "  (4): EegNormalizePerSignal(eps=1e-08)\n",
      "),\n",
      " 'preprocess_train': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda', index=0))\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2670], device='cuda:0'), std=tensor([9.3919], device='cuda:0'), eps=1e-08, std_eps=tensor([9.3919], device='cuda:0'))\n",
      "  (2): EegAddGaussianNoiseAge(mean=0.0, std=0.001)\n",
      "  (3): EegNormalizePerSignal(eps=1e-08)\n",
      "  (4): EegChannelDropOut(p=0.1)\n",
      "  (5): EegMultiplicativeGaussianNoise(mean=0.0, std=0.05)\n",
      "  (6): EegAdditiveGaussianNoise(mean=0.0, std=0.05)\n",
      "  (7): EegSpectrogram(n_fft=155, complex_mode='as_real', stft_kwargs={'hop_length': 39})\n",
      "  (8): EegNormalizePerSignal(eps=1e-08)\n",
      "),\n",
      " 'project': 'caueeg-ssl-finetune-abnormal',\n",
      " 'run_mode': 'train',\n",
      " 'save_model': True,\n",
      " 'search_lr': True,\n",
      " 'search_multiplier': 1.0,\n",
      " 'seed': 0,\n",
      " 'seq_len_2d': (78, 77),\n",
      " 'seq_length': 3000,\n",
      " 'signal_header': ['Fp1-AVG',\n",
      "                   'F3-AVG',\n",
      "                   'C3-AVG',\n",
      "                   'P3-AVG',\n",
      "                   'O1-AVG',\n",
      "                   'Fp2-AVG',\n",
      "                   'F4-AVG',\n",
      "                   'C4-AVG',\n",
      "                   'P4-AVG',\n",
      "                   'O2-AVG',\n",
      "                   'F7-AVG',\n",
      "                   'T3-AVG',\n",
      "                   'T5-AVG',\n",
      "                   'F8-AVG',\n",
      "                   'T4-AVG',\n",
      "                   'T6-AVG',\n",
      "                   'FZ-AVG',\n",
      "                   'CZ-AVG',\n",
      "                   'PZ-AVG',\n",
      "                   'EKG',\n",
      "                   'Photic'],\n",
      " 'signal_length_limit': 10000000,\n",
      " 'stft_params': {'hop_length': 39, 'n_fft': 155},\n",
      " 'target_ema': 0.99,\n",
      " 'task': 'abnormal',\n",
      " 'task_description': 'Classification of [Normal] and [Abnormal] symptoms',\n",
      " 'task_name': 'CAUEEG-Abnormal benchmark',\n",
      " 'test_crop_multiple': 8,\n",
      " 'total_samples': 1000000.0,\n",
      " 'transform': Compose(\n",
      "    EegRandomCrop(crop_length=3000, length_limit=10000000, multiple=8, latency=2000, segment_simulation=False, return_timing=False, reject_events=False)\n",
      "    EegDropChannels(drop_index=[20])\n",
      "    EegToTensor()\n",
      "),\n",
      " 'transform_multicrop': Compose(\n",
      "    EegRandomCrop(crop_length=3000, length_limit=10000000, multiple=8, latency=2000, segment_simulation=False, return_timing=False, reject_events=False)\n",
      "    EegDropChannels(drop_index=[20])\n",
      "    EegToTensor()\n",
      "),\n",
      " 'use_age': 'fc',\n",
      " 'use_wandb': True,\n",
      " 'warmup_min': 300,\n",
      " 'warmup_ratio': 0.05,\n",
      " 'watch_model': False,\n",
      " 'weight_decay': 0.01}\n",
      "\n",
      "********************************************************************************************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mipis-mjkim\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/imkbsz/workspace/eeg_analysis/wandb/run-20230527_123808-q8jgoigd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ipis-mjkim/caueeg-ssl-finetune-abnormal/runs/q8jgoigd' target=\"_blank\">dry-vortex-2</a></strong> to <a href='https://wandb.ai/ipis-mjkim/caueeg-ssl-finetune-abnormal' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ipis-mjkim/caueeg-ssl-finetune-abnormal' target=\"_blank\">https://wandb.ai/ipis-mjkim/caueeg-ssl-finetune-abnormal</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ipis-mjkim/caueeg-ssl-finetune-abnormal/runs/q8jgoigd' target=\"_blank\">https://wandb.ai/ipis-mjkim/caueeg-ssl-finetune-abnormal/runs/q8jgoigd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imkbsz/anaconda3/envs/eeg/lib/python3.9/site-packages/wandb/sdk/wandb_run.py:2914: ResourceWarning:\n",
      "\n",
      "unclosed <ssl.SSLSocket fd=90, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('165.194.87.113', 42292), raddr=('35.186.228.49', 443)>\n",
      "\n",
      "/home/imkbsz/anaconda3/envs/eeg/lib/python3.9/site-packages/wandb/sdk/lib/ipython.py:70: DeprecationWarning:\n",
      "\n",
      "Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Learning Rate</td><td>▂▅███████▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Loss</td><td>█▇▆▇▆▅▄▅▅▅▆▃▂▄▅▅▄▄▃▂▅▄▁▂▂▄▃▃▁▂▄▄▃▄▃▃▅▄▃▁</td></tr><tr><td>Multi-Crop Test Accuracy</td><td>▁</td></tr><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Train Accuracy</td><td>▁▂▃▂▂▃▄▄▅▄▄▅▅▅▄▃▅▄▅▆▄▅█▇█▆▆▅▇▆▇▅▇▆▆▇▅▅▆▆</td></tr><tr><td>Validation Accuracy</td><td>▆▆▇▆▁▇▆█▇▆▆▆▆▆▆▆▆█▇▆▆▇▆▆▆█▇▇▇▇▆▇▇▇▆▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Learning Rate</td><td>0.0</td></tr><tr><td>Loss</td><td>0.47073</td></tr><tr><td>Multi-Crop Test Accuracy</td><td>72.13235</td></tr><tr><td>Test Accuracy</td><td>72.8125</td></tr><tr><td>Train Accuracy</td><td>82.00605</td></tr><tr><td>Validation Accuracy</td><td>68.81127</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dry-vortex-2</strong> at: <a href='https://wandb.ai/ipis-mjkim/caueeg-ssl-finetune-abnormal/runs/q8jgoigd' target=\"_blank\">https://wandb.ai/ipis-mjkim/caueeg-ssl-finetune-abnormal/runs/q8jgoigd</a><br/>Synced 7 W&B file(s), 3 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230527_123808-q8jgoigd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train\n",
    "train_script(\n",
    "    config,\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    multicrop_test_loader,\n",
    "    config[\"preprocess_train\"],\n",
    "    config[\"preprocess_test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
