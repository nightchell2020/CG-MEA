{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Finetune Self-Supervision\n",
    "\n",
    "- Finetune the deep network after pretraining the self-supervised learning framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/imkbsz/workspace/eeg_analysis\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'EegRandomChannelDropOut' from 'datasets.pipeline' (/home/imkbsz/workspace/eeg_analysis/datasets/pipeline.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# custom package\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrun_train\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_device_env\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrun_train\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m set_seed\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrun_train\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compose_dataset\n",
      "File \u001b[0;32m~/workspace/eeg_analysis/run_train.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultiprocessing\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain_script\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_script\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcaueeg_script\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_dataset_for_train\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtemple_eeg_script\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_dataset_for_tuab_train\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m count_parameters\n",
      "File \u001b[0;32m~/workspace/eeg_analysis/datasets/caueeg_script.py:17\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EegAdditiveGaussianNoise, EegMultiplicativeGaussianNoise\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EegAddGaussianNoiseAge\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EegRandomChannelDropOut\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EegToTensor, EegToDevice\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EegSpectrogram\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'EegRandomChannelDropOut' from 'datasets.pipeline' (/home/imkbsz/workspace/eeg_analysis/datasets/pipeline.py)"
     ]
    }
   ],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "import pprint\n",
    "import torch\n",
    "\n",
    "# custom package\n",
    "from run_train import check_device_env\n",
    "from run_train import set_seed\n",
    "from run_train import compose_dataset\n",
    "from train.train_script import train_script\n",
    "from models.utils import count_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Specify the dataset, model, and train setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_model_path = 'local/checkpoint/'\n",
    "pre_model_name = '6tv8k95u'\n",
    "finetune = 'whole'\n",
    "\n",
    "project = 'caueeg-ssl-finetune-abnormal'\n",
    "use_wandb = True\n",
    "device = 'cuda:0'\n",
    "\n",
    "crop_multiple = 8\n",
    "total_samples = 1.0e+6\n",
    "reset_minibatch = False\n",
    "search_lr = True   ##########\n",
    "base_lr = 1e-3  #########\n",
    "warmup_min = 300 # None\n",
    "lr_scheduler_type = 'cosine_decay_with_warmup_half'  # 'consine_decay_with_warmup_half', 'linear_decay_with_warmup'\n",
    "\n",
    "mixup = 0.0    ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Load and modify the pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load pretrained configurations\n",
    "path = os.path.join(pre_model_path, pre_model_name.split(',')[-1], 'checkpoint.pt')\n",
    "try:\n",
    "    ckpt = torch.load(path, map_location=device)\n",
    "    config = ckpt['config']\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f'- checkpoint cannot be opened: {path}')\n",
    "\n",
    "# initiate the model\n",
    "model = hydra.utils.instantiate(config).to(device)\n",
    "    \n",
    "# initiate SSL model and load model state\n",
    "ssl_config = deepcopy(config)\n",
    "ssl_config['_target_'] = ssl_config['_ssl_target_']\n",
    "ssl_model = hydra.utils.instantiate(ssl_config, model).to(device)\n",
    "\n",
    "if ckpt[\"config\"][\"ddp\"] == ssl_config[\"ddp\"]:\n",
    "    ssl_model.load_state_dict(ckpt[\"ssl_model_state\"])\n",
    "elif ckpt[\"config\"][\"ddp\"]:\n",
    "    ssl_model_state_ddp = deepcopy(ckpt[\"ssl_model_state\"])\n",
    "    ssl_model_state = OrderedDict()\n",
    "    for k, v in ssl_model_state_ddp.items():\n",
    "        name = k[7:]  # remove 'module.' of DataParallel/DistributedDataParallel\n",
    "        ssl_model_state[name] = v\n",
    "    ssl_model.load_state_dict(ssl_model_state)\n",
    "else:\n",
    "    \n",
    "    ssl_model.module.load_state_dict(ckpt[\"ssl_model_state\"])    \n",
    "\n",
    "model_state = deepcopy(ssl_model.backbone.state_dict())\n",
    "del ssl_config, ssl_model\n",
    "\n",
    "# load\n",
    "model.load_state_dict(model_state)\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define finetuning range   \n",
    "if finetune == 'fc_stage':\n",
    "    model.requires_grad_(False)\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'fc_stage' in name:\n",
    "            param.requires_grad_(True)\n",
    "        elif 'heads' in name:\n",
    "            param.requires_grad_(True)\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{str(param.requires_grad):^15}\\t{name}\")\n",
    "elif finetune == 'whole':\n",
    "    model.requires_grad_(True)\n",
    "elif finetune == 'reset':\n",
    "    model = model = hydra.utils.instantiate(config).to(device)\n",
    "    model.requires_grad_(True)\n",
    "else:\n",
    "    raise NotImplementedError('Not implemented!')\n",
    "    \n",
    "# TODO: Need to think about the DropOut and Batch/LayerNorms statistics\n",
    "# eval/train mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'project' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# modify configuration\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mproject\u001b[49m\n\u001b[1;32m      3\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_wandb\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m use_wandb\n\u001b[1;32m      4\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre_model\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pre_model_name\n",
      "\u001b[0;31mNameError\u001b[0m: name 'project' is not defined"
     ]
    }
   ],
   "source": [
    "# modify configuration\n",
    "config['project'] = project\n",
    "config['use_wandb'] = use_wandb\n",
    "config['pre_model'] = pre_model_name\n",
    "config['finetune'] = finetune\n",
    "config['device'] = device\n",
    "config['task'] = 'abnormal'\n",
    "\n",
    "config['crop_multiple'] = crop_multiple\n",
    "config['total_samples'] = total_samples\n",
    "if reset_minibatch: \n",
    "    config.pop('minibatch')\n",
    "config['search_lr'] = search_lr\n",
    "config['base_lr'] = base_lr\n",
    "config['lr_scheduler_type'] = lr_scheduler_type\n",
    "\n",
    "config[\"output_length\"] = model.get_output_length()\n",
    "config[\"num_params\"] = count_parameters(model)\n",
    "if warmup_min:\n",
    "    config[\"warmup_min\"] = warmup_min\n",
    "\n",
    "config['mixup'] = mixup\n",
    "    \n",
    "# remove unused keywords\n",
    "config.pop('_ssl_target_', None)\n",
    "config.pop('embedding_layer', None)\n",
    "config.pop('mlp_hidden_size', None)\n",
    "config.pop('projection_size', None)\n",
    "config.pop('warmup_steps', None)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the workstation environment and update some configurations\n",
    "check_device_env(config)\n",
    "\n",
    "# collect some garbage\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# fix the seed for reproducibility (a negative seed value means not fixing)\n",
    "set_seed(config, rank=None)\n",
    "\n",
    "# compose dataset\n",
    "train_loader, val_loader, test_loader, multicrop_test_loader = compose_dataset(config)\n",
    "\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train\n",
    "train_script(\n",
    "    config,\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    multicrop_test_loader,\n",
    "    config[\"preprocess_train\"],\n",
    "    config[\"preprocess_test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
