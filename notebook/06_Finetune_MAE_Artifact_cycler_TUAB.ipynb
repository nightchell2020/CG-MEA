{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Finetune Masked-AutoEncoder\n",
    "\n",
    "- Finetune the deep network after pretraining the self-supervised learning framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\GitHub\\eeg_analysis\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "import pprint\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from collections import OrderedDict\n",
    "from cycler import cycler\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "\n",
    "# custom package\n",
    "from run_train import check_device_env\n",
    "from run_train import set_seed\n",
    "from run_train import compose_dataset\n",
    "from run_train import generate_model\n",
    "from train.ssl_train_script import ssl_train_script\n",
    "from train.train_script import train_script\n",
    "from models.utils import count_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Specify the dataset, model, and train setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_model_path = 'local/checkpoint/'\n",
    "pre_model_name = 'g6ww1utl'\n",
    "device = 'cuda:0'\n",
    "\n",
    "############\n",
    "# Artifact #\n",
    "############\n",
    "art_config = dict()\n",
    "art_config['project'] = 'tuab-mae-artifact'\n",
    "art_config['use_wandb'] = False\n",
    "art_config['pre_model'] = pre_model_name\n",
    "art_config['device'] = device\n",
    "\n",
    "# art_config[\"art_filter_list\"] = [9, 9, 9, 9, 9]\n",
    "art_config[\"art_dropout\"] = 0.1\n",
    "art_config[\"art_use_age\"] = \"no\"  # \"conv\", \"embedding\", \"no\"\n",
    "\n",
    "art_config['total_samples'] = 5.0e+5\n",
    "art_config['search_lr'] = False\n",
    "art_config['base_lr'] = 1e-3\n",
    "art_config['lr_scheduler_type'] = 'cosine_decay_with_warmup_half'\n",
    "\n",
    "art_config[\"warmup_min\"] = 150\n",
    "art_config[\"num_history\"] = 50\n",
    "art_config['save_model'] = False\n",
    "\n",
    "##################\n",
    "# Classification #\n",
    "##################\n",
    "finetune_config = dict()\n",
    "finetune_config['project'] = 'tuab-mae-artifact-finetune'\n",
    "finetune_config['use_wandb'] = True\n",
    "finetune_config['pre_model'] = pre_model_name\n",
    "finetune_config['device'] = device\n",
    "finetune_config[\"task\"] = \"dementia\"\n",
    "finetune_config[\"out_dims\"] = 3\n",
    "\n",
    "# finetune_config[\"mask_ratio\"] = 0.25\n",
    "finetune_config[\"descending\"] = False  #######################################################\n",
    "finetune_config[\"global_pool\"] = True\n",
    "finetune_config[\"fc_stages\"] = 3\n",
    "finetune_config[\"dropout\"] = 0.1\n",
    "# finetune_config[\"use_age\"] = \"fc\"\n",
    "# finetune_config[\"mixup\"] = 0.3 ###\n",
    "# finetune_config[\"crop_length\"] = 8192*4  #############################################################\n",
    "# finetune_config[\"criterion\"] = \"multi-bce\"  # \"cross-entropy\", \"multi-bce\"\n",
    "\n",
    "finetune_config[\"tuning_type\"] = \"finetune\"  # \"finetune\", \"fc_stage\"\n",
    "finetune_config[\"layer_wise_lr\"] = True\n",
    "\n",
    "finetune_config['total_samples'] = 2.0e+7\n",
    "finetune_config['base_lr'] = 1e-3\n",
    "finetune_config['search_lr'] = False\n",
    "finetune_config['lr_scheduler_type'] = 'cosine_decay_with_warmup_half'\n",
    "finetune_config[\"warmup_min\"] = 200\n",
    "finetune_config[\"num_history\"] = 50\n",
    "finetune_config['save_model'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mask_ratio': 0.3, 'crop_length': 5120, 'minibatch': 256, 'descending': True, 'mixup': 0.0}\n",
      "{'mask_ratio': 0.3, 'crop_length': 5120, 'minibatch': 256, 'descending': True, 'mixup': 0.3}\n",
      "{'mask_ratio': 0.3, 'crop_length': 10240, 'minibatch': 192, 'descending': False, 'mixup': 0.0}\n",
      "{'mask_ratio': 0.3, 'crop_length': 10240, 'minibatch': 192, 'descending': False, 'mixup': 0.3}\n",
      "{'mask_ratio': 0.5, 'crop_length': 5120, 'minibatch': 256, 'descending': True, 'mixup': 0.0}\n",
      "{'mask_ratio': 0.5, 'crop_length': 5120, 'minibatch': 256, 'descending': True, 'mixup': 0.3}\n",
      "{'mask_ratio': 0.5, 'crop_length': 10240, 'minibatch': 192, 'descending': False, 'mixup': 0.0}\n",
      "{'mask_ratio': 0.5, 'crop_length': 10240, 'minibatch': 192, 'descending': False, 'mixup': 0.3}\n"
     ]
    }
   ],
   "source": [
    "finetune_cycler = cycler(mask_ratio=[0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "finetune_cycler *= cycler(crop_length=[5120, 5120*2]) + cycler(minibatch=[256, 192])\n",
    "# finetune_cycler *= cycler(mixup=[0.0, 0.3])\n",
    "finetune_cycler *= cycler(descending=[False, True])\n",
    "for cyc in finetune_cycler:\n",
    "    print(cyc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.0+cu117\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Uncertainty Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EKG': 'O',\n",
      " '_target_': 'models.ssl.mae.mae_pre_b_e768_d512',\n",
      " 'activation': 'gelu',\n",
      " 'age_mean': tensor([0.], device='cuda:0'),\n",
      " 'age_std': tensor([0.], device='cuda:0'),\n",
      " 'awgn': 0.001,\n",
      " 'awgn_age': 0,\n",
      " 'base_lr': 0.0005,\n",
      " 'class_label_to_name': ['Normal', 'Abnormal'],\n",
      " 'class_name_to_label': {'Abnormal': 1, 'Normal': 0},\n",
      " 'criterion': 'cross-entropy',\n",
      " 'crop_length': 5120,\n",
      " 'crop_multiple': 4,\n",
      " 'crop_timing_analysis': False,\n",
      " 'cwd': '',\n",
      " 'dataset_name': 'tuab',\n",
      " 'dataset_path': 'local/dataset/tuab/',\n",
      " 'ddp': False,\n",
      " 'device': device(type='cuda'),\n",
      " 'draw_result': True,\n",
      " 'file_format': 'memmap',\n",
      " 'in_channels': 24,\n",
      " 'input_norm': 'datapoint',\n",
      " 'iterations': 781250,\n",
      " 'latency': 2500,\n",
      " 'lr_scheduler_type': 'cosine_decay_with_warmup_half',\n",
      " 'mask_ratio': 0.5,\n",
      " 'mgn': 0.001,\n",
      " 'minibatch': 256,\n",
      " 'minibatch_3090': 256,\n",
      " 'mixed_precision': True,\n",
      " 'mixup': 0.0,\n",
      " 'multi_batch_size': 32,\n",
      " 'norm_pix_loss': True,\n",
      " 'num_history': 500,\n",
      " 'num_params': 125248512,\n",
      " 'out_dims': 2,\n",
      " 'output_length': 41,\n",
      " 'patch_size': 64,\n",
      " 'preprocess_test': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda'))\n",
      "  (1): EegResample(orig_freq=250, new_freq=125, resampling_method='sinc_interp_hann')\n",
      "  (2): EegNormalizeAge(mean=tensor([0.], device='cuda:0'), std=tensor([0.], device='cuda:0'), eps=1e-08, std_eps=tensor([1.0000e-08], device='cuda:0'))\n",
      "  (3): EegNormalizePerSignal(eps=1e-08)\n",
      "),\n",
      " 'preprocess_train': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda'))\n",
      "  (1): EegResample(orig_freq=250, new_freq=125, resampling_method='sinc_interp_hann')\n",
      "  (2): EegNormalizeAge(mean=tensor([0.], device='cuda:0'), std=tensor([0.], device='cuda:0'), eps=1e-08, std_eps=tensor([1.0000e-08], device='cuda:0'))\n",
      "  (3): EegNormalizePerSignal(eps=1e-08)\n",
      "  (4): EegMultiplicativeGaussianNoise(mean=0.0, std=0.001)\n",
      "  (5): EegAdditiveGaussianNoise(mean=0.0, std=0.001)\n",
      "),\n",
      " 'project': 'tuab-mae',\n",
      " 'resample': 125,\n",
      " 'run_mode': 'train',\n",
      " 'sampling_rate': 250,\n",
      " 'save_model': True,\n",
      " 'search_lr': False,\n",
      " 'search_multiplier': 1.0,\n",
      " 'seed': 0,\n",
      " 'seq_length': 2560,\n",
      " 'signal_header': ['EEG FP1-REF',\n",
      "                   'EEG FP2-REF',\n",
      "                   'EEG F3-REF',\n",
      "                   'EEG F4-REF',\n",
      "                   'EEG C3-REF',\n",
      "                   'EEG C4-REF',\n",
      "                   'EEG P3-REF',\n",
      "                   'EEG P4-REF',\n",
      "                   'EEG O1-REF',\n",
      "                   'EEG O2-REF',\n",
      "                   'EEG F7-REF',\n",
      "                   'EEG F8-REF',\n",
      "                   'EEG T3-REF',\n",
      "                   'EEG T4-REF',\n",
      "                   'EEG T5-REF',\n",
      "                   'EEG T6-REF',\n",
      "                   'EEG A1-REF',\n",
      "                   'EEG A2-REF',\n",
      "                   'EEG FZ-REF',\n",
      "                   'EEG CZ-REF',\n",
      "                   'EEG PZ-REF',\n",
      "                   'EEG T1-REF',\n",
      "                   'EEG T2-REF',\n",
      "                   'EEG EKG1-REF'],\n",
      " 'signal_length_limit': 10000000,\n",
      " 'task_description': 'Pathological classification of [Normal] and [Abnormal] '\n",
      "                     'EEG',\n",
      " 'task_name': 'Temple University Hospital Abnormal Corpus v2.0.0',\n",
      " 'test_crop_multiple': 8,\n",
      " 'total_samples': 200000000.0,\n",
      " 'transform': Compose(\n",
      "    EegRandomCrop(crop_length=5120, length_limit=10000000, multiple=4, latency=2500, segment_simulation=False, return_timing=False, reject_events=False)\n",
      "    EegToTensor()\n",
      "),\n",
      " 'transform_multicrop': Compose(\n",
      "    EegRandomCrop(crop_length=5120, length_limit=10000000, multiple=8, latency=2500, segment_simulation=False, return_timing=False, reject_events=False)\n",
      "    EegToTensor()\n",
      "),\n",
      " 'use_age': 'no',\n",
      " 'use_wandb': True,\n",
      " 'val_fraction': 15,\n",
      " 'warmup_min': 3000,\n",
      " 'warmup_ratio': 0.05,\n",
      " 'warmup_steps': 39062,\n",
      " 'watch_model': False,\n",
      " 'weight_decay': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# load pretrained configurations\n",
    "path = os.path.join(pre_model_path, pre_model_name.split(',')[-1], 'checkpoint.pt')\n",
    "try:\n",
    "    ckpt = torch.load(path, map_location=device)\n",
    "    config = ckpt['config']\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f'- checkpoint cannot be opened: {path}')\n",
    "config[\"cwd\"] = \"\"\n",
    "\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update configuration\n",
    "for k, v in art_config.items():\n",
    "    config[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EKG': 'O',\n",
      " '_target_': 'models.ssl.mae.mae_pre_b_e768_d512',\n",
      " 'activation': 'gelu',\n",
      " 'age_mean': tensor([0.], device='cuda:0'),\n",
      " 'age_std': tensor([0.], device='cuda:0'),\n",
      " 'art_dropout': 0.1,\n",
      " 'art_use_age': 'no',\n",
      " 'awgn': 0.001,\n",
      " 'awgn_age': 0,\n",
      " 'base_lr': 0.001,\n",
      " 'class_label_to_name': ['Normal', 'Abnormal'],\n",
      " 'class_name_to_label': {'Abnormal': 1, 'Normal': 0},\n",
      " 'criterion': 'cross-entropy',\n",
      " 'crop_length': 5120,\n",
      " 'crop_multiple': 4,\n",
      " 'crop_timing_analysis': False,\n",
      " 'cwd': '',\n",
      " 'dataset_name': 'tuab',\n",
      " 'dataset_path': 'local/dataset/tuab/',\n",
      " 'ddp': False,\n",
      " 'device': device(type='cuda', index=0),\n",
      " 'draw_result': True,\n",
      " 'file_format': 'memmap',\n",
      " 'in_channels': 24,\n",
      " 'input_norm': 'datapoint',\n",
      " 'iterations': 781250,\n",
      " 'latency': 2500,\n",
      " 'lr_scheduler_type': 'cosine_decay_with_warmup_half',\n",
      " 'mask_ratio': 0.5,\n",
      " 'mgn': 0.001,\n",
      " 'minibatch': 256,\n",
      " 'minibatch_3090': 256,\n",
      " 'mixed_precision': True,\n",
      " 'mixup': 0.0,\n",
      " 'multi_batch_size': 32,\n",
      " 'norm_pix_loss': True,\n",
      " 'num_history': 50,\n",
      " 'num_params': 125248512,\n",
      " 'out_dims': 2,\n",
      " 'output_length': 41,\n",
      " 'patch_size': 64,\n",
      " 'pre_model': 'g6ww1utl',\n",
      " 'preprocess_test': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda', index=0))\n",
      "  (1): EegResample(orig_freq=250, new_freq=125, resampling_method='sinc_interp_hann')\n",
      "  (2): EegNormalizeAge(mean=tensor([0.], device='cuda:0'), std=tensor([0.], device='cuda:0'), eps=1e-08, std_eps=tensor([1.0000e-08], device='cuda:0'))\n",
      "  (3): EegNormalizePerSignal(eps=1e-08)\n",
      "),\n",
      " 'preprocess_train': Sequential(\n",
      "  (0): EegToDevice(device=device(type='cuda', index=0))\n",
      "  (1): EegResample(orig_freq=250, new_freq=125, resampling_method='sinc_interp_hann')\n",
      "  (2): EegNormalizeAge(mean=tensor([0.], device='cuda:0'), std=tensor([0.], device='cuda:0'), eps=1e-08, std_eps=tensor([1.0000e-08], device='cuda:0'))\n",
      "  (3): EegNormalizePerSignal(eps=1e-08)\n",
      "  (4): EegMultiplicativeGaussianNoise(mean=0.0, std=0.001)\n",
      "  (5): EegAdditiveGaussianNoise(mean=0.0, std=0.001)\n",
      "),\n",
      " 'project': 'tuab-mae-artifact',\n",
      " 'resample': 125,\n",
      " 'run_mode': 'train',\n",
      " 'sampling_rate': 250,\n",
      " 'save_model': False,\n",
      " 'search_lr': False,\n",
      " 'search_multiplier': 1.0,\n",
      " 'seed': 0,\n",
      " 'seq_length': 2560,\n",
      " 'signal_header': ['EEG FP1-REF',\n",
      "                   'EEG FP2-REF',\n",
      "                   'EEG F3-REF',\n",
      "                   'EEG F4-REF',\n",
      "                   'EEG C3-REF',\n",
      "                   'EEG C4-REF',\n",
      "                   'EEG P3-REF',\n",
      "                   'EEG P4-REF',\n",
      "                   'EEG O1-REF',\n",
      "                   'EEG O2-REF',\n",
      "                   'EEG F7-REF',\n",
      "                   'EEG F8-REF',\n",
      "                   'EEG T3-REF',\n",
      "                   'EEG T4-REF',\n",
      "                   'EEG T5-REF',\n",
      "                   'EEG T6-REF',\n",
      "                   'EEG A1-REF',\n",
      "                   'EEG A2-REF',\n",
      "                   'EEG FZ-REF',\n",
      "                   'EEG CZ-REF',\n",
      "                   'EEG PZ-REF',\n",
      "                   'EEG T1-REF',\n",
      "                   'EEG T2-REF',\n",
      "                   'EEG EKG1-REF'],\n",
      " 'signal_length_limit': 10000000,\n",
      " 'task_description': 'Pathological classification of [Normal] and [Abnormal] '\n",
      "                     'EEG',\n",
      " 'task_name': 'Temple University Hospital Abnormal Corpus v2.0.0',\n",
      " 'test_crop_multiple': 8,\n",
      " 'total_samples': 500000.0,\n",
      " 'transform': Compose(\n",
      "    EegRandomCrop(crop_length=5120, length_limit=10000000, multiple=4, latency=2500, segment_simulation=False, return_timing=False, reject_events=False)\n",
      "    EegToTensor()\n",
      "),\n",
      " 'transform_multicrop': Compose(\n",
      "    EegRandomCrop(crop_length=5120, length_limit=10000000, multiple=8, latency=2500, segment_simulation=False, return_timing=False, reject_events=False)\n",
      "    EegToTensor()\n",
      "),\n",
      " 'use_age': 'no',\n",
      " 'use_wandb': False,\n",
      " 'val_fraction': 15,\n",
      " 'warmup_min': 150,\n",
      " 'warmup_ratio': 0.05,\n",
      " 'warmup_steps': 39062,\n",
      " 'watch_model': False,\n",
      " 'weight_decay': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# check the workstation environment and update some configurations\n",
    "check_device_env(config)\n",
    "\n",
    "# compose dataset\n",
    "train_loader, val_loader, test_loader, multicrop_test_loader = compose_dataset(config)\n",
    "\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "if not config.get(\"ddp\", False):\n",
    "    pre_model_state = ckpt[\"ssl_model_state\"]\n",
    "else:\n",
    "    pre_model_state_ddp = deepcopy(ckpt[\"ssl_model_state\"])\n",
    "    pre_model_state = OrderedDict()\n",
    "    for k, v in pre_model_state_ddp.items():\n",
    "        name = k[7:]  # remove 'module.' of DataParallel/DistributedDataParallel\n",
    "        pre_model_state[name] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "InstantiationException",
     "evalue": "Error locating target 'models.ssl.mae_artifact.mae_pre_art_b_e768_d512', set env var HYDRA_FULL_ERROR=1 to see chained exception.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg\\lib\\site-packages\\hydra\\_internal\\utils.py:644\u001b[0m, in \u001b[0;36m_locate\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 644\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc_attr:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'models.ssl' has no attribute 'mae_artifact'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg\\lib\\site-packages\\hydra\\_internal\\utils.py:650\u001b[0m, in \u001b[0;36m_locate\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:984\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'models.ssl.mae_artifact'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg\\lib\\site-packages\\hydra\\_internal\\instantiate\\_instantiate2.py:134\u001b[0m, in \u001b[0;36m_resolve_target\u001b[1;34m(target, full_key)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 134\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[43m_locate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg\\lib\\site-packages\\hydra\\_internal\\utils.py:653\u001b[0m, in \u001b[0;36m_locate\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc_import:\n\u001b[1;32m--> 653\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    654\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(exc_import)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    655\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAre you sure that \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is importable from module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent_dotpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    656\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc_import\u001b[39;00m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc_import:\n",
      "\u001b[1;31mImportError\u001b[0m: Error loading 'models.ssl.mae_artifact.mae_pre_art_b_e768_d512':\nModuleNotFoundError(\"No module named 'models.ssl.mae_artifact'\")\nAre you sure that 'mae_artifact' is importable from module 'models.ssl'?",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mInstantiationException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# generate the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_target_\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_target_\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre_art\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mae.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mae_artifact.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# load the model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m model_state \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mstate_dict()\n",
      "File \u001b[1;32mD:\\GitHub\\eeg_analysis\\run_train.py:87\u001b[0m, in \u001b[0;36mgenerate_model\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_model\u001b[39m(config):\n\u001b[1;32m---> 87\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mhydra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mddp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     89\u001b[0m         torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mset_device(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg\\lib\\site-packages\\hydra\\_internal\\instantiate\\_instantiate2.py:226\u001b[0m, in \u001b[0;36minstantiate\u001b[1;34m(config, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m     _convert_ \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mpop(_Keys\u001b[38;5;241m.\u001b[39mCONVERT, ConvertMode\u001b[38;5;241m.\u001b[39mNONE)\n\u001b[0;32m    224\u001b[0m     _partial_ \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mpop(_Keys\u001b[38;5;241m.\u001b[39mPARTIAL, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstantiate_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_recursive_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_convert_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_partial_\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m OmegaConf\u001b[38;5;241m.\u001b[39mis_list(config):\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m# Finalize config (convert targets to strings, merge with kwargs)\u001b[39;00m\n\u001b[0;32m    231\u001b[0m     config_copy \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(config)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg\\lib\\site-packages\\hydra\\_internal\\instantiate\\_instantiate2.py:333\u001b[0m, in \u001b[0;36minstantiate_node\u001b[1;34m(node, convert, recursive, partial, *args)\u001b[0m\n\u001b[0;32m    331\u001b[0m exclude_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_target_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_convert_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_recursive_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_partial_\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_target(node):\n\u001b[1;32m--> 333\u001b[0m     _target_ \u001b[38;5;241m=\u001b[39m \u001b[43m_resolve_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_Keys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTARGET\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    335\u001b[0m     is_partial \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_partial_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m partial\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg\\lib\\site-packages\\hydra\\_internal\\instantiate\\_instantiate2.py:139\u001b[0m, in \u001b[0;36m_resolve_target\u001b[1;34m(target, full_key)\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m full_key:\n\u001b[0;32m    138\u001b[0m             msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mfull_key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 139\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InstantiationException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(target):\n\u001b[0;32m    141\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a callable target, got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(target)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mInstantiationException\u001b[0m: Error locating target 'models.ssl.mae_artifact.mae_pre_art_b_e768_d512', set env var HYDRA_FULL_ERROR=1 to see chained exception."
     ]
    }
   ],
   "source": [
    "# generate the model\n",
    "config[\"_target_\"] = config[\"_target_\"].replace('pre', 'pre_art').replace('.mae.', '.mae_artifact.')\n",
    "model = generate_model(config).to(device)\n",
    "\n",
    "# load the model\n",
    "model_state = model.state_dict()\n",
    "for k, v in model_state.items():\n",
    "    if not k.startswith('art') and not k.endswith(\"pos_embed\"):\n",
    "        model_state[k] = pre_model_state[k]\n",
    "\n",
    "pre_model_state = deepcopy(model.state_dict())\n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.requires_grad_(False)\n",
    "model = model.eval()\n",
    "\n",
    "model.art_net.requires_grad_(True)\n",
    "for k, v in model._parameters.items():\n",
    "    if k.startswith(\"art\"):\n",
    "        v.requires_grad_(True)\n",
    "model.art_net = model.art_net.train()\n",
    "\n",
    "config[\"num_params\"] = count_parameters(model)\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name:100}\\t|\\t{param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# collect some garbage\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# fix the seed for reproducibility (a negative seed value means not fixing)\n",
    "set_seed(config, rank=None)\n",
    "\n",
    "# train\n",
    "ssl_train_script(\n",
    "    config,\n",
    "    model,\n",
    "    train_loader,\n",
    "    config[\"preprocess_train\"],\n",
    ")\n",
    "\n",
    "pre_model_state = deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_header = [channel.split('-')[0] for i, channel in enumerate(config[\"signal_header\"])]\n",
    "fps = config.get('resample', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@plt.style.context(['ieee', 'science', 'default'])\n",
    "def draw_eeg_graph(x, pred, mask, art_out, rec_loss, num=None):\n",
    "    plt.rcParams.update({'font.family': 'Ubuntu'})\n",
    "    N, C, L = x.shape\n",
    "    _, l = mask.shape\n",
    "    patch_size = L // l\n",
    "\n",
    "    art_out = art_out.reshape(N, -1)\n",
    "    rec_loss = rec_loss.reshape(N, -1)\n",
    "\n",
    "    for n in range(N):\n",
    "        if num is not None and num <= n:\n",
    "            break\n",
    "        \n",
    "        fig = plt.figure(num=1, clear=True, figsize=(25.0, 17.0))\n",
    "        fig.subplots_adjust(hspace=0)\n",
    "        \n",
    "        for c in range(C):\n",
    "            ax = fig.add_subplot(C, 1, c + 1)\n",
    "            ax.plot(x[n, c].cpu().numpy(), lw=1, c='tab:red', label='origin')\n",
    "            ax.plot(pred[n, c].cpu().numpy(), lw=1, c='tab:blue', label='pred')\n",
    "\n",
    "            art_mid = art_out[n].median()\n",
    "            rec_mid = art_out[n].median()\n",
    "            for r in range(l):\n",
    "                if r > 0:\n",
    "                    ax.axvline(r*patch_size, color='tab:purple', alpha=0.4)\n",
    "                if mask[n, r]:\n",
    "                    ax.axvspan(r*patch_size, (r + 1)*patch_size, facecolor='tab:purple', alpha=0.2)\n",
    "\n",
    "                if c == 0:\n",
    "                    if art_mid <= art_out[n, r]:\n",
    "                        ax.annotate(f\"{art_out[n, r]:3.2f}\", \n",
    "                                    xy=((r + 0.5)*patch_size, 1), ha='center', va='bottom', color='tab:purple')\n",
    "                    else:\n",
    "                        ax.annotate(f\"{art_out[n, r]:3.2f}\", \n",
    "                                    xy=((r + 0.5)*patch_size, 1), ha='center', va='bottom')\n",
    "                    if rec_mid <= rec_loss[n, r]:\n",
    "                        ax.annotate(f\"{rec_loss[n, r]:3.2f}\", \n",
    "                                    xy=((r + 0.5)*patch_size, -1), ha='center', va='bottom', color='tab:purple')\n",
    "                    else:\n",
    "                        ax.annotate(f\"{rec_loss[n, r]:3.2f}\", \n",
    "                                    xy=((r + 0.5)*patch_size, -1), ha='center', va='bottom')\n",
    "\n",
    "            ax.set_xlim(0, L)\n",
    "            ax.set_ylabel(signal_header[c])\n",
    "            ax.set_xticks(np.arange(round(config[\"seq_length\"] / fps) + 1) * fps)\n",
    "            ax.set_xticklabels([])\n",
    "            # ax.tick_params(axis='x', width=0.1, length=0.1)\n",
    "            ax.set_yticks([0])\n",
    "            ax.set_yticklabels([])\n",
    "        \n",
    "        ax.set_xticks(np.arange(round(config[\"seq_length\"] / fps) + 1) * fps)\n",
    "        ax.set_xticklabels(np.arange(round(config[\"seq_length\"] / fps) + 1))\n",
    "        \n",
    "        ax.set_xlabel('Time (s)')\n",
    "        # fig.savefig(os.path.join(output_folder, 'signal_example.pdf'), transparent=True)\n",
    "        plt.show()\n",
    "        fig.clear()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for target_dataset in tqdm([\"val\"], desc=\"Dataset\", leave=False):\n",
    "        if target_dataset == 'train':\n",
    "            loader = train_loader\n",
    "        elif target_dataset == 'val':\n",
    "            loader = val_loader\n",
    "        elif target_dataset == 'test':\n",
    "            loader = test_loader\n",
    "        else:\n",
    "            raise ValueError('')\n",
    "                \n",
    "        for sample_batched in tqdm(loader, total=len(loader), desc='Batch', leave=False):\n",
    "            print(target_dataset)\n",
    "            config[\"preprocess_test\"](sample_batched)\n",
    "            x = sample_batched[\"signal\"]\n",
    "            age = sample_batched[\"age\"]\n",
    "\n",
    "            pred, mask = model.mask_and_reconstruct(x, age, config[\"mask_ratio\"])\n",
    "            rec_loss = model.compute_reconstruction_loss2(x, pred)\n",
    "            art_out = model.forward_artifact(x, age)\n",
    "            \n",
    "            pred_eeg = model.unpatchify(pred)\n",
    "            draw_eeg_graph(x, pred_eeg, mask, art_out, rec_loss, 2)\n",
    "\n",
    "            break\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cyc in finetune_cycler:\n",
    "    # update configuration\n",
    "    for k, v in finetune_config.items():\n",
    "        config[k] = v\n",
    "    for k, v in cyc.items():\n",
    "        config[k] = v\n",
    "\n",
    "    # check the workstation environment and update some configurations\n",
    "    check_device_env(config)\n",
    "    \n",
    "    # compose dataset\n",
    "    train_loader, val_loader, test_loader, multicrop_test_loader = compose_dataset(config)\n",
    "    pprint.pprint(config)\n",
    "\n",
    "    # generate the model\n",
    "    config[\"_target_\"] = config[\"_target_\"].replace('.ssl', '').replace('_pre', '')\n",
    "    model = generate_model(config).to(device)\n",
    "    \n",
    "    # load the model\n",
    "    model_state = model.state_dict()\n",
    "    for k, v in model_state.items():\n",
    "        if not k.startswith(\"fc\") and not k.endswith(\"pos_embed\"):\n",
    "            model_state[k] = deepcopy(pre_model_state[k])\n",
    "    \n",
    "    model.load_state_dict(model_state)\n",
    "\n",
    "    model.finetune_mode(config[\"tuning_type\"])\n",
    "    config[\"num_params\"] = count_parameters(model)\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"{name:100}\\t|\\t{param.requires_grad}\")\n",
    "\n",
    "    # collect some garbage\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    # fix the seed for reproducibility (a negative seed value means not fixing)\n",
    "    set_seed(config, rank=None)\n",
    "    \n",
    "    # train\n",
    "    train_script(\n",
    "        config,\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        multicrop_test_loader,\n",
    "        config[\"preprocess_train\"],\n",
    "        config[\"preprocess_test\"],\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"- END -\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
