{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74515d5-5f25-477b-9a97-ed1f9b6d4c51",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluate\n",
    "\n",
    "This notebook evaluates the network trained previous notebooks and analyzes the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a2666f-6b4b-4748-9dca-2884347a1f0f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df587e38-b1a9-42c8-9b50-680200a9bec7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bengb\\OneDrive\\문서\\GitHub\\eeg_analysis\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8fb41bf8-1713-4228-b799-0e1c87545a16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import pprint\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_script import build_dataset_for_train\n",
    "import models\n",
    "from train.evaluate import check_accuracy\n",
    "from train.evaluate import check_accuracy_extended\n",
    "from train.evaluate import check_accuracy_extended_debug\n",
    "from train.evaluate import check_accuracy_multicrop\n",
    "from train.evaluate import check_accuracy_multicrop_extended\n",
    "from train.visualize import draw_roc_curve\n",
    "from train.visualize import draw_confusion\n",
    "from train.visualize import draw_error_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d10e3f39-ed55-422c-b47f-376691cbeed6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.11.0\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a62fa4-aa53-49d5-8ab4-2e2aaf7b65d1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "-----\n",
    "\n",
    "## Load the configuration used during the train phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bee4f853-3cad-4b01-8ee8-44ac9e49adbe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model_state', 'config', 'optimizer_state', 'scheduler_state'])\n"
     ]
    }
   ],
   "source": [
    "model_name = 'luhprdie'\n",
    "model_path = os.path.join('local/checkpoint_temp', model_name, 'last_checkpoint.pt')\n",
    "\n",
    "ckpt = torch.load(model_path, map_location=device)\n",
    "print(ckpt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab204c6e-25bc-4bb2-b83d-ffbab6dfd4d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_state = ckpt['model_state']\n",
    "config = ckpt['config']\n",
    "optimizer = ckpt['optimizer_state']\n",
    "scheduler = ckpt['scheduler_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6a582ce-495b-4f2e-9376-6d5591019f46",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EKG': 'X',\n",
      " '_target_': 'models.resnet_1d.ResNet1D',\n",
      " 'activation': 'gelu',\n",
      " 'age_mean': tensor([71.3768], device='cuda:0'),\n",
      " 'age_std': tensor([9.7025], device='cuda:0'),\n",
      " 'awgn': 0.01833870630857289,\n",
      " 'awgn_age': 0.2504092552157154,\n",
      " 'base_channels': 64,\n",
      " 'base_lr': 0.001264911064067352,\n",
      " 'block': 'bottleneck',\n",
      " 'class_label_to_name': ['Normal', 'Abnormal'],\n",
      " 'class_name_to_label': {'Abnormal': 1, 'Normal': 0},\n",
      " 'conv_layers': [3, 4, 6, 3],\n",
      " 'criterion': 'multi-bce',\n",
      " 'crop_multiple': 4,\n",
      " 'crop_timing_analysis': False,\n",
      " 'cwd': 'C:\\\\Users\\\\bengb\\\\OneDrive\\\\문서\\\\GitHub\\\\eeg_analysis',\n",
      " 'dataset_name': 'CAUEEG dataset',\n",
      " 'dataset_path': 'local/dataset/02_Curated_Data_220419/',\n",
      " 'ddp': False,\n",
      " 'device': device(type='cuda'),\n",
      " 'draw_result': True,\n",
      " 'dropout': 0.2699148150683074,\n",
      " 'fc_stages': 4,\n",
      " 'file_format': 'memmap',\n",
      " 'groups': 32,\n",
      " 'in_channels': 20,\n",
      " 'input_norm': 'dataset',\n",
      " 'iterations': 312500,\n",
      " 'latency': 2000,\n",
      " 'load_event': False,\n",
      " 'lr_scheduler_type': 'cosine_decay_with_warmup_one_and_half',\n",
      " 'mgn': 0.04122310004806722,\n",
      " 'minibatch': 128,\n",
      " 'mixup': 0,\n",
      " 'model': '1D-ResNeXt-50',\n",
      " 'multi_batch_size': 16,\n",
      " 'num_history': 500,\n",
      " 'num_params': 25782210,\n",
      " 'out_dims': 2,\n",
      " 'output_length': 6,\n",
      " 'photic': 'O',\n",
      " 'preprocess_test': Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([71.3768], device='cuda:0'),std=tensor([9.7025], device='cuda:0'),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([-0.0814,  0.0439,  0.0076, -0.0501, -0.0239, -0.0584,  0.0630,  0.0025,\n",
      "          -0.0483, -0.0152, -0.0189,  0.0338, -0.0088,  0.0219,  0.0846,  0.0061,\n",
      "           0.0149,  0.0016, -0.0272, -0.0126], device='cuda:0'),std=tensor([48.7583, 21.2484, 12.2378, 12.2846, 16.3226, 51.5700, 20.6271, 10.9920,\n",
      "          12.1157, 16.5601, 21.4847, 14.6775, 14.1403, 22.2428, 18.5709, 15.5188,\n",
      "          19.9918, 11.6944, 11.9881, 74.1481], device='cuda:0'),eps=1e-08)\n",
      "),\n",
      " 'preprocess_train': Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([71.3768], device='cuda:0'),std=tensor([9.7025], device='cuda:0'),eps=1e-08)\n",
      "  (2): EegAddGaussianNoiseAge(mean=0.0,std=0.2504092552157154)\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([-0.0814,  0.0439,  0.0076, -0.0501, -0.0239, -0.0584,  0.0630,  0.0025,\n",
      "          -0.0483, -0.0152, -0.0189,  0.0338, -0.0088,  0.0219,  0.0846,  0.0061,\n",
      "           0.0149,  0.0016, -0.0272, -0.0126], device='cuda:0'),std=tensor([48.7583, 21.2484, 12.2378, 12.2846, 16.3226, 51.5700, 20.6271, 10.9920,\n",
      "          12.1157, 16.5601, 21.4847, 14.6775, 14.1403, 22.2428, 18.5709, 15.5188,\n",
      "          19.9918, 11.6944, 11.9881, 74.1481], device='cuda:0'),eps=1e-08)\n",
      "  (4): EegAdditiveGaussianNoise(mean=0.0,std=0.01833870630857289)\n",
      "  (5): EegMultiplicativeGaussianNoise(mean=0.0,std=0.04122310004806722)\n",
      "),\n",
      " 'run_mode': 'train',\n",
      " 'save_model': True,\n",
      " 'search_lr': True,\n",
      " 'search_multiplier': 1.0,\n",
      " 'seed': 0,\n",
      " 'seq_length': 3000,\n",
      " 'signal_header': ['Fp1-AVG', 'F3-AVG', 'C3-AVG', 'P3-AVG', 'O1-AVG', 'Fp2-AVG', 'F4-AVG', 'C4-AVG', 'P4-AVG', 'O2-AVG', 'F7-AVG', 'T3-AVG', 'T5-AVG', 'F8-AVG', 'T4-AVG', 'T6-AVG', 'FZ-AVG', 'CZ-AVG', 'PZ-AVG', 'EKG', 'Photic'],\n",
      " 'signal_length_limit': 10000000,\n",
      " 'signal_mean': tensor([[[-0.0814],\n",
      "         [ 0.0439],\n",
      "         [ 0.0076],\n",
      "         [-0.0501],\n",
      "         [-0.0239],\n",
      "         [-0.0584],\n",
      "         [ 0.0630],\n",
      "         [ 0.0025],\n",
      "         [-0.0483],\n",
      "         [-0.0152],\n",
      "         [-0.0189],\n",
      "         [ 0.0338],\n",
      "         [-0.0088],\n",
      "         [ 0.0219],\n",
      "         [ 0.0846],\n",
      "         [ 0.0061],\n",
      "         [ 0.0149],\n",
      "         [ 0.0016],\n",
      "         [-0.0272],\n",
      "         [-0.0126]]], device='cuda:0'),\n",
      " 'signal_std': tensor([[[48.7583],\n",
      "         [21.2484],\n",
      "         [12.2378],\n",
      "         [12.2846],\n",
      "         [16.3226],\n",
      "         [51.5700],\n",
      "         [20.6271],\n",
      "         [10.9920],\n",
      "         [12.1157],\n",
      "         [16.5601],\n",
      "         [21.4847],\n",
      "         [14.6775],\n",
      "         [14.1403],\n",
      "         [22.2428],\n",
      "         [18.5709],\n",
      "         [15.5188],\n",
      "         [19.9918],\n",
      "         [11.6944],\n",
      "         [11.9881],\n",
      "         [74.1481]]], device='cuda:0'),\n",
      " 'task': 'task1',\n",
      " 'task_description': 'Classification of [Normal] and [Abnormal] symptoms',\n",
      " 'task_name': 'CAUEEG-task1 benchmark',\n",
      " 'test_crop_multiple': 8,\n",
      " 'total_samples': 40000000.0,\n",
      " 'transform': Compose(\n",
      "    EegRandomCrop(crop_length=3000, length_limit=10000000, multiple=4, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=[19])\n",
      "    EegToTensor()\n",
      "),\n",
      " 'transform_multicrop': Compose(\n",
      "    EegRandomCrop(crop_length=3000, length_limit=10000000, multiple=8, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=[19])\n",
      "    EegToTensor()\n",
      "),\n",
      " 'use_age': 'conv',\n",
      " 'use_wandb': True,\n",
      " 'warmup_min': 3000,\n",
      " 'warmup_ratio': 0.05,\n",
      " 'warmup_steps': 15625,\n",
      " 'watch_model': True,\n",
      " 'weight_decay': 0.02746510469766896,\n",
      " 'width_per_group': 4}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(config, width=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c85edd9-772b-4525-8acc-095850716b4e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load the target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d88946aa-6d3c-4b14-869e-b558783b8148",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model = config['generator'](**config).to(device)\n",
    "model = hydra.utils.instantiate(config).to(device)\n",
    "\n",
    "if config.get('ddp', False):\n",
    "    model_state_ddp = deepcopy(model_state)\n",
    "    model_state = OrderedDict()\n",
    "    for k, v in model_state_ddp.items():\n",
    "        name = k[7:] # remove 'module.' of DataParallel/DistributedDataParallel\n",
    "        model_state[name] = v\n",
    "    model.load_state_dict(model_state)\n",
    "else:\n",
    "    model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a751ab89-fe12-4e98-94e1-9a616ba08670",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Evaluate the model and analyze the performance by the crop timing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76b02db-da4e-4e65-830b-ba4214ff1bd7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89fa65ab-c9ce-4182-97c7-1adb2ca651d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "config = ckpt['config']\n",
    "\n",
    "config.pop('cwd', 0)\n",
    "config['ddp'] = False\n",
    "config['crop_timing_analysis'] = True\n",
    "config['eval'] = True\n",
    "config['device'] = device\n",
    "\n",
    "repeat = round(200 / config['crop_multiple'])\n",
    "print(repeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bc5f3a-1321-406c-ad0f-d8cb6f587bd1",
   "metadata": {},
   "source": [
    "### Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "316ce735-4ffd-49a6-a9d1-51584df94390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transform: Compose(\n",
      "    EegRandomCrop(crop_length=3000, length_limit=10000000, multiple=4, latency=2000, return_timing=True)\n",
      "    EegDropChannels(drop_index=[19])\n",
      "    EegToTensor()\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "transform_multicrop: Compose(\n",
      "    EegRandomCrop(crop_length=3000, length_limit=10000000, multiple=8, latency=2000, return_timing=True)\n",
      "    EegDropChannels(drop_index=[19])\n",
      "    EegToTensor()\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "task config:\n",
      "{'class_label_to_name': ['Normal', 'Abnormal'],\n",
      " 'class_name_to_label': {'Abnormal': 1, 'Normal': 0},\n",
      " 'task_description': 'Classification of [Normal] and [Abnormal] symptoms',\n",
      " 'task_name': 'CAUEEG-task1 benchmark'}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "train_dataset[0].keys():\n",
      "dict_keys(['serial', 'age', 'symptom', 'class_name', 'class_label', 'signal', 'crop_timing'])\n",
      "train signal shape: torch.Size([20, 3000])\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "val_dataset[0].keys():\n",
      "dict_keys(['serial', 'age', 'symptom', 'class_name', 'class_label', 'signal', 'crop_timing'])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_dataset[0].keys():\n",
      "dict_keys(['serial', 'age', 'symptom', 'class_name', 'class_label', 'signal', 'crop_timing'])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "test_dataset[0].keys():\n",
      "dict_keys(['serial', 'age', 'symptom', 'class_name', 'class_label', 'signal', 'crop_timing'])\n",
      "test signal shape: torch.Size([20, 3000])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "preprocess_train: Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([71.3768], device='cuda:0'),std=tensor([9.7025], device='cuda:0'),eps=1e-08)\n",
      "  (2): EegAddGaussianNoiseAge(mean=0.0,std=0.2504092552157154)\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([-0.0814,  0.0439,  0.0076, -0.0501, -0.0239, -0.0584,  0.0630,  0.0025,\n",
      "          -0.0483, -0.0152, -0.0189,  0.0338, -0.0088,  0.0219,  0.0846,  0.0061,\n",
      "           0.0149,  0.0016, -0.0272, -0.0126], device='cuda:0'),std=tensor([48.7583, 21.2484, 12.2378, 12.2846, 16.3226, 51.5700, 20.6271, 10.9920,\n",
      "          12.1157, 16.5601, 21.4847, 14.6775, 14.1403, 22.2428, 18.5709, 15.5188,\n",
      "          19.9918, 11.6944, 11.9881, 74.1481], device='cuda:0'),eps=1e-08)\n",
      "  (4): EegMultiplicativeGaussianNoise(mean=0.0,std=0.04122310004806722)\n",
      "  (5): EegAdditiveGaussianNoise(mean=0.0,std=0.01833870630857289)\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "preprocess_test: Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([71.3768], device='cuda:0'),std=tensor([9.7025], device='cuda:0'),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([-0.0814,  0.0439,  0.0076, -0.0501, -0.0239, -0.0584,  0.0630,  0.0025,\n",
      "          -0.0483, -0.0152, -0.0189,  0.0338, -0.0088,  0.0219,  0.0846,  0.0061,\n",
      "           0.0149,  0.0016, -0.0272, -0.0126], device='cuda:0'),std=tensor([48.7583, 21.2484, 12.2378, 12.2846, 16.3226, 51.5700, 20.6271, 10.9920,\n",
      "          12.1157, 16.5601, 21.4847, 14.6775, 14.1403, 22.2428, 18.5709, 15.5188,\n",
      "          19.9918, 11.6944, 11.9881, 74.1481], device='cuda:0'),eps=1e-08)\n",
      ")\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "0 torch.Size([128, 20, 3000]) torch.Size([128]) torch.Size([128])\n",
      "1 torch.Size([128, 20, 3000]) torch.Size([128]) torch.Size([128])\n",
      "2 torch.Size([128, 20, 3000]) torch.Size([128]) torch.Size([128])\n",
      "3 torch.Size([128, 20, 3000]) torch.Size([128]) torch.Size([128])\n",
      "4 torch.Size([128, 20, 3000]) torch.Size([128]) torch.Size([128])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, multicrop_test_loader = build_dataset_for_train(config, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0116501-0a1b-4460-92a4-f1c632993366",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "266a7e96-bc3e-413e-849a-ed63ae59e16a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_accuracy_extended_debug\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpreprocess_test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepeat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m _[\u001b[38;5;241m0\u001b[39m] \n\u001b[0;32m      4\u001b[0m train_score \u001b[38;5;241m=\u001b[39m _[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg_analysis\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\OneDrive\\문서\\GitHub\\eeg_analysis\\train\\evaluate.py:152\u001b[0m, in \u001b[0;36mcheck_accuracy_extended_debug\u001b[1;34m(model, loader, preprocess, config, repeat)\u001b[0m\n\u001b[0;32m    149\u001b[0m confusion_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((C, C), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# for error table\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m error_table \u001b[38;5;241m=\u001b[39m {data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserial\u001b[39m\u001b[38;5;124m'\u001b[39m]: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGT\u001b[39m\u001b[38;5;124m'\u001b[39m: data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[0;32m    153\u001b[0m                                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPred\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m C} \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m loader\u001b[38;5;241m.\u001b[39mdataset}\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# for crop timing\u001b[39;00m\n\u001b[0;32m    156\u001b[0m crop_timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n",
      "File \u001b[1;32m~\\OneDrive\\문서\\GitHub\\eeg_analysis\\train\\evaluate.py:152\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    149\u001b[0m confusion_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((C, C), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# for error table\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m error_table \u001b[38;5;241m=\u001b[39m {data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserial\u001b[39m\u001b[38;5;124m'\u001b[39m]: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGT\u001b[39m\u001b[38;5;124m'\u001b[39m: data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[0;32m    153\u001b[0m                                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPred\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m C} \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m loader\u001b[38;5;241m.\u001b[39mdataset}\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# for crop timing\u001b[39;00m\n\u001b[0;32m    156\u001b[0m crop_timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n",
      "File \u001b[1;32m~\\OneDrive\\문서\\GitHub\\eeg_analysis\\datasets\\caueeg_dataset.py:220\u001b[0m, in \u001b[0;36mCauEegDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    217\u001b[0m sample \u001b[38;5;241m=\u001b[39m deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list[idx])\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# signal\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msignal\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_signal\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# event\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_event:\n",
      "File \u001b[1;32m~\\OneDrive\\문서\\GitHub\\eeg_analysis\\datasets\\caueeg_dataset.py:237\u001b[0m, in \u001b[0;36mCauEegDataset._read_signal\u001b[1;34m(self, anno)\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_feather(anno)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_memmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43manno\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\문서\\GitHub\\eeg_analysis\\datasets\\caueeg_dataset.py:251\u001b[0m, in \u001b[0;36mCauEegDataset._read_memmap\u001b[1;34m(self, anno)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_memmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, anno):\n\u001b[0;32m    250\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignal/memmap/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00manno[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserial\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.dat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 251\u001b[0m     signal \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mint32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m signal\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg_analysis\\lib\\site-packages\\numpy\\core\\memmap.py:228\u001b[0m, in \u001b[0;36mmemmap.__new__\u001b[1;34m(subtype, filename, dtype, mode, offset, shape, order)\u001b[0m\n\u001b[0;32m    226\u001b[0m     f_ctx \u001b[38;5;241m=\u001b[39m nullcontext(filename)\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 228\u001b[0m     f_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m f_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[0;32m    231\u001b[0m     fid\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_ = check_accuracy_extended_debug(model, train_loader, \n",
    "                                  config['preprocess_test'], config, repeat=repeat)\n",
    "train_acc = _[0] \n",
    "train_score = _[1]\n",
    "train_target = _[2]\n",
    "train_confusion = _[3]\n",
    "train_error_table = _[4]\n",
    "train_crop_timing = _[5]\n",
    "\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802da575-01f7-4046-b1fd-64321adb58ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "draw_roc_curve(train_score, train_target, config['class_label_to_name'], use_wandb=False)\n",
    "draw_confusion(train_confusion, config['class_label_to_name'], use_wandb=False)\n",
    "draw_error_table(train_error_table, use_wandb=False, fig_size=(60.0, 4.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d83768-0b92-41f8-9276-08f444ae3006",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcce1ba-ccb0-4b77-aebc-b6ee966ab28c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_ = check_accuracy_extended_debug(model, val_loader, \n",
    "                                  config['preprocess_test'], config, repeat=repeat)\n",
    "val_acc = _[0]\n",
    "val_score = _[1]\n",
    "val_target = _[2]\n",
    "val_confusion = _[3]\n",
    "val_error_table = _[4]\n",
    "val_crop_timing = _[5]\n",
    "\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb56c9a-31e2-4bf4-8d19-5aa918390e59",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "draw_roc_curve(val_score, val_target, config['class_label_to_name'], use_wandb=False)\n",
    "draw_confusion(val_confusion, config['class_label_to_name'], use_wandb=False)\n",
    "draw_error_table(val_error_table, use_wandb=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0423d5-d26b-4a02-84a9-b4577b81cf82",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7572abf6-6c8d-429b-b18b-9eafbbe2b5b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.5431654676259\n"
     ]
    }
   ],
   "source": [
    "_ = check_accuracy_extended_debug(model, test_loader, \n",
    "                                  config['preprocess_test'], config, repeat=repeat)\n",
    "test_acc = _[0]\n",
    "test_score = _[1]\n",
    "test_target = _[2]\n",
    "test_confusion = _[3]\n",
    "test_error_table = _[4]\n",
    "test_crop_timing = _[5]\n",
    "\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2e562892-8c5a-4f7c-b5f7-3ddecb5980d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(data, row_labels, col_labels, ax=None,\n",
    "            cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Create a heatmap from a numpy array and two lists of labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data\n",
    "        A 2D numpy array of shape (M, N).\n",
    "    row_labels\n",
    "        A list or array of length M with the labels for the rows.\n",
    "    col_labels\n",
    "        A list or array of length N with the labels for the columns.\n",
    "    ax\n",
    "        A `matplotlib.axes.Axes` instance to which the heatmap is plotted.  If\n",
    "        not provided, use current axes or create a new one.  Optional.\n",
    "    cbar_kw\n",
    "        A dictionary with arguments to `matplotlib.Figure.colorbar`.  Optional.\n",
    "    cbarlabel\n",
    "        The label for the colorbar.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to `imshow`.\n",
    "    \"\"\"\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # Show all ticks and label them with the respective list entries.\n",
    "    ax.set_xticks(np.arange(data.shape[1]), labels=col_labels)\n",
    "    ax.set_yticks(np.arange(data.shape[0]), labels=row_labels)\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=True, bottom=False,\n",
    "                   labeltop=False, labelbottom=True)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-30, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Turn spines off and create white grid.\n",
    "    ax.spines[:].set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "    return im, cbar\n",
    "\n",
    "\n",
    "def annotate_heatmap(im, data=None, valfmt=\"{x:.2f}\",\n",
    "                     textcolors=(\"black\", \"white\"),\n",
    "                     threshold=None, **textkw):\n",
    "    \"\"\"\n",
    "    A function to annotate a heatmap.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    im\n",
    "        The AxesImage to be labeled.\n",
    "    data\n",
    "        Data used to annotate.  If None, the image's data is used.  Optional.\n",
    "    valfmt\n",
    "        The format of the annotations inside the heatmap.  This should either\n",
    "        use the string format method, e.g. \"$ {x:.2f}\", or be a\n",
    "        `matplotlib.ticker.Formatter`.  Optional.\n",
    "    textcolors\n",
    "        A pair of colors.  The first is used for values below a threshold,\n",
    "        the second for those above.  Optional.\n",
    "    threshold\n",
    "        Value in data units according to which the colors from textcolors are\n",
    "        applied.  If None (the default) uses the middle of the colormap as\n",
    "        separation.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to each call to `text` used to create\n",
    "        the text labels.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "\n",
    "    # Normalize the threshold to the images color range.\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max())/2.\n",
    "\n",
    "    # Set default alignment to center, but allow it to be\n",
    "    # overwritten by textkw.\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "\n",
    "    # Get the formatter in case a string is supplied\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "\n",
    "    # Loop over the data and create a `Text` for each \"pixel\".\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[int(im.norm(data[i, j]) > threshold)])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d8452475-b73d-4cdb-a156-7f618d80f7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_to_name = config['class_label_to_name']\n",
    "C = len(class_label_to_name)\n",
    "\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "\n",
    "im, cbar = heatmap(test_confusion, class_label_to_name, class_label_to_name, ax=ax,\n",
    "                   cmap=\"jet\", cbarlabel=\"test data\")\n",
    "texts = annotate_heatmap(im, valfmt=\"{x:d}\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "ax = fig.add_subplot(2, 1, 2)\n",
    "from train.evaluate import calculate_class_wise_metrics\n",
    "class_wise_metrics = calculate_class_wise_metrics(confusion)\n",
    "ax.imshow(np.zeros((C, len(class_wise_metrics) + 1)), alpha=0.8)\n",
    "\n",
    "ax.set_xticks(np.arange(len(class_wise_metrics) + 1))\n",
    "ax.set_yticks(np.arange(C))\n",
    "ax.set_xticklabels([*class_wise_metrics.keys()] + ['Accuracy'])\n",
    "ax.set_yticklabels(class_label_to_name)\n",
    "\n",
    "for c in range(len(class_wise_metrics)):\n",
    "    for r in range(C):\n",
    "        metric_name = [*class_wise_metrics.keys()][c]\n",
    "        ax.text(c, r, f\"{class_wise_metrics[metric_name][r] * 100:.2f}%\",\n",
    "                ha=\"center\", va=\"center\", color='k')\n",
    "        \n",
    "ax.text(len(class_wise_metrics), 0, f\"{np.trace(confusion) / np.sum(confusion) * 100:.2f}%\",\n",
    "        ha=\"center\", va=\"center\", color='k')\n",
    "\n",
    "ax.set_title('Class-wise metrics')\n",
    "ax.set_ylabel('Class')\n",
    "ax.set_xlabel('Metric')\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# draw\n",
    "fig.savefig(os.path.join(output_folder, 'confusion_temp.pdf'), transparent=True)\n",
    "\n",
    "plt.show()\n",
    "fig.clear()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7e3bb9-388d-4251-87f1-6ed289067739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153f97a7-1871-4f73-94e6-984a3c160e99",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "draw_roc_curve(test_score, test_target, config['class_label_to_name'], use_wandb=False)\n",
    "draw_confusion(test_confusion, config['class_label_to_name'], use_wandb=False)\n",
    "draw_error_table(test_error_table, use_wandb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6313d640-f44f-4564-bd0c-cbd20f02ba8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = check_accuracy_extended(model, test_loader, \n",
    "                            config['preprocess_test'], config, repeat=repeat)\n",
    "test_acc = _[0]\n",
    "test_score = _[1]\n",
    "test_target = _[2]\n",
    "test_confusion = _[3]\n",
    "test_error_table = _[4]\n",
    "\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1d240c-1264-478a-88c3-5481ac520cd1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test set (with test-time augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643e8af7-e6cb-4b25-89b0-c115296be5e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = check_accuracy_multicrop_extended(model, multicrop_test_loader, \n",
    "                                      config['preprocess_test'], config, repeat=repeat)\n",
    "multi_test_acc = _[0]\n",
    "multi_test_score = _[1]\n",
    "multi_test_target = _[2]\n",
    "multi_test_confusion = _[3]\n",
    "multi_test_error_table = _[4]\n",
    "\n",
    "print(multi_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d78977-2a2a-4a49-8802-3884c19aee07",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "draw_roc_curve(multi_test_score, multi_test_target, config['class_label_to_name'], use_wandb=False)\n",
    "draw_confusion(multi_test_confusion, config['class_label_to_name'], use_wandb=False)\n",
    "draw_error_table(multi_test_error_table, use_wandb=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a741cd35-65a8-458a-ad5e-a7cf9e66b43a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Examine whether the model has a bias related to the cropping starting time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd145cf6-1af1-4bed-9ee2-bf76a991a778",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_pos = []\n",
    "train_neg = []\n",
    "\n",
    "for k, v in train_crop_timing.items():\n",
    "    for i in range(v.get('correct', 0)):\n",
    "        train_pos.append(k)\n",
    "    for i in range(v.get('incorrect', 0)):\n",
    "        train_neg.append(k)\n",
    "\n",
    "##\n",
    "\n",
    "val_pos = []\n",
    "val_neg = []\n",
    "\n",
    "for k, v in val_crop_timing.items():\n",
    "    for i in range(v.get('correct', 0)):\n",
    "        val_pos.append(k)\n",
    "    for i in range(v.get('incorrect', 0)):\n",
    "        val_neg.append(k)\n",
    "\n",
    "##\n",
    "\n",
    "test_pos = []\n",
    "test_neg = []\n",
    "\n",
    "for k, v in test_crop_timing.items():\n",
    "    for i in range(v.get('correct', 0)):\n",
    "        test_pos.append(k)\n",
    "    for i in range(v.get('incorrect', 0)):\n",
    "        test_neg.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd4b339-4d0c-4dc8-bafb-a75f89c8bbba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(num=1, clear=True, figsize=(16, 10), constrained_layout=True)\n",
    "n_bins = 50\n",
    "density = False\n",
    "\n",
    "ax = fig.add_subplot(3, 1, 1)\n",
    "ax.hist(train_pos, bins=n_bins, color='g', alpha=0.7, density=density)\n",
    "ax.hist(train_neg, bins=n_bins, color='r', alpha=0.7, density=density)\n",
    "ax.set_title(f'Training Set: True/Neg Historgram by Random Crop Time')\n",
    "ax.set_xlabel('Random Crop Time')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "ax = fig.add_subplot(3, 1, 2)\n",
    "ax.hist(val_pos, bins=n_bins, color='g', alpha=0.7, density=density)\n",
    "ax.hist(val_neg, bins=n_bins, color='r', alpha=0.7, density=density)\n",
    "ax.set_title(f'Validation Set: True/Neg Historgram by Random Crop Time')\n",
    "ax.set_xlabel('Random Crop Time')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "ax = fig.add_subplot(3, 1, 3)\n",
    "ax.hist(test_pos, bins=n_bins, color='g', alpha=0.7, density=density)\n",
    "ax.hist(test_neg, bins=n_bins, color='r', alpha=0.7, density=density)\n",
    "ax.set_title(f'Test Set: True/Neg Historgram by Random Crop Time')\n",
    "ax.set_xlabel('Random Crop Time')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "plt.show()\n",
    "fig.clear()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e0ca82-cc3d-4303-bf31-7e4d7a375136",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Evaluate the model with length limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ab8480-5e29-4b5e-bdb2-4409e045e315",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd0cfc6-1ef3-4135-a5fb-5876ceb305ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = ckpt['config']\n",
    "\n",
    "config['crop_timing_analysis'] = False\n",
    "config['signal_length_limit'] = 200 * 60 * 7  # 7 minutes\n",
    "config['eval'] = True\n",
    "config['device'] = device\n",
    "\n",
    "repeat = round(50 / config['crop_multiple'])\n",
    "\n",
    "train_loader, val_loader, test_loader, multi_test_loader = build_dataset_for_train(config, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67152a06-610f-480d-9512-b3547ced808c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# train\n",
    "train_acc = check_accuracy(model, train_loader, \n",
    "                           config['preprocess_test'], config, repeat=repeat)\n",
    "val_acc = check_accuracy(model, val_loader, \n",
    "                         config['preprocess_test'], config, repeat=repeat)\n",
    "test_acc = check_accuracy(model, test_loader, \n",
    "                          config['preprocess_test'], config, repeat=repeat)\n",
    "multi_test_acc = check_accuracy_multicrop(model, multi_test_loader, \n",
    "                                          config['preprocess_test'], config, repeat=repeat)\n",
    "\n",
    "print(train_acc, val_acc, test_acc, multi_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23811ac5-4a94-4d8a-b4fb-68161557a87d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
