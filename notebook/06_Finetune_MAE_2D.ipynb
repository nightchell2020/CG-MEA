{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Finetune Masked-AutoEncoder\n",
    "\n",
    "- Finetune the deep network after pretraining the self-supervised learning framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import gc\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import wandb\n",
    "import pprint\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.transforms as mtransforms\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredDirectionArrows\n",
    "\n",
    "# custom package\n",
    "from run_train import check_device_env\n",
    "from run_train import set_seed\n",
    "from run_train import compose_dataset\n",
    "from run_train import generate_model\n",
    "from train.ssl_train_script import ssl_train_script\n",
    "from train.train_script import train_script\n",
    "from models.utils import count_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Specify the dataset, model, and train setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_model_path = 'local/checkpoint/'\n",
    "pre_model_name = '2023-1110-2304'\n",
    "\n",
    "use_wandb = False\n",
    "project = 'caueeg-mae'\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Load and modify the pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load pretrained configurations\n",
    "path = os.path.join(pre_model_path, pre_model_name.split(',')[-1], 'checkpoint.pt')\n",
    "try:\n",
    "    ckpt = torch.load(path, map_location=device)\n",
    "    config = ckpt['config']\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f'- checkpoint cannot be opened: {path}')\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the model\n",
    "model = generate_model(config).to(device)\n",
    "model.load_state_dict(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the workstation environment and update some configurations\n",
    "check_device_env(config)\n",
    "\n",
    "# compose dataset\n",
    "train_loader, val_loader, test_loader, multicrop_test_loader = compose_dataset(config)\n",
    "\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_header = [channel.split('-')[0] for i, channel in enumerate(config[\"signal_header\"])]\n",
    "fps = config.get('resample', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_as_real_to_complex(signal):\n",
    "    N, _, H, W = signal.shape\n",
    "    C = signal.shape[1] // 2\n",
    "\n",
    "    sig_out = torch.zeros((N, C, H, W, 2))\n",
    "    sig_out[..., 0] = signal[:, :C]\n",
    "    sig_out[..., 1] = signal[:, C:]\n",
    "\n",
    "    sig_out = torch.view_as_complex(sig_out)\n",
    "    return sig_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_stft(img, pred, mask, config, index=0, log_scale=False, save_fig=None):\n",
    "    img = from_as_real_to_complex(img)[index].abs().cpu().numpy()\n",
    "    pred = from_as_real_to_complex(pred)[index].abs().cpu().numpy()\n",
    "    \n",
    "    # always do not consider EKG and Photic channels\n",
    "    C, H, W = img.shape\n",
    "    p = config[\"patch_size\"]\n",
    "    h = H // p\n",
    "    w = W // p\n",
    "    mask = mask[index].reshape(h, w)\n",
    "\n",
    "    signal_f = np.zeros_like(img)\n",
    "    for hh in range(h):\n",
    "        for ww in range(w):\n",
    "            if mask[hh, ww] > 0.5:\n",
    "                signal_f[:, hh*p:(hh + 1)*p, ww*p:(ww + 1)*p] = img[:, hh*p:(hh + 1)*p, ww*p:(ww + 1)*p]\n",
    "            else:\n",
    "                signal_f[:, hh*p:(hh + 1)*p, ww*p:(ww + 1)*p] = pred[:, hh*p:(hh + 1)*p, ww*p:(ww + 1)*p]\n",
    "    \n",
    "    columns = 7\n",
    "    rows = round(np.ceil(C / columns))\n",
    "    fig, ax = plt.subplots(rows, columns, \n",
    "                           figsize=(22.0, 9.5), constrained_layout=True)\n",
    "    normalizer = Normalize()\n",
    "    \n",
    "    for k in range(columns * rows):\n",
    "        r = k // columns\n",
    "        c = k % columns\n",
    "\n",
    "        if k < C:\n",
    "            im = ax[r, c].imshow(np.log(signal_f[k] + 1e-8) if log_scale else signal_f[k],\n",
    "                                 interpolation='nearest',\n",
    "                                 extent=[0, config['seq_length']/fps, 0, fps/2.0], \n",
    "                                 aspect=(config['seq_length']/fps) / (fps/2.0))\n",
    "            ax[r, c].set_title(config['signal_header'][k].split('-')[0], \n",
    "                               fontsize=18, fontweight='bold', color='darkred')\n",
    "            ax[r, c].set_xlabel('Time (s)', fontsize=13)\n",
    "            ax[r, c].set_ylabel('Frequency (Hz)', fontsize=13)\n",
    "            # ax[r, c].invert_yaxis()\n",
    "        else:\n",
    "            axins = ax[r, c]\n",
    "            ax[r, c].axis('off')\n",
    "        \n",
    "    fig.suptitle('Time-Frequency Representation', fontsize=20, fontweight='semibold')\n",
    "    # cax = inset_axes(axins,\n",
    "    #                  width=\"10%\",  # width = 10% of parent_bbox width\n",
    "    #                  height=\"80%\",  # height : 50%\n",
    "    #                  loc='center',\n",
    "    #                  bbox_to_anchor=(0., 0., 1, 1),\n",
    "    #                  bbox_transform=axins.transAxes,\n",
    "    #                  borderpad=0,\n",
    "    #                  )\n",
    "    # cbar = fig.colorbar(im, ax=ax.ravel().tolist(), cax=cax)\n",
    "    # cbar.ax.set_xlabel('Magnitude in log-scale' if log_scale else 'Magnitude', fontsize=13) \n",
    "\n",
    "    plt.show()\n",
    "    fig.clear()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for target_dataset in tqdm([\"val\"], desc=\"Dataset\", leave=False):\n",
    "        if target_dataset == 'train':\n",
    "            loader = train_loader\n",
    "        elif target_dataset == 'val':\n",
    "            loader = val_loader\n",
    "        elif target_dataset == 'test':\n",
    "            loader = test_loader\n",
    "        else:\n",
    "            raise ValueError('')\n",
    "                \n",
    "        for sample_batched in tqdm(loader, total=len(loader), desc='Batch', leave=False):\n",
    "            config[\"preprocess_test\"](sample_batched)\n",
    "            img = sample_batched[\"signal\"]\n",
    "\n",
    "            pred, mask = model.mask_and_reconstruct(img, sample_batched[\"age\"], config[\"mask_ratio\"])\n",
    "            pred_img = model.unpatchify(pred)\n",
    "\n",
    "            draw_stft(img, pred_img, mask, config, index=0, log_scale=False, save_fig=None)            \n",
    "            break\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model = deepcopy(model)\n",
    "pre_model_state = pre_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training configuration\n",
    "config['project'] = project\n",
    "config['use_wandb'] = use_wandb\n",
    "config['pre_model'] = pre_model_name\n",
    "config['device'] = device\n",
    "\n",
    "config['total_samples'] = 5.0e+5\n",
    "config['search_lr'] = False\n",
    "config['base_lr'] = 1e-3\n",
    "config['lr_scheduler_type'] = 'cosine_decay_with_warmup_half'\n",
    "\n",
    "config[\"warmup_min\"] = 200   \n",
    "\n",
    "# model\n",
    "config[\"tuning_type\"] = \"finetune\"  # \"finetune\", \"fc_stage\"\n",
    "config[\"layer_wise_lr\"] = True\n",
    "\n",
    "config[\"out_dims\"] = 3\n",
    "config[\"task\"] = \"dementia\"\n",
    "config[\"use_age\"] = 'fc'\n",
    "config[\"fc_stages\"] = 3\n",
    "config[\"global_pool\"] = True\n",
    "config[\"dropout\"] = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the workstation environment and update some configurations\n",
    "check_device_env(config)\n",
    "\n",
    "# compose dataset\n",
    "train_loader, val_loader, test_loader, multicrop_test_loader = compose_dataset(config)\n",
    "\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the model\n",
    "config[\"_target_\"] = config[\"_target_\"].replace('.ssl', '').replace('_pre', '')\n",
    "model = generate_model(config).to(device)\n",
    "\n",
    "# load the model\n",
    "model_state = model.state_dict()\n",
    "for k, v in model_state.items():\n",
    "    if not k.startswith('fc') and not k.endswith(\"pos_embed\"):\n",
    "        model_state[k] = pre_model_state[k]\n",
    "\n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.finetune_mode(config[\"tuning_type\"])\n",
    "config[\"num_params\"] = count_parameters(model)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name:100}\\t|\\t{param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect some garbage\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# fix the seed for reproducibility (a negative seed value means not fixing)\n",
    "set_seed(config, rank=None)\n",
    "\n",
    "# train\n",
    "train_script(\n",
    "    config,\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    multicrop_test_loader,\n",
    "    config[\"preprocess_train\"],\n",
    "    config[\"preprocess_test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
