{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1982041c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/imkbsz/workspace/eeg_analysis\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca89409f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff1ec1e-4b2d-426e-a3a9-9387feed4d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eg6s5fay': 0.75, 'r3db85gm': 0.75, '9rrhec00': 0.75, '5xlos421': 0.5, 'rhqfowxp': 0.5, '255ugwah': 0.5, 'cmru56bi': 0.5, 'nfbtrm5s': 0.2, '3f90hsjz': 0.5, 'p25u3bun': 0.5, '0ei2cjne': 0.5, '4xb6ohzp': 0.25, '0473gnjs': 0.5, 'ah6loko1': 0.5, '7uf9ofni': 0.5, 'voosm1bm': 0.5, 'klo0kw08': 0.5, 'wxaaytah': 0.5, 'fvuepvb9': 0.25, '4ui9h39h': 0.75, 'wftcdahj': 0.5, '2ew55ua4': 0.5, 'dch78dwg': 0.5}\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "runs = api.runs('caueeg-mae')\n",
    "\n",
    "pre_name_to_mask_ratio = {}\n",
    "for run in runs:\n",
    "    pre_name_to_mask_ratio[run.name] = run.config[\"mask_ratio\"]\n",
    "print(pre_name_to_mask_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71920a04-f148-450c-ae43-d9465967b570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eg6s5fay': 0.75, 'r3db85gm': 0.75, '9rrhec00': 0.75, '5xlos421': 0.5, 'rhqfowxp': 0.5, '255ugwah': 0.5, 'cmru56bi': 0.5, 'nfbtrm5s': 0.2, '3f90hsjz': 0.5, 'p25u3bun': 0.5, '0ei2cjne': 0.5, '4xb6ohzp': 0.25, '0473gnjs': 0.5, 'ah6loko1': 0.5, '7uf9ofni': 0.5, 'voosm1bm': 0.5, 'klo0kw08': 0.5, 'wxaaytah': 0.5, 'fvuepvb9': 0.25, '4ui9h39h': 0.75, 'wftcdahj': 0.5, '2ew55ua4': 0.5, 'dch78dwg': 0.5, 'e57t1ac8': 0.75, 'nyb2t0p2': 0.75, '40o98jml': 0.75, 'vt7lwk2m': 0.75, 'jwf6efps': 0.75, '7akfmk44': 0.5}\n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "runs = api.runs('tuab-mae')\n",
    "\n",
    "# pre_name_to_mask_ratio = {}\n",
    "for run in runs:\n",
    "    pre_name_to_mask_ratio[run.name] = run.config[\"mask_ratio\"]\n",
    "print(pre_name_to_mask_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a55ef5e5-9fe6-4008-ae32-94867b11b281",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "runs = api.runs('caueeg-mae-artifact-finetune')\n",
    "\n",
    "for run in runs:\n",
    "    if run.config.get(\"_target_\", \"\").startswith(\"models.mae_artifact\") and \"descending\" in run.config:\n",
    "        descending = run.config.pop(\"descending\")\n",
    "        art_patch_usage = {}\n",
    "        art_patch_usage[\"type\"] = \"drop_low\" if descending else \"drop_high\"\n",
    "        art_patch_usage[\"value\"] = run.config[\"mask_ratio\"]\n",
    "        run.config[\"mask_ratio\"] = pre_name_to_mask_ratio[run.config[\"pre_model\"]]\n",
    "        run.config[\"art_patch_usage\"] = art_patch_usage\n",
    "        run.config[\"art_out_activation\"] = \"none\"\n",
    "        run.config[\"art_loss_type\"] = \"mse\"\n",
    "        run.config.update()\n",
    "        run.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f715197f-666d-4a4e-8934-d10a712a75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "runs = api.runs('caueeg-abnormal-mae-artifact-finetune')\n",
    "\n",
    "for run in runs:\n",
    "    if run.config.get(\"_target_\", \"\").startswith(\"models.mae_artifact\") and \"descending\" in run.config:\n",
    "        descending = run.config.pop(\"descending\")\n",
    "        art_patch_usage = {}\n",
    "        art_patch_usage[\"type\"] = \"drop_low\" if descending else \"drop_high\"\n",
    "        art_patch_usage[\"value\"] = run.config[\"mask_ratio\"]\n",
    "        run.config[\"mask_ratio\"] = pre_name_to_mask_ratio[run.config[\"pre_model\"]]\n",
    "        run.config[\"art_patch_usage\"] = art_patch_usage\n",
    "        run.config[\"art_out_activation\"] = \"none\"\n",
    "        run.config[\"art_loss_type\"] = \"mse\"\n",
    "        run.config.update()\n",
    "        run.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbea4418-5df6-496a-9b7a-b4efc1113fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "runs = api.runs('tuab-mae-artifact-finetune')\n",
    "\n",
    "for run in runs:\n",
    "    if run.config.get(\"_target_\", \"\").startswith(\"models.mae_artifact\") and \"descending\" in run.config:\n",
    "        descending = run.config.pop(\"descending\")\n",
    "        art_patch_usage = {}\n",
    "        art_patch_usage[\"type\"] = \"drop_low\" if descending else \"drop_high\"\n",
    "        art_patch_usage[\"value\"] = run.config[\"mask_ratio\"]\n",
    "        run.config[\"mask_ratio\"] = pre_name_to_mask_ratio[run.config[\"pre_model\"]]\n",
    "        run.config[\"art_patch_usage\"] = art_patch_usage\n",
    "        run.config[\"art_out_activation\"] = \"none\"\n",
    "        run.config[\"art_loss_type\"] = \"mse\"\n",
    "        run.config.update()\n",
    "        run.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beadf401-1530-4ed4-9734-1f6ce5da5070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "print('PyTorch version:', torch.__version__)\n",
    "device = 'cuda:0'\n",
    "device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.')\n",
    "\n",
    "for f in tqdm(glob.glob(r\"./local/checkpoint/*/checkpoint.pt\")):\n",
    "    # load pretrained configurations\n",
    "    try:\n",
    "        ckpt = torch.load(f, map_location=device)\n",
    "        config = ckpt['config']\n",
    "        if config[\"_target_\"].startswith(\"models.mae_artifact\") and \"descending\" in config:\n",
    "            descending = config.pop(\"descending\")\n",
    "            art_patch_usage = {}\n",
    "            art_patch_usage[\"type\"] = \"drop_low\" if descending else \"drop_high\"\n",
    "            art_patch_usage[\"value\"] = run.config[\"mask_ratio\"]\n",
    "            config[\"mask_ratio\"] = pre_name_to_mask_ratio[config[\"pre_model\"]]\n",
    "            config[\"art_patch_usage\"] = art_patch_usage\n",
    "            config[\"art_out_activation\"] = \"none\"\n",
    "            config[\"art_loss_type\"] = \"mse\"\n",
    "            ckpt[\"config\"] = config\n",
    "            torch.save(ckpt, f)\n",
    "                        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'- checkpoint cannot be opened: {f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f05aa-a1c6-447e-98b6-b0f9b583c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_names = ['mwwzp6b1', 'q3fgkjoc', '3xg5i2z2', 'ccstq34j', 'emknf2qj',\n",
    "#              'hysvvul2', 'va9swnif', 'e7c3x7iz', 'uidjldyf', '353eu3zg',]\n",
    "\n",
    "# api = wandb.Api()\n",
    "\n",
    "# for run_name in run_names:\n",
    "#     run = api.run(f\"ipis-mjkim/caueeg-dementia/{run_name}\")\n",
    "    \n",
    "#     run.config['distil_type'] = 'hard'\n",
    "#     run.config['distil_alpha'] = run.config['distillation_ratio']\n",
    "#     del run.config['distillation_ratio']\n",
    "#     run.config['distil_tau'] = 1.0\n",
    "#     run.config['distil_teacher'] = run.config['teacher']['name']\n",
    "#     run.config['distil_teacher_criterion'] = run.config['teacher']['criterion']\n",
    "#     del run.config['teacher']\n",
    "    \n",
    "#     run.config.update()\n",
    "#     run.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc7504a-6138-4435-be6e-cfd30e022f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api = wandb.Api()\n",
    "# wandb.init(project='caueeg-task1', id='atbhqdgg', resume='must')\n",
    "# wandb.run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59af9c5-3a52-4026-932d-26fe0511570a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# api = wandb.Api()\n",
    "# runs = api.runs('ipis-mjkim/caueeg-task1')\n",
    "\n",
    "# for run in runs:\n",
    "#     # print(run, run.config['model'])\n",
    "#     # if run.name == '1tdyketc':\n",
    "#     if run.name == '18lkfaaw':\n",
    "#     # if run.state == \"finished\":\n",
    "#         print(run.name)\n",
    "\n",
    "#         confusion = np.array(run.summary['Confusion Matrix (Array)'])\n",
    "#         n_classes = confusion.shape[0]\n",
    "\n",
    "#         accuracy = np.zeros((n_classes,))\n",
    "#         sensitivity = np.zeros((n_classes,))\n",
    "#         specificity = np.zeros((n_classes,))\n",
    "#         precision = np.zeros((n_classes,))\n",
    "#         recall = np.zeros((n_classes,))\n",
    "#         f1_score = np.zeros((n_classes,))\n",
    "\n",
    "#         for c in range(n_classes):\n",
    "#             tp = confusion[c, c]\n",
    "#             fn = confusion[c].sum() - tp\n",
    "#             fp = confusion[:, c].sum() - tp\n",
    "#             tn = confusion.sum() - tp - fn - fp\n",
    "\n",
    "#             accuracy[c] = (tp + tn) / (tp + fn + fp + tn)\n",
    "#             sensitivity[c] = tp / (tp + fn)\n",
    "#             specificity[c] = tn / (fp + tn)\n",
    "#             precision[c] = tp / (tp + fp)\n",
    "#             recall[c] = tp / (tp + fn)\n",
    "\n",
    "#         f1_score = 2 * precision * recall / (precision + recall)\n",
    "        \n",
    "#         print(run.summary['Test Accuracy'])\n",
    "#         print('accuracy:', accuracy)\n",
    "#         print('sensitivity:', sensitivity)\n",
    "#         print('specificity:', specificity)\n",
    "#         print('precision:', precision)\n",
    "#         print('recall:', recall)\n",
    "#         print('f1_score:', f1_score)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587f9a40-9b28-44b7-a816-86b9a3cdf90d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# api = wandb.Api()\n",
    "# runs = api.runs('ipis-mjkim/eeg-analysis')\n",
    "\n",
    "# for run in runs:\n",
    "#     print(run)\n",
    "#     debug_table_serial = run.summary['Test Debug Table/Serial']\n",
    "#     debug_table_edf = run.summary['Test Debug Table/EDF']\n",
    "#     debug_table_pred = run.summary['Test Debug Table/Pred']\n",
    "#     debug_table_gt = run.summary['Test Debug Table/GT']\n",
    "    \n",
    "#     fig = plt.figure(num=1, clear=True, figsize=(20.0, 4.0), constrained_layout=True)\n",
    "#     ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "#     total_error, total_count = (0, 0)\n",
    "\n",
    "#     for edf in np.unique(debug_table_edf):\n",
    "#         indices = [i for i, x in enumerate(debug_table_edf) if x == edf]\n",
    "\n",
    "#         err, cnt = (0, 0)\n",
    "#         for i in indices:\n",
    "#             cnt += sum(debug_table_pred[i])\n",
    "#             err += sum(debug_table_pred[i]) - debug_table_pred[i][debug_table_gt[i]]\n",
    "\n",
    "#         total_error += err\n",
    "#         total_count += cnt\n",
    "\n",
    "#         ax.bar(edf, err / cnt, color=['g', 'b', 'r'][debug_table_gt[i]])\n",
    "\n",
    "#     ax.set_title(f'Test Debug Table (Acc. {1.0 - total_error / total_count: .2f}%)', fontsize=18)\n",
    "#     ax.set_ylim(0.0, 1.0)\n",
    "#     plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\", fontsize=9, visible=True)\n",
    "\n",
    "#     # run.summary['Test Debug Table (Image)'] = wandb.Image(plt)\n",
    "#     # run.summary.update()\n",
    "#     print(type(wandb.Image(plt)))\n",
    "#     run.summary.update({'Test Debug Table (Image)': wandb.Image(plt)})\n",
    "#     fig.clear()\n",
    "#     plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee764777-e413-4e21-82ae-1f1645a36808",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# api = wandb.Api()\n",
    "# run = api.run(\"ipis-mjkim/eeg-analysis/1nhn425l\")\n",
    "# print(run)\n",
    "\n",
    "# run.summary.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0bb5af-2350-4f9a-aada-802ce6f2cbd2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# api = wandb.Api()\n",
    "# runs = api.runs('ipis-mjkim/eeg-analysis')\n",
    "\n",
    "# for run in runs:\n",
    "#     print(run)\n",
    "#     if 'Age' in run.config:\n",
    "#         del run.config['Age']\n",
    "#         run.config.update()\n",
    "#         run.update()        \n",
    "    \n",
    "#     if 'no-age' not in run.config['model']:\n",
    "#         run.config['use_age'] = 'fc'\n",
    "#         run.config.update()\n",
    "#         run.update()\n",
    "#     else:\n",
    "#         run.config['use_age'] = None\n",
    "#         run.config.update()\n",
    "#         run.update()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f940f7-594d-44a0-9405-7a77060ac3d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# api = wandb.Api()\n",
    "# runs = api.runs('ipis-mjkim/eeg-analysis')\n",
    "\n",
    "# for run in runs:\n",
    "#     print(run)\n",
    "#     debug_table_serial = run.summary['Test Debug Table/Serial']\n",
    "#     debug_table_edf = run.summary['Test Debug Table/EDF']\n",
    "#     debug_table_pred = run.summary['Test Debug Table/Pred']\n",
    "#     debug_table_gt = run.summary['Test Debug Table/GT']\n",
    "    \n",
    "#     fig = plt.figure(num=1, clear=True, figsize=(20.0, 4.0), constrained_layout=True)\n",
    "#     ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "#     total_error, total_count = (0, 0)\n",
    "\n",
    "#     for edf in np.unique(debug_table_edf):\n",
    "#         indices = [i for i, x in enumerate(debug_table_edf) if x == edf]\n",
    "\n",
    "#         err, cnt = (0, 0)\n",
    "#         for i in indices:\n",
    "#             cnt += sum(debug_table_pred[i])\n",
    "#             err += sum(debug_table_pred[i]) - debug_table_pred[i][debug_table_gt[i]]\n",
    "\n",
    "#         total_error += err\n",
    "#         total_count += cnt\n",
    "\n",
    "#         ax.bar(edf, err / cnt, color=['g', 'b', 'r'][debug_table_gt[i]])\n",
    "\n",
    "#     ax.set_title(f'Test Debug Table (Acc. {1.0 - total_error / total_count: .2f}%)', fontsize=18)\n",
    "#     ax.set_ylim(0.0, 1.0)\n",
    "#     plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\", fontsize=9, visible=True)\n",
    "\n",
    "#     # run.summary['Test Debug Table (Image)'] = wandb.Image(plt)\n",
    "#     # run.summary.update()\n",
    "#     print(type(wandb.Image(plt)))\n",
    "#     run.summary.update({'Test Debug Table (Image)': wandb.Image(plt)})\n",
    "#     fig.clear()\n",
    "#     plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be56197-17b1-4b36-b9c3-0b625b31f28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaf2629-0448-472c-8214-31f3595d848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import torch\n",
    "# from tqdm.auto import tqdm\n",
    "# from run_train import generate_model\n",
    "\n",
    "# print('PyTorch version:', torch.__version__)\n",
    "# device = 'cuda:0'\n",
    "# device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# if torch.cuda.is_available(): print('cuda is available.')\n",
    "# else: print('cuda is unavailable.')\n",
    "\n",
    "# for f in tqdm(glob.glob(r\"D:\\GitHub\\eeg_analysis\\local\\checkpoint\\1udvls4y\\checkpoint.pt\")):\n",
    "#     # load pretrained configurations\n",
    "#     try:\n",
    "#         ckpt = torch.load(f, map_location=device)\n",
    "#         config = ckpt['config']\n",
    "#         if \"_target_\" in config.keys() and 'mae' in config[\"_target_\"] and 'mae_1d' not in config[\"_target_\"]:\n",
    "#             config[\"_target_\"] = config[\"_target_\"].replace('mae', 'mae_1d')\n",
    "#             ckpt['config'] = config\n",
    "#             torch.save(ckpt, f)\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         print(f'- checkpoint cannot be opened: {f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba9ff01-3a36-4de4-bd0f-15d719fa57fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import torch\n",
    "# from tqdm.auto import tqdm\n",
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# print('PyTorch version:', torch.__version__)\n",
    "# device = 'cuda:0'\n",
    "# device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# if torch.cuda.is_available(): print('cuda is available.')\n",
    "# else: print('cuda is unavailable.')\n",
    "\n",
    "# for f in tqdm(glob.glob(r\"D:\\GitHub\\eeg_analysis\\local\\checkpoint\\*\\checkpoint.pt\")):\n",
    "#     # load pretrained configurations\n",
    "#     try:\n",
    "#         ckpt = torch.load(f, map_location=device)\n",
    "#         config = ckpt['config']\n",
    "#         if config[\"dataset_name\"] == \"tuab\":\n",
    "#             print(os.path.dirname(f))\n",
    "#             shutil.rmtree(os.path.dirname(f))\n",
    "                        \n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         print(f'- checkpoint cannot be opened: {f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf86ad94-691d-4782-86a6-f55afda0cb70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
