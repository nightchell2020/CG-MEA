{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74515d5-5f25-477b-9a97-ed1f9b6d4c51",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluate Ensemble\n",
    "\n",
    "This notebook combines the classification results of some models via logit-ensembling way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a2666f-6b4b-4748-9dca-2884347a1f0f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df587e38-b1a9-42c8-9b50-680200a9bec7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bengb\\OneDrive\\문서\\GitHub\\eeg_analysis\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb41bf8-1713-4228-b799-0e1c87545a16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bengb\\anaconda3\\envs\\eeg_analysis\\lib\\site-packages\\torchaudio\\backend\\utils.py:66: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "import pprint\n",
    "import wandb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_script import build_dataset_for_train\n",
    "import models\n",
    "from train.evaluate import check_accuracy\n",
    "from train.evaluate import check_accuracy_extended\n",
    "from train.evaluate import check_accuracy_extended_debug\n",
    "from train.evaluate import check_accuracy_multicrop\n",
    "from train.evaluate import check_accuracy_multicrop_extended\n",
    "from train.evaluate import calculate_confusion_matrix\n",
    "from train.evaluate import calculate_class_wise_metrics\n",
    "from train.visualize import draw_roc_curve\n",
    "from train.visualize import draw_confusion\n",
    "from train.visualize import draw_class_wise_metrics\n",
    "from train.visualize import draw_error_table\n",
    "from train.visualize import annotate_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d10e3f39-ed55-422c-b47f-376691cbeed6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.11.0\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a62fa4-aa53-49d5-8ab4-2e2aaf7b65d1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "-----\n",
    "\n",
    "## List up the models to check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06d3404e-be31-4a63-ac4b-214868fe0cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lo88puq7']\n"
     ]
    }
   ],
   "source": [
    "model_names = [\n",
    "    'lo88puq7',\n",
    "    # '2s1700lg',\n",
    "    # 'v301o425',\n",
    "    # '1sl7ipca',\n",
    "    # 'gvqyvmrj',\n",
    "    # 'gjkysllw',\n",
    "    # 'xci5svkl',\n",
    "    # '1vc80n1f',\n",
    "    # 'syrx7bmk',\n",
    "]\n",
    "\n",
    "model_pool = []\n",
    "\n",
    "for model_name in model_names:\n",
    "    path = os.path.join(r'./local\\checkpoint', model_name, 'checkpoint.pt')\n",
    "    try:\n",
    "        ckpt = torch.load(path, map_location=device)\n",
    "        model_pool.append({'name': model_name, 'path': path})\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'- checkpoint cannot be opened: {path}')\n",
    "        \n",
    "pprint.pprint([model_dict['name'] for model_dict in model_pool])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00973b7-d2ba-4e54-a4ac-86879c1fe89f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7dfec22-3837-46a7-8b4d-4588300068bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_repeat = 500  # 500\n",
    "crop_multiple = 8\n",
    "test_crop_multiple = 8\n",
    "verbose = False\n",
    "save_fig = True\n",
    "task = 'exp-dementia'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e25ca9a-48ee-4c0d-8e06-616a84e59527",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Evaluate each model and accumulate the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bee4f853-3cad-4b01-8ee8-44ac9e49adbe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- checking for lo88puq7 2D-VGG-19 ...\n",
      "==== Finished ====\n"
     ]
    }
   ],
   "source": [
    "for model_dict in model_pool:\n",
    "    # load and parse the checkpoint\n",
    "    ckpt = torch.load(model_dict['path'], map_location=device)\n",
    "    model_state = ckpt['model_state']\n",
    "    config = ckpt['config']\n",
    "    \n",
    "    model_dict['model'] = config['model']\n",
    "    model_dict['num_params'] = config.get('num_params', '???')\n",
    "    model_dict['model size (MiB)'] = sys.getsizeof(pickle.dumps(model_state)) / (1024 * 1024)\n",
    "    # torch.save(model_state, 'temptemptemp.pt')\n",
    "    \n",
    "    model_dict['seq_length'] = config['seq_length']\n",
    "    model_dict['use_age'] = config['use_age']\n",
    "    model_dict['photic'] = config['photic']\n",
    "    model_dict['EKG'] = config['EKG']\n",
    "\n",
    "    model_dict['awgn'] = config.get('awgn', 0)\n",
    "    model_dict['awgn_age'] = config.get('awgn_age', 0)\n",
    "    model_dict['mgn'] = config.get('mgn', 0)\n",
    "    model_dict['mixup'] = config.get('mixup', 0)\n",
    "    model_dict['dropout'] = config.get('dropout', 0)\n",
    "    model_dict['weight_decay'] = config.get('weight_decay', '???')\n",
    "    model_dict['fc_stages'] = config.get('fc_stages', 1)\n",
    "    model_dict['activation'] = config.get('activation', 0)\n",
    "\n",
    "    model_dict['minibatch'] = round(config['minibatch'])\n",
    "    model_dict['total_samples'] = round(config.get('total_samples', config['iterations'] * config['minibatch']))\n",
    "    model_dict['base_lr'] = config.get('base_lr', config.get('LR', '???'))\n",
    "    model_dict['lr_scheduler_type'] = config.get('lr_scheduler_type', 'constant_with_decay')\n",
    "    model_dict['warmup_steps'] = config.get('warmup_steps', '???')\n",
    "    model_dict['seed'] = config.get('seed', '???')\n",
    "    \n",
    "    print('- checking for', model_dict['name'], config['model'], '...')\n",
    "    \n",
    "    # initiate the model\n",
    "    if '_target_' in config:\n",
    "        model = hydra.utils.instantiate(config).to(device)\n",
    "    elif type(config['generator']) is str:\n",
    "        config['generator'] = getattr(models, config['generator'].split('.')[-1])\n",
    "        if 'block' in config:\n",
    "            config['block'] = getattr(models, config['block'].split('.')[-1])\n",
    "        model = config['generator'](**config).to(device)\n",
    "    else:\n",
    "        if 'block' in config:\n",
    "            if config['block'] == models.resnet_1d.BottleneckBlock1D:\n",
    "                config['block'] = 'bottleneck'\n",
    "            elif config['block'] == models.resnet_2d.Bottleneck2D:\n",
    "                config['block'] = 'bottleneck'\n",
    "            elif config['block'] == models.resnet_1d.BasicBlock1D:\n",
    "                config['block'] = 'basic'\n",
    "            elif config['block'] == models.resnet_2d.BasicBlock2D:\n",
    "                config['block'] = 'basic'\n",
    "                \n",
    "        model = config['generator'](**config).to(device)\n",
    "    \n",
    "    if config.get('ddp', False):\n",
    "        model_state_ddp = deepcopy(model_state)\n",
    "        model_state = OrderedDict()\n",
    "        for k, v in model_state_ddp.items():\n",
    "            name = k[7:]  # remove 'module.' of DataParallel/DistributedDataParallel\n",
    "            model_state[name] = v\n",
    "    \n",
    "    model.load_state_dict(model_state)\n",
    "    \n",
    "    # reconfigure and update\n",
    "    config.pop('cwd', 0)\n",
    "    config['ddp'] = False\n",
    "    config['crop_multiple'] = crop_multiple\n",
    "    config['test_crop_multiple'] = test_crop_multiple\n",
    "    config['crop_timing_analysis'] = False\n",
    "    config['eval'] = True\n",
    "    config['device'] = device\n",
    "    \n",
    "    repeat = round(base_repeat / crop_multiple)\n",
    "    model_dict['repeat'] = repeat\n",
    "    model_dict['crop_multiple'] = crop_multiple\n",
    "    model_dict['test_crop_multiple'] = test_crop_multiple\n",
    "    \n",
    "    # build dataset\n",
    "    _ = build_dataset_for_train(config, verbose=verbose)\n",
    "    train_loader = _[0]\n",
    "    val_loader = _[1]\n",
    "    test_loader = _[2]\n",
    "    multicrop_test_loader = _[3]\n",
    "    \n",
    "    # train accuracy\n",
    "    train_acc = check_accuracy(model, train_loader, \n",
    "                               config['preprocess_test'], config, repeat=repeat)\n",
    "    model_dict['Train Accuracy'] = train_acc\n",
    "    \n",
    "    # val accuracy\n",
    "    val_acc = check_accuracy(model, val_loader, \n",
    "                             config['preprocess_test'], config, repeat=repeat)\n",
    "    model_dict['Validation Accuracy'] = val_acc\n",
    "    \n",
    "    # Test accuracy\n",
    "    _ = check_accuracy_extended(model, test_loader, \n",
    "                                config['preprocess_test'], config, repeat=repeat)\n",
    "    model_dict['Test Throughput'] = _[4]\n",
    "    model_dict['Test Accuracy'] = _[0]\n",
    "    model_dict['Test Score'] = _[1]\n",
    "    model_dict['Test Target'] = _[2]\n",
    "    test_confusion = _[3]\n",
    "    test_class_wise_metrics = calculate_class_wise_metrics(test_confusion)\n",
    "    \n",
    "    for k, v in test_class_wise_metrics.items():\n",
    "        for c in range(config['out_dims']):\n",
    "            c_name = config['class_label_to_name'][c]\n",
    "            model_dict[f'{k} ({c_name})'] = test_class_wise_metrics[k][c]\n",
    "            \n",
    "    if save_fig:\n",
    "        draw_roc_curve(model_dict['Test Score'], \n",
    "                       model_dict['Test Target'], \n",
    "                       config['class_label_to_name'], \n",
    "                       use_wandb=False, \n",
    "                       save_path=f'local/output/imgs/{model_dict[\"name\"]}-ROC.pdf')\n",
    "\n",
    "        draw_confusion(test_confusion, \n",
    "                       config['class_label_to_name'], \n",
    "                       use_wandb=False, \n",
    "                       save_path=f'local/output/imgs/{model_dict[\"name\"]}-confusion.pdf')\n",
    "\n",
    "        draw_class_wise_metrics(test_confusion, \n",
    "                                config['class_label_to_name'], \n",
    "                                use_wandb=False, \n",
    "                                save_path=f'local/output/imgs/{model_dict[\"name\"]}-class-wise.pdf')    \n",
    "    # Multi-crop test accuracy\n",
    "    _ = check_accuracy_multicrop_extended(model, multicrop_test_loader, \n",
    "                                          config['preprocess_test'], config, repeat=repeat)\n",
    "    model_dict['Multi-Crop Test Throughput'] = _[4]\n",
    "    model_dict['Multi-Crop Test Accuracy'] = _[0]\n",
    "    model_dict['Multi-Crop Test Score'] = _[1]\n",
    "    model_dict['Multi-Crop Test Target'] = _[2]\n",
    "    multi_test_confusion = _[3]\n",
    "    multi_test_class_wise_metrics = calculate_class_wise_metrics(multi_test_confusion)\n",
    "    \n",
    "    for k, v in multi_test_class_wise_metrics.items():\n",
    "        for c in range(config['out_dims']):\n",
    "            c_name = config['class_label_to_name'][c]\n",
    "            model_dict[f'Multi-Crop {k} ({c_name})'] = multi_test_class_wise_metrics[k][c]\n",
    "            \n",
    "    if save_fig:\n",
    "        draw_roc_curve(model_dict['Multi-Crop Test Score'], \n",
    "                       model_dict['Multi-Crop Test Target'], \n",
    "                       config['class_label_to_name'], \n",
    "                       use_wandb=False, \n",
    "                       save_path=f'local/output/imgs/{model_dict[\"name\"]}-roc-tta.pdf')\n",
    "\n",
    "        draw_confusion(multi_test_confusion, \n",
    "                       config['class_label_to_name'], \n",
    "                       use_wandb=False, \n",
    "                       save_path=f'local/output/imgs/{model_dict[\"name\"]}-confusion-tta.pdf')\n",
    "\n",
    "        draw_class_wise_metrics(multi_test_confusion, \n",
    "                                config['class_label_to_name'], \n",
    "                                use_wandb=False, \n",
    "                                save_path=f'local/output/imgs/{model_dict[\"name\"]}-class-wise-tta.pdf') \n",
    "            \n",
    "print('==== Finished ====')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f20c63-6d13-47a3-b6d5-8cbf89b5b25e",
   "metadata": {},
   "source": [
    "## Conduct ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3343a302-6361-49db-b31e-68f5b43f98b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_test_score = np.zeros_like(model_pool[0]['Test Score'])\n",
    "ensemble_multi_test_score = np.zeros_like(model_pool[0]['Multi-Crop Test Score'])\n",
    "\n",
    "ensemble_test_latency = 0\n",
    "ensemble_multi_test_latency = 0\n",
    "\n",
    "ensemble_params = 0\n",
    "ensemble_model_size = 0\n",
    "\n",
    "for model_dict in model_pool:\n",
    "    ensemble_test_score += model_dict['Test Score'] / len(model_pool)\n",
    "    ensemble_multi_test_score += model_dict['Multi-Crop Test Score'] / len(model_pool)\n",
    "    \n",
    "    ensemble_test_latency += 1 / model_dict['Test Throughput']\n",
    "    ensemble_multi_test_latency += 1 / model_dict['Multi-Crop Test Throughput']\n",
    "    \n",
    "    ensemble_params += model_dict['num_params']\n",
    "    ensemble_model_size += model_dict['model size (MiB)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "412e7fa3-c13f-4b40-bf4a-74c029c1a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble accuracy\n",
    "pred = ensemble_test_score.argmax(axis=-1)\n",
    "ensemble_test_acc = 100.0 * (pred.squeeze() == model_pool[0]['Test Target']).sum() / pred.shape[0]\n",
    "\n",
    "# class wise metrics\n",
    "ensemble_test_confusion = calculate_confusion_matrix(pred, model_pool[0]['Test Target'], \n",
    "                                                     num_classes=ensemble_test_score.shape[-1])\n",
    "ensembel_test_class_wise_metrics = calculate_class_wise_metrics(ensemble_test_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "849eb54a-909d-4261-99fc-49de781583f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-crop accuracy\n",
    "pred = ensemble_multi_test_score.argmax(axis=-1)\n",
    "ensemble_multi_test_acc = 100.0 * (pred.squeeze() == model_pool[0]['Multi-Crop Test Target']).sum() / pred.shape[0]\n",
    "\n",
    "# class wise metrics\n",
    "ensemble_multi_test_confusion = calculate_confusion_matrix(pred, model_pool[0]['Multi-Crop Test Target'], \n",
    "                                                           num_classes=ensemble_multi_test_score.shape[-1])\n",
    "ensembel_multi_test_class_wise_metrics = calculate_class_wise_metrics(ensemble_multi_test_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e5fc9c-d890-4050-a844-ecd2a0e7791e",
   "metadata": {},
   "source": [
    "## Visualize the ensemble results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c046bc5e-8b28-4c2c-941a-490a809b57dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw\n",
    "save_path = f'local/output/imgs/{task}-ensemble-roc.pdf' if save_fig else None\n",
    "draw_roc_curve(ensemble_test_score, model_pool[0]['Test Target'], config['class_label_to_name'], \n",
    "               use_wandb=False, save_path=save_path)\n",
    "\n",
    "save_path = f'local/output/imgs/{task}-ensemble-confusion.pdf' if save_fig else None\n",
    "draw_confusion(ensemble_test_confusion, config['class_label_to_name'], \n",
    "               normalize=True, use_wandb=False, save_path=save_path)\n",
    "\n",
    "save_path = f'local/output/imgs/{task}-ensemble-class-wise.pdf' if save_fig else None\n",
    "draw_class_wise_metrics(ensemble_test_confusion, config['class_label_to_name'], \n",
    "                        use_wandb=False, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0289203-64f9-409f-83aa-d22327e1711b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Text' object has no property 'text_face'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m draw_roc_curve(ensemble_multi_test_score, model_pool[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMulti-Crop Test Target\u001b[39m\u001b[38;5;124m'\u001b[39m], config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_label_to_name\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m      4\u001b[0m                use_wandb\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, save_path\u001b[38;5;241m=\u001b[39msave_path)\n\u001b[0;32m      6\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal/output/imgs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-ensemble-confusion-tta.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m save_fig \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mdraw_confusion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensemble_multi_test_confusion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass_label_to_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m               \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal/output/imgs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-ensemble-class-wise-tta.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m save_fig \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     11\u001b[0m draw_class_wise_metrics(ensemble_multi_test_confusion, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_label_to_name\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m     12\u001b[0m                         use_wandb\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, save_path\u001b[38;5;241m=\u001b[39msave_path)\n",
      "File \u001b[1;32m~\\OneDrive\\문서\\GitHub\\eeg_analysis\\train\\visualize.py:241\u001b[0m, in \u001b[0;36mdraw_confusion\u001b[1;34m(confusion, class_label_to_name, normalize, use_wandb, save_path)\u001b[0m\n\u001b[0;32m    237\u001b[0m     data \u001b[38;5;241m=\u001b[39m confusion \u001b[38;5;241m/\u001b[39m confusion\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    238\u001b[0m     im \u001b[38;5;241m=\u001b[39m draw_heatmap(data, class_label_to_name, class_label_to_name,\n\u001b[0;32m    239\u001b[0m                       ax\u001b[38;5;241m=\u001b[39max, imshow_kw\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcmap\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYlOrRd\u001b[39m\u001b[38;5;124m\"\u001b[39m},  \u001b[38;5;66;03m# jet, YlOrRd, RdPu\u001b[39;00m\n\u001b[0;32m    240\u001b[0m                       draw_cbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, cbar_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, cbar_kw\u001b[38;5;241m=\u001b[39m{})\n\u001b[1;32m--> 241\u001b[0m     \u001b[43mannotate_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manno_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{x:.2f}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_colors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblack\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mface\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbold\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m     annotate_heatmap(im, data\u001b[38;5;241m=\u001b[39mconfusion, data_for_color\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m    244\u001b[0m                      anno_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{x:d}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m, text_colors\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    245\u001b[0m                      threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m, text_kw\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmall\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m    247\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfusion Matrix\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\OneDrive\\문서\\GitHub\\eeg_analysis\\train\\visualize.py:220\u001b[0m, in \u001b[0;36mannotate_heatmap\u001b[1;34m(im, data, data_for_color, anno_format, text_colors, threshold, text_kw)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m    219\u001b[0m     kw\u001b[38;5;241m.\u001b[39mupdate(color\u001b[38;5;241m=\u001b[39mtext_colors[\u001b[38;5;28mint\u001b[39m(im\u001b[38;5;241m.\u001b[39mnorm(data_for_color[i, j]) \u001b[38;5;241m>\u001b[39m threshold)])\n\u001b[1;32m--> 220\u001b[0m     im\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mtext(j, i, anno_format(data[i, j], \u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg_analysis\\lib\\site-packages\\matplotlib\\axes\\_axes.py:659\u001b[0m, in \u001b[0;36mAxes.text\u001b[1;34m(self, x, y, s, fontdict, **kwargs)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;124;03mAdd text to the Axes.\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;124;03m    >>> text(x, y, s, bbox=dict(facecolor='red', alpha=0.5))\u001b[39;00m\n\u001b[0;32m    650\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    651\u001b[0m effective_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    652\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverticalalignment\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbaseline\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    653\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhorizontalalignment\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    658\u001b[0m }\n\u001b[1;32m--> 659\u001b[0m t \u001b[38;5;241m=\u001b[39m mtext\u001b[38;5;241m.\u001b[39mText(x, y, text\u001b[38;5;241m=\u001b[39ms, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39meffective_kwargs)\n\u001b[0;32m    660\u001b[0m t\u001b[38;5;241m.\u001b[39mset_clip_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch)\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_text(t)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg_analysis\\lib\\site-packages\\matplotlib\\text.py:160\u001b[0m, in \u001b[0;36mText.__init__\u001b[1;34m(self, x, y, text, color, verticalalignment, horizontalalignment, multialignment, fontproperties, rotation, linespacing, rotation_mode, usetex, wrap, transform_rotates_text, parse_math, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_linespacing \u001b[38;5;241m=\u001b[39m linespacing\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_rotation_mode(rotation_mode)\n\u001b[1;32m--> 160\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg_analysis\\lib\\site-packages\\matplotlib\\text.py:172\u001b[0m, in \u001b[0;36mText.update\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# Update bbox last, as it depends on font properties.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m bbox \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m\"\u001b[39m, sentinel)\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sentinel:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bbox(bbox)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\eeg_analysis\\lib\\site-packages\\matplotlib\\artist.py:1064\u001b[0m, in \u001b[0;36mArtist.update\u001b[1;34m(self, props)\u001b[0m\n\u001b[0;32m   1062\u001b[0m             func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1063\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(func):\n\u001b[1;32m-> 1064\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1065\u001b[0m                                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas no property \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1066\u001b[0m             ret\u001b[38;5;241m.\u001b[39mappend(func(v))\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Text' object has no property 'text_face'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 350x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw\n",
    "save_path = f'local/output/imgs/{task}-ensemble-roc-tta.pdf' if save_fig else None\n",
    "draw_roc_curve(ensemble_multi_test_score, model_pool[0]['Multi-Crop Test Target'], config['class_label_to_name'], \n",
    "               use_wandb=False, save_path=save_path)\n",
    "\n",
    "save_path = f'local/output/imgs/{task}-ensemble-confusion-tta.pdf' if save_fig else None\n",
    "draw_confusion(ensemble_multi_test_confusion, config['class_label_to_name'], \n",
    "               normalize=True, use_wandb=False, save_path=save_path)\n",
    "\n",
    "save_path = f'local/output/imgs/{task}-ensemble-class-wise-tta.pdf' if save_fig else None\n",
    "draw_class_wise_metrics(ensemble_multi_test_confusion, config['class_label_to_name'], \n",
    "                        use_wandb=False, save_path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82fdfdb-b237-409a-b896-12d8c5118159",
   "metadata": {},
   "source": [
    "## Summarize the ensemble results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d045fb8c-2a4f-4c84-b3d5-a688e079fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_dict = {}\n",
    "\n",
    "ensemble_dict['name'] = 'Ensemble'\n",
    "ensemble_dict['Test Throughput'] = 1 / ensemble_test_latency\n",
    "ensemble_dict['Test Accuracy'] = ensemble_test_acc\n",
    "ensemble_dict['Multi-Crop Test Throughput'] = 1 / ensemble_multi_test_latency\n",
    "ensemble_dict['Multi-Crop Test Accuracy'] = ensemble_multi_test_acc\n",
    "ensemble_dict['num_params'] = ensemble_params\n",
    "ensemble_dict['model size (MiB)'] = ensemble_model_size\n",
    "\n",
    "for k, v in ensembel_test_class_wise_metrics.items():\n",
    "    for c in range(config['out_dims']):\n",
    "        c_name = config['class_label_to_name'][c]\n",
    "        ensemble_dict[f'{k} ({c_name})'] = ensembel_test_class_wise_metrics[k][c]\n",
    "        \n",
    "for k, v in ensembel_multi_test_class_wise_metrics.items():\n",
    "    for c in range(config['out_dims']):\n",
    "        c_name = config['class_label_to_name'][c]\n",
    "        ensemble_dict[f'Multi-Crop {k} ({c_name})'] = ensembel_multi_test_class_wise_metrics[k][c]\n",
    "        \n",
    "model_pool.append(ensemble_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f973f6-b799-4ba5-9258-9eee4f2f88ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_dict in model_pool:\n",
    "    model_dict.pop('Test Score', None)\n",
    "    model_dict.pop('Test Target', None)\n",
    "    model_dict.pop('Multi-Crop Test Score', None)\n",
    "    model_dict.pop('Multi-Crop Test Target', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ae7d8-ac60-42ad-b852-c38d3d52987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfabea6-e56f-4f29-8027-cb290a3d2d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_pool).to_csv(f'local/output/{task}-ensemble.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18fd432-14fc-4771-a203-3e705537685a",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
