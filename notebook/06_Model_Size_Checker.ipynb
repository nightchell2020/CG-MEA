{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f6e9da6-f6ce-4bbf-aff0-3b456a825784",
   "metadata": {},
   "source": [
    "# Model Size Checker\n",
    "\n",
    "This notebook builds up the various models in the standard EEG classification environments, measure their GPU usage, and check the proper minibatch sizes for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e031bea-5b21-4e5b-b20d-1ea7ef892640",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5eae6f5-87aa-4325-9522-b7d7ffd679b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minjae\\Desktop\\EEG_Project\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d6e389-787c-4ace-a759-dd2c017864d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import glob\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import pprint\n",
    "import torch\n",
    "from torchsummaryX import summary\n",
    "\n",
    "# custom package\n",
    "from run_train import check_device_env\n",
    "from datasets.caueeg_script import build_dataset_for_train\n",
    "from models.utils import count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e476d0a-34af-4cfa-b277-b0b7bd97fa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24470421504, 25769148416)\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(torch.cuda.mem_get_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4d0301-fb95-44ef-b1c1-08e2d5a53350",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Default settings and all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad3d289-f4bb-45ab-bc11-d82f6ea0d06d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = 'no_wandb'\n",
    "data_cfg_file = 'task2'\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa4fd3c-13ad-4069-96ea-e15f251177c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [os.path.basename(full_path)[:-5] for full_path in glob.glob('./config/model/*.yaml')]\n",
    "model_names = [m for m in model_names if 'base' not in m.lower()]\n",
    "pprint.pprint(model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ded77d-0ac4-43ba-aa47-71e6f617eba7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Checking Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc6dc30-5062-4d5b-80c3-63826490dac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_size_dict = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    with hydra.initialize(config_path='../config'):\n",
    "        add_configs = [f\"data={data_cfg_file}\",\n",
    "                       f\"data.input_norm=no\",\n",
    "                       f\"+data.age_mean=1.0\",\n",
    "                       f\"+data.age_std=1.0\",\n",
    "                       f\"train={train}\",\n",
    "                       f\"+train.device={device}\", \n",
    "                       f\"model={model_name}\"]\n",
    "\n",
    "        cfg = hydra.compose(config_name='default', overrides=add_configs)\n",
    "\n",
    "    config = {**OmegaConf.to_container(cfg.data), \n",
    "              **OmegaConf.to_container(cfg.train),\n",
    "              **OmegaConf.to_container(cfg.model)}\n",
    "\n",
    "    # pprint.pprint(config)\n",
    "    check_device_env(config)\n",
    "    \n",
    "    train_loader, val_loader, test_loader, multicrop_test_loader = build_dataset_for_train(config)    \n",
    "    model = hydra.utils.instantiate(config).to(config['device'])\n",
    "    model_size_dict[model_name] = count_parameters(model)\n",
    "    \n",
    "    # print('\\n\\n')\n",
    "    # x = config['preprocess_train'](next(iter(train_loader)))\n",
    "    # summary(model, x['signal'], x['age'])\n",
    "    \n",
    "pprint.pprint(model_size_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8921aa-f3aa-413f-a153-bffd1c87fb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e8b0db-f554-4123-bdbb-eb0f1c44dedb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
