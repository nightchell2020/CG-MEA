{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Dataset and DataLoader\n",
    "\n",
    "This notebook loads the `CAUEEG` dataset, tests some useful preprocessing, and makes up the PyTorch DataLoader instances for the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minjae\\Desktop\\EEG_Project\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_dataset import *\n",
    "from datasets.caueeg_script import *\n",
    "from datasets.pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.12.1+cu113\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Data file path\n",
    "data_path = r'local/dataset/caueeg-dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\tdataset_name:\n",
      "\t\tCAUEEG dataset\n",
      "\n",
      "\tsignal_header:\n",
      "\t\tFp1-AVG\n",
      "\t\tF3-AVG\n",
      "\t\tC3-AVG\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\tPhotic\n",
      "\n",
      "\tdata:\n",
      "\t\t{'serial': '00001', 'age': 78, 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf']}\n",
      "\t\t{'serial': '00002', 'age': 56, 'symptom': ['normal', 'smi']}\n",
      "\t\t{'serial': '00003', 'age': 93, 'symptom': ['mci', 'mci_vascular']}\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t{'serial': '01388', 'age': 73, 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_ef']}\n",
      "\n",
      "}\n",
      "{\n",
      "\ttask_name:\n",
      "\t\tCAUEEG-Abnormal benchmark\n",
      "\n",
      "\ttask_description:\n",
      "\t\tClassification of [Normal] and [Abnormal] symptoms\n",
      "\n",
      "\tclass_label_to_name:\n",
      "\t\t['Normal', 'Abnormal']\n",
      "\n",
      "\tclass_name_to_label:\n",
      "\t\t{'Normal': 0, 'Abnormal': 1}\n",
      "\n",
      "\ttrain_split:\n",
      "\t\t{'serial': '01258', 'age': 77, 'symptom': ['dementia', 'vd', 'sivd'], 'class_name': 'Abnormal', 'class_label': 1}\n",
      "\t\t{'serial': '00836', 'age': 80, 'symptom': ['normal', 'smi'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\t\t{'serial': '00761', 'age': 75, 'symptom': ['dementia', 'ad', 'load'], 'class_name': 'Abnormal', 'class_label': 1}\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t{'serial': '00105', 'age': 71, 'symptom': ['normal', 'smi'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\n",
      "\tvalidation_split:\n",
      "\t\t{'serial': '00152', 'age': 81, 'symptom': ['dementia', 'ad', 'load'], 'class_name': 'Abnormal', 'class_label': 1}\n",
      "\t\t{'serial': '01034', 'age': 81, 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_ef'], 'class_name': 'Abnormal', 'class_label': 1}\n",
      "\t\t{'serial': '00296', 'age': 71, 'symptom': ['tga'], 'class_name': 'Abnormal', 'class_label': 1}\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t{'serial': '00684', 'age': 65, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\n",
      "\ttest_split:\n",
      "\t\t{'serial': '00560', 'age': 57, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\t\t{'serial': '01156', 'age': 62, 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf'], 'class_name': 'Abnormal', 'class_label': 1}\n",
      "\t\t{'serial': '00098', 'age': 62, 'symptom': ['normal', 'smi'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t{'serial': '00888', 'age': 52, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\n",
      "}\n",
      "{\n",
      "\ttask_name:\n",
      "\t\tCAUEEG-Dementia benchmark\n",
      "\n",
      "\ttask_description:\n",
      "\t\tClassification of [Normal], [MCI], and [Dementia] symptoms.\n",
      "\n",
      "\tclass_label_to_name:\n",
      "\t\t['Normal', 'MCI', 'Dementia']\n",
      "\n",
      "\tclass_name_to_label:\n",
      "\t\t{'Normal': 0, 'MCI': 1, 'Dementia': 2}\n",
      "\n",
      "\ttrain_split:\n",
      "\t\t{'serial': '00587', 'age': 53, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\t\t{'serial': '01301', 'age': 88, 'symptom': ['dementia', 'ad', 'load'], 'class_name': 'Dementia', 'class_label': 2}\n",
      "\t\t{'serial': '00781', 'age': 68, 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf'], 'class_name': 'MCI', 'class_label': 1}\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t{'serial': '00153', 'age': 64, 'symptom': ['mci', 'mci_non_amnestic'], 'class_name': 'MCI', 'class_label': 1}\n",
      "\n",
      "\tvalidation_split:\n",
      "\t\t{'serial': '00341', 'age': 80, 'symptom': ['dementia', 'ad', 'load'], 'class_name': 'Dementia', 'class_label': 2}\n",
      "\t\t{'serial': '00510', 'age': 82, 'symptom': ['dementia', 'vd', 'sivd'], 'class_name': 'Dementia', 'class_label': 2}\n",
      "\t\t{'serial': '00172', 'age': 86, 'symptom': ['mci', 'mci_amnestic'], 'class_name': 'MCI', 'class_label': 1}\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t{'serial': '01303', 'age': 52, 'symptom': ['normal', 'smi'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\n",
      "\ttest_split:\n",
      "\t\t{'serial': '00789', 'age': 62, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\t\t{'serial': '00934', 'age': 61, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\t\t{'serial': '00142', 'age': 70, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t.\n",
      "\t\t{'serial': '00520', 'age': 55, 'symptom': ['normal', 'smi'], 'class_name': 'Normal', 'class_label': 0}\n",
      "\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for task in ['annotation.json', 'abnormal.json', 'dementia.json']:\n",
    "    task_path = os.path.join(data_path, task)\n",
    "    with open(task_path, 'r') as json_file:\n",
    "        task_dict = json.load(json_file)\n",
    "        \n",
    "    print('{')\n",
    "    for k, v in task_dict.items():\n",
    "        print(f'\\t{k}:')\n",
    "        if isinstance(v, list) and len(v) > 3:\n",
    "            print(f'\\t\\t{v[0]}')\n",
    "            print(f'\\t\\t{v[1]}')\n",
    "            print(f'\\t\\t{v[2]}')\n",
    "            print(f'\\t\\t.')\n",
    "            print(f'\\t\\t.')\n",
    "            print(f'\\t\\t.')\n",
    "            print(f'\\t\\t{v[-1]}')\n",
    "        else:\n",
    "            print(f'\\t\\t{v}')\n",
    "        print()\n",
    "    print('}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load the CAUEEG dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load the whole CAUEEG data as a PyTorch dataset instance without considering the target task (no train/val/test sets and no class label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_name': 'CAUEEG dataset',\n",
      " 'signal_header': ['Fp1-AVG', 'F3-AVG', 'C3-AVG', 'P3-AVG', 'O1-AVG', 'Fp2-AVG', 'F4-AVG', 'C4-AVG', 'P4-AVG', 'O2-AVG', 'F7-AVG', 'T3-AVG', 'T5-AVG', 'F8-AVG', 'T4-AVG', 'T6-AVG', 'FZ-AVG', 'CZ-AVG', 'PZ-AVG', 'EKG', 'Photic']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 78,\n",
      " 'serial': '00001',\n",
      " 'signal': array([[  0., -11., -13., ...,   0.,   0.,   0.],\n",
      "       [ 29.,  33.,  34., ...,   0.,   0.,   0.],\n",
      "       [ -3.,  -6.,  -3., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ -4.,  -2.,   1., ...,   0.,   0.,   0.],\n",
      "       [112.,  67.,  76., ...,   0.,   0.,   0.],\n",
      "       [ -1.,  -1.,  -1., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 56,\n",
      " 'serial': '00002',\n",
      " 'signal': array([[  39.,   58.,   72., ...,    0.,    0.,    0.],\n",
      "       [   4.,   12.,   13., ...,    0.,    0.,    0.],\n",
      "       [   1.,   -2.,   -3., ...,    0.,    0.,    0.],\n",
      "       ...,\n",
      "       [   2.,    1.,    1., ...,    0.,    0.,    0.],\n",
      "       [ -22., -173., -175., ...,    0.,    0.,    0.],\n",
      "       [   2.,    0.,    0., ...,    0.,    0.,    0.]]),\n",
      " 'symptom': ['normal', 'smi']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         load_event=False, \n",
    "                                                         file_format='edf',\n",
    "                                                         transform=None)\n",
    "\n",
    "pprint.pprint(config_data, width=250)\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(full_eeg_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(full_eeg_dataset[1])\n",
    "print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load the CAUEEG task1 datasets as the PyTorch dataset instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_label_to_name': ['Normal', 'Abnormal'],\n",
      " 'class_name_to_label': {'Abnormal': 1, 'Normal': 0},\n",
      " 'task_description': 'Classification of [Normal] and [Abnormal] symptoms',\n",
      " 'task_name': 'CAUEEG-Abnormal benchmark'}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 77,\n",
      " 'class_label': 1,\n",
      " 'class_name': 'Abnormal',\n",
      " 'serial': '01258',\n",
      " 'signal': array([[ 3., -1., -5., ...,  0.,  0.,  0.],\n",
      "       [ 7., 15.,  9., ...,  0.,  0.,  0.],\n",
      "       [-6., -5., -3., ...,  0.,  0.,  0.],\n",
      "       ...,\n",
      "       [ 4.,  6.,  5., ...,  0.,  0.,  0.],\n",
      "       [62., 54., 53., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1., ...,  0.,  0.,  0.]]),\n",
      " 'symptom': ['dementia', 'vd', 'sivd']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 81,\n",
      " 'class_label': 1,\n",
      " 'class_name': 'Abnormal',\n",
      " 'serial': '00152',\n",
      " 'signal': array([[ 14.,  10.,   2., ...,   0.,   0.,   0.],\n",
      "       [  8.,   6.,   0., ...,   0.,   0.,   0.],\n",
      "       [  9.,  10.,   2., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [  8.,  10.,   1., ...,   0.,   0.,   0.],\n",
      "       [166., 505., 512., ...,   0.,   0.,   0.],\n",
      "       [ -1.,   0.,   0., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['dementia', 'ad', 'load']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 57,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00560',\n",
      " 'signal': array([[  7.,  41.,  49., ...,   0.,   0.,   0.],\n",
      "       [ 23.,  26.,  27., ...,   0.,   0.,   0.],\n",
      "       [-16., -20., -18., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ 32.,  31.,  31., ...,   0.,   0.,   0.],\n",
      "       [177., 228., 142., ...,   0.,   0.,   0.],\n",
      "       [  0.,  -1.,   0., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['normal', 'cb_normal']}\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf', \n",
    "                                                                                  transform=None)\n",
    "pprint.pprint(config_data)\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(train_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(val_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load the CAUEEG task2 datasets as the PyTorch dataset instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_label_to_name': ['Normal', 'MCI', 'Dementia'],\n",
      " 'class_name_to_label': {'Dementia': 2, 'MCI': 1, 'Normal': 0},\n",
      " 'task_description': 'Classification of [Normal], [MCI], and [Dementia] '\n",
      "                     'symptoms.',\n",
      " 'task_name': 'CAUEEG-Dementia benchmark'}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 53,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00587',\n",
      " 'signal': array([[30., 15., 18., ...,  0.,  0.,  0.],\n",
      "       [-3.,  4.,  5., ...,  0.,  0.,  0.],\n",
      "       [-2.,  7.,  8., ...,  0.,  0.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  5.,  7., ...,  0.,  0.,  0.],\n",
      "       [27., 27., 34., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0., -1., ...,  0.,  0.,  0.]]),\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 80,\n",
      " 'class_label': 2,\n",
      " 'class_name': 'Dementia',\n",
      " 'serial': '00341',\n",
      " 'signal': array([[ -9.,  -2.,  -3., ...,   0.,   0.,   0.],\n",
      "       [ -4.,  -7.,  -6., ...,   0.,   0.,   0.],\n",
      "       [ -2., -10., -11., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [-27., -30., -30., ...,   0.,   0.,   0.],\n",
      "       [-14.,   3., -14., ...,   0.,   0.,   0.],\n",
      "       [  0.,  -2.,  -3., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['dementia', 'ad', 'load']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 62,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00789',\n",
      " 'signal': array([[-87., -69., -70., ...,   0.,   0.,   0.],\n",
      "       [-25., -18., -19., ...,   0.,   0.,   0.],\n",
      "       [ -6.,   1.,   0., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [  0.,  -5.,  -4., ...,   0.,   0.,   0.],\n",
      "       [-31.,  -8.,  -7., ...,   0.,   0.,   0.],\n",
      "       [  0.,   1.,  -1., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['normal', 'cb_normal']}\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf', \n",
    "                                                                                  transform=None)\n",
    "pprint.pprint(config_data)\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(train_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(val_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [367, 740] 1107\n",
      "val [46, 90] 136\n",
      "test [46, 90] 136\n",
      "\n",
      "total [459, 920] 1379\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap', \n",
    "                                                                                  transform=None)\n",
    "\n",
    "num_train = [0, 0]\n",
    "for d in train_dataset:\n",
    "    num_train[d['class_label']] += 1\n",
    "print('train', num_train, sum(num_train))\n",
    "\n",
    "num_val = [0, 0]\n",
    "for d in val_dataset:\n",
    "    num_val[d['class_label']] += 1\n",
    "print('val', num_val, sum(num_val))\n",
    "        \n",
    "num_test = [0, 0]\n",
    "for d in test_dataset:\n",
    "    num_test[d['class_label']] += 1\n",
    "print('test', num_test, sum(num_test))\n",
    "           \n",
    "print()\n",
    "print('total', [num1 + num2 + num3 for num1, num2, num3 in zip(num_train, num_val, num_test)], sum(num_train + num_val + num_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [367, 334, 249] 950\n",
      "val [46, 42, 31] 119\n",
      "test [46, 41, 31] 118\n",
      "\n",
      "total [459, 417, 311] 1187\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap', \n",
    "                                                                                  transform=None)\n",
    "\n",
    "num_train = [0, 0, 0]\n",
    "for d in train_dataset:\n",
    "    num_train[d['class_label']] += 1\n",
    "print('train', num_train, sum(num_train))\n",
    "\n",
    "num_val = [0, 0, 0]\n",
    "for d in val_dataset:\n",
    "    num_val[d['class_label']] += 1\n",
    "print('val', num_val, sum(num_val))\n",
    "        \n",
    "num_test = [0, 0, 0]\n",
    "for d in test_dataset:\n",
    "    num_test[d['class_label']] += 1\n",
    "print('test', num_test, sum(num_test))\n",
    "           \n",
    "print()\n",
    "print('total', [num1 + num2 + num3 for num1, num2, num3 in zip(num_train, num_val, num_test)], sum(num_train + num_val + num_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Event information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 77,\n",
      " 'class_label': 1,\n",
      " 'class_name': 'Abnormal',\n",
      " 'event': [[0, 'Start Recording'],\n",
      "           [0, 'New Montage - Montage 002'],\n",
      "           [1358, 'Eyes Open'],\n",
      "           [6146, 'Eyes Closed'],\n",
      "           [11984, 'Eyes Open'],\n",
      "           [22232, 'Eyes Closed'],\n",
      "           [27650, 'Eyes Open'],\n",
      "           [30170, 'Eyes Closed'],\n",
      "           [36218, 'Eyes Open'],\n",
      "           [42098, 'Eyes Closed'],\n",
      "           [48692, 'Eyes Open'],\n",
      "           [54236, 'Eyes Closed'],\n",
      "           [65324, 'Eyes Open'],\n",
      "           [66668, 'Eyes Closed'],\n",
      "           [72548, 'Eyes Open'],\n",
      "           [77408, 'Move'],\n",
      "           [78848, 'Eyes Closed'],\n",
      "           [84056, 'Eyes Open'],\n",
      "           [90272, 'Eyes Closed'],\n",
      "           [96782, 'Eyes Open'],\n",
      "           [102326, 'Eyes Closed'],\n",
      "           [108583, 'Eyes Open'],\n",
      "           [114170, 'Eyes Closed'],\n",
      "           [121438, 'Photic On - 3.0 Hz'],\n",
      "           [123454, 'Photic Off'],\n",
      "           [125511, 'Photic On - 6.0 Hz'],\n",
      "           [127528, 'Photic Off'],\n",
      "           [127820, 'Eyes Open'],\n",
      "           [129122, 'Eyes Closed'],\n",
      "           [129585, 'Photic On - 9.0 Hz'],\n",
      "           [131602, 'Photic Off'],\n",
      "           [131936, 'Eyes Open'],\n",
      "           [133154, 'Eyes Closed'],\n",
      "           [133618, 'Photic On - 12.0 Hz'],\n",
      "           [135636, 'Photic Off'],\n",
      "           [137694, 'Photic On - 15.0 Hz'],\n",
      "           [139710, 'Photic Off'],\n",
      "           [141768, 'Photic On - 18.0 Hz'],\n",
      "           [143784, 'Photic Off'],\n",
      "           [144288, 'Eyes Open'],\n",
      "           [145380, 'Eyes Closed'],\n",
      "           [145800, 'Photic On - 21.0 Hz'],\n",
      "           [147858, 'Photic Off'],\n",
      "           [149874, 'Photic On - 24.0 Hz'],\n",
      "           [151890, 'Photic Off'],\n",
      "           [153948, 'Photic On - 27.0 Hz'],\n",
      "           [155964, 'Photic Off'],\n",
      "           [158022, 'Photic On - 30.0 Hz'],\n",
      "           [160038, 'Photic Off'],\n",
      "           [163314, 'Eyes Open'],\n",
      "           [164448, 'Eyes Closed'],\n",
      "           [183200, 'Paused']],\n",
      " 'serial': '01258',\n",
      " 'signal': array([[ 3., -1., -5., ...,  0.,  0.,  0.],\n",
      "       [ 7., 15.,  9., ...,  0.,  0.,  0.],\n",
      "       [-6., -5., -3., ...,  0.,  0.,  0.],\n",
      "       ...,\n",
      "       [ 4.,  6.,  5., ...,  0.,  0.,  0.],\n",
      "       [62., 54., 53., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1., ...,  0.,  0.,  0.]]),\n",
      " 'symptom': ['dementia', 'vd', 'sivd']}\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=True, \n",
    "                                                                                  file_format='edf', \n",
    "                                                                                  transform=None)\n",
    "pprint.pprint(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data Format: `EDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'serial': '00587', 'age': 53, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0, 'signal': array([[30., 15., 18., ...,  0.,  0.,  0.],\n",
      "       [-3.,  4.,  5., ...,  0.,  0.,  0.],\n",
      "       [-2.,  7.,  8., ...,  0.,  0.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  5.,  7., ...,  0.,  0.,  0.],\n",
      "       [27., 27., 34., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0., -1., ...,  0.,  0.,  0.]])}\n",
      "{'serial': '01301', 'age': 88, 'symptom': ['dementia', 'ad', 'load'], 'class_name': 'Dementia', 'class_label': 2, 'signal': array([[ 18.,  15.,  13., ...,   0.,   0.,   0.],\n",
      "       [ -2.,   1.,   1., ...,   0.,   0.,   0.],\n",
      "       [  5.,   0.,  -1., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [  2.,  -3.,  -3., ...,   0.,   0.,   0.],\n",
      "       [ 51., 115., 103., ...,   0.,   0.,   0.],\n",
      "       [  0.,  -1.,  -1., ...,   0.,   0.,   0.]])}\n",
      "CPU times: total: 141 ms\n",
      "Wall time: 152 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf', \n",
    "                                                                                  transform=None)\n",
    "\n",
    "print(train_dataset[0])\n",
    "print(train_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data Format: `NumPy Memmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'serial': '00587', 'age': 53, 'symptom': ['normal', 'cb_normal'], 'class_name': 'Normal', 'class_label': 0, 'signal': memmap([[ 30,  15,  18, ..., -42, -40, -38],\n",
      "        [ -3,   4,   5, ..., -16, -14, -13],\n",
      "        [ -2,   7,   8, ...,  -3,  -7,  -9],\n",
      "        ...,\n",
      "        [  0,   5,   7, ..., -10, -12, -12],\n",
      "        [ 27,  27,  34, ..., -25, -27, -27],\n",
      "        [  0,   0,  -1, ...,   1,   1,  -1]])}\n",
      "{'serial': '01301', 'age': 88, 'symptom': ['dementia', 'ad', 'load'], 'class_name': 'Dementia', 'class_label': 2, 'signal': memmap([[ 18,  15,  13, ...,  36,  37,  39],\n",
      "        [ -2,   1,   1, ...,  20,  19,  13],\n",
      "        [  5,   0,  -1, ...,  -5,  -3,   1],\n",
      "        ...,\n",
      "        [  2,  -3,  -3, ...,   9,   9,  11],\n",
      "        [ 51, 115, 103, ...,  -6, -14,  -8],\n",
      "        [  0,  -1,  -1, ...,  -1,   0,  -1]])}\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap', \n",
    "                                                                                  transform=None)\n",
    "\n",
    "print(train_dataset[0])\n",
    "print(train_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## PyTorch Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Random crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 53,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00587',\n",
      " 'signal': memmap([[143, 139, 134, ...,  23,  24,  20],\n",
      "        [ 31,  26,  22, ...,  11,  16,  16],\n",
      "        [  6,   2,  -2, ...,   5,   7,   9],\n",
      "        ...,\n",
      "        [ -4,  -7,  -8, ...,   1,   2,   4],\n",
      "        [ -5,  -4,  -3, ..., -43, -49, -58],\n",
      "        [  0,   2,   2, ...,   0,  -1,  -1]]),\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      ">>> signal shape: (21, 100)\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 53,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00587',\n",
      " 'signal': memmap([[  65,   69,   66, ...,  103,   95,   94],\n",
      "        [ -12,  -13,  -13, ...,    6,    2,    0],\n",
      "        [  -6,   -6,   -8, ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   0,    2,    6, ...,    2,    5,    7],\n",
      "        [ -17,  -18,  -17, ..., -105, -114, -121],\n",
      "        [  -1,    0,    2, ...,   -1,    0,   -1]]),\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      ">>> signal shape: (21, 100)\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = EegRandomCrop(crop_length=100)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path,\n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    "for i in range(2):\n",
    "    d = train_dataset[0]\n",
    "    pprint.pprint(d)\n",
    "    print()\n",
    "    print('>>> signal shape:', d['signal'].shape)\n",
    "    print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Random crop with multiple cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 53,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00587',\n",
      " 'signal': [memmap([[ 79,  84,  87, ...,  92,  92,  86],\n",
      "        [  7,   9,  11, ...,   6,   5,   7],\n",
      "        [  1,   1,   4, ...,  -3,  -3,  -2],\n",
      "        ...,\n",
      "        [  4,   3,   2, ...,  -5,  -6,  -5],\n",
      "        [114,  99,  95, ..., -16, -22, -31],\n",
      "        [ -1,   0,   2, ...,   0,  -1,  -1]]),\n",
      "            memmap([[  24,   24,   21, ...,  -13,  -12,  -10],\n",
      "        [  -1,   -3,   -3, ...,   13,   13,   17],\n",
      "        [  -2,   -2,   -2, ...,   -1,    1,    2],\n",
      "        ...,\n",
      "        [ -11,   -9,   -5, ...,   -6,   -5,   -8],\n",
      "        [ 108,   97,   98, ..., -475, -263,    6],\n",
      "        [   1,    1,   -3, ...,   -1,    0,    0]])],\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      ">>> signal shape: [(21, 200), (21, 200)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 53,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00587',\n",
      " 'signal': [memmap([[-109, -109, -108, ..., -118, -117, -118],\n",
      "        [  -6,   -5,   -3, ...,   -8,   -9,   -9],\n",
      "        [  -9,  -10,   -7, ...,   -7,   -8,   -7],\n",
      "        ...,\n",
      "        [ -10,   -9,   -8, ...,   -8,   -6,   -3],\n",
      "        [  25,   22,   19, ...,  133,  140,  146],\n",
      "        [   3,    3,    0, ...,    0,    2,    2]]),\n",
      "            memmap([[-15, -19, -19, ...,  -2,   2,   0],\n",
      "        [  8,   7,  10, ...,   5,  10,  12],\n",
      "        [  5,   7,   9, ...,   2,   3,   5],\n",
      "        ...,\n",
      "        [  7,   7,   7, ...,   2,   1,   0],\n",
      "        [-53, -63, -73, ...,  48,  45,  44],\n",
      "        [  0,   0,  -1, ...,   1,   0,   0]])],\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      ">>> signal shape: [(21, 200), (21, 200)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = EegRandomCrop(crop_length=200, multiple=2)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    "for i in range(2):\n",
    "    d = train_dataset[0]\n",
    "    pprint.pprint(d)\n",
    "    print()\n",
    "    print('>>> signal shape:', [signal.shape for signal in d['signal']])\n",
    "    print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Random crop with multiple cropping and latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 53,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'crop_timing': [113726, 71569, 86599],\n",
      " 'serial': '00587',\n",
      " 'signal': [memmap([[-20, -22, -22, ..., 115, 110, 108],\n",
      "        [  1,   4,   3, ...,  17,  14,  14],\n",
      "        [  3,   3,   3, ..., -11, -10,  -9],\n",
      "        ...,\n",
      "        [  0,   2,   3, ..., -15, -11,  -7],\n",
      "        [ 71,  68,  64, ..., -19, -18, -19],\n",
      "        [ -1,   1,   2, ...,   0,   1,   1]]),\n",
      "            memmap([[-41, -42, -45, ..., -63, -71, -74],\n",
      "        [  2,   0,   1, ...,   8,   8,   8],\n",
      "        [  8,   7,   4, ...,   5,   7,   8],\n",
      "        ...,\n",
      "        [ 10,   9,   9, ...,   2,   3,   2],\n",
      "        [ 60,  59,  58, ...,  62,  59,  54],\n",
      "        [  3,   0,  -1, ...,   3,  -1,  -1]]),\n",
      "            memmap([[ 262,  261,  262, ...,  -15,  -12,  -14],\n",
      "        [  35,   36,   37, ...,   -4,   -4,   -5],\n",
      "        [  -2,   -2,   -1, ...,   -3,   -4,   -5],\n",
      "        ...,\n",
      "        [ -10,  -11,  -12, ...,   -6,   -6,   -4],\n",
      "        [-562, -536, -352, ...,   93,   88,   84],\n",
      "        [  -1,   -1,    0, ...,   -1,   -1,    0]])],\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      ">>> signal shape: [(21, 300), (21, 300), (21, 300)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 53,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'crop_timing': [104696, 115376, 63334],\n",
      " 'serial': '00587',\n",
      " 'signal': [memmap([[-47, -46, -47, ...,  63,  57,  48],\n",
      "        [  1,  -1,  -2, ...,  22,  21,  18],\n",
      "        [ -3,  -2,  -2, ...,  11,  12,  12],\n",
      "        ...,\n",
      "        [  4,   5,   5, ...,   1,   0,   0],\n",
      "        [ -1,  -3,  -6, ..., -35, -29, -14],\n",
      "        [ -1,   0,  -1, ...,  -1,   0,  -1]]),\n",
      "            memmap([[-20, -18, -13, ...,  35,  35,  34],\n",
      "        [ -7,  -6,  -5, ...,  20,  20,  20],\n",
      "        [-11,  -9,  -6, ...,   5,   5,   4],\n",
      "        ...,\n",
      "        [-11,  -9,  -8, ...,  -4,  -4,  -4],\n",
      "        [ 74,  77,  75, ...,  11,   7,   4],\n",
      "        [ -1,  -1,  -1, ...,  -1,  -1,   0]]),\n",
      "            memmap([[ 46,  46,  46, ...,   4,   5,   8],\n",
      "        [ 23,  22,  19, ...,   2,   2,   0],\n",
      "        [  4,   4,   4, ...,   7,   4,   2],\n",
      "        ...,\n",
      "        [ -6,  -4,  -2, ...,   4,   3,   0],\n",
      "        [-22, -25, -28, ...,  44,  43, -26],\n",
      "        [  0,  -1,  -1, ...,   0,  -1,  -1]])],\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      ">>> signal shape: [(21, 300), (21, 300), (21, 300)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = EegRandomCrop(crop_length=300, multiple=3, latency=50000, return_timing=True)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    "for i in range(2): \n",
    "    d = train_dataset[0]\n",
    "    pprint.pprint(d)\n",
    "    print()\n",
    "    print('>>> signal shape:', [signal.shape for signal in d['signal']])\n",
    "    print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Random crop with multiple cropping, latency, and max length limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 77,\n",
      " 'class_label': 1,\n",
      " 'class_name': 'Abnormal',\n",
      " 'crop_timing': [50051, 50001, 50048],\n",
      " 'serial': '01258',\n",
      " 'signal': [memmap([[ 89,  76,  68, ...,   1,  -1,  -2],\n",
      "        [ 75,  66,  55, ...,   9,  14,  21],\n",
      "        [-29, -28, -27, ..., -40, -39, -41],\n",
      "        ...,\n",
      "        [-13,  -8,  -4, ...,  -4,  -5,  -4],\n",
      "        [  4,   0,  10, ..., -37, -39, -26],\n",
      "        [  0,   0,   0, ...,  -1,   0,  -1]]),\n",
      "            memmap([[  6,   3,   9, ...,   0,   2,   5],\n",
      "        [ 44,  38,  40, ...,  21,  21,  34],\n",
      "        [-18, -19, -21, ..., -43, -41, -44],\n",
      "        ...,\n",
      "        [ -5,  -5,  -5, ...,  -4,  -7,  -8],\n",
      "        [-15, -13, -22, ...,   4,   5,  21],\n",
      "        [  3,   2,  -1, ...,  -1,   2,   2]]),\n",
      "            memmap([[111, 103,  96, ...,  -9, -13,  -1],\n",
      "        [ 47,  58,  68, ...,  12,   4,  16],\n",
      "        [-20, -25, -30, ..., -41, -42, -43],\n",
      "        ...,\n",
      "        [-11, -13, -16, ...,  -3,  -3,  -3],\n",
      "        [ 25,  25,  15, ..., -28, -22, -27],\n",
      "        [  0,   0,   0, ...,   0,  -1,  -1]])],\n",
      " 'symptom': ['dementia', 'vd', 'sivd']}\n",
      "\n",
      ">>> signal shape: [(21, 200), (21, 200), (21, 200)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 77,\n",
      " 'class_label': 1,\n",
      " 'class_name': 'Abnormal',\n",
      " 'crop_timing': [50016, 50001, 50035],\n",
      " 'serial': '01258',\n",
      " 'signal': [memmap([[ -1,   0,   3, ...,  35,  50,  50],\n",
      "        [ 40,  41,  28, ...,  31,  25,   6],\n",
      "        [-21, -21, -19, ..., -48, -48, -43],\n",
      "        ...,\n",
      "        [ -2,  -1,   0, ...,  -6,  -6,  -2],\n",
      "        [ 55,  41,  47, ...,  44,  62,  71],\n",
      "        [  0,  -1,  -1, ...,  -1,   0,  -1]]),\n",
      "            memmap([[  6,   3,   9, ...,   0,   2,   5],\n",
      "        [ 44,  38,  40, ...,  21,  21,  34],\n",
      "        [-18, -19, -21, ..., -43, -41, -44],\n",
      "        ...,\n",
      "        [ -5,  -5,  -5, ...,  -4,  -7,  -8],\n",
      "        [-15, -13, -22, ...,   4,   5,  21],\n",
      "        [  3,   2,  -1, ...,  -1,   2,   2]]),\n",
      "            memmap([[ 68,  77,  83, ...,  17,  12,  20],\n",
      "        [ 43,  45,  48, ...,   9,  27,  22],\n",
      "        [-24, -23, -21, ..., -46, -46, -48],\n",
      "        ...,\n",
      "        [ -4,  -6,  -7, ...,  -9, -10,  -9],\n",
      "        [ 76,  85,  51, ...,  64,  63,  57],\n",
      "        [ -1,  -1,   0, ...,   0,  -1,  -1]])],\n",
      " 'symptom': ['dementia', 'vd', 'sivd']}\n",
      "\n",
      ">>> signal shape: [(21, 200), (21, 200), (21, 200)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200, \n",
    "                  length_limit=50300,\n",
    "                  multiple=3, \n",
    "                  latency=50000, \n",
    "                  return_timing=True)\n",
    "])\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    "for i in range(2):\n",
    "    d = train_dataset[0]\n",
    "    pprint.pprint(d)\n",
    "    print()\n",
    "    print('>>> signal shape:', [signal.shape for signal in d['signal']])\n",
    "    print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Drop channel(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1-AVG', 'F3-AVG', 'C3-AVG', 'P3-AVG', 'O1-AVG', 'Fp2-AVG', 'F4-AVG', 'C4-AVG', 'P4-AVG', 'O2-AVG', 'F7-AVG', 'T3-AVG', 'T5-AVG', 'F8-AVG', 'T4-AVG', 'T6-AVG', 'FZ-AVG', 'CZ-AVG', 'PZ-AVG', 'EKG', 'Photic']\n",
      "channel_ekg:  19\n",
      "channel_photic:  20\n"
     ]
    }
   ],
   "source": [
    "anno_path = os.path.join(data_path, 'annotation.json')\n",
    "with open(anno_path, 'r') as json_file:\n",
    "    annotation = json.load(json_file)\n",
    "signal_headers = annotation['signal_header']\n",
    "del annotation\n",
    "print(signal_headers)\n",
    "\n",
    "channel_ekg = signal_headers.index('EKG')\n",
    "print('channel_ekg: ', channel_ekg)\n",
    "\n",
    "channel_photic = signal_headers.index('Photic')\n",
    "print('channel_photic: ', channel_photic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: (21, 183200)\n",
      "[[   3   -1   -5 ...   -5   -2   -9]\n",
      " [   7   15    9 ...    8  -10  -15]\n",
      " [  -6   -5   -3 ...   -2    0    3]\n",
      " ...\n",
      " [   4    6    5 ...    2    6    8]\n",
      " [  62   54   53 ...  -22 -137 -282]\n",
      " [   0    0    1 ...    0   -1    0]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "after: (20, 183200)\n",
      "[[  3  -1  -5 ...  -5  -2  -9]\n",
      " [  7  15   9 ...   8 -10 -15]\n",
      " [ -6  -5  -3 ...  -2   0   3]\n",
      " ...\n",
      " [  0   6   3 ...  10   7   5]\n",
      " [  4   6   5 ...   2   6   8]\n",
      " [  0   0   1 ...   0  -1   0]]\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap', \n",
    "                                                                                  transform=None)\n",
    "print('before:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap', \n",
    "                                                                                  transform=EegDropChannels(channel_ekg))\n",
    "print('after:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: (21, 183200)\n",
      "[[   3   -1   -5 ...   -5   -2   -9]\n",
      " [   7   15    9 ...    8  -10  -15]\n",
      " [  -6   -5   -3 ...   -2    0    3]\n",
      " ...\n",
      " [   4    6    5 ...    2    6    8]\n",
      " [  62   54   53 ...  -22 -137 -282]\n",
      " [   0    0    1 ...    0   -1    0]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "after: (20, 183200)\n",
      "[[   3   -1   -5 ...   -5   -2   -9]\n",
      " [   7   15    9 ...    8  -10  -15]\n",
      " [  -6   -5   -3 ...   -2    0    3]\n",
      " ...\n",
      " [   0    6    3 ...   10    7    5]\n",
      " [   4    6    5 ...    2    6    8]\n",
      " [  62   54   53 ...  -22 -137 -282]]\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=None)\n",
    "print('before:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=EegDropChannels(channel_photic))\n",
    "print('after:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: (21, 183200)\n",
      "[[   3   -1   -5 ...   -5   -2   -9]\n",
      " [   7   15    9 ...    8  -10  -15]\n",
      " [  -6   -5   -3 ...   -2    0    3]\n",
      " ...\n",
      " [   4    6    5 ...    2    6    8]\n",
      " [  62   54   53 ...  -22 -137 -282]\n",
      " [   0    0    1 ...    0   -1    0]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "after: (19, 183200)\n",
      "[[  3  -1  -5 ...  -5  -2  -9]\n",
      " [  7  15   9 ...   8 -10 -15]\n",
      " [ -6  -5  -3 ...  -2   0   3]\n",
      " ...\n",
      " [-30 -27 -27 ...  22  18  14]\n",
      " [  0   6   3 ...  10   7   5]\n",
      " [  4   6   5 ...   2   6   8]]\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=None)\n",
    "print('before:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=EegDropChannels([channel_ekg, channel_photic]))\n",
    "print('after:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### To Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "{'age': 78,\n",
      " 'serial': '00001',\n",
      " 'signal': memmap([[  0, -11, -13, ...,  18,  21,  22],\n",
      "        [ 29,  33,  34, ...,  -7,  -4,  -4],\n",
      "        [ -3,  -6,  -3, ...,  -1,   1,   2],\n",
      "        ...,\n",
      "        [ -4,  -2,   1, ...,   0,  -1,  -1],\n",
      "        [112,  67,  76, ..., -13, -15, -11],\n",
      "        [ -1,  -1,  -1, ...,  -1,  -1,  -1]]),\n",
      " 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf']}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "After:\n",
      "{'age': tensor(78.),\n",
      " 'serial': '00001',\n",
      " 'signal': tensor([[  0., -11., -13.,  ...,  18.,  21.,  22.],\n",
      "        [ 29.,  33.,  34.,  ...,  -7.,  -4.,  -4.],\n",
      "        [ -3.,  -6.,  -3.,  ...,  -1.,   1.,   2.],\n",
      "        ...,\n",
      "        [ -4.,  -2.,   1.,  ...,   0.,  -1.,  -1.],\n",
      "        [112.,  67.,  76.,  ..., -13., -15., -11.],\n",
      "        [ -1.,  -1.,  -1.,  ...,  -1.,  -1.,  -1.]]),\n",
      " 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf']}\n"
     ]
    }
   ],
   "source": [
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         load_event=False, \n",
    "                                                         file_format='memmap',\n",
    "                                                         transform=None)\n",
    "print('Before:')\n",
    "pprint.pprint(full_eeg_dataset[0])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "\n",
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         load_event=False, \n",
    "                                                         file_format='memmap',\n",
    "                                                         transform=EegToTensor())\n",
    "print('After:')\n",
    "pprint.pprint(full_eeg_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Compose the above all in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': tensor(77.),\n",
      " 'class_label': tensor(1),\n",
      " 'class_name': 'Abnormal',\n",
      " 'serial': '01258',\n",
      " 'signal': [tensor([[ 66.,  77.,  79.,  ..., -16., -13.,  -9.],\n",
      "        [ 43.,  42.,  35.,  ...,   5., -11., -27.],\n",
      "        [-35., -31., -26.,  ..., -36., -32., -28.],\n",
      "        ...,\n",
      "        [ -9.,  -9.,  -6.,  ..., -11., -10.,  -9.],\n",
      "        [-10.,  -8.,  -6.,  ...,   4.,   7.,   9.],\n",
      "        [-28., -20.,   2.,  ...,  -7.,   4., -20.]]),\n",
      "            tensor([[ -9., -19., -26.,  ...,  29.,  24.,  10.],\n",
      "        [ -8., -11., -14.,  ...,  18.,  24.,  20.],\n",
      "        [ 15.,  18.,  20.,  ..., -27., -27., -27.],\n",
      "        ...,\n",
      "        [  3.,   4.,   4.,  ...,  -4.,  -2.,   2.],\n",
      "        [  8.,   9.,   7.,  ...,  -1.,   0.,   4.],\n",
      "        [-22., -30., -11.,  ...,  31.,  27.,   9.]]),\n",
      "            tensor([[ 23.,  16.,  10.,  ..., -53., -51., -53.],\n",
      "        [-22.,  -7.,  -1.,  ..., -28., -21., -20.],\n",
      "        [ 29.,  18.,  13.,  ..., -32., -35., -32.],\n",
      "        ...,\n",
      "        [  5.,   1.,  -1.,  ..., -12., -12., -11.],\n",
      "        [  0.,  -1.,   0.,  ...,  -1.,  -2.,   0.],\n",
      "        [ -4., -22., -22.,  ..., 163., 127.,  67.]]),\n",
      "            tensor([[ -52.,  -55.,  -54.,  ...,    6.,    5.,    9.],\n",
      "        [  12.,    9.,   11.,  ...,   21.,   30.,   27.],\n",
      "        [  17.,   14.,   15.,  ...,   12.,   11.,   11.],\n",
      "        ...,\n",
      "        [  -7.,   -9.,   -9.,  ...,    9.,    9.,   10.],\n",
      "        [  -8.,   -9.,   -8.,  ...,   12.,   12.,   13.],\n",
      "        [  27.,   24.,    6.,  ..., -106.,  -96.,  -83.]])],\n",
      " 'symptom': ['dementia', 'vd', 'sivd']}\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*10,       # crop: 10s\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=4, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "pprint.pprint(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if device.type == 'cuda':\n",
    "    num_workers = 0  # A number other than 0 causes an error\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': tensor([75., 75., 74., 74., 82., 82., 80., 80.]),\n",
      " 'serial': ['01275',\n",
      "            '01275',\n",
      "            '00855',\n",
      "            '00855',\n",
      "            '00326',\n",
      "            '00326',\n",
      "            '00007',\n",
      "            '00007'],\n",
      " 'signal': tensor([[[   0.,    0.,   -2.,  ...,    4.,    5.,    8.],\n",
      "         [   0.,   -2.,   -3.,  ...,    5.,    7.,    8.],\n",
      "         [  -2.,   -3.,   -4.,  ...,    5.,    7.,    6.],\n",
      "         ...,\n",
      "         [  -2.,    0.,    1.,  ...,   10.,    9.,    7.],\n",
      "         [   0.,    0.,    0.,  ...,    1.,    0.,    0.],\n",
      "         [  17.,   13.,   10.,  ...,  142.,  133.,  133.]],\n",
      "\n",
      "        [[   0.,    1.,    0.,  ...,  -21.,  -15.,  -14.],\n",
      "         [   1.,    2.,    1.,  ...,    0.,    2.,    4.],\n",
      "         [  -4.,   -4.,   -4.,  ...,   18.,   20.,   21.],\n",
      "         ...,\n",
      "         [  -3.,   -1.,    0.,  ...,    9.,    7.,    6.],\n",
      "         [ -10.,   -9.,   -8.,  ...,    5.,    5.,    5.],\n",
      "         [  11.,   27.,   37.,  ...,   62.,   33.,    8.]],\n",
      "\n",
      "        [[ -12.,   -9.,   -7.,  ...,   -3.,   -2.,    2.],\n",
      "         [  -1.,    3.,    5.,  ...,    4.,    2.,   -1.],\n",
      "         [  -4.,   -3.,   -4.,  ...,   -1.,    0.,    1.],\n",
      "         ...,\n",
      "         [   7.,    9.,   11.,  ...,   -4.,   -4.,   -3.],\n",
      "         [   9.,    6.,    3.,  ...,   -1.,    0.,    0.],\n",
      "         [ -59.,  -41.,  -27.,  ...,   66.,   57.,   44.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  39.,   41.,   43.,  ...,  -40.,  -37.,  -38.],\n",
      "         [  21.,   20.,   21.,  ...,  -30.,  -28.,  -29.],\n",
      "         [  -7.,   -6.,   -5.,  ...,   18.,   16.,   14.],\n",
      "         ...,\n",
      "         [ -33.,  -31.,  -30.,  ...,    5.,    4.,    4.],\n",
      "         [ -21.,  -20.,  -19.,  ...,   20.,   18.,   16.],\n",
      "         [ 164.,  194.,  155.,  ...,  -31.,   -2.,   14.]],\n",
      "\n",
      "        [[  -7.,  -15.,  -13.,  ...,   -7.,   -6.,   -3.],\n",
      "         [  -3.,   -5.,   -8.,  ...,   -2.,   -4.,   -4.],\n",
      "         [  -4.,   -7.,   -6.,  ...,   -9.,   -6.,   -3.],\n",
      "         ...,\n",
      "         [  -1.,    0.,   -1.,  ...,  -15.,  -15.,  -10.],\n",
      "         [  -6.,  -10.,  -10.,  ...,   -3.,    3.,    7.],\n",
      "         [-125., -202., -276.,  ...,   74.,   86.,   80.]],\n",
      "\n",
      "        [[   2.,   -2.,   -6.,  ...,   10.,   11.,   13.],\n",
      "         [   1.,   -1.,   -1.,  ...,    4.,    4.,    4.],\n",
      "         [   7.,    9.,   11.,  ...,    9.,    6.,    3.],\n",
      "         ...,\n",
      "         [ -14.,  -12.,   -8.,  ...,   23.,   21.,   17.],\n",
      "         [  -5.,   -6.,   -7.,  ...,    7.,    5.,    0.],\n",
      "         [ -11.,  -25.,  -33.,  ...,   78.,   63.,   58.]]]),\n",
      " 'symptom': [['parkinson_synd', 'parkinson_disease'],\n",
      "             ['parkinson_synd', 'parkinson_disease'],\n",
      "             ['normal', 'smi'],\n",
      "             ['normal', 'smi'],\n",
      "             ['mci', 'mci_amnestic', 'mci_amnestic_ef'],\n",
      "             ['mci', 'mci_amnestic', 'mci_amnestic_ef'],\n",
      "             ['dementia', 'ad', 'load'],\n",
      "             ['dementia', 'ad', 'load']]}\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*10,       # crop: 10s\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=2, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "\n",
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         load_event=False, \n",
    "                                                         file_format='memmap',\n",
    "                                                         transform=transform)\n",
    "\n",
    "full_loader = DataLoader(full_eeg_dataset,\n",
    "                         batch_size=4,\n",
    "                         shuffle=True,\n",
    "                         drop_last=True,\n",
    "                         num_workers=num_workers,\n",
    "                         pin_memory=pin_memory,\n",
    "                         collate_fn=eeg_collate_fn)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(full_loader):\n",
    "    pprint.pprint(sample_batched)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': tensor([71., 71., 77., 77., 86., 86., 57., 57., 76., 76., 80., 80., 78., 78.,\n",
      "        73., 73.]),\n",
      " 'class_label': tensor([1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]),\n",
      " 'class_name': ['Abnormal', 'Abnormal', 'Normal', 'Normal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Abnormal', 'Normal', 'Normal'],\n",
      " 'serial': ['00671', '00671', '00672', '00672', '00405', '00405', '01218', '01218', '00763', '00763', '00258', '00258', '00288', '00288', '01152', '01152'],\n",
      " 'signal': tensor([[[-2.4000e+01, -2.2000e+01, -2.4000e+01,  ...,  1.1000e+01,\n",
      "           8.0000e+00,  6.0000e+00],\n",
      "         [-2.0000e+00, -1.0000e+00, -3.0000e+00,  ...,  4.0000e+00,\n",
      "           0.0000e+00, -1.0000e+00],\n",
      "         [-5.0000e+00, -4.0000e+00, -3.0000e+00,  ...,  6.0000e+00,\n",
      "           4.0000e+00,  1.0000e+00],\n",
      "         ...,\n",
      "         [ 2.0000e+00,  3.0000e+00,  1.0000e+00,  ...,  2.0000e+00,\n",
      "           0.0000e+00, -1.0000e+00],\n",
      "         [-3.0000e+00, -2.0000e+00, -2.0000e+00,  ..., -5.0000e+00,\n",
      "           1.0000e+00,  3.0000e+00],\n",
      "         [ 2.5300e+02,  2.2900e+02,  2.3200e+02,  ...,  3.0500e+02,\n",
      "           2.8200e+02,  2.5200e+02]],\n",
      "\n",
      "        [[ 1.9000e+01,  1.7000e+01,  1.4000e+01,  ...,  3.3100e+02,\n",
      "           3.1700e+02,  3.0500e+02],\n",
      "         [ 1.2000e+01,  1.0000e+01,  1.0000e+01,  ...,  1.2000e+01,\n",
      "           1.8000e+01,  1.9000e+01],\n",
      "         [ 3.0000e+00,  3.0000e+00,  1.0000e+00,  ..., -1.0000e+00,\n",
      "          -1.0000e+00, -1.0000e+00],\n",
      "         ...,\n",
      "         [-1.0000e+00,  0.0000e+00,  1.0000e+00,  ..., -1.2000e+01,\n",
      "          -1.2000e+01, -1.2000e+01],\n",
      "         [-6.0000e+00, -5.0000e+00, -3.0000e+00,  ..., -2.9000e+01,\n",
      "          -2.6000e+01, -2.4000e+01],\n",
      "         [-1.1870e+03, -1.4660e+03, -1.3530e+03,  ..., -6.5000e+01,\n",
      "          -7.4000e+01, -8.2000e+01]],\n",
      "\n",
      "        [[-6.2000e+01, -6.3000e+01, -6.1000e+01,  ..., -6.2000e+01,\n",
      "          -6.4000e+01, -6.4000e+01],\n",
      "         [-1.5000e+01, -1.3000e+01, -1.2000e+01,  ...,  4.0000e+00,\n",
      "           3.0000e+00,  1.0000e+00],\n",
      "         [ 3.0000e+00,  5.0000e+00,  4.0000e+00,  ...,  8.0000e+00,\n",
      "           8.0000e+00,  9.0000e+00],\n",
      "         ...,\n",
      "         [ 4.0000e+00,  5.0000e+00,  5.0000e+00,  ...,  1.2000e+01,\n",
      "           1.2000e+01,  1.2000e+01],\n",
      "         [ 6.0000e+00,  6.0000e+00,  5.0000e+00,  ...,  1.6000e+01,\n",
      "           1.5000e+01,  1.2000e+01],\n",
      "         [ 7.7000e+01,  7.5000e+01,  7.0000e+01,  ..., -8.0000e+00,\n",
      "          -9.0000e+00, -1.0000e+01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.0000e+00, -6.0000e+00,  7.0000e+00,  ..., -1.4000e+01,\n",
      "          -5.0000e+00, -1.2000e+01],\n",
      "         [ 6.0000e+00, -4.0000e+00,  1.0000e+00,  ...,  5.0000e+00,\n",
      "          -3.0000e+00, -7.0000e+00],\n",
      "         [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+01,\n",
      "           9.0000e+00,  7.0000e+00],\n",
      "         ...,\n",
      "         [ 1.8000e+01,  1.8000e+01,  1.3000e+01,  ...,  9.0000e+00,\n",
      "           9.0000e+00,  8.0000e+00],\n",
      "         [ 1.2000e+01,  1.2000e+01,  9.0000e+00,  ...,  3.0000e+00,\n",
      "           3.0000e+00,  3.0000e+00],\n",
      "         [-4.0000e+00,  2.0000e+00,  4.9000e+01,  ...,  1.6000e+01,\n",
      "           3.1000e+01,  3.8000e+01]],\n",
      "\n",
      "        [[ 2.4000e+01,  2.3000e+01,  2.5000e+01,  ...,  6.0000e+00,\n",
      "           9.0000e+00,  1.1000e+01],\n",
      "         [-2.5000e+01, -2.4000e+01, -2.2000e+01,  ...,  1.7000e+01,\n",
      "           1.9000e+01,  2.1000e+01],\n",
      "         [-4.0000e+00, -4.0000e+00, -4.0000e+00,  ...,  2.0000e+00,\n",
      "           2.0000e+00,  2.0000e+00],\n",
      "         ...,\n",
      "         [ 9.0000e+00,  1.6000e+01,  1.7000e+01,  ..., -8.0000e+00,\n",
      "          -1.2000e+01, -1.7000e+01],\n",
      "         [ 6.0000e+00,  1.0000e+01,  8.0000e+00,  ..., -8.0000e+00,\n",
      "          -1.1000e+01, -1.5000e+01],\n",
      "         [ 3.1000e+01,  2.6000e+01,  1.7000e+01,  ..., -6.3000e+01,\n",
      "          -6.0000e+01, -5.1000e+01]],\n",
      "\n",
      "        [[ 1.8000e+01,  1.8000e+01,  1.8000e+01,  ...,  2.0000e+00,\n",
      "           6.0000e+00,  9.0000e+00],\n",
      "         [ 1.9000e+01,  2.1000e+01,  1.9000e+01,  ...,  8.0000e+00,\n",
      "           1.5000e+01,  1.9000e+01],\n",
      "         [ 4.0000e+00,  3.0000e+00,  2.0000e+00,  ...,  1.0000e+01,\n",
      "           1.5000e+01,  1.5000e+01],\n",
      "         ...,\n",
      "         [ 5.0000e+00,  4.0000e+00,  0.0000e+00,  ...,  6.0000e+00,\n",
      "           1.1000e+01,  1.4000e+01],\n",
      "         [ 4.0000e+00, -2.0000e+00, -6.0000e+00,  ...,  0.0000e+00,\n",
      "           1.0000e+00,  4.0000e+00],\n",
      "         [ 0.0000e+00,  2.0000e+00, -3.0000e+00,  ...,  6.0000e+00,\n",
      "          -4.0000e+00, -4.0000e+00]]]),\n",
      " 'symptom': [['dementia', 'ad', 'load'],\n",
      "             ['dementia', 'ad', 'load'],\n",
      "             ['normal', 'smi'],\n",
      "             ['normal', 'smi'],\n",
      "             ['dementia', 'ad', 'load'],\n",
      "             ['dementia', 'ad', 'load'],\n",
      "             ['tga'],\n",
      "             ['tga'],\n",
      "             ['dementia', 'ad', 'load'],\n",
      "             ['dementia', 'ad', 'load'],\n",
      "             ['dementia', 'vd', 'sivd'],\n",
      "             ['dementia', 'vd', 'sivd'],\n",
      "             ['mci', 'mci_amnestic', 'mci_amnestic_rf'],\n",
      "             ['mci', 'mci_amnestic', 'mci_amnestic_rf'],\n",
      "             ['normal', 'smi'],\n",
      "             ['normal', 'smi']]}\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*10,       # crop: 10s\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=2, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='abnormal',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=8,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    pprint.pprint(sample_batched, width=250)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Preprocessing steps run by the PyTorch Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*10,       # crop: 10s\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=2, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=2,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### To GPU device if it is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      ")\n",
      "- Before -\n",
      "{'age': tensor([58., 58., 67., 67.]),\n",
      " 'class_label': tensor([1, 1, 0, 0]),\n",
      " 'class_name': ['MCI', 'MCI', 'Normal', 'Normal'],\n",
      " 'serial': ['01176', '01176', '01320', '01320'],\n",
      " 'signal': tensor([[[-46., -48., -46.,  ..., -52., -47., -50.],\n",
      "         [ -6.,  -6.,  -5.,  ..., -14., -15., -15.],\n",
      "         [ -3.,  -3.,  -4.,  ...,  -2.,  -2.,  -1.],\n",
      "         ...,\n",
      "         [ 20.,  19.,  18.,  ...,  -9.,  -9.,  -9.],\n",
      "         [ -2.,  -1.,  -2.,  ..., -13., -13., -14.],\n",
      "         [-79., -70., -54.,  ..., -82., -80., -80.]],\n",
      "\n",
      "        [[290., 287., 295.,  ...,   7.,   0.,  -6.],\n",
      "         [ 42.,  35.,  29.,  ...,   5.,   3.,   5.],\n",
      "         [ -5.,  -6.,  -9.,  ...,   6.,   8.,   8.],\n",
      "         ...,\n",
      "         [-11., -12., -14.,  ...,  -4.,  -4.,  -5.],\n",
      "         [-10.,  -8.,  -7.,  ...,   0.,   1.,   3.],\n",
      "         [-35., -44., -43.,  ...,  81.,  -9., -73.]],\n",
      "\n",
      "        [[  0.,   0.,   0.,  ...,  14.,  13.,  13.],\n",
      "         [-15., -16., -16.,  ...,   2.,   2.,   3.],\n",
      "         [  2.,   1.,   1.,  ...,  -5.,  -5.,  -4.],\n",
      "         ...,\n",
      "         [-10., -11., -11.,  ..., -19., -18., -14.],\n",
      "         [  9.,   9.,   9.,  ...,  10.,  10.,  11.],\n",
      "         [117., 118., 120.,  ...,  12.,  13.,  15.]],\n",
      "\n",
      "        [[ -3.,  -1.,   1.,  ...,  -8.,  -8., -10.],\n",
      "         [  4.,   5.,   6.,  ..., -15., -15., -13.],\n",
      "         [  4.,   5.,   5.,  ...,  -7.,  -2.,   2.],\n",
      "         ...,\n",
      "         [ 10.,  10.,   8.,  ...,   0.,  -1.,  -4.],\n",
      "         [ 13.,  13.,  12.,  ...,   0.,  -2.,  -3.],\n",
      "         [-34., -34., -32.,  ...,  69.,  48.,  33.]]]),\n",
      " 'symptom': [['mci', 'mci_amnestic', 'mci_amnestic_ef'],\n",
      "             ['mci', 'mci_amnestic', 'mci_amnestic_ef'],\n",
      "             ['normal', 'smi'],\n",
      "             ['normal', 'smi']]}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "{'age': tensor([58., 58., 67., 67.], device='cuda:0'),\n",
      " 'class_label': tensor([1, 1, 0, 0], device='cuda:0'),\n",
      " 'class_name': ['MCI', 'MCI', 'Normal', 'Normal'],\n",
      " 'serial': ['01176', '01176', '01320', '01320'],\n",
      " 'signal': tensor([[[-46., -48., -46.,  ..., -52., -47., -50.],\n",
      "         [ -6.,  -6.,  -5.,  ..., -14., -15., -15.],\n",
      "         [ -3.,  -3.,  -4.,  ...,  -2.,  -2.,  -1.],\n",
      "         ...,\n",
      "         [ 20.,  19.,  18.,  ...,  -9.,  -9.,  -9.],\n",
      "         [ -2.,  -1.,  -2.,  ..., -13., -13., -14.],\n",
      "         [-79., -70., -54.,  ..., -82., -80., -80.]],\n",
      "\n",
      "        [[290., 287., 295.,  ...,   7.,   0.,  -6.],\n",
      "         [ 42.,  35.,  29.,  ...,   5.,   3.,   5.],\n",
      "         [ -5.,  -6.,  -9.,  ...,   6.,   8.,   8.],\n",
      "         ...,\n",
      "         [-11., -12., -14.,  ...,  -4.,  -4.,  -5.],\n",
      "         [-10.,  -8.,  -7.,  ...,   0.,   1.,   3.],\n",
      "         [-35., -44., -43.,  ...,  81.,  -9., -73.]],\n",
      "\n",
      "        [[  0.,   0.,   0.,  ...,  14.,  13.,  13.],\n",
      "         [-15., -16., -16.,  ...,   2.,   2.,   3.],\n",
      "         [  2.,   1.,   1.,  ...,  -5.,  -5.,  -4.],\n",
      "         ...,\n",
      "         [-10., -11., -11.,  ..., -19., -18., -14.],\n",
      "         [  9.,   9.,   9.,  ...,  10.,  10.,  11.],\n",
      "         [117., 118., 120.,  ...,  12.,  13.,  15.]],\n",
      "\n",
      "        [[ -3.,  -1.,   1.,  ...,  -8.,  -8., -10.],\n",
      "         [  4.,   5.,   6.,  ..., -15., -15., -13.],\n",
      "         [  4.,   5.,   5.,  ...,  -7.,  -2.,   2.],\n",
      "         ...,\n",
      "         [ 10.,  10.,   8.,  ...,   0.,  -1.,  -4.],\n",
      "         [ 13.,  13.,  12.,  ...,   0.,  -2.,  -3.],\n",
      "         [-34., -34., -32.,  ...,  69.,  48.,  33.]]], device='cuda:0'),\n",
      " 'symptom': [['mci', 'mci_amnestic', 'mci_amnestic_ef'],\n",
      "             ['mci', 'mci_amnestic', 'mci_amnestic_ef'],\n",
      "             ['normal', 'smi'],\n",
      "             ['normal', 'smi']]}\n"
     ]
    }
   ],
   "source": [
    "print('device:', device)\n",
    "print()\n",
    "\n",
    "preprocess_train = transforms.Compose([EegToDevice(device=device)])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    pprint.pprint(sample_batched)\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    pprint.pprint(sample_batched)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Normalization per signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizePerSignal(eps=1e-08)\n",
      ")\n",
      "- Before -\n",
      "Mean: tensor([[ 2.5840e+00,  7.3250e-01, -8.6700e-01, -1.1030e+00, -2.5000e-01,\n",
      "          3.5350e-01, -4.0000e-03, -1.2645e+00, -3.5600e-01, -7.4000e-02,\n",
      "          4.6300e-01, -8.4550e-01, -9.5000e-03, -7.7550e-01,  3.9500e-02,\n",
      "          6.6800e-01,  2.3065e+00, -5.1000e-02, -2.6750e-01, -1.1885e+00],\n",
      "        [ 1.0295e+00,  3.5005e+00,  2.0060e+00,  1.4000e+00,  8.8900e-01,\n",
      "         -4.7830e+00, -1.2810e+00, -1.0960e+00,  1.3050e-01,  2.9650e-01,\n",
      "          5.4350e-01,  1.8190e+00,  1.2685e+00, -4.4585e+00, -1.1405e+00,\n",
      "          2.1350e-01, -2.6330e+00, -1.4085e+00,  8.6300e-01,  9.8350e-01],\n",
      "        [-2.7827e+01, -7.0015e+00, -2.3280e+00, -5.0900e-01,  4.4250e-01,\n",
      "         -1.3829e+01,  2.1150e-01,  8.5050e-01,  4.3100e+00,  3.0140e+00,\n",
      "         -3.2100e+00, -5.8150e-01, -4.9750e-01,  1.4759e+01,  6.0050e+00,\n",
      "          7.9075e+00,  2.1950e-01, -6.1400e-01,  3.3075e+00,  2.0575e+00],\n",
      "        [ 4.7625e+00,  5.2795e+00, -7.2650e-01,  8.6500e-02,  6.2000e-02,\n",
      "          8.3200e-01,  1.2110e+00,  3.2900e-01,  1.2925e+00, -2.7950e-01,\n",
      "          1.5040e+00,  1.9350e+00, -1.6030e+00,  2.4165e+00,  2.0650e-01,\n",
      "         -2.7650e-01, -6.4120e+00, -1.0400e-01,  4.5150e-01, -2.0000e-02]])\n",
      "\n",
      "Std: tensor([[ 12.8902,   9.4027,   5.8926,   5.2593,   6.1097,  15.0898,   6.5699,\n",
      "           5.3491,   4.1573,   5.5998,  13.0007,   8.9147,   6.0157,  19.7982,\n",
      "           5.9994,   7.2779,  14.1370,   4.3809,   4.3206, 104.8510],\n",
      "        [ 18.5821,  15.5581,   9.7233,   7.1828,   5.5578,  19.3127,  11.6717,\n",
      "           8.0611,   5.8258,   5.8241,  12.0491,   9.7576,   5.7223,  20.4466,\n",
      "           9.7048,   8.1476,  11.5497,   5.9769,   5.3630,  99.3137],\n",
      "        [153.9661,  31.1559,  25.2263,  27.1243,  38.9772,  86.9526,  19.4734,\n",
      "          11.7899,  23.3155,  23.5796,  33.9455,  29.7606,  60.3190,  89.3679,\n",
      "          31.2479,  79.0218,  25.4446,  17.0593,  27.6134, 117.0193],\n",
      "        [ 28.0955,  19.4893,   9.5571,   6.7683,   9.1419,  27.2634,  10.7891,\n",
      "           7.2487,   5.9213,  12.9704,  17.2157,  10.3160,  11.0857,  29.0766,\n",
      "           9.1495,  11.1274,  33.4638,   6.0886,   5.6623,  94.5204]])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "Mean: tensor([[ 3.8147e-09, -9.5367e-10, -1.9073e-09,  1.1444e-08, -1.9073e-09,\n",
      "         -8.5831e-09, -7.6294e-09,  1.0967e-08, -6.6757e-09,  4.7684e-09,\n",
      "          1.3351e-08,  9.5367e-09, -5.7220e-09, -5.7220e-09,  9.5367e-09,\n",
      "         -1.3351e-08,  3.3379e-08, -4.7684e-09, -1.6212e-08, -1.1444e-08],\n",
      "        [ 1.8597e-08,  2.1458e-08, -2.0027e-08, -5.7220e-09, -4.7684e-10,\n",
      "          2.4796e-08,  9.5367e-09,  9.5367e-09,  2.3842e-09, -1.3351e-08,\n",
      "         -1.3351e-08, -9.5367e-09, -3.0518e-08,  2.3842e-09,  4.7684e-10,\n",
      "         -1.9073e-09,  1.3351e-08,  7.6294e-09,  4.7684e-09,  6.6757e-09],\n",
      "        [ 3.8147e-09, -1.1444e-08, -3.3379e-09, -3.8147e-09,  0.0000e+00,\n",
      "          7.6294e-09,  3.8147e-09, -7.6294e-09,  0.0000e+00,  0.0000e+00,\n",
      "         -1.4305e-08, -1.9073e-09, -7.6294e-09,  8.2254e-09, -2.2888e-08,\n",
      "         -8.5831e-09,  0.0000e+00, -5.7220e-09, -1.9073e-09, -1.5259e-08],\n",
      "        [-2.1935e-08,  2.1935e-08, -2.2650e-08, -1.5259e-08, -5.7220e-09,\n",
      "         -1.5259e-08, -9.5367e-09, -2.5749e-08,  7.6294e-09, -1.5259e-08,\n",
      "         -4.7684e-10,  2.6703e-08, -1.5259e-08, -6.3181e-09,  7.6294e-09,\n",
      "         -3.5763e-09, -2.1935e-08,  1.2875e-08,  5.7220e-09, -3.8147e-09]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Std: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizePerSignal()\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Signal normalization using the specified mean and std values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and standard deviation for signal:\n",
      "tensor([[[ 0.3848],\n",
      "         [ 0.0929],\n",
      "         [ 0.0679],\n",
      "         [ 0.1235],\n",
      "         [ 0.2628],\n",
      "         [-0.1592],\n",
      "         [-0.0261],\n",
      "         [-0.0366],\n",
      "         [-0.1227],\n",
      "         [ 0.1542],\n",
      "         [-0.1571],\n",
      "         [-0.0203],\n",
      "         [ 0.0513],\n",
      "         [-0.3129],\n",
      "         [-0.1915],\n",
      "         [-0.1468],\n",
      "         [ 0.1375],\n",
      "         [-0.0133],\n",
      "         [ 0.0477],\n",
      "         [ 0.0199]]])\n",
      "-\n",
      "tensor([[[46.6161],\n",
      "         [21.1672],\n",
      "         [11.7478],\n",
      "         [11.2979],\n",
      "         [14.8326],\n",
      "         [49.3067],\n",
      "         [19.5424],\n",
      "         [10.4230],\n",
      "         [11.6122],\n",
      "         [15.3615],\n",
      "         [21.0841],\n",
      "         [14.5436],\n",
      "         [13.6893],\n",
      "         [21.1969],\n",
      "         [17.4971],\n",
      "         [13.7927],\n",
      "         [19.8298],\n",
      "         [11.1799],\n",
      "         [11.2053],\n",
      "         [94.0091]]])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeMeanStd(mean=tensor([ 0.3848,  0.0929,  0.0679,  0.1235,  0.2628, -0.1592, -0.0261, -0.0366,\n",
      "          -0.1227,  0.1542, -0.1571, -0.0203,  0.0513, -0.3129, -0.1915, -0.1468,\n",
      "           0.1375, -0.0133,  0.0477,  0.0199]),std=tensor([46.6161, 21.1672, 11.7478, 11.2979, 14.8326, 49.3067, 19.5424, 10.4230,\n",
      "          11.6122, 15.3615, 21.0841, 14.5436, 13.6893, 21.1969, 17.4971, 13.7927,\n",
      "          19.8298, 11.1799, 11.2053, 94.0091]),eps=1e-08)\n",
      ")\n",
      "- Before -\n",
      "Mean: tensor([[-1.2790e+00, -1.2800e+00,  4.4750e-01, -3.7600e-01,  1.1600e+00,\n",
      "          1.1265e+00,  1.3095e+00, -1.1255e+00,  4.8200e-01,  1.0045e+00,\n",
      "          2.8000e-01, -7.0050e-01,  5.1650e-01, -2.1195e+00,  6.0700e-01,\n",
      "          8.8950e-01, -4.3500e-01, -5.5550e-01, -8.2000e-02,  4.7500e-02],\n",
      "        [-3.2070e+00,  1.0510e+00,  3.3090e+00, -4.5150e-01,  6.5000e-03,\n",
      "         -1.8710e+00, -2.2250e-01, -5.2100e-01,  1.4500e-01, -5.4350e-01,\n",
      "          2.0030e+00,  1.0210e+00,  1.1805e+00, -2.0390e+00, -5.4900e-01,\n",
      "          2.6300e-01, -2.8025e+00, -9.8250e-01, -8.2600e-01,  1.0000e-01],\n",
      "        [-1.7597e+01, -1.6550e-01,  8.8100e-01,  1.0670e+00,  6.4500e-01,\n",
      "         -1.0663e+01, -1.4270e+00, -1.5850e-01, -3.5200e-01,  1.1765e+00,\n",
      "         -1.8250e-01, -1.2215e+00,  5.3600e-01,  9.1050e-01,  8.1600e-01,\n",
      "          7.2550e-01, -3.5235e+00, -4.0100e-01,  6.6100e-01,  8.0000e-02],\n",
      "        [-4.3300e+00,  5.9550e-01,  1.1800e-01,  6.3200e-01,  9.5350e-01,\n",
      "          6.6090e+00,  1.1500e-02,  8.5600e-01,  1.0660e+00,  1.5510e+00,\n",
      "          1.7010e+00,  3.8950e-01,  3.5500e-01, -3.6580e+00, -3.6500e-01,\n",
      "          8.6550e-01, -7.3960e+00,  1.1445e+00,  1.2060e+00, -7.9350e-01]])\n",
      "\n",
      "Std: tensor([[64.3308, 18.6249, 11.1081,  8.4235,  9.2198, 75.4726, 21.4778, 10.6719,\n",
      "          7.8750,  9.4038, 45.5895, 16.8493, 10.0429, 43.1812, 12.9879, 10.6649,\n",
      "         16.7658,  6.7707,  6.0078, 72.9274],\n",
      "        [56.2600, 17.0250,  9.7123,  8.9371, 13.6385, 54.7798, 11.1329,  7.5606,\n",
      "          8.0248,  9.9615, 31.5215,  8.3344,  8.4101, 25.2980, 11.0048, 11.7691,\n",
      "         12.8527,  9.2892,  8.8505, 73.6572],\n",
      "        [49.6999,  8.5092,  4.9185,  4.9566,  9.2609, 37.4165,  7.8636,  3.7756,\n",
      "          4.3836,  8.5554, 17.1518,  7.0647,  7.4138,  8.4522,  6.8975,  6.4596,\n",
      "         22.2799,  4.2554,  4.2305, 88.5435],\n",
      "        [63.7160, 11.0309,  4.9969,  6.4275, 10.1541, 55.2884, 11.9562,  3.6234,\n",
      "          6.1891,  9.4427, 15.5103,  7.1955,  8.4229,  7.6505,  5.4508,  8.4068,\n",
      "         22.6981,  4.2283,  4.0914, 88.4446]])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "Mean: tensor([[-3.5691e-02, -6.4862e-02,  3.2313e-02, -4.4209e-02,  6.0488e-02,\n",
      "          2.6076e-02,  6.8345e-02, -1.0447e-01,  5.2072e-02,  5.5350e-02,\n",
      "          2.0733e-02, -4.6769e-02,  3.3986e-02, -8.5232e-02,  4.5639e-02,\n",
      "          7.5135e-02, -2.8872e-02, -4.8493e-02, -1.1579e-02,  2.9393e-04],\n",
      "        [-7.7050e-02,  4.5262e-02,  2.7589e-01, -5.0891e-02, -1.7281e-02,\n",
      "         -3.4717e-02, -1.0049e-02, -4.6471e-02,  2.3051e-02, -4.5422e-02,\n",
      "          1.0245e-01,  7.1599e-02,  8.2491e-02, -8.1434e-02, -2.0429e-02,\n",
      "          2.9712e-02, -1.4826e-01, -8.6687e-02, -7.7976e-02,  8.5238e-04],\n",
      "        [-3.8574e-01, -1.2210e-02,  6.9214e-02,  8.3514e-02,  2.5767e-02,\n",
      "         -2.1303e-01, -7.1684e-02, -1.1692e-02, -1.9749e-02,  6.6547e-02,\n",
      "         -1.2031e-03, -8.2593e-02,  3.5410e-02,  5.7714e-02,  5.7584e-02,\n",
      "          6.3245e-02, -1.8462e-01, -3.4674e-02,  5.4729e-02,  6.3964e-04],\n",
      "        [-1.0114e-01,  2.3742e-02,  4.2656e-03,  4.5011e-02,  4.6566e-02,\n",
      "          1.3727e-01,  1.9251e-03,  8.5640e-02,  1.0236e-01,  9.0926e-02,\n",
      "          8.8129e-02,  2.8178e-02,  2.2188e-02, -1.5781e-01, -9.9132e-03,\n",
      "          7.3395e-02, -3.7991e-01,  1.0356e-01,  1.0337e-01, -8.6520e-03]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Std: tensor([[1.3800, 0.8799, 0.9456, 0.7456, 0.6216, 1.5307, 1.0990, 1.0239, 0.6782,\n",
      "         0.6122, 2.1623, 1.1585, 0.7336, 2.0372, 0.7423, 0.7732, 0.8455, 0.6056,\n",
      "         0.5362, 0.7757],\n",
      "        [1.2069, 0.8043, 0.8267, 0.7910, 0.9195, 1.1110, 0.5697, 0.7254, 0.6911,\n",
      "         0.6485, 1.4950, 0.5731, 0.6144, 1.1935, 0.6290, 0.8533, 0.6481, 0.8309,\n",
      "         0.7898, 0.7835],\n",
      "        [1.0662, 0.4020, 0.4187, 0.4387, 0.6244, 0.7589, 0.4024, 0.3622, 0.3775,\n",
      "         0.5569, 0.8135, 0.4858, 0.5416, 0.3987, 0.3942, 0.4683, 1.1236, 0.3806,\n",
      "         0.3775, 0.9419],\n",
      "        [1.3668, 0.5211, 0.4253, 0.5689, 0.6846, 1.1213, 0.6118, 0.3476, 0.5330,\n",
      "         0.6147, 0.7356, 0.4948, 0.6153, 0.3609, 0.3115, 0.6095, 1.1446, 0.3782,\n",
      "         0.3651, 0.9408]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "signal_mean, signal_std = calculate_signal_statistics(train_loader, repeats=1, verbose=True)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Age normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age mean and standard deviation:\n",
      "tensor([71.2453]) tensor([6.3654])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2453]),std=tensor([6.3654]),eps=1e-08)\n",
      ")\n",
      "- Before -\n",
      "tensor([74., 74., 83., 83.])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "tensor([0.4328, 0.4328, 1.8466, 1.8466], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "age_mean, age_std = calculate_age_statistics(train_loader, verbose=True)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    pprint.pprint(sample_batched['age'])\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    pprint.pprint(sample_batched['age'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Short time Fourier transform (STFT or spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegSpectrogram(n_fft=200, complex_mode=as_real, stft_kwargs={})\n",
      ")\n",
      "- Before -\n",
      "torch.Size([4, 20, 2000])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "torch.Size([4, 40, 101, 41])\n"
     ]
    }
   ],
   "source": [
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegSpectrogram(n_fft=200, complex_mode='as_real')\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    pprint.pprint(sample_batched['signal'].shape)\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    pprint.pprint(sample_batched['signal'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Signal normalization after STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegSpectrogram(n_fft=200, complex_mode=as_real, stft_kwargs={})\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegNormalizeMeanStd(mean=tensor([[ 1.5429e+01,  6.4722e-01,  3.8627e-02,  ...,  2.4955e-02,\n",
      "            2.2957e-02,  2.9620e-02],\n",
      "          [ 7.0377e+00,  3.1176e-01, -5.6557e-02,  ...,  1.6799e-02,\n",
      "            1.8693e-02,  1.0362e-02],\n",
      "          [-8.2014e+00,  9.6021e-02, -6.2677e-02,  ..., -1.7618e-02,\n",
      "           -1.6574e-02, -2.3030e-03],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  1.1431e+00,  6.7176e-01,  ...,  1.7511e-03,\n",
      "            2.2550e-03, -1.6554e-08],\n",
      "          [ 0.0000e+00,  1.1292e+00,  7.2300e-01,  ...,  1.3086e-03,\n",
      "            7.3269e-04, -6.1795e-09],\n",
      "          [ 0.0000e+00,  2.4342e+00,  1.1617e+00,  ...,  6.9995e-04,\n",
      "           -7.2238e-04, -4.8062e-08]], device='cuda:0'),std=tensor([[7.3918e+03, 1.5109e+03, 7.8873e+02,  ..., 2.8842e+01, 2.8815e+01,\n",
      "           2.9036e+01],\n",
      "          [3.2748e+03, 5.9179e+02, 3.0332e+02,  ..., 1.3358e+01, 1.3315e+01,\n",
      "           1.3690e+01],\n",
      "          [1.7877e+03, 2.8261e+02, 1.5144e+02,  ..., 8.0211e+00, 7.9636e+00,\n",
      "           8.5363e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 4.5049e+02, 2.4541e+02,  ..., 2.7943e+00, 2.8723e+00,\n",
      "           3.2397e-06],\n",
      "          [0.0000e+00, 4.9719e+02, 2.6918e+02,  ..., 2.7955e+00, 2.8820e+00,\n",
      "           3.2478e-06],\n",
      "          [0.0000e+00, 2.0904e+03, 1.9729e+03,  ..., 3.6471e+00, 4.7721e+00,\n",
      "           5.9462e-05]], device='cuda:0'),eps=1e-08)\n",
      ")\n",
      "- Before -\n",
      "Mean: tensor([[[ 2.8959e+02,  1.0710e+01, -3.6889e+00,  ...,  2.9007e-03,\n",
      "           2.0728e-01, -1.8293e+00],\n",
      "         [ 7.7537e+01, -5.9001e+00,  3.1087e+00,  ...,  4.0850e-02,\n",
      "           6.9827e-02, -1.0000e+00],\n",
      "         [-5.6390e+01, -1.0660e+00,  1.3198e+00,  ...,  8.1481e-02,\n",
      "           2.2979e-01, -4.8777e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -3.2375e+00, -5.8790e+00,  ...,  1.3952e-01,\n",
      "           2.1493e-01,  2.2661e-08],\n",
      "         [ 0.0000e+00,  1.1021e+01,  4.4997e+00,  ..., -1.1524e-02,\n",
      "           8.0906e-02, -2.3745e-07],\n",
      "         [ 0.0000e+00, -1.4156e+02, -9.6745e+01,  ...,  3.9833e-01,\n",
      "           4.2432e-01, -3.1255e-05]],\n",
      "\n",
      "        [[ 2.8020e+02,  1.0855e+01, -1.6295e+00,  ...,  8.9670e-01,\n",
      "           7.8884e-01,  3.4634e+00],\n",
      "         [-2.6649e+02,  2.7014e+00, -1.5952e+00,  ...,  2.4905e-01,\n",
      "           8.8093e-02,  5.8536e-01],\n",
      "         [ 5.9073e+01,  6.2145e+00,  1.7258e+00,  ...,  4.4310e-01,\n",
      "           3.0040e-01,  1.5122e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -1.5278e+01, -3.7575e+00,  ...,  3.2823e-02,\n",
      "          -1.0323e-02,  2.3544e-06],\n",
      "         [ 0.0000e+00, -5.2347e+00, -1.9539e+00,  ...,  8.3975e-02,\n",
      "           2.0445e-01,  2.5022e-06],\n",
      "         [ 0.0000e+00, -4.2190e+01,  9.5950e+00,  ..., -1.3041e-01,\n",
      "          -2.0100e-01, -4.2902e-07]],\n",
      "\n",
      "        [[ 2.3237e+02,  8.5571e+00, -3.4636e+01,  ...,  9.2031e-01,\n",
      "           9.9350e-01,  1.3415e+00],\n",
      "         [-2.0968e+02,  1.3773e+00, -8.6277e+00,  ...,  4.1559e-01,\n",
      "           2.8799e-01,  2.5122e+00],\n",
      "         [ 1.0280e+02,  1.6741e+00,  6.8070e-01,  ...,  7.2338e-03,\n",
      "          -3.0441e-02,  1.0976e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -2.2181e+00, -1.7588e+00,  ...,  3.7998e-02,\n",
      "           9.8426e-02, -1.3670e-06],\n",
      "         [ 0.0000e+00,  1.0612e+01,  5.8868e+00,  ...,  2.0037e-02,\n",
      "           7.2949e-02, -1.9694e-06],\n",
      "         [ 0.0000e+00, -1.2262e+02, -5.0900e+01,  ..., -6.3532e-02,\n",
      "           5.3256e-01, -1.0946e-05]],\n",
      "\n",
      "        [[-1.1073e+03, -2.6977e+01,  2.5311e-01,  ...,  2.1956e+00,\n",
      "           2.1160e+00,  4.1463e+00],\n",
      "         [ 5.1239e+02, -5.5990e+00, -1.0239e+01,  ..., -1.2819e+00,\n",
      "          -1.2082e+00, -7.8049e-01],\n",
      "         [-1.8817e+02, -9.7524e+00, -5.6324e+00,  ..., -1.3628e-01,\n",
      "          -6.2189e-02, -1.7073e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  2.2564e+01,  1.5676e+01,  ...,  1.6769e-02,\n",
      "           6.2801e-02, -2.6567e-06],\n",
      "         [ 0.0000e+00, -1.9653e+01, -8.7625e+00,  ..., -2.1609e-02,\n",
      "          -1.6638e-01, -3.2498e-06],\n",
      "         [ 0.0000e+00, -5.4698e+01, -1.6768e+00,  ...,  5.0319e-02,\n",
      "           6.8462e-02, -1.2706e-05]]], device='cuda:0')\n",
      "\n",
      "Std: tensor([[[3.3454e+03, 1.0361e+03, 4.6166e+02,  ..., 1.6786e+01,\n",
      "          1.6741e+01, 1.6242e+01],\n",
      "         [6.6534e+02, 3.9555e+02, 2.0995e+02,  ..., 7.9469e+00,\n",
      "          7.7853e+00, 7.0498e+00],\n",
      "         [4.6026e+02, 1.4918e+02, 7.7942e+01,  ..., 6.2343e+00,\n",
      "          5.8778e+00, 8.8740e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 2.3542e+02, 1.5234e+02,  ..., 2.4573e+00,\n",
      "          2.7657e+00, 5.0309e-06],\n",
      "         [0.0000e+00, 2.4332e+02, 1.3663e+02,  ..., 3.1402e+00,\n",
      "          2.4150e+00, 4.6388e-06],\n",
      "         [0.0000e+00, 1.7218e+03, 1.1979e+03,  ..., 3.1204e+00,\n",
      "          3.1152e+00, 6.5616e-05]],\n",
      "\n",
      "        [[2.3637e+03, 8.2104e+02, 3.6388e+02,  ..., 1.2926e+01,\n",
      "          1.2479e+01, 1.3347e+01],\n",
      "         [7.1844e+02, 2.3161e+02, 1.7290e+02,  ..., 7.4647e+00,\n",
      "          7.0746e+00, 7.4127e+00],\n",
      "         [3.7824e+02, 2.1660e+02, 1.1094e+02,  ..., 7.2092e+00,\n",
      "          6.1883e+00, 7.9439e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 2.1525e+02, 1.4071e+02,  ..., 2.4354e+00,\n",
      "          2.7368e+00, 7.3516e-06],\n",
      "         [0.0000e+00, 1.8245e+02, 1.6634e+02,  ..., 2.6242e+00,\n",
      "          2.6257e+00, 4.8617e-06],\n",
      "         [0.0000e+00, 1.6141e+03, 1.6894e+03,  ..., 4.0757e+00,\n",
      "          2.3922e+00, 6.4627e-05]],\n",
      "\n",
      "        [[8.3059e+03, 1.4616e+03, 8.3789e+02,  ..., 3.2124e+01,\n",
      "          3.2447e+01, 3.1660e+01],\n",
      "         [2.7960e+03, 6.3481e+02, 2.8026e+02,  ..., 1.3017e+01,\n",
      "          1.2715e+01, 1.3083e+01],\n",
      "         [5.1883e+02, 1.6532e+02, 8.1329e+01,  ..., 4.8925e+00,\n",
      "          4.2905e+00, 5.7698e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 2.2600e+02, 1.1731e+02,  ..., 4.1975e+00,\n",
      "          2.9421e+00, 3.2493e-06],\n",
      "         [0.0000e+00, 4.2824e+02, 2.0652e+02,  ..., 2.5920e+00,\n",
      "          2.5260e+00, 3.1783e-06],\n",
      "         [0.0000e+00, 2.3236e+03, 1.3784e+03,  ..., 3.7858e+00,\n",
      "          3.2672e+00, 4.9249e-05]],\n",
      "\n",
      "        [[5.4203e+03, 1.4479e+03, 9.0716e+02,  ..., 2.7536e+01,\n",
      "          2.6985e+01, 2.6629e+01],\n",
      "         [2.9252e+03, 1.3111e+03, 6.8481e+02,  ..., 2.4431e+01,\n",
      "          2.4170e+01, 2.2801e+01],\n",
      "         [2.1551e+03, 8.8369e+02, 3.5970e+02,  ..., 1.3848e+01,\n",
      "          1.3855e+01, 1.5372e+01],\n",
      "         ...,\n",
      "         [0.0000e+00, 2.3416e+02, 1.3666e+02,  ..., 2.9508e+00,\n",
      "          2.0783e+00, 2.2651e-06],\n",
      "         [0.0000e+00, 2.3732e+02, 1.6997e+02,  ..., 2.1208e+00,\n",
      "          2.9044e+00, 2.7632e-06],\n",
      "         [0.0000e+00, 2.2076e+03, 1.9519e+03,  ..., 4.7317e+00,\n",
      "          3.5652e+00, 5.3436e-05]]], device='cuda:0')\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "Mean: tensor([[[ 3.7090e-02,  6.6601e-03, -4.7260e-03,  ..., -7.6465e-04,\n",
      "           6.3969e-03, -6.4021e-02],\n",
      "         [ 2.1527e-02, -1.0497e-02,  1.0436e-02,  ...,  1.8005e-03,\n",
      "           3.8404e-03, -7.3804e-02],\n",
      "         [-2.6955e-02, -4.1117e-03,  9.1287e-03,  ...,  1.2355e-02,\n",
      "           3.0936e-02, -5.4443e-03],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -9.7240e-03, -2.6693e-02,  ...,  4.9305e-02,\n",
      "           7.4045e-02,  1.2067e-02],\n",
      "         [ 0.0000e+00,  1.9895e-02,  1.4030e-02,  ..., -4.5904e-03,\n",
      "           2.7818e-02, -7.0991e-02],\n",
      "         [ 0.0000e+00, -6.8882e-02, -4.9627e-02,  ...,  1.0903e-01,\n",
      "           8.9068e-02, -5.2474e-01]],\n",
      "\n",
      "        [[ 3.5819e-02,  6.7559e-03, -2.1150e-03,  ...,  3.0225e-02,\n",
      "           2.6579e-02,  1.1826e-01],\n",
      "         [-8.3523e-02,  4.0379e-03, -5.0727e-03,  ...,  1.7386e-02,\n",
      "           5.2122e-03,  4.2002e-02],\n",
      "         [ 3.7631e-02,  2.1650e-02,  1.1810e-02,  ...,  5.7438e-02,\n",
      "           3.9803e-02,  1.7742e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -3.6452e-02, -1.8048e-02,  ...,  1.1120e-02,\n",
      "          -4.3791e-03,  7.2957e-01],\n",
      "         [ 0.0000e+00, -1.2800e-02, -9.9445e-03,  ...,  2.9571e-02,\n",
      "           7.0687e-02,  7.6994e-01],\n",
      "         [ 0.0000e+00, -2.1347e-02,  4.2747e-03,  ..., -3.5950e-02,\n",
      "          -4.1968e-02, -6.4057e-03]],\n",
      "\n",
      "        [[ 2.9349e-02,  5.2351e-03, -4.3963e-02,  ...,  3.1044e-02,\n",
      "           3.3682e-02,  4.5180e-02],\n",
      "         [-6.6177e-02,  1.8005e-03, -2.8258e-02,  ...,  2.9854e-02,\n",
      "           2.0225e-02,  1.8275e-01],\n",
      "         [ 6.2093e-02,  5.5839e-03,  4.9087e-03,  ...,  3.0983e-03,\n",
      "          -1.7412e-03,  1.2885e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -7.4613e-03, -9.9040e-03,  ...,  1.2972e-02,\n",
      "           3.3482e-02, -4.1554e-01],\n",
      "         [ 0.0000e+00,  1.9073e-02,  1.9183e-02,  ...,  6.6995e-03,\n",
      "           2.5057e-02, -6.0263e-01],\n",
      "         [ 0.0000e+00, -5.9825e-02, -2.6389e-02,  ..., -1.7612e-02,\n",
      "           1.1175e-01, -1.8325e-01]],\n",
      "\n",
      "        [[-1.5189e-01, -1.8283e-02,  2.7194e-04,  ...,  7.5260e-02,\n",
      "           7.2636e-02,  1.4178e-01],\n",
      "         [ 1.5431e-01, -9.9881e-03, -3.3570e-02,  ..., -9.7224e-02,\n",
      "          -9.2143e-02, -5.7769e-02],\n",
      "         [-1.0067e-01, -3.4848e-02, -3.6779e-02,  ..., -1.4794e-02,\n",
      "          -5.7279e-03, -1.9731e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  4.7550e-02,  6.1140e-02,  ...,  5.3745e-03,\n",
      "           2.1079e-02, -8.1243e-01],\n",
      "         [ 0.0000e+00, -4.1798e-02, -3.5238e-02,  ..., -8.1978e-03,\n",
      "          -5.7983e-02, -9.9565e-01],\n",
      "         [ 0.0000e+00, -2.7331e-02, -1.4387e-03,  ...,  1.3605e-02,\n",
      "           1.4498e-02, -2.1284e-01]]], device='cuda:0')\n",
      "\n",
      "Std: tensor([[[0.4526, 0.6858, 0.5853,  ..., 0.5820, 0.5810, 0.5594],\n",
      "         [0.2032, 0.6684, 0.6922,  ..., 0.5949, 0.5847, 0.5150],\n",
      "         [0.2575, 0.5279, 0.5147,  ..., 0.7772, 0.7381, 1.0396],\n",
      "         ...,\n",
      "         [0.0000, 0.5226, 0.6208,  ..., 0.8794, 0.9629, 1.5481],\n",
      "         [0.0000, 0.4894, 0.5076,  ..., 1.1233, 0.8380, 1.4239],\n",
      "         [0.0000, 0.8237, 0.6072,  ..., 0.8556, 0.6528, 1.1033]],\n",
      "\n",
      "        [[0.3198, 0.5434, 0.4613,  ..., 0.4482, 0.4331, 0.4597],\n",
      "         [0.2194, 0.3914, 0.5700,  ..., 0.5588, 0.5313, 0.5415],\n",
      "         [0.2116, 0.7664, 0.7326,  ..., 0.8988, 0.7771, 0.9306],\n",
      "         ...,\n",
      "         [0.0000, 0.4778, 0.5734,  ..., 0.8715, 0.9528, 2.2622],\n",
      "         [0.0000, 0.3670, 0.6180,  ..., 0.9387, 0.9111, 1.4923],\n",
      "         [0.0000, 0.7721, 0.8563,  ..., 1.1175, 0.5013, 1.0867]],\n",
      "\n",
      "        [[1.1237, 0.9674, 1.0623,  ..., 1.1138, 1.1261, 1.0904],\n",
      "         [0.8538, 1.0727, 0.9240,  ..., 0.9745, 0.9549, 0.9556],\n",
      "         [0.2902, 0.5850, 0.5370,  ..., 0.6100, 0.5388, 0.6759],\n",
      "         ...,\n",
      "         [0.0000, 0.5017, 0.4780,  ..., 1.5022, 1.0243, 0.9999],\n",
      "         [0.0000, 0.8613, 0.7672,  ..., 0.9272, 0.8765, 0.9756],\n",
      "         [0.0000, 1.1115, 0.6987,  ..., 1.0380, 0.6846, 0.8281]],\n",
      "\n",
      "        [[0.7333, 0.9583, 1.1502,  ..., 0.9547, 0.9365, 0.9171],\n",
      "         [0.8932, 2.2155, 2.2577,  ..., 1.8289, 1.8152, 1.6655],\n",
      "         [1.2055, 3.1269, 2.3752,  ..., 1.7265, 1.7398, 1.8008],\n",
      "         ...,\n",
      "         [0.0000, 0.5198, 0.5569,  ..., 1.0560, 0.7235, 0.6970],\n",
      "         [0.0000, 0.4773, 0.6314,  ..., 0.7586, 1.0078, 0.8482],\n",
      "         [0.0000, 1.0561, 0.9894,  ..., 1.2974, 0.7471, 0.8985]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegSpectrogram(n_fft=200, complex_mode='as_real')\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "\n",
    "signal_2d_mean, signal_2d_std = calculate_signal_statistics(train_loader, preprocess_train)\n",
    "\n",
    "preprocess_train2 = transforms.Compose([\n",
    "    EegNormalizeMeanStd(mean=signal_2d_mean, std=signal_2d_std)\n",
    "])\n",
    "preprocess_train2 = torch.nn.Sequential(*preprocess_train2.transforms).to(device)\n",
    "\n",
    "pprint.pprint(preprocess_train)\n",
    "pprint.pprint(preprocess_train2)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    preprocess_train(sample_batched)   \n",
    "    \n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "    \n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    print('- After -')\n",
    "    preprocess_train2(sample_batched)\n",
    "    \n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Speed check without STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "crop_length = 200 * 10\n",
    "multiple = 4\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### `EDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### `memmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    " \n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### `memmap` (Drop  Crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    " \n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Speed check with STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence length: (3000) would become (78, 77) after the STFT with n_fft (155) and hop_length (39).\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crop_length = 300 * 10\n",
    "n_fft, hop_length, seq_len_2d = calculate_stft_params(seq_length=crop_length, verbose=True)\n",
    "multiple = 2\n",
    "batch_size = 128\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegSpectrogram(n_fft=n_fft, hop_length=hop_length, complex_mode='as_real')\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "signal_2d_mean, signal_2d_std = calculate_signal_statistics(train_loader, preprocess_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### `EDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf',\n",
    "                                                                                  transform=transform)\n",
    " \n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegSpectrogram(n_fft=n_fft, hop_length=hop_length, complex_mode='as_real'),\n",
    "    EegNormalizeMeanStd(mean=signal_2d_mean, std=signal_2d_std),\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)\n",
    "    size = sample_batched['signal'].size()\n",
    "    \n",
    "print(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### `memmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegSpectrogram(n_fft=n_fft, hop_length=hop_length, complex_mode='as_real'),\n",
    "    EegNormalizeMeanStd(mean=signal_2d_mean, std=signal_2d_std),\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)\n",
    "    size = sample_batched['signal'].size()\n",
    "    \n",
    "print(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Test on longer sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "longer_transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*10*6,     # crop: 1m\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=2, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(longer_transform)\n",
    "\n",
    "config_data, longer_test_dataset = load_caueeg_task_split(dataset_path=data_path, \n",
    "                                                          task='dementia', \n",
    "                                                          split='test',\n",
    "                                                          load_event=False,\n",
    "                                                          file_format='memmap', \n",
    "                                                          transform=longer_transform)\n",
    "\n",
    "longer_test_loader = DataLoader(longer_test_dataset,\n",
    "                                batch_size=32,\n",
    "                                shuffle=True,\n",
    "                                drop_last=False,\n",
    "                                num_workers=num_workers,\n",
    "                                pin_memory=pin_memory,\n",
    "                                collate_fn=eeg_collate_fn)\n",
    " \n",
    "preprocess_test = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std),\n",
    "    EegNormalizeAge(mean=age_mean, std=age_std),\n",
    "])\n",
    "preprocess_test = torch.nn.Sequential(*preprocess_test.transforms).to(device)\n",
    "pprint.pprint(preprocess_test)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_test(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=40000, length_limit=120000, multiple=2, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegResample(resampling_method='kaiser_best', resampler=Resample())\n",
      "  (2): EegResample(resampling_method='kaiser_best', resampler=Resample())\n",
      "  (3): EegNormalizeAge(mean=tensor([71.2453]),std=tensor([6.3654]),eps=1e-08)\n",
      "  (4): EegNormalizeMeanStd(mean=tensor([ 0.3848,  0.0929,  0.0679,  0.1235,  0.2628, -0.1592, -0.0261, -0.0366,\n",
      "          -0.1227,  0.1542, -0.1571, -0.0203,  0.0513, -0.3129, -0.1915, -0.1468,\n",
      "           0.1375, -0.0133,  0.0477,  0.0199]),std=tensor([46.6161, 21.1672, 11.7478, 11.2979, 14.8326, 49.3067, 19.5424, 10.4230,\n",
      "          11.6122, 15.3615, 21.0841, 14.5436, 13.6893, 21.1969, 17.4971, 13.7927,\n",
      "          19.8298, 11.1799, 11.2053, 94.0091]),eps=1e-08)\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2453]),std=tensor([6.3654]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([ 0.3848,  0.0929,  0.0679,  0.1235,  0.2628, -0.1592, -0.0261, -0.0366,\n",
      "          -0.1227,  0.1542, -0.1571, -0.0203,  0.0513, -0.3129, -0.1915, -0.1468,\n",
      "           0.1375, -0.0133,  0.0477,  0.0199]),std=tensor([46.6161, 21.1672, 11.7478, 11.2979, 14.8326, 49.3067, 19.5424, 10.4230,\n",
      "          11.6122, 15.3615, 21.0841, 14.5436, 13.6893, 21.1969, 17.4971, 13.7927,\n",
      "          19.8298, 11.1799, 11.2053, 94.0091]),eps=1e-08)\n",
      ")\n",
      "0.0852751360507682\n",
      "CPU times: total: 7min 50s\n",
      "Wall time: 42.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*200,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train1 = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegResample(orig_freq=200, new_freq=250, resampling_method='kaiser_best'),\n",
    "    EegResample(orig_freq=250, new_freq=200, resampling_method='kaiser_best'),\n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std),\n",
    "])\n",
    "preprocess_train1 = torch.nn.Sequential(*preprocess_train1.transforms).to(device)\n",
    "pprint.pprint(preprocess_train1)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train2 = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std),\n",
    "])\n",
    "preprocess_train2 = torch.nn.Sequential(*preprocess_train2.transforms).to(device)\n",
    "pprint.pprint(preprocess_train2)\n",
    "\n",
    "diff = 0.0\n",
    "for e in range(5):\n",
    "    for i_batch, sample_batched in enumerate(train_loader):\n",
    "        from copy import deepcopy\n",
    "        sb1 = deepcopy(sample_batched)\n",
    "        sb2 = deepcopy(sample_batched)\n",
    "\n",
    "        preprocess_train1(sb1)\n",
    "        preprocess_train2(sb2)\n",
    "        \n",
    "        diff += (torch.norm(sb1['signal'] - sb2['signal']) / torch.sqrt(torch.norm(sb1['signal'])) / torch.sqrt(torch.norm(sb1['signal']))).item()\n",
    "        \n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=40000, length_limit=120000, multiple=2, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegResample(resampling_method='kaiser_fast', resampler=Resample())\n",
      "  (2): EegResample(resampling_method='kaiser_fast', resampler=Resample())\n",
      "  (3): EegNormalizeAge(mean=tensor([71.2453]),std=tensor([6.3654]),eps=1e-08)\n",
      "  (4): EegNormalizeMeanStd(mean=tensor([ 0.3848,  0.0929,  0.0679,  0.1235,  0.2628, -0.1592, -0.0261, -0.0366,\n",
      "          -0.1227,  0.1542, -0.1571, -0.0203,  0.0513, -0.3129, -0.1915, -0.1468,\n",
      "           0.1375, -0.0133,  0.0477,  0.0199]),std=tensor([46.6161, 21.1672, 11.7478, 11.2979, 14.8326, 49.3067, 19.5424, 10.4230,\n",
      "          11.6122, 15.3615, 21.0841, 14.5436, 13.6893, 21.1969, 17.4971, 13.7927,\n",
      "          19.8298, 11.1799, 11.2053, 94.0091]),eps=1e-08)\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2453]),std=tensor([6.3654]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([ 0.3848,  0.0929,  0.0679,  0.1235,  0.2628, -0.1592, -0.0261, -0.0366,\n",
      "          -0.1227,  0.1542, -0.1571, -0.0203,  0.0513, -0.3129, -0.1915, -0.1468,\n",
      "           0.1375, -0.0133,  0.0477,  0.0199]),std=tensor([46.6161, 21.1672, 11.7478, 11.2979, 14.8326, 49.3067, 19.5424, 10.4230,\n",
      "          11.6122, 15.3615, 21.0841, 14.5436, 13.6893, 21.1969, 17.4971, 13.7927,\n",
      "          19.8298, 11.1799, 11.2053, 94.0091]),eps=1e-08)\n",
      ")\n",
      "0.21522221295163035\n",
      "CPU times: total: 7min 53s\n",
      "Wall time: 41.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*200,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train1 = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegResample(orig_freq=200, new_freq=250, resampling_method='kaiser_fast'),\n",
    "    EegResample(orig_freq=250, new_freq=200, resampling_method='kaiser_fast'),\n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std),\n",
    "])\n",
    "preprocess_train1 = torch.nn.Sequential(*preprocess_train1.transforms).to(device)\n",
    "pprint.pprint(preprocess_train1)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train2 = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std),\n",
    "])\n",
    "preprocess_train2 = torch.nn.Sequential(*preprocess_train2.transforms).to(device)\n",
    "pprint.pprint(preprocess_train2)\n",
    "\n",
    "diff = 0.0\n",
    "for e in range(5):\n",
    "    for i_batch, sample_batched in enumerate(train_loader):\n",
    "        from copy import deepcopy\n",
    "        sb1 = deepcopy(sample_batched)\n",
    "        sb2 = deepcopy(sample_batched)\n",
    "\n",
    "        preprocess_train1(sb1)\n",
    "        preprocess_train2(sb2)\n",
    "        \n",
    "        diff += (torch.norm(sb1['signal'] - sb2['signal']) / torch.sqrt(torch.norm(sb1['signal'])) / torch.sqrt(torch.norm(sb1['signal']))).item()\n",
    "        \n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=40000, length_limit=120000, multiple=2, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegResample(resampling_method='sinc_interpolation', resampler=Resample())\n",
      "  (2): EegResample(resampling_method='sinc_interpolation', resampler=Resample())\n",
      "  (3): EegNormalizeAge(mean=tensor([71.2453]),std=tensor([6.3654]),eps=1e-08)\n",
      "  (4): EegNormalizeMeanStd(mean=tensor([ 0.3848,  0.0929,  0.0679,  0.1235,  0.2628, -0.1592, -0.0261, -0.0366,\n",
      "          -0.1227,  0.1542, -0.1571, -0.0203,  0.0513, -0.3129, -0.1915, -0.1468,\n",
      "           0.1375, -0.0133,  0.0477,  0.0199]),std=tensor([46.6161, 21.1672, 11.7478, 11.2979, 14.8326, 49.3067, 19.5424, 10.4230,\n",
      "          11.6122, 15.3615, 21.0841, 14.5436, 13.6893, 21.1969, 17.4971, 13.7927,\n",
      "          19.8298, 11.1799, 11.2053, 94.0091]),eps=1e-08)\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([71.2453]),std=tensor([6.3654]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([ 0.3848,  0.0929,  0.0679,  0.1235,  0.2628, -0.1592, -0.0261, -0.0366,\n",
      "          -0.1227,  0.1542, -0.1571, -0.0203,  0.0513, -0.3129, -0.1915, -0.1468,\n",
      "           0.1375, -0.0133,  0.0477,  0.0199]),std=tensor([46.6161, 21.1672, 11.7478, 11.2979, 14.8326, 49.3067, 19.5424, 10.4230,\n",
      "          11.6122, 15.3615, 21.0841, 14.5436, 13.6893, 21.1969, 17.4971, 13.7927,\n",
      "          19.8298, 11.1799, 11.2053, 94.0091]),eps=1e-08)\n",
      ")\n",
      "0.04858447617152706\n",
      "CPU times: total: 7min 56s\n",
      "Wall time: 41.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*200,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='dementia',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train1 = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegResample(orig_freq=200, new_freq=250),\n",
    "    EegResample(orig_freq=250, new_freq=200),\n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std),\n",
    "])\n",
    "preprocess_train1 = torch.nn.Sequential(*preprocess_train1.transforms).to(device)\n",
    "pprint.pprint(preprocess_train1)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train2 = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std),\n",
    "])\n",
    "preprocess_train2 = torch.nn.Sequential(*preprocess_train2.transforms).to(device)\n",
    "pprint.pprint(preprocess_train2)\n",
    "\n",
    "diff = 0.0\n",
    "for e in range(5):\n",
    "    for i_batch, sample_batched in enumerate(train_loader):\n",
    "        from copy import deepcopy\n",
    "        sb1 = deepcopy(sample_batched)\n",
    "        sb2 = deepcopy(sample_batched)\n",
    "\n",
    "        preprocess_train1(sb1)\n",
    "        preprocess_train2(sb2)\n",
    "        \n",
    "        diff += (torch.norm(sb1['signal'] - sb2['signal']) / torch.sqrt(torch.norm(sb1['signal'])) / torch.sqrt(torch.norm(sb1['signal']))).item()\n",
    "        \n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
