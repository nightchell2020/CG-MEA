{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d74515d5-5f25-477b-9a97-ed1f9b6d4c51",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluate Ensemble\n",
    "\n",
    "This notebook combines the classification results of some models via logit-ensembling way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a2666f-6b4b-4748-9dca-2884347a1f0f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df587e38-b1a9-42c8-9b50-680200a9bec7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/imkbsz/workspace/eeg_analysis\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb41bf8-1713-4228-b799-0e1c87545a16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "import pprint\n",
    "import wandb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_script import load_caueeg_config\n",
    "from datasets.caueeg_script import make_dataloader\n",
    "from datasets.caueeg_script import compose_transforms, compose_preprocess\n",
    "from datasets.caueeg_script import load_caueeg_task_datasets\n",
    "from datasets.caueeg_script import load_caueeg_task_split\n",
    "import models\n",
    "from train.evaluate import check_accuracy\n",
    "from train.evaluate import check_accuracy_extended\n",
    "from train.evaluate import check_accuracy_extended_debug\n",
    "from train.evaluate import check_accuracy_multicrop\n",
    "from train.evaluate import check_accuracy_multicrop_extended\n",
    "from train.evaluate import calculate_confusion_matrix\n",
    "from train.evaluate import calculate_confusion_matrix2\n",
    "from train.evaluate import calculate_class_wise_metrics\n",
    "from train.visualize import draw_roc_curve\n",
    "from train.visualize import draw_confusion, draw_confusion2\n",
    "from train.visualize import draw_class_wise_metrics\n",
    "from train.visualize import draw_error_table\n",
    "from train.visualize import annotate_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d10e3f39-ed55-422c-b47f-376691cbeed6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.11.0\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a62fa4-aa53-49d5-8ab4-2e2aaf7b65d1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "-----\n",
    "\n",
    "## List up the models to check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06d3404e-be31-4a63-ac4b-214868fe0cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D-VGG-19\n",
      "1D-ResNet-18\n",
      "1D-ResNeXt-50\n",
      "2D-ResNeXt-50\n",
      "1D-ResNet-50\n",
      "2D-ViT-B-16\n",
      "2D-ResNet-18\n",
      "1D-VGG-19\n",
      "2D-ResNet-50\n",
      "['lo88puq7',\n",
      " 'l8524nml',\n",
      " 'v301o425',\n",
      " '1sl7ipca',\n",
      " 'gvqyvmrj',\n",
      " 'gjkysllw',\n",
      " 'xci5svkl',\n",
      " '1vc80n1f',\n",
      " 'syrx7bmk']\n"
     ]
    }
   ],
   "source": [
    "model_names = [\n",
    "    'lo88puq7',  # 2D-VGG-19\n",
    "    'l8524nml',  # 1D-ResNet-18   // 2s1700lg, l8524nml\n",
    "    'v301o425',  # 1D-ResNeXt-50 \n",
    "    '1sl7ipca',  # 2D-ResNeXt-50 \n",
    "    'gvqyvmrj',  # 1D-ResNet-50 \n",
    "    'gjkysllw',  # 2D-ViT-B-16 \n",
    "    'xci5svkl',  # 2D-ResNet-18 \n",
    "    '1vc80n1f',  # 1D-VGG-19 \n",
    "    'syrx7bmk',  # 2D-ResNet-50 \n",
    "]\n",
    "\n",
    "# model_names = [\n",
    "#     'tp7qn5hd',  # 1D-ResNeXt-50 \n",
    "#     'q1hhkmik',  # 1D-ResNet-50\n",
    "#     '0svudowu',  # 2D-ResNeXt-50\n",
    "#     'ruqd8r7g',  # 2D-VGG-19\n",
    "#     'dn10a6bv',  # 2D-ResNet-18\n",
    "#     'atbhqdgg',  # 2D-ResNet-50\n",
    "#     '4439k9pg',  # 1D-ResNet-18\n",
    "#     'nemy8ikm',  # 1D-VGG-19\n",
    "#     '1cdws3t5',  # 2D-ViT-B-16\n",
    "# ]\n",
    "\n",
    "model_pool = []\n",
    "\n",
    "for model_name in model_names:\n",
    "    path = os.path.join(r'local/checkpoint', model_name, 'checkpoint.pt')\n",
    "    try:\n",
    "        ckpt = torch.load(path, map_location=device)\n",
    "        print(ckpt['config']['model'])\n",
    "        model_pool.append({'name': model_name, 'path': path})\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'- checkpoint cannot be opened: {path}')\n",
    "        \n",
    "pprint.pprint([model_dict['name'] for model_dict in model_pool])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00973b7-d2ba-4e54-a4ac-86879c1fe89f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7dfec22-3837-46a7-8b4d-4588300068bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'ensemble-dementia-class-score'\n",
    "no_patient_overlap = False\n",
    "eval_ensemble = True\n",
    "\n",
    "base_repeat = 8 # 800\n",
    "crop_multiple = 8\n",
    "test_crop_multiple = 8\n",
    "\n",
    "verbose = False\n",
    "save_fig = False\n",
    "\n",
    "eval_train = True\n",
    "eval_val = True\n",
    "eval_test = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ea3cfe6-4211-485d-a169-396f52e7d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "if no_patient_overlap:\n",
    "    task += '-no-overlap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f5c7324-8852-4493-b33d-ea022ab59e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset_for_train(config, verbose=False):\n",
    "    dataset_path = config[\"dataset_path\"]\n",
    "    if \"cwd\" in config:\n",
    "        dataset_path = os.path.join(config[\"cwd\"], dataset_path)\n",
    "\n",
    "    config_dataset = load_caueeg_config(dataset_path)\n",
    "    config.update(**config_dataset)\n",
    "\n",
    "    if \"run_mode\" not in config.keys():\n",
    "        print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "        print('WARNING: run_mode is not specified.\\n \\t==> run_mode is set to \"train\" automatically.')\n",
    "        print(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "        config[\"run_mode\"] = \"train\"\n",
    "\n",
    "    (\n",
    "        transform,\n",
    "        transform_multicrop,\n",
    "    ) = compose_transforms(config, verbose=verbose)\n",
    "    config[\"transform\"] = transform\n",
    "    config[\"transform_multicrop\"] = transform_multicrop\n",
    "    load_event = config[\"load_event\"] or config.get(\"reject_events\", False)\n",
    "\n",
    "    (\n",
    "        config_task,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        test_dataset,\n",
    "    ) = load_caueeg_task_datasets(\n",
    "        dataset_path=dataset_path,\n",
    "        task=config[\"task\"],\n",
    "        load_event=load_event,\n",
    "        file_format=config[\"file_format\"],\n",
    "        transform=transform,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "    config.update(**config_task)\n",
    "\n",
    "    _, multicrop_train_dataset = load_caueeg_task_split(dataset_path=dataset_path, \n",
    "                                                       task=config[\"task\"], split=\"train\", \n",
    "                                                       load_event=load_event, file_format=config[\"file_format\"], \n",
    "                                                       transform=transform_multicrop, verbose=verbose)\n",
    "    _, multicrop_val_dataset = load_caueeg_task_split(dataset_path=dataset_path, \n",
    "                                                      task=config[\"task\"], split=\"validation\", \n",
    "                                                      load_event=load_event, file_format=config[\"file_format\"], \n",
    "                                                      transform=transform_multicrop, verbose=verbose)\n",
    "    _, multicrop_test_dataset = load_caueeg_task_split(dataset_path=dataset_path, \n",
    "                                                       task=config[\"task\"], split=\"test\", \n",
    "                                                       load_event=load_event, file_format=config[\"file_format\"], \n",
    "                                                       transform=transform_multicrop, verbose=verbose)\n",
    "\n",
    "    train_loader, val_loader, test_loader, multicrop_train_loader = make_dataloader(config, train_dataset, val_dataset, test_dataset, \n",
    "                                                                                    multicrop_train_dataset, verbose=False)\n",
    "    train_loader, val_loader, test_loader, multicrop_val_loader = make_dataloader(config, train_dataset, val_dataset, test_dataset, \n",
    "                                                                                  multicrop_val_dataset, verbose=False)\n",
    "    train_loader, val_loader, test_loader, multicrop_test_loader = make_dataloader(config, train_dataset, val_dataset, test_dataset, \n",
    "                                                                                   multicrop_test_dataset, verbose=False)\n",
    "\n",
    "    (\n",
    "        preprocess_train,\n",
    "        preprocess_test,\n",
    "    ) = compose_preprocess(config, train_loader, verbose=verbose)\n",
    "    config[\"preprocess_train\"] = preprocess_train\n",
    "    config[\"preprocess_test\"] = preprocess_test\n",
    "    config[\"in_channels\"] = preprocess_train(next(iter(train_loader)))[\"signal\"].shape[1]\n",
    "    config[\"out_dims\"] = len(config[\"class_label_to_name\"])\n",
    "\n",
    "    if verbose:\n",
    "        for i_batch, sample_batched in enumerate(train_loader):\n",
    "            # preprocessing includes to-device operation\n",
    "            preprocess_train(sample_batched)\n",
    "\n",
    "            print(\n",
    "                i_batch,\n",
    "                sample_batched[\"signal\"].shape,\n",
    "                sample_batched[\"age\"].shape,\n",
    "                sample_batched[\"class_label\"].shape,\n",
    "            )\n",
    "\n",
    "            if i_batch > 3:\n",
    "                break\n",
    "        print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "    return (\n",
    "        multicrop_train_loader,\n",
    "        multicrop_val_loader,\n",
    "        multicrop_test_loader,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e25ca9a-48ee-4c0d-8e06-616a84e59527",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Evaluate each model and accumulate the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bee4f853-3cad-4b01-8ee8-44ac9e49adbe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- checking for lo88puq7 2D-VGG-19 ...\n",
      "- checking for l8524nml 1D-ResNet-18 ...\n",
      "- checking for v301o425 1D-ResNeXt-50 ...\n",
      "- checking for 1sl7ipca 2D-ResNeXt-50 ...\n",
      "- checking for gvqyvmrj 1D-ResNet-50 ...\n",
      "- checking for gjkysllw 2D-ViT-B-16 ...\n",
      "- checking for xci5svkl 2D-ResNet-18 ...\n",
      "- checking for 1vc80n1f 1D-VGG-19 ...\n",
      "- checking for syrx7bmk 2D-ResNet-50 ...\n",
      "==== Finished ====\n"
     ]
    }
   ],
   "source": [
    "for model_dict in model_pool:\n",
    "    # load and parse the checkpoint\n",
    "    ckpt = torch.load(model_dict['path'], map_location=device)\n",
    "    model_state = ckpt['model_state']\n",
    "    config = ckpt['config']\n",
    "    \n",
    "    model_dict['model'] = config['model']\n",
    "    model_dict['num_params'] = config.get('num_params', '???')\n",
    "    model_dict['model size (MiB)'] = sys.getsizeof(pickle.dumps(model_state)) / (1024 * 1024)\n",
    "\n",
    "    if no_patient_overlap:\n",
    "        config['task'] += '-no-overlap' \n",
    "\n",
    "    \n",
    "    if '220419' in config['dataset_path']:\n",
    "        config['dataset_path'] = './local/dataset/caueeg-dataset/'\n",
    "    config['run_mode'] = 'eval'\n",
    "    \n",
    "    model_dict['seq_length'] = config['seq_length']\n",
    "    model_dict['use_age'] = config['use_age']\n",
    "    model_dict['photic'] = config['photic']\n",
    "    model_dict['EKG'] = config['EKG']\n",
    "\n",
    "    model_dict['awgn'] = config.get('awgn', 0)\n",
    "    model_dict['awgn_age'] = config.get('awgn_age', 0)\n",
    "    model_dict['mgn'] = config.get('mgn', 0)\n",
    "    model_dict['mixup'] = config.get('mixup', 0)\n",
    "    model_dict['dropout'] = config.get('dropout', 0)\n",
    "    model_dict['weight_decay'] = config.get('weight_decay', '???')\n",
    "    model_dict['fc_stages'] = config.get('fc_stages', 1)\n",
    "    model_dict['activation'] = config.get('activation', 0)\n",
    "\n",
    "    model_dict['minibatch'] = round(config['minibatch'])\n",
    "    model_dict['total_samples'] = round(config.get('total_samples', config['iterations'] * config['minibatch']))\n",
    "    model_dict['base_lr'] = config.get('base_lr', config.get('LR', '???'))\n",
    "    model_dict['lr_scheduler_type'] = config.get('lr_scheduler_type', 'constant_with_decay')\n",
    "    model_dict['warmup_steps'] = config.get('warmup_steps', '???')\n",
    "    model_dict['seed'] = config.get('seed', '???')\n",
    "    \n",
    "    print('- checking for', model_dict['name'], config['model'], '...')\n",
    "    \n",
    "    # initiate the model\n",
    "    if '_target_' in config:\n",
    "        model = hydra.utils.instantiate(config).to(device)\n",
    "    elif type(config['generator']) is str:\n",
    "        config['generator'] = getattr(models, config['generator'].split('.')[-1])\n",
    "        if 'block' in config:\n",
    "            config['block'] = getattr(models, config['block'].split('.')[-1])\n",
    "        model = config['generator'](**config).to(device)\n",
    "    else:\n",
    "        if 'block' in config:\n",
    "            if config['block'] == models.resnet_1d.BottleneckBlock1D:\n",
    "                config['block'] = 'bottleneck'\n",
    "            elif config['block'] == models.resnet_2d.Bottleneck2D:\n",
    "                config['block'] = 'bottleneck'\n",
    "            elif config['block'] == models.resnet_1d.BasicBlock1D:\n",
    "                config['block'] = 'basic'\n",
    "            elif config['block'] == models.resnet_2d.BasicBlock2D:\n",
    "                config['block'] = 'basic'\n",
    "                \n",
    "        model = config['generator'](**config).to(device)\n",
    "    \n",
    "    if config.get('ddp', False):\n",
    "        model_state_ddp = deepcopy(model_state)\n",
    "        model_state = OrderedDict()\n",
    "        for k, v in model_state_ddp.items():\n",
    "            name = k[7:]  # remove 'module.' of DataParallel/DistributedDataParallel\n",
    "            model_state[name] = v\n",
    "    \n",
    "    model.load_state_dict(model_state)\n",
    "    \n",
    "    # reconfigure and update\n",
    "    config.pop('cwd', 0)\n",
    "    config['ddp'] = False\n",
    "    config['crop_multiple'] = crop_multiple\n",
    "    config['test_crop_multiple'] = test_crop_multiple\n",
    "    config['crop_timing_analysis'] = False\n",
    "    config['eval'] = True\n",
    "    config['device'] = device\n",
    "    \n",
    "    repeat = round(base_repeat / crop_multiple)\n",
    "    model_dict['repeat'] = repeat\n",
    "    model_dict['crop_multiple'] = crop_multiple\n",
    "    model_dict['test_crop_multiple'] = test_crop_multiple\n",
    "    \n",
    "    # build dataset\n",
    "    _ = build_dataset_for_train(config, verbose=verbose)\n",
    "    train_loader = _[0]\n",
    "    val_loader = _[1]\n",
    "    test_loader = _[2]\n",
    "    \n",
    "    # warm-up stage\n",
    "    _ = check_accuracy_extended(model, test_loader, \n",
    "                                config['preprocess_test'], config, repeat=1)\n",
    "    \n",
    "    # Multi-crop train accuracy\n",
    "    if eval_train:\n",
    "        _ = check_accuracy_multicrop_extended(model, train_loader, \n",
    "                                              config['preprocess_test'], config, repeat=repeat)\n",
    "        model_dict['Multi-Crop Train Throughput'] = _[4]\n",
    "        model_dict['Multi-Crop Train Accuracy'] = _[0]\n",
    "        model_dict['Multi-Crop Train Score'] = _[1]\n",
    "        model_dict['Multi-Crop Train Target'] = _[2]\n",
    "        \n",
    "    # Multi-crop val accuracy\n",
    "    if eval_val:\n",
    "        _ = check_accuracy_multicrop_extended(model, val_loader, \n",
    "                                              config['preprocess_test'], config, repeat=repeat)\n",
    "        model_dict['Multi-Crop Val Throughput'] = _[4]\n",
    "        model_dict['Multi-Crop Val Accuracy'] = _[0]\n",
    "        model_dict['Multi-Crop Val Score'] = _[1]\n",
    "        model_dict['Multi-Crop Val Target'] = _[2]\n",
    "        \n",
    "    # Multi-crop test accuracy\n",
    "    if eval_test:\n",
    "        _ = check_accuracy_multicrop_extended(model, test_loader, \n",
    "                                              config['preprocess_test'], config, repeat=repeat)\n",
    "        model_dict['Multi-Crop Test Throughput'] = _[4]\n",
    "        model_dict['Multi-Crop Test Accuracy'] = _[0]\n",
    "        model_dict['Multi-Crop Test Score'] = _[1]\n",
    "        model_dict['Multi-Crop Test Target'] = _[2]\n",
    "            \n",
    "print('==== Finished ====')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f20c63-6d13-47a3-b6d5-8cbf89b5b25e",
   "metadata": {},
   "source": [
    "## Conduct ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3343a302-6361-49db-b31e-68f5b43f98b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval_ensemble:\n",
    "    if 'Ensemble' == model_pool[-1]['name']:\n",
    "        model_pool.remove(model_pool[-1])     \n",
    "\n",
    "    # conduct ensembling\n",
    "    if eval_train:\n",
    "        ensem_multi_train_score = np.zeros_like(model_pool[0]['Multi-Crop Train Score'])\n",
    "        ensem_multi_train_latency = 0\n",
    "        \n",
    "    if eval_val:\n",
    "        ensem_multi_val_score = np.zeros_like(model_pool[0]['Multi-Crop Val Score'])\n",
    "        ensem_multi_val_latency = 0\n",
    "\n",
    "    if eval_test:\n",
    "        ensem_multi_test_score = np.zeros_like(model_pool[0]['Multi-Crop Test Score'])\n",
    "        ensem_multi_test_latency = 0\n",
    "\n",
    "    ensem_params = 0\n",
    "    ensem_model_size = 0\n",
    "\n",
    "    for model_dict in model_pool:        \n",
    "        ensem_params += model_dict['num_params']\n",
    "        ensem_model_size += model_dict['model size (MiB)']\n",
    "\n",
    "        if eval_train:\n",
    "            ensem_multi_train_score += model_dict['Multi-Crop Train Score'] / len(model_pool)\n",
    "            ensem_multi_train_latency += 1 / model_dict['Multi-Crop Train Throughput']\n",
    "\n",
    "        if eval_val:\n",
    "            ensem_multi_val_score += model_dict['Multi-Crop Val Score'] / len(model_pool)\n",
    "            ensem_multi_val_latency += 1 / model_dict['Multi-Crop Val Throughput']\n",
    "\n",
    "        \n",
    "        if eval_test:\n",
    "            ensem_multi_test_score += model_dict['Multi-Crop Test Score'] / len(model_pool)\n",
    "            ensem_multi_test_latency += 1 / model_dict['Multi-Crop Test Throughput']\n",
    "            \n",
    "    if eval_train:\n",
    "        # confusion matrix\n",
    "        pred = ensem_multi_train_score.argmax(axis=-1)\n",
    "        target = model_pool[0]['Multi-Crop Train Target']\n",
    "        ensem_multi_train_acc = 100.0 * (pred.squeeze() == target).sum() / pred.shape[0]\n",
    "\n",
    "    if eval_val:\n",
    "        # confusion matrix\n",
    "        pred = ensem_multi_val_score.argmax(axis=-1)\n",
    "        target = model_pool[0]['Multi-Crop Val Target']\n",
    "        ensem_multi_val_acc = 100.0 * (pred.squeeze() == target).sum() / pred.shape[0]\n",
    "\n",
    "    if eval_test:\n",
    "        # confusion matrix\n",
    "        pred = ensem_multi_test_score.argmax(axis=-1)\n",
    "        target = model_pool[0]['Multi-Crop Test Target']\n",
    "        ensem_multi_test_acc = 100.0 * (pred.squeeze() == target).sum() / pred.shape[0]\n",
    "        \n",
    "    # summarize the ensemble results\n",
    "    ensem_dict = {}\n",
    "\n",
    "    ensem_dict['name'] = 'Ensemble'\n",
    "    ensem_dict['num_params'] = ensem_params\n",
    "    ensem_dict['model size (MiB)'] = ensem_model_size\n",
    "\n",
    "    if eval_train:\n",
    "        ensem_dict['Multi-Crop Train Throughput'] = 1 / ensem_multi_train_latency\n",
    "        ensem_dict['Multi-Crop Train Accuracy'] = ensem_multi_train_acc\n",
    "        ensem_dict['Multi-Crop Train Score'] = ensem_multi_train_score\n",
    "\n",
    "    if eval_val:\n",
    "        ensem_dict['Multi-Crop Val Throughput'] = 1 / ensem_multi_val_latency\n",
    "        ensem_dict['Multi-Crop Val Accuracy'] = ensem_multi_val_acc\n",
    "        ensem_dict['Multi-Crop Val Score'] = ensem_multi_val_score\n",
    "\n",
    "    if eval_test:\n",
    "        ensem_dict['Multi-Crop Test Throughput'] = 1 / ensem_multi_test_latency\n",
    "        ensem_dict['Multi-Crop Test Accuracy'] = ensem_multi_test_acc\n",
    "        ensem_dict['Multi-Crop Test Score'] = ensem_multi_test_score\n",
    "\n",
    "    model_pool.append(ensem_dict)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85f973f6-b799-4ba5-9258-9eee4f2f88ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>model</th>\n",
       "      <th>num_params</th>\n",
       "      <th>model size (MiB)</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>use_age</th>\n",
       "      <th>photic</th>\n",
       "      <th>EKG</th>\n",
       "      <th>awgn</th>\n",
       "      <th>...</th>\n",
       "      <th>seed</th>\n",
       "      <th>repeat</th>\n",
       "      <th>crop_multiple</th>\n",
       "      <th>test_crop_multiple</th>\n",
       "      <th>Multi-Crop Train Throughput</th>\n",
       "      <th>Multi-Crop Train Accuracy</th>\n",
       "      <th>Multi-Crop Val Throughput</th>\n",
       "      <th>Multi-Crop Val Accuracy</th>\n",
       "      <th>Multi-Crop Test Throughput</th>\n",
       "      <th>Multi-Crop Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lo88puq7</td>\n",
       "      <td>local/checkpoint/lo88puq7/checkpoint.pt</td>\n",
       "      <td>2D-VGG-19</td>\n",
       "      <td>20184131</td>\n",
       "      <td>77.073947</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>conv</td>\n",
       "      <td>X</td>\n",
       "      <td>O</td>\n",
       "      <td>0.047940</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>279.923334</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>277.724131</td>\n",
       "      <td>67.226891</td>\n",
       "      <td>278.252892</td>\n",
       "      <td>67.796610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l8524nml</td>\n",
       "      <td>local/checkpoint/l8524nml/checkpoint.pt</td>\n",
       "      <td>1D-ResNet-18</td>\n",
       "      <td>11394051</td>\n",
       "      <td>43.551189</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>conv</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.004873</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1448.368414</td>\n",
       "      <td>99.473684</td>\n",
       "      <td>1433.228223</td>\n",
       "      <td>62.184874</td>\n",
       "      <td>1430.853026</td>\n",
       "      <td>69.491525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v301o425</td>\n",
       "      <td>local/checkpoint/v301o425/checkpoint.pt</td>\n",
       "      <td>1D-ResNeXt-50</td>\n",
       "      <td>25650051</td>\n",
       "      <td>98.228438</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>fc</td>\n",
       "      <td>X</td>\n",
       "      <td>O</td>\n",
       "      <td>0.037536</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>542.062034</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>540.304496</td>\n",
       "      <td>66.386555</td>\n",
       "      <td>540.804528</td>\n",
       "      <td>68.644068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1sl7ipca</td>\n",
       "      <td>local/checkpoint/1sl7ipca/checkpoint.pt</td>\n",
       "      <td>2D-ResNeXt-50</td>\n",
       "      <td>25886467</td>\n",
       "      <td>99.137356</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>fc</td>\n",
       "      <td>O</td>\n",
       "      <td>X</td>\n",
       "      <td>0.103950</td>\n",
       "      <td>...</td>\n",
       "      <td>???</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>155.030883</td>\n",
       "      <td>98.947368</td>\n",
       "      <td>154.879775</td>\n",
       "      <td>69.747899</td>\n",
       "      <td>155.612666</td>\n",
       "      <td>68.644068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gvqyvmrj</td>\n",
       "      <td>local/checkpoint/gvqyvmrj/checkpoint.pt</td>\n",
       "      <td>1D-ResNet-50</td>\n",
       "      <td>26178179</td>\n",
       "      <td>100.185495</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>fc</td>\n",
       "      <td>O</td>\n",
       "      <td>X</td>\n",
       "      <td>0.012513</td>\n",
       "      <td>...</td>\n",
       "      <td>???</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1286.208750</td>\n",
       "      <td>99.684211</td>\n",
       "      <td>1284.985731</td>\n",
       "      <td>63.025210</td>\n",
       "      <td>1281.997365</td>\n",
       "      <td>67.796610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gjkysllw</td>\n",
       "      <td>local/checkpoint/gjkysllw/checkpoint.pt</td>\n",
       "      <td>2D-ViT-B-16</td>\n",
       "      <td>90054147</td>\n",
       "      <td>343.588083</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>conv</td>\n",
       "      <td>X</td>\n",
       "      <td>O</td>\n",
       "      <td>0.029602</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.386958</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>44.408312</td>\n",
       "      <td>60.504202</td>\n",
       "      <td>44.371241</td>\n",
       "      <td>66.101695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xci5svkl</td>\n",
       "      <td>local/checkpoint/xci5svkl/checkpoint.pt</td>\n",
       "      <td>2D-ResNet-18</td>\n",
       "      <td>11425155</td>\n",
       "      <td>43.664536</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>fc</td>\n",
       "      <td>X</td>\n",
       "      <td>O</td>\n",
       "      <td>0.074615</td>\n",
       "      <td>...</td>\n",
       "      <td>???</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>424.566894</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>425.869460</td>\n",
       "      <td>64.705882</td>\n",
       "      <td>424.176850</td>\n",
       "      <td>66.101695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1vc80n1f</td>\n",
       "      <td>local/checkpoint/1vc80n1f/checkpoint.pt</td>\n",
       "      <td>1D-VGG-19</td>\n",
       "      <td>20205251</td>\n",
       "      <td>77.157321</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>conv</td>\n",
       "      <td>X</td>\n",
       "      <td>O</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1259.372863</td>\n",
       "      <td>99.789474</td>\n",
       "      <td>1207.736137</td>\n",
       "      <td>61.344538</td>\n",
       "      <td>1212.794715</td>\n",
       "      <td>67.796610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>syrx7bmk</td>\n",
       "      <td>local/checkpoint/syrx7bmk/checkpoint.pt</td>\n",
       "      <td>2D-ResNet-50</td>\n",
       "      <td>25729475</td>\n",
       "      <td>98.468181</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>conv</td>\n",
       "      <td>X</td>\n",
       "      <td>O</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>181.748415</td>\n",
       "      <td>99.894737</td>\n",
       "      <td>181.977453</td>\n",
       "      <td>62.184874</td>\n",
       "      <td>181.534706</td>\n",
       "      <td>67.796610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256706907</td>\n",
       "      <td>981.054547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.463787</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>22.434757</td>\n",
       "      <td>72.268908</td>\n",
       "      <td>22.433679</td>\n",
       "      <td>75.423729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name                                     path          model  \\\n",
       "0  lo88puq7  local/checkpoint/lo88puq7/checkpoint.pt      2D-VGG-19   \n",
       "1  l8524nml  local/checkpoint/l8524nml/checkpoint.pt   1D-ResNet-18   \n",
       "2  v301o425  local/checkpoint/v301o425/checkpoint.pt  1D-ResNeXt-50   \n",
       "3  1sl7ipca  local/checkpoint/1sl7ipca/checkpoint.pt  2D-ResNeXt-50   \n",
       "4  gvqyvmrj  local/checkpoint/gvqyvmrj/checkpoint.pt   1D-ResNet-50   \n",
       "5  gjkysllw  local/checkpoint/gjkysllw/checkpoint.pt    2D-ViT-B-16   \n",
       "6  xci5svkl  local/checkpoint/xci5svkl/checkpoint.pt   2D-ResNet-18   \n",
       "7  1vc80n1f  local/checkpoint/1vc80n1f/checkpoint.pt      1D-VGG-19   \n",
       "8  syrx7bmk  local/checkpoint/syrx7bmk/checkpoint.pt   2D-ResNet-50   \n",
       "9  Ensemble                                      NaN            NaN   \n",
       "\n",
       "   num_params  model size (MiB)  seq_length use_age photic  EKG      awgn  \\\n",
       "0    20184131         77.073947      4000.0    conv      X    O  0.047940   \n",
       "1    11394051         43.551189      2000.0    conv      O    O  0.004873   \n",
       "2    25650051         98.228438      4000.0      fc      X    O  0.037536   \n",
       "3    25886467         99.137356      4000.0      fc      O    X  0.103950   \n",
       "4    26178179        100.185495      1000.0      fc      O    X  0.012513   \n",
       "5    90054147        343.588083     12000.0    conv      X    O  0.029602   \n",
       "6    11425155         43.664536      2000.0      fc      X    O  0.074615   \n",
       "7    20205251         77.157321      2000.0    conv      X    O  0.008120   \n",
       "8    25729475         98.468181      4000.0    conv      X    O  0.002375   \n",
       "9   256706907        981.054547         NaN     NaN    NaN  NaN       NaN   \n",
       "\n",
       "   ...  seed  repeat  crop_multiple  test_crop_multiple  \\\n",
       "0  ...     0     1.0            8.0                 8.0   \n",
       "1  ...     0     1.0            8.0                 8.0   \n",
       "2  ...     0     1.0            8.0                 8.0   \n",
       "3  ...   ???     1.0            8.0                 8.0   \n",
       "4  ...   ???     1.0            8.0                 8.0   \n",
       "5  ...     0     1.0            8.0                 8.0   \n",
       "6  ...   ???     1.0            8.0                 8.0   \n",
       "7  ...     0     1.0            8.0                 8.0   \n",
       "8  ...     0     1.0            8.0                 8.0   \n",
       "9  ...   NaN     NaN            NaN                 NaN   \n",
       "\n",
       "   Multi-Crop Train Throughput  Multi-Crop Train Accuracy  \\\n",
       "0                   279.923334                 100.000000   \n",
       "1                  1448.368414                  99.473684   \n",
       "2                   542.062034                 100.000000   \n",
       "3                   155.030883                  98.947368   \n",
       "4                  1286.208750                  99.684211   \n",
       "5                    44.386958                 100.000000   \n",
       "6                   424.566894                 100.000000   \n",
       "7                  1259.372863                  99.789474   \n",
       "8                   181.748415                  99.894737   \n",
       "9                    22.463787                 100.000000   \n",
       "\n",
       "  Multi-Crop Val Throughput  Multi-Crop Val Accuracy  \\\n",
       "0                277.724131                67.226891   \n",
       "1               1433.228223                62.184874   \n",
       "2                540.304496                66.386555   \n",
       "3                154.879775                69.747899   \n",
       "4               1284.985731                63.025210   \n",
       "5                 44.408312                60.504202   \n",
       "6                425.869460                64.705882   \n",
       "7               1207.736137                61.344538   \n",
       "8                181.977453                62.184874   \n",
       "9                 22.434757                72.268908   \n",
       "\n",
       "   Multi-Crop Test Throughput  Multi-Crop Test Accuracy  \n",
       "0                  278.252892                 67.796610  \n",
       "1                 1430.853026                 69.491525  \n",
       "2                  540.804528                 68.644068  \n",
       "3                  155.612666                 68.644068  \n",
       "4                 1281.997365                 67.796610  \n",
       "5                   44.371241                 66.101695  \n",
       "6                  424.176850                 66.101695  \n",
       "7                 1212.794715                 67.796610  \n",
       "8                  181.534706                 67.796610  \n",
       "9                   22.433679                 75.423729  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pool_frame = deepcopy(model_pool)\n",
    "\n",
    "for model_dict in model_pool_frame:\n",
    "    model_dict.pop('Train Score', None)\n",
    "    model_dict.pop('Train Target', None)\n",
    "    model_dict.pop('Multi-Crop Train Score', None)\n",
    "    model_dict.pop('Multi-Crop Train Target', None)\n",
    "    model_dict.pop('Val Score', None)\n",
    "    model_dict.pop('Val Target', None)\n",
    "    model_dict.pop('Multi-Crop Val Score', None)\n",
    "    model_dict.pop('Multi-Crop Val Target', None)\n",
    "    model_dict.pop('Test Score', None)\n",
    "    model_dict.pop('Test Target', None)\n",
    "    model_dict.pop('Multi-Crop Test Score', None)\n",
    "    model_dict.pop('Multi-Crop Test Target', None)\n",
    "    \n",
    "pd.DataFrame(model_pool_frame).to_csv(f'local/output/{task}.csv')\n",
    "pd.DataFrame(model_pool_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18fd432-14fc-4771-a203-3e705537685a",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a16d07ff-2961-49fa-8095-30974d66840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "serials = np.array([])\n",
    "for sample_batched in train_loader:\n",
    "    serials = np.concatenate((serials, sample_batched['serial'][::test_crop_multiple]))\n",
    "\n",
    "for model_dict in model_pool:\n",
    "    if model_dict['name'] != 'Ensemble':\n",
    "        continue\n",
    "    ensemble_scores = {}\n",
    "\n",
    "    for i, serial in enumerate(serials):\n",
    "        ensemble_scores[serial] = torch.tensor(model_dict['Multi-Crop Train Score'][i])\n",
    "\n",
    "    # pprint.pprint(model_dict)\n",
    "    torch.save(ensemble_scores, f'local/{task}.pt')\n",
    "\n",
    "# pprint.pprint(ensemble_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfb473b5-b868-479a-a3e5-fc866560697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.load(f'local/{task}.pt', map_location=config[\"device\"])\n",
    "\n",
    "teacher_score = torch.zeros((max([int(k) for k in a.keys()]) + 1, *[*a.values()][0].shape))\n",
    "\n",
    "for k, v in a.items():\n",
    "    teacher_score[int(k)] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f77b048-e3c1-4933-b18f-f1bfb0895fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.4546, -2.6231, -3.3622],\n",
       "        [-3.4511,  3.4890, -3.4008],\n",
       "        [ 3.1652, -2.4867, -2.4365],\n",
       "        [-2.6721, -2.0320,  3.5146]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_score[[2, 5, 12,31]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea17783b-921c-4280-96a1-d016c90fcc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [-3.4511,  3.4890, -3.4008],\n",
       "        [ 4.4546, -2.6231, -3.3622],\n",
       "        [-3.4511,  3.4890, -3.4008],\n",
       "        [ 3.0729, -2.0876, -2.4810]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_score[[*list(map(int, ['00001','00005', '00002', '00005', '00100']))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40561b91-3ec1-489c-80fe-e745ef61c1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [ 4.4546, -2.6231, -3.3622],\n",
       "        [-3.4511,  3.4890, -3.4008],\n",
       "        [ 3.0729, -2.0876, -2.4810]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_score[[1,2, 5, 100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d03bc-82db-48bd-ac3e-d09537258144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
