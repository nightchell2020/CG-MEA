{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Data Curation Part 1\n",
    "\n",
    "2020-10-20 에 전달받은 EEG 데이터인 EDF 파일들과 `DB_list.xlsx` 메타데이터 파일을 살펴보고, 이후 학습을 위해 정리하여 `new_DB_list.xlsx` 파일로 저장하는 노트북."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "-----\n",
    "\n",
    "## 파일 수작업 정리 1\n",
    "\n",
    "이 노트북을 작성하는 동안, 일부 중복된 파일이나 메타데이터들을 수작업으로 통합하고 제거하였다.  \n",
    "수정된 메타데이터 파일은 `220304_DB_list_modified.xlsx`로 저장해두었다.  \n",
    "수작업 내용은 아래를 참고하자.\n",
    "\n",
    "1. One-to-many matching case\n",
    "\n",
    "   전달받은 `DB_list.xlsx`에 중복된 메타데이터 (병록/나이/진단) 행이 존재하는 경우이다.  \n",
    "   이 경우, 중복된 정보들을 하나의 행으로 통합하였다.  \n",
    "   작업 방법은 `210316_중복제거_one-to-many.xlsx` 파일에 기록해두었다.\n",
    "\n",
    "2. Many-to-one matching case\n",
    "\n",
    "   동일한 병록번호를 가진 환자가 여러차례 EEG를 측정한 경우이다.  \n",
    "   이 경우, 파일명과 용량을 토대로 중복 저장된 파일들을 제거해주었다.  \n",
    "   또한 일부 파일들은 파일명을 변경해주었다.  \n",
    "   작업 내역은 `210504_many-to-one_Diagnosis_추가수정.xlsx` 파일에 기록해두었다.  \n",
    "   노트북 가장 아래쪽에, 증상의 변화를 자동으로 업데이트하는 코드를 작성했으니, 실행하도록 하자.\n",
    "\n",
    "3. Many-to-many matching case\n",
    "\n",
    "   위에 언급된 두 가지 상황이 동시에 발생한 경우이다.  \n",
    "   이 경우, (1) `DB_list.xlsx`에서 중복된 정보들을 하나로 통합하고, (2) 중복 저장된 파일들을 직접 제거하였다.  \n",
    "   구체적인 작업 방법은 `210420_many-to-many_Diagnosis_YY정리.xlsx` 파일에 기록해두었다.  \n",
    "   노트북 가장 아래쪽에, 증상의 변화를 자동으로 업데이트하는 코드를 작성했으니, 실행하도록 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 환경 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minjae\\Desktop\\EEG_Project\n"
     ]
    }
   ],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import glob\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook, Workbook, styles\n",
    "import pprint\n",
    "import datetime\n",
    "import warnings\n",
    "import pyedflib\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_data_curation import MultiEegLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other settings\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # cleaner text\n",
    "\n",
    "# plt.style.use('default') \n",
    "# ['Solarize_Light2', '_classic_test_patch', 'bmh', 'classic', 'dark_background', 'fast', \n",
    "#  'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn', 'seaborn-bright', 'seaborn-colorblind', \n",
    "#  'seaborn-dark', 'seaborn-dark-palette', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', \n",
    "#  'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', \n",
    "#  'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'tableau-colorblind10']\n",
    "\n",
    "# plt.rcParams['image.interpolation'] = 'nearest'\n",
    "# plt.rcParams[\"font.family\"] = 'NanumGothic' # for Hangul in Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 데이터 파일 `(EDF, XLSX)` 구성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Data file path\n",
    "inform_path = r'local\\dataset\\00_Information'\n",
    "origin_path = r'local\\dataset\\01_Original_Data_220419'\n",
    "output_path = r'local\\output'\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2,872 files in total, and their extensions are among of ['edf', 'xlsx'].\n",
      " - edf 1,436 files\n",
      " - xlsx 1,436 files\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "file_dict = {}\n",
    "r = re.compile('[\\\\\\/]([^\\\\\\/]+)\\.([^\\\\\\/]+)$')\n",
    "\n",
    "for i, f in enumerate(glob.glob(os.path.join(origin_path, '*.*'))):\n",
    "    match_result = r.search(f)\n",
    "    \n",
    "    if match_result is None:\n",
    "        print('Cannot parse this file:', f)\n",
    "    \n",
    "    fname = match_result.group(1)\n",
    "    ext = match_result.group(2).lower()\n",
    "    \n",
    "    if ext not in file_dict.keys():\n",
    "        file_dict.setdefault(ext, [])\n",
    "\n",
    "    file_dict[ext].append(fname)\n",
    "    count += 1\n",
    "\n",
    "print('There are {:,} files in total, and their extensions are among of {}.'.format(count, list(file_dict.keys())))\n",
    "for k, v in file_dict.items():\n",
    "    print(' - {ext} {num:,} files'.format(ext=k, num=len(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,433 EDF and XLSX files are paired in total.\n",
      "\n",
      "3 EDF and 3 XLSX files are unmatched, respectively, and they are:\n",
      "{'edf': ['00604274_160718', '01321906_120417', 'c'],\n",
      " 'xlsx': ['DB_list', 'DB_list_modified', 'new_DB_list']}\n"
     ]
    }
   ],
   "source": [
    "unpaired_file_dict = copy.deepcopy(file_dict)\n",
    "edf_paired = []\n",
    "\n",
    "for fname in file_dict['edf']:\n",
    "    if fname in file_dict['xlsx']:\n",
    "        edf_paired.append(fname)\n",
    "        unpaired_file_dict['edf'].remove(fname)\n",
    "        unpaired_file_dict['xlsx'].remove(fname)\n",
    "\n",
    "print('{:,} EDF and XLSX files are paired in total.'.format(len(edf_paired)))\n",
    "print()\n",
    "print('{:,} EDF and {:,} XLSX files are unmatched, respectively, and they are:'.format(len(unpaired_file_dict['edf']), len(unpaired_file_dict['xlsx'])))\n",
    "pprint.pp(unpaired_file_dict)\n",
    "\n",
    "del file_dict, unpaired_file_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the duplicated files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_paired_temp = copy.deepcopy(edf_paired)\n",
    "\n",
    "for fname in edf_paired_temp:\n",
    "    if fname.endswith('(1)') and fname[:-3] in edf_paired_temp:\n",
    "        edf_size1 = os.path.getsize(os.path.join(origin_path, f'{fname}.edf'))\n",
    "        xlsx_size1 = os.path.getsize(os.path.join(origin_path, f'{fname}.xlsx'))\n",
    "\n",
    "        edf_size2 = os.path.getsize(os.path.join(origin_path, f'{fname[:-3]}.edf'))\n",
    "        xlsx_size2 = os.path.getsize(os.path.join(origin_path, f'{fname[:-3]}.xlsx'))\n",
    "        \n",
    "        if edf_size1 == edf_size1 and xlsx_size1 == xlsx_size2:\n",
    "            print(f'- {fname}.edf and {fname}.xlsx files are deleted due to the duplication.')\n",
    "            edf_paired.remove(fname)\n",
    "            os.remove(os.path.join(origin_path, f'{fname}.edf'))\n",
    "            os.remove(os.path.join(origin_path, f'{fname}.xlsx'))\n",
    "            \n",
    "del edf_paired_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 메타데이터 구성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,621 metadata is loaded.\n",
      "\n",
      "Among them,\n",
      " - 0 samples have the duplication of the name field. They are:\n",
      "{}\n",
      "\n",
      " - we know their birth of 1,169 samples, but not of the other 452 samples.\n",
      "\n",
      " - there are 52 types of diagnoses. Each is:\n",
      "{'load': 238,\n",
      " 'cb_normal': 241,\n",
      " 'eoad': 135,\n",
      " 'ad_mci': 25,\n",
      " 'smi': 225,\n",
      " 'bvftd': 18,\n",
      " 'nph': 46,\n",
      " 'parkinson_synd': 6,\n",
      " 'sivd': 81,\n",
      " 'cind': 1,\n",
      " 'unknown': 8,\n",
      " 'semantic aphasia': 3,\n",
      " 'pd': 29,\n",
      " 'pdd': 2,\n",
      " 'non fluent aphasia': 4,\n",
      " 'mci retrieval failure': 81,\n",
      " 'mci non-amnestic': 9,\n",
      " 'hc_normal': 11,\n",
      " 'mci encoding failure': 91,\n",
      " \"parkinson's disease\": 54,\n",
      " 'parkinson dementia': 1,\n",
      " 'mci amnestic': 53,\n",
      " 'mci': 4,\n",
      " 'tga': 80,\n",
      " 'vascular mci': 64,\n",
      " 'mci_ef': 20,\n",
      " 'other parkinson synd': 29,\n",
      " 'mci_rf': 8,\n",
      " '0': 1,\n",
      " 'vd': 1,\n",
      " 'mci ef': 15,\n",
      " 'mci rf': 13,\n",
      " '?검사없음': 1,\n",
      " 'nc': 1,\n",
      " 'amci rf': 1,\n",
      " 'nl': 1,\n",
      " 'amci': 2,\n",
      " 'mci encoding failure multi-domain': 1,\n",
      " 'ad-mci (ef)': 1,\n",
      " 'amci (ef)': 1,\n",
      " 'amci(ef)': 1,\n",
      " 'vmci(rf)': 2,\n",
      " 'mci(rf) multi-domain': 1,\n",
      " 'ad-mci': 2,\n",
      " 'mci (rf)': 1,\n",
      " 'mci(ef)': 1,\n",
      " 'ad-vd-mixed': 1,\n",
      " 'mci non amnestic': 2,\n",
      " 'vmci(ef)': 1,\n",
      " 'language ftd': 1,\n",
      " 'vascular dementia': 1,\n",
      " 'ftd': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meta_file = os.path.join(origin_path, r'DB_list_modified.xlsx')\n",
    "ws = load_workbook(meta_file, data_only=True)['Sheet1']\n",
    "\n",
    "meta_names = []\n",
    "meta_dx1 = []\n",
    "meta_birth = []\n",
    "\n",
    "dx1_counter = {}\n",
    "name_duplication_counter = {}\n",
    "\n",
    "num = 2\n",
    "while True:\n",
    "    # (deprecated) field 1: age\n",
    "    # a = ws.cell(row=num, column=1).value\n",
    "    # a = a.strip(' \\n') if a is not None else None\n",
    "    \n",
    "    # field 2: hosp_id\n",
    "    n = ws.cell(row=num, column=2).value\n",
    "    n = '{:>08s}'.format(n.strip(' \\n')) if n is not None else None\n",
    "    \n",
    "    # field 3: dx_1\n",
    "    d = ws.cell(row=num, column=3).value\n",
    "    d = d.lower().strip(' \\n') if d is not None else 'unknown'\n",
    "    \n",
    "    # (new) field 4: birth\n",
    "    b = ws.cell(row=num, column=4).value\n",
    "\n",
    "    # check whether the row is empty (which is EOF condition)\n",
    "    if n is None:\n",
    "        break\n",
    "\n",
    "    # count the number of the name duplication\n",
    "    if n in meta_names:\n",
    "        name_duplication_counter[n] = name_duplication_counter.get(n, 1) + 1\n",
    "    \n",
    "    # count the total number of the emergence for each dx_1's value\n",
    "    dx1_counter[d] = dx1_counter.get(d, 0) + 1\n",
    "\n",
    "    # update information\n",
    "    meta_names.append(n)\n",
    "    meta_dx1.append(d)\n",
    "    meta_birth.append(b)\n",
    "    \n",
    "    # move the pivot row\n",
    "    num += 1\n",
    "\n",
    "print('{:,} metadata is loaded.'.format(len(meta_names)))\n",
    "print()\n",
    "\n",
    "print('Among them,')\n",
    "\n",
    "print(' - {:,} samples have the duplication of the name field. They are:'.format(sum([v for v in name_duplication_counter.values()])))\n",
    "pprint.pp(name_duplication_counter)\n",
    "\n",
    "temp = len(list(filter(lambda x: float(x) > 0 if x is not None else False, meta_birth)))\n",
    "print('\\n - we know their birth of {:,} samples, but not of the other {:,} samples.'.format(temp, len(meta_birth) - temp))\n",
    "print('\\n - there are {:,} types of diagnoses. Each is:'.format(len(dx1_counter)))\n",
    "pprint.pp(dx1_counter)\n",
    "print()\n",
    "\n",
    "del temp, dx1_counter, name_duplication_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## `(EDF, XLSX)` 데이터 $\\longleftrightarrow$ 메타데이터 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total (EDF, XLSX) pair        : 1,433\n",
      "Total rows of metadata        : 1,621\n",
      "----------------------------------------------------------------------\n",
      "-    32 EDF data has no linked metadata.\n",
      "-   450 metadata has no linked EDf file.\n",
      "= Only 1,171 data has the connection between them.\n",
      "----------------------------------------------------------------------\n",
      "Among them,\n",
      "- 1,008 are the   one-to-one matching between (EDF - metadata).\n",
      "-   163 are the  many-to-one matching between (EDF - metadata).\n",
      "-     0 are the  one-to-many matching between (EDF - metadata).\n",
      "-     0 are the many-to-many matching between (EDF - metadata).\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for f in edf_paired:\n",
    "    # parse the first fragment of the file name\n",
    "    parsed = re.match('^([0-9]+)_?', f).group(1)\n",
    "    \n",
    "    # When the same patient ID is already registered, \n",
    "    # add only the EDF file on the existing link\n",
    "    registered = False\n",
    "    for d in data:\n",
    "        if len(d[1]) > 0 and d[1][0][0] == parsed:\n",
    "            registered = True\n",
    "            d[0].append(f)\n",
    "            break\n",
    "            \n",
    "    # add the patient ID, and link between the EDF file and metadata\n",
    "    if not registered:\n",
    "        meta_temp = [m for m in zip(meta_names, meta_birth, meta_dx1) if m[0] == parsed]\n",
    "        data.append(([f], meta_temp))\n",
    "\n",
    "#  When there is no linked file for some metadata, make an empty connection\n",
    "for n in meta_names:\n",
    "    if not any([d[1][0][0] == n for d in data if len(d[1]) > 0]):\n",
    "        meta_temp = [m for m in zip(meta_names, meta_birth, meta_dx1) if m[0] == n]\n",
    "        data.append(([], meta_temp))\n",
    "        \n",
    "# Sanity check\n",
    "if sum([len(d[0]) for d in data]) != len(edf_paired):\n",
    "    print('ERROR 1')\n",
    "\n",
    "if sum([len(d[1]) for d in data]) != len(meta_names):\n",
    "    print('ERROR 2')\n",
    "\n",
    "\n",
    "print('{:<30}: {:,}'.format('Total (EDF, XLSX) pair', len(edf_paired)))\n",
    "print('{:<30}: {:,}'.format('Total rows of metadata', len(meta_names)))\n",
    "print('-' * 70)\n",
    "\n",
    "# print('{:<30}: {:,}'.format('Total data', len(data)))\n",
    "# print()\n",
    "\n",
    "print('- {:>5,} EDF data has no linked metadata.'.format(sum([len(d[1]) == 0 for d in data])))\n",
    "# print([d[0][0] for d in data if len(d[1]) == 0])\n",
    "# print('-' * 70)\n",
    "\n",
    "print('- {:>5,} metadata has no linked EDf file.'.format(sum([len(d[0]) == 0 for d in data])))\n",
    "# print([d[1][0][0] for d in data if len(d[0]) == 0])\n",
    "# print('-' * 70)\n",
    "\n",
    "data = [d for d in data if len(d[1]) > 0 and len(d[0]) > 0]\n",
    "print('= Only {:>5,} data has the connection between them.'.format(len(data)))\n",
    "print('-' * 70)\n",
    "\n",
    "print('Among them,')\n",
    "print(f'- {sum([len(d[0]) == 1 and len(d[1]) == 1 for d in data]):>5,} are the   one-to-one matching between (EDF - metadata).')\n",
    "print(f'- {sum([len(d[0]) > 1 and len(d[1]) == 1 for d in data]):>5,} are the  many-to-one matching between (EDF - metadata).')\n",
    "print(f'- {sum([len(d[0]) == 1 and len(d[1]) > 1 for d in data]):>5,} are the  one-to-many matching between (EDF - metadata).')\n",
    "print(f'- {sum([len(d[0]) > 1 and len(d[1]) > 1 for d in data]):>5,} are the many-to-many matching between (EDF - metadata).')\n",
    "\n",
    "del edf_paired, meta_names, meta_birth, meta_dx1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## `(EDF, XLSX)` 데이터 $\\longleftrightarrow$ 메타데이터 톺아보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 톺아보기 1\n",
    "\n",
    "- 다대일, 일대다, 다대다 매칭 목록 작성 ($\\Rightarrow$ 손수 데이터를 정제하는데 참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one-to-many.xlsx is saved.\n",
      "many-to-one.xlsx is saved.\n",
      "many-to-many.xlsx is saved.\n"
     ]
    }
   ],
   "source": [
    "# list-up one-to-many matching in excel sheet\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'one-to-many'\n",
    "ws.cell(row=1, column=1).value = 'EDF filename'\n",
    "ws.cell(row=1, column=2).value = 'Metadata'\n",
    "ws.cell(row=1, column=3).value = 'birth'\n",
    "ws.cell(row=1, column=4).value = 'dx_1'\n",
    "ws.cell(row=1, column=5).value = 'New birth'\n",
    "ws.cell(row=1, column=6).value = 'New dx_1'\n",
    "\n",
    "(r_pivot, r_max, c_counter) = (2, 2, 0)\n",
    "for d in data:\n",
    "    if len(d[0]) == 1 and len(d[1]) > 1:\n",
    "        # edf\n",
    "        for (k, edf_name) in enumerate(d[0]):\n",
    "            r_max = max(r_max, r_pivot + k)\n",
    "            ws.cell(row=r_pivot + k, column=1).value = edf_name\n",
    "        # metadata\n",
    "        for (k, meta) in enumerate(d[1]):\n",
    "            r_max = max(r_max, r_pivot + k)\n",
    "            ws.cell(row=r_pivot + k, column=2).value = meta[0]\n",
    "            ws.cell(row=r_pivot + k, column=3).value = meta[1]\n",
    "            ws.cell(row=r_pivot + k, column=4).value = meta[2]\n",
    "        # coloring\n",
    "        for rows in ws.iter_rows(min_row=r_pivot, max_row=r_max, min_col=1, max_col=6):\n",
    "            for cell in rows:\n",
    "                color = 'FFFFCC' if c_counter % 2 == 0 else '00C0C0C0'\n",
    "                cell.fill = styles.PatternFill(start_color=color, end_color=color, fill_type=\"solid\")\n",
    "        r_pivot = r_max + 1\n",
    "        c_counter += 1\n",
    "\n",
    "wb.save(os.path.join(output_path, 'one-to-many.xlsx'))\n",
    "print('one-to-many.xlsx is saved.')\n",
    "\n",
    "# list-up many-to-one matching in excel sheet\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'many-to-one'\n",
    "ws.cell(row=1, column=1).value = 'EDF filename'\n",
    "ws.cell(row=1, column=2).value = 'Metadata name'\n",
    "ws.cell(row=1, column=3).value = 'Metadata birth'\n",
    "ws.cell(row=1, column=4).value = 'dx_1'\n",
    "ws.cell(row=1, column=5).value = 'Delete?'\n",
    "\n",
    "(r_pivot, r_max, c_counter) = (2, 2, 0)\n",
    "for d in data:\n",
    "    if len(d[0]) > 1 and len(d[1]) == 1:\n",
    "        # edf\n",
    "        for (k, edf_name) in enumerate(d[0]):\n",
    "            r_max = max(r_max, r_pivot + k)\n",
    "            ws.cell(row=r_pivot + k, column=1).value = edf_name\n",
    "        # metadata\n",
    "        for (k, meta) in enumerate(d[1]):\n",
    "            r_max = max(r_max, r_pivot + k)\n",
    "            ws.cell(row=r_pivot + k, column=2).value = meta[0]\n",
    "            ws.cell(row=r_pivot + k, column=3).value = meta[1]\n",
    "            ws.cell(row=r_pivot + k, column=4).value = meta[2]\n",
    "        # coloring\n",
    "        for rows in ws.iter_rows(min_row=r_pivot, max_row=r_max, min_col=1, max_col=5):\n",
    "            for cell in rows:\n",
    "                color = 'FFFFCC' if c_counter % 2 == 0 else '00C0C0C0'\n",
    "                cell.fill = styles.PatternFill(start_color=color, end_color=color, fill_type=\"solid\")\n",
    "        r_pivot = r_max + 1\n",
    "        c_counter += 1\n",
    "        \n",
    "wb.save(os.path.join(output_path, 'many-to-one.xlsx'))\n",
    "print('many-to-one.xlsx is saved.')\n",
    "\n",
    "# list-up many-to-many matching in excel sheet\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'many-to-many'\n",
    "ws.cell(row=1, column=1).value = 'EDF filename'\n",
    "ws.cell(row=1, column=2).value = 'Metadata name'\n",
    "ws.cell(row=1, column=3).value = 'Metadata birth'\n",
    "ws.cell(row=1, column=4).value = 'dx_1'\n",
    "ws.cell(row=1, column=5).value = 'New birth'\n",
    "ws.cell(row=1, column=6).value = 'New dx_1'\n",
    "\n",
    "(r_pivot, r_max, c_counter) = (2, 2, 0)\n",
    "for d in data:\n",
    "    if len(d[0]) > 1 and len(d[1]) > 1:\n",
    "        # edf\n",
    "        for (k, edf_name) in enumerate(d[0]):\n",
    "            r_max = max(r_max, r_pivot + k)\n",
    "            ws.cell(row=r_pivot + k, column=1).value = edf_name\n",
    "        # metadata\n",
    "        for (k, meta) in enumerate(d[1]):\n",
    "            r_max = max(r_max, r_pivot + k)\n",
    "            ws.cell(row=r_pivot + k, column=2).value = meta[0]\n",
    "            ws.cell(row=r_pivot + k, column=3).value = meta[1]\n",
    "            ws.cell(row=r_pivot + k, column=4).value = meta[2]\n",
    "        # coloring\n",
    "        for rows in ws.iter_rows(min_row=r_pivot, max_row=r_max, min_col=1, max_col=6):\n",
    "            for cell in rows:\n",
    "                color = 'FFFFCC' if c_counter % 2 == 0 else 'C0C0C0'\n",
    "                cell.fill = styles.PatternFill(start_color=color, end_color=color, fill_type=\"solid\")\n",
    "        r_pivot = r_max + 1\n",
    "        c_counter += 1\n",
    "        \n",
    "wb.save(os.path.join(output_path, 'many-to-many.xlsx'))\n",
    "print('many-to-many.xlsx is saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 톺아보기 2\n",
    "\n",
    "- 일대일 대응만 추려내기\n",
    "- 그 중 (Dementia, MCI, Normal) 진단명을 갖는 데이터 수 통계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of one-to-one data is \t\t\t1,008\n",
      "Among them,\n",
      " - # of data with <Dementia> diagnosis is \t\t  207\n",
      "   * # of data with <MCI> diagnosis is \t\t\t  304\n",
      "   * # of data with <MCI-Amnestic-EF> diagnosis is \t\t   96\n",
      " - # of data with <MCI-Amnestic-RF> diagnosis is \t\t   91\n",
      " - # of data with <Normal> diagnosis is \t\t  318\n",
      " - # of data with the other diagnoses is \t\t  179\n",
      "\n",
      "filtered_one_to_one_data.xlsx is saved.\n"
     ]
    }
   ],
   "source": [
    "# pull out some data\n",
    "# 1. one-to-one matching between (EDF, XLSX) and (metadata)\n",
    "# 2. with the diagnoses among (normal, mci, dementia)\n",
    "# (regardless of birth value)\n",
    "one_to_one_data = [(d[0][0], d[1][0][1], MultiEegLabel.load_from_string(d[1][0][2])) for d in data \n",
    "                   if len(d[0]) == 1 and len(d[1]) == 1]\n",
    "\n",
    "# count the numbers of patients in the category of 'normal,' 'mci,' 'dementia.'\n",
    "(num_normal, num_mci, num_dementia, num_others) = (0, 0, 0, 0)\n",
    "(num_ef, num_rf) = (0, 0)\n",
    "for d in one_to_one_data:\n",
    "    if d[2].check('dementia'):\n",
    "        num_dementia += 1\n",
    "    elif d[2].check('mci'):\n",
    "        num_mci += 1\n",
    "        if d[2].check('mci_amnestic_ef'):\n",
    "            num_ef += 1\n",
    "        elif d[2].check('mci_amnestic_rf'):\n",
    "            num_rf += 1\n",
    "    elif d[2].check('normal'):\n",
    "        num_normal += 1\n",
    "    else:\n",
    "        num_others += 1\n",
    "\n",
    "print(f'The number of one-to-one data is \\t\\t\\t{len(one_to_one_data):>5,}')\n",
    "print('Among them,')\n",
    "print(f' - # of data with <Dementia> diagnosis is \\t\\t{num_dementia:>5,}')\n",
    "print(f'   * # of data with <MCI> diagnosis is \\t\\t\\t{num_mci:>5,}')\n",
    "print(f'   * # of data with <MCI-Amnestic-EF> diagnosis is \\t\\t{num_ef:>5,}')\n",
    "print(f' - # of data with <MCI-Amnestic-RF> diagnosis is \\t\\t{num_rf:>5,}')\n",
    "print(f' - # of data with <Normal> diagnosis is \\t\\t{num_normal:>5,}')\n",
    "print(f' - # of data with the other diagnoses is \\t\\t{num_others:>5,}')\n",
    "print()\n",
    "\n",
    "# save the filtered data\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'one_to_one_data'\n",
    "ws.cell(row=1, column=1).value = 'EDF filename'\n",
    "ws.cell(row=1, column=2).value = 'birth'\n",
    "for (i, label) in enumerate(one_to_one_data[0][2].get_label_types()):\n",
    "    ws.cell(row=1, column=3 + i).value = label\n",
    "\n",
    "for (i, d) in enumerate(one_to_one_data):\n",
    "    ws.cell(row=2 + i, column=1).value = d[0] \n",
    "    ws.cell(row=2 + i, column=2).value = d[1] if d[1] is not None and float(d[1]) > 0 else None\n",
    "    for (k, label) in enumerate(d[2].get_label_values()):\n",
    "        ws.cell(row=2 + i, column=3 + k).value = label if label is not False else None\n",
    "\n",
    "    # coloring\n",
    "    color = 'FDFDD0' if i % 2 == 0 else 'D9E5FF'\n",
    "    for rows in ws.iter_rows(min_row=2 + i, max_row=2 + i, min_col=1, max_col=2 + d[2].get_size()):\n",
    "        for cell in rows:\n",
    "            cell.fill = styles.PatternFill(start_color=color, end_color=color, fill_type=\"solid\")\n",
    "\n",
    "wb.save(os.path.join(output_path, 'filtered_one_to_one_data.xlsx'))\n",
    "print('filtered_one_to_one_data.xlsx is saved.')\n",
    "\n",
    "del one_to_one_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 톺아보기 3\n",
    "\n",
    "- 일대일 대응\n",
    "- 유효한 나이 값\n",
    "- 그 중 (Dementia, MCI, Normal) 진단명을 갖는 데이터 수 통계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of one-to-one aged data is \t\t\t1,006\n",
      "Among them,\n",
      " - # of data with <Dementia> diagnosis is \t\t  207\n",
      "   * # of data with <MCI> diagnosis is \t\t\t  303\n",
      "   * # of data with <MCI-Amnestic-EF> diagnosis is \t\t   96\n",
      " - # of data with <MCI-Amnestic-RF> diagnosis is \t\t   91\n",
      " - # of data with <Normal> diagnosis is \t\t  317\n",
      " - # of data with the other diagnoses is \t\t  179\n",
      "\n",
      "filtered_one_to_one_aged_data.xlsx is saved.\n"
     ]
    }
   ],
   "source": [
    "# pull out some data\n",
    "# 1. one-to-one matching between (EDF, XLSX) and (metadata)\n",
    "# 2. with the valid birth value\n",
    "# 3. with the diagnoses among (normal, mci, dementia)\n",
    "one_to_one_aged_data = [(d[0][0], d[1][0][1], MultiEegLabel.load_from_string(d[1][0][2])) for d in data \n",
    "                        if len(d[0]) == 1 and len(d[1]) == 1 and \n",
    "                        d[1][0][1] is not None and float(d[1][0][1]) > 0]\n",
    "\n",
    "# count the numbers of patients in the category of 'normal,' 'mci,' 'dementia.'\n",
    "(num_normal, num_mci, num_dementia, num_others) = (0, 0, 0, 0)\n",
    "(num_ef, num_rf) = (0, 0)\n",
    "for d in one_to_one_aged_data:\n",
    "    if d[2].check('dementia'):\n",
    "        num_dementia += 1\n",
    "    elif d[2].check('mci'):\n",
    "        num_mci += 1\n",
    "        if d[2].check('mci_amnestic_ef'):\n",
    "            num_ef += 1\n",
    "        elif d[2].check('mci_amnestic_rf'):\n",
    "            num_rf += 1\n",
    "    elif d[2].check('normal'):\n",
    "        num_normal += 1\n",
    "    else:\n",
    "        num_others += 1\n",
    "\n",
    "print(f'The number of one-to-one aged data is \\t\\t\\t{len(one_to_one_aged_data):>5,}')\n",
    "print('Among them,')\n",
    "print(f' - # of data with <Dementia> diagnosis is \\t\\t{num_dementia:>5,}')\n",
    "print(f'   * # of data with <MCI> diagnosis is \\t\\t\\t{num_mci:>5,}')\n",
    "print(f'   * # of data with <MCI-Amnestic-EF> diagnosis is \\t\\t{num_ef:>5,}')\n",
    "print(f' - # of data with <MCI-Amnestic-RF> diagnosis is \\t\\t{num_rf:>5,}')\n",
    "print(f' - # of data with <Normal> diagnosis is \\t\\t{num_normal:>5,}')\n",
    "print(f' - # of data with the other diagnoses is \\t\\t{num_others:>5,}')\n",
    "print()\n",
    "      \n",
    "# save the filtered data\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'one_to_one_aged_data'\n",
    "ws.cell(row=1, column=1).value = 'EDF filename'\n",
    "ws.cell(row=1, column=2).value = 'birth'\n",
    "for (i, label) in enumerate(one_to_one_aged_data[0][2].get_label_types()):\n",
    "    ws.cell(row=1, column=3 + i).value = label\n",
    "\n",
    "for (i, d) in enumerate(one_to_one_aged_data):\n",
    "    ws.cell(row=2 + i, column=1).value = d[0]\n",
    "    ws.cell(row=2 + i, column=2).value = d[1]\n",
    "    for (k, label) in enumerate(d[2].get_label_values()):\n",
    "        ws.cell(row=2 + i, column=3 + k).value = label if label is not False else None\n",
    "\n",
    "    # coloring\n",
    "    color = 'FDFDD0' if i % 2 == 0 else 'D9E5FF'\n",
    "    for rows in ws.iter_rows(min_row=2 + i, max_row=2 + i, min_col=1, max_col=2 + d[2].get_size()):\n",
    "        for cell in rows:\n",
    "            cell.fill = styles.PatternFill(start_color=color, end_color=color, fill_type=\"solid\")\n",
    "        \n",
    "wb.save(os.path.join(output_path, 'filtered_one_to_one_aged_data.xlsx'))\n",
    "print('filtered_one_to_one_aged_data.xlsx is saved.')\n",
    "\n",
    "del one_to_one_aged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 톺아보기 4\n",
    "\n",
    "- 유효하지 않은 나이 값 ($\\Rightarrow$ 나이 값 업데이트 필요한 데이터가 무엇인지 파악)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of one-to-one data with invalid age is     2\n",
      "filtered_invalid_age_data.xlsx is saved.\n"
     ]
    }
   ],
   "source": [
    "# pull out some data\n",
    "# 1. with *INVALID* birth values\n",
    "\n",
    "data_temp = []\n",
    "for d in data:\n",
    "    for edf in d[0]:\n",
    "        data_temp.append((edf, d[1]))\n",
    "\n",
    "invalid_age_data = [(d[0], d[1][0][1], d[1][0][2]) for d in data_temp \n",
    "                   if d[1][0][1] is None or float(d[1][0][1]) < 0]\n",
    "invalid_age_data = sorted(invalid_age_data, key=lambda x: x[0])\n",
    "\n",
    "print(f'The number of one-to-one data with invalid age is {len(invalid_age_data):>5,}')\n",
    "\n",
    "# save the filtered data\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'invalid_age_data'\n",
    "ws.cell(row=1, column=1).value = 'EDF filename'\n",
    "ws.cell(row=1, column=2).value = 'birth'\n",
    "ws.cell(row=1, column=3).value = 'dx_1'\n",
    "\n",
    "for (i, d) in enumerate(invalid_age_data):\n",
    "    ws.cell(row=2 + i, column=1).value = d[0]\n",
    "    ws.cell(row=2 + i, column=2).value = d[1]\n",
    "    ws.cell(row=2 + i, column=3).value = d[2]\n",
    "    \n",
    "wb.save(os.path.join(output_path, 'filtered_invalid_age_data.xlsx'))\n",
    "print('filtered_invalid_age_data.xlsx is saved.')\n",
    "\n",
    "del invalid_age_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 톺아보기 5\n",
    "\n",
    "- 다대일 대응, 또는 다대다 대응\n",
    "- 측정 시간차가 큰 순으로 정렬 ($\\Rightarrow$ 진단명 업데이트가 필요한 데이터가 무엇인지 파악)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "many_edf_data.xlsx is saved.\n"
     ]
    }
   ],
   "source": [
    "# pull out some data\n",
    "# 1. many-to-one or many-to-many matching between (EDF, XLSX) and (metadata)\n",
    "# 2. sort the data by the time delta between EEG measurements\n",
    "\n",
    "many_edf_data =[[(edf_name, datetime.date(2000 + int(edf_name[-2:]), int(edf_name[-4:-2]), int(edf_name[-6:-4])) \n",
    "                  if len(edf_name) == 15 else datetime.date.max) for edf_name in d[0]] for d in data if len(d[0]) > 1]\n",
    "\n",
    "many_edf_data_temp = []\n",
    "for d in many_edf_data:\n",
    "    d = sorted(d, key=lambda x: x[1])\n",
    "    many_edf_data_temp.append(d)\n",
    "\n",
    "many_edf_data = sorted(many_edf_data_temp, key=lambda x: x[-1][1] - x[0][1], reverse=True)\n",
    "del many_edf_data_temp\n",
    "\n",
    "# list-up many edf data matching in excel sheet\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'many_edf_data'\n",
    "ws.cell(row=1, column=1).value = 'EDF filename'\n",
    "ws.cell(row=1, column=2).value = 'Time delta (years)'\n",
    "ws.cell(row=1, column=3).value = '파일명이 잘못 되었을 경우, 새로운 파일명'\n",
    "\n",
    "(r_pivot, r_max, c_counter) = (2, 2, 0)\n",
    "for d in many_edf_data:\n",
    "    # edf\n",
    "    for (k, edf_name) in enumerate(d):\n",
    "        r_max = max(r_max, r_pivot + k)\n",
    "        ws.cell(row=r_pivot + k, column=1).value = edf_name[0]\n",
    "        \n",
    "    # time delta\n",
    "    ws.cell(row=r_pivot, column=2).value = '%.2f' % ((d[-1][1] - d[0][1]).days / 365)\n",
    "\n",
    "    # coloring\n",
    "    for rows in ws.iter_rows(min_row=r_pivot, max_row=r_max, min_col=1, max_col=3):\n",
    "        for cell in rows:\n",
    "            color = 'FAF4C0' if c_counter % 2 == 0 else 'B2CCFF'\n",
    "            cell.fill = styles.PatternFill(start_color=color, end_color=color, fill_type=\"solid\")\n",
    "    r_pivot = r_max + 1\n",
    "    c_counter += 1\n",
    "        \n",
    "wb.save(os.path.join(output_path, 'many_edf_data.xlsx'))\n",
    "print('many_edf_data.xlsx is saved.')\n",
    "\n",
    "del many_edf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 톺아보기 6\n",
    "\n",
    "- 일대일 대응, 그에 더해\n",
    "- 다대일 대응 데이터를 쪼개서 여러 개의 일대일 대응 데이터로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After splitted, the number of one-to-one data is \t1,401\n",
      "Among them,\n",
      " - # of data with <Dementia> diagnosis is \t\t  309\n",
      "   - # of data with <MCI> diagnosis is \t\t\t  423\n",
      "   - # of data with <MCI-Amnestic-EF> diagnosis is \t\t  158\n",
      " - # of data with <MCI-Amnestic-RF> diagnosis is \t\t  117\n",
      " - # of data with <Normal> diagnosis is \t\t  468\n",
      " - # of data with the other diagnoses is \t\t  201\n",
      "\n",
      "filtered_splitted_many_data.xlsx is saved.\n"
     ]
    }
   ],
   "source": [
    "# pull out some data\n",
    "# 1. one-to-one matching between (EDF, XLSX) and (metadata)\n",
    "# 2. split many-to-one matching into many one-to-one matching\n",
    "\n",
    "splitted_many_data = []\n",
    "for d in data:\n",
    "    # one edf vs one metadata case\n",
    "    if len(d[0]) == 1 and len(d[1]) == 1:\n",
    "        birth = d[1][0][1] if d[1][0][1] is not None and float(d[1][0][1]) > 0 else None\n",
    "        dx1 = d[1][0][2]\n",
    "        splitted_many_data.append((d[0][0], birth, dx1, MultiEegLabel.load_from_string(d[1][0][2])))\n",
    "    # many edfs vs one metadata case\n",
    "    elif len(d[0]) >= 1 and len(d[1]) == 1:\n",
    "        birth = d[1][0][1] if d[1][0][1] is not None and float(d[1][0][1]) > 0 else None\n",
    "        dx1 = d[1][0][2]\n",
    "        splitted_many_data.extend([(edf_name, birth, dx1, MultiEegLabel.load_from_string(d[1][0][2])) for edf_name in d[0]])\n",
    "    # one edf vs many metadata case\n",
    "    elif len(d[0]) == 1 and len(d[1]) >= 1:\n",
    "        pass\n",
    "    # many edfs vs many metadata case\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(f'After splitted, the number of one-to-one data is \\t{len(splitted_many_data):>5,}')\n",
    "\n",
    "# count the numbers of patients in the category of 'normal,' 'mci,' 'dementia.'\n",
    "(num_normal, num_mci, num_dementia, num_others) = (0, 0, 0, 0)\n",
    "(num_ef, num_rf) = (0, 0)\n",
    "for d in splitted_many_data:\n",
    "    if d[3].check('dementia'):\n",
    "        num_dementia += 1\n",
    "    elif d[3].check('mci'):\n",
    "        num_mci += 1\n",
    "        if d[3].check('mci_amnestic_ef'):\n",
    "            num_ef += 1\n",
    "        elif d[3].check('mci_amnestic_rf'):\n",
    "            num_rf += 1\n",
    "    elif d[3].check('normal'):\n",
    "        num_normal += 1\n",
    "    else:\n",
    "        num_others += 1\n",
    "\n",
    "print('Among them,')\n",
    "print(f' - # of data with <Dementia> diagnosis is \\t\\t{num_dementia:>5,}')\n",
    "print(f'   - # of data with <MCI> diagnosis is \\t\\t\\t{num_mci:>5,}')\n",
    "print(f'   - # of data with <MCI-Amnestic-EF> diagnosis is \\t\\t{num_ef:>5,}')\n",
    "print(f' - # of data with <MCI-Amnestic-RF> diagnosis is \\t\\t{num_rf:>5,}')\n",
    "print(f' - # of data with <Normal> diagnosis is \\t\\t{num_normal:>5,}')\n",
    "print(f' - # of data with the other diagnoses is \\t\\t{num_others:>5,}')\n",
    "print()\n",
    "\n",
    "# save the filtered data\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'splitted_many_data'\n",
    "ws.cell(row=1, column=1).value = 'EDF filename'\n",
    "ws.cell(row=1, column=2).value = 'birth'\n",
    "ws.cell(row=1, column=3).value = 'dx1'\n",
    "for (i, label) in enumerate(splitted_many_data[0][3].get_label_types()):\n",
    "    ws.cell(row=1, column=4 + i).value = label\n",
    "\n",
    "for (i, d) in enumerate(splitted_many_data):\n",
    "    ws.cell(row=2 + i, column=1).value = d[0]\n",
    "    ws.cell(row=2 + i, column=2).value = d[1]\n",
    "    ws.cell(row=2 + i, column=3).value = d[2]\n",
    "    for (k, label) in enumerate(d[3].get_label_values()):\n",
    "        ws.cell(row=2 + i, column=4 + k).value = label if label is not False else None\n",
    "    \n",
    "    # coloring\n",
    "    color = 'FDFDD0' if i % 2 == 0 else 'D9E5FF'\n",
    "    for rows in ws.iter_rows(min_row=2 + i, max_row=2 + i, min_col=1, max_col=3 + d[3].get_size()):\n",
    "        for cell in rows:\n",
    "            cell.fill = styles.PatternFill(start_color=color, end_color=color, fill_type=\"solid\")\n",
    "    \n",
    "wb.save(os.path.join(output_path, 'filtered_splitted_many_data.xlsx'))\n",
    "print('filtered_splitted_many_data.xlsx is saved.')\n",
    "\n",
    "metadata_temp = splitted_many_data\n",
    "del splitted_many_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 톺아보기 7\n",
    "\n",
    "- 일대일 대응, 그에 더해\n",
    "- 다대일 대응 데이터 중 하나만 선택 (측정일시 기준으로 가장 마지막 데이터만)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After splitted, the number of one-to-one data is \t1,171\n",
      "Among them,\n",
      " - # of data with <Dementia> diagnosis is \t\t  244\n",
      "   - # of data with <MCI> diagnosis is \t\t\t  350\n",
      "   - # of data with <MCI-Amnestic-EF> diagnosis is \t\t  117\n",
      " - # of data with <MCI-Amnestic-RF> diagnosis is \t\t  103\n",
      " - # of data with <Normal> diagnosis is \t\t  389\n",
      " - # of data with the other diagnoses is \t\t  188\n",
      "\n",
      "filtered_selected_many_data.xlsx is saved.\n"
     ]
    }
   ],
   "source": [
    "# pull out some data\n",
    "# 1. one-to-one matching between (EDF, XLSX) and (metadata)\n",
    "# 2. select the most recently recorded EDF among many-to-one matching\n",
    "\n",
    "selected_many_data = []\n",
    "for d in data:\n",
    "    # one edf vs one metadata case\n",
    "    if len(d[0]) == 1 and len(d[1]) == 1:\n",
    "        birth = d[1][0][1] if d[1][0][1] is not None and float(d[1][0][1]) > 0 else None\n",
    "        selected_many_data.append((d[0][0], birth, MultiEegLabel.load_from_string(d[1][0][2])))\n",
    "    # many edfs vs one metadata case\n",
    "    elif len(d[0]) >= 1 and len(d[1]) == 1:\n",
    "        (last, idx) = (datetime.date.min, 0)\n",
    "        for (k, edf_name) in enumerate(d[0]):\n",
    "            if len(edf_name) != 15: \n",
    "                continue\n",
    "            date = datetime.date(2000 + int(edf_name[-2:]), int(edf_name[-4:-2]), int(edf_name[-6:-4]))\n",
    "            if last < date:\n",
    "                (last, idx) = (date, k)\n",
    "        birth = d[1][0][1] if d[1][0][1] is not None and float(d[1][0][1]) > 0 else None\n",
    "        selected_many_data.append((d[0][idx], birth, MultiEegLabel.load_from_string(d[1][0][2]))) \n",
    "    # one edf vs many metadata case\n",
    "    elif len(d[0]) == 1 and len(d[1]) >= 1:\n",
    "        pass\n",
    "    # many edfs vs many metadata case\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(f'After splitted, the number of one-to-one data is \\t{len(selected_many_data):>5,}')\n",
    "\n",
    "# count the numbers of patients in the category of 'normal,' 'mci,' 'dementia.'\n",
    "(num_normal, num_mci, num_dementia, num_others) = (0, 0, 0, 0)\n",
    "(num_ef, num_rf) = (0, 0)\n",
    "for d in selected_many_data:\n",
    "    if d[2].check('dementia'):\n",
    "        num_dementia += 1\n",
    "    elif d[2].check('mci'):\n",
    "        num_mci += 1\n",
    "        if d[2].check('mci_amnestic_ef'):\n",
    "            num_ef += 1\n",
    "        elif d[2].check('mci_amnestic_rf'):\n",
    "            num_rf += 1\n",
    "    elif d[2].check('normal'):\n",
    "        num_normal += 1\n",
    "    else:\n",
    "        num_others += 1\n",
    "\n",
    "print('Among them,')\n",
    "print(f' - # of data with <Dementia> diagnosis is \\t\\t{num_dementia:>5,}')\n",
    "print(f'   - # of data with <MCI> diagnosis is \\t\\t\\t{num_mci:>5,}')\n",
    "print(f'   - # of data with <MCI-Amnestic-EF> diagnosis is \\t\\t{num_ef:>5,}')\n",
    "print(f' - # of data with <MCI-Amnestic-RF> diagnosis is \\t\\t{num_rf:>5,}')\n",
    "print(f' - # of data with <Normal> diagnosis is \\t\\t{num_normal:>5,}')\n",
    "print(f' - # of data with the other diagnoses is \\t\\t{num_others:>5,}')\n",
    "print()\n",
    "\n",
    "# save the filtered data\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'selected_many_data'\n",
    "ws.cell(row=1, column=1).value = 'EDF filename'\n",
    "ws.cell(row=1, column=2).value = 'birth'\n",
    "for (i, label) in enumerate(selected_many_data[0][2].get_label_types()):\n",
    "    ws.cell(row=1, column=3 + i).value = label\n",
    "\n",
    "for (i, d) in enumerate(selected_many_data):\n",
    "    ws.cell(row=2 + i, column=1).value = d[0]\n",
    "    ws.cell(row=2 + i, column=2).value = d[1]\n",
    "    for (k, label) in enumerate(d[2].get_label_values()):\n",
    "        ws.cell(row=2 + i, column=3 + k).value = label if label is not False else None\n",
    "    \n",
    "    # coloring\n",
    "    color = 'FDFDD0' if i % 2 == 0 else 'D9E5FF'\n",
    "    for rows in ws.iter_rows(min_row=2 + i, max_row=2 + i, min_col=1, max_col=2 + d[2].get_size()):\n",
    "        for cell in rows:\n",
    "            cell.fill = styles.PatternFill(start_color=color, end_color=color, fill_type=\"solid\")\n",
    "    \n",
    "wb.save(os.path.join(output_path, 'filtered_selected_many_data.xlsx'))\n",
    "print('filtered_selected_many_data.xlsx is saved.')\n",
    "\n",
    "del selected_many_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## 메타데이터 정리하여 새로 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_DB_list.xlsx is saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the metadata\n",
    "# 1. one-to-one matching between (EDF, XLSX) and (metadata)\n",
    "# 2. split many-to-one matching into many one-to-one matching\n",
    "\n",
    "new_metadata = []\n",
    "for d in data:\n",
    "    # one edf vs one metadata case\n",
    "    if len(d[0]) == 1 and len(d[1]) == 1:\n",
    "        birth = d[1][0][1]\n",
    "        dx1 = d[1][0][2]\n",
    "        new_metadata.append((d[0][0], birth, dx1))\n",
    "    # many edfs vs one metadata case\n",
    "    elif len(d[0]) >= 1 and len(d[1]) == 1:\n",
    "        birth = d[1][0][1]\n",
    "        dx1 = d[1][0][2]\n",
    "        new_metadata.extend([(edf_name, birth, dx1) for edf_name in d[0]])\n",
    "    # one edf vs many metadata case\n",
    "    elif len(d[0]) == 1 and len(d[1]) >= 1:\n",
    "        pass\n",
    "    # many edfs vs many metadata case\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# save new metadata as XLSX\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = 'metadata'\n",
    "ws.cell(row=1, column=1).value = 'EDF filename'\n",
    "ws.cell(row=1, column=2).value = 'dx1'\n",
    "ws.cell(row=1, column=3).value = 'birth'\n",
    "\n",
    "for (i, d) in enumerate(new_metadata):\n",
    "    ws.cell(row=2 + i, column=1).value = d[0]\n",
    "    ws.cell(row=2 + i, column=2).value = d[2] # dx1\n",
    "    ws.cell(row=2 + i, column=3).value = d[1] # birth\n",
    "    \n",
    "    # coloring\n",
    "    color = 'FDFDD0' if i % 2 == 0 else 'D9E5FF'\n",
    "    for rows in ws.iter_rows(min_row=2 + i, max_row=2 + i, min_col=1, max_col=3):\n",
    "        for cell in rows:\n",
    "            cell.fill = styles.PatternFill(start_color=color, end_color=color, fill_type=\"solid\")\n",
    "    \n",
    "wb.save(os.path.join(output_path, 'new_DB_list.xlsx'))\n",
    "print('new_DB_list.xlsx is saved.')\n",
    "\n",
    "metadata_temp = new_metadata\n",
    "del new_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## `210504_many-to-one_Diagnosis_추가수정` 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_DB_list.xlsx is updated.\n"
     ]
    }
   ],
   "source": [
    "meta_file = os.path.join(inform_path, r'210504_many-to-one_Diagnosis_추가수정.xlsx')\n",
    "ws = load_workbook(meta_file, data_only=True)['many-to-one']\n",
    "\n",
    "meta_names = []\n",
    "meta_dx1 = []\n",
    "\n",
    "num = 2\n",
    "while True:\n",
    "    # field 1: EDF filename\n",
    "    n = ws.cell(row=num, column=1).value\n",
    "    \n",
    "    # field 4: dx_1\n",
    "    d1 = ws.cell(row=num, column=4).value\n",
    "    \n",
    "    # field 6: dx_1 (2)\n",
    "    d2 = ws.cell(row=num, column=6).value\n",
    "    \n",
    "    # check whether the row is empty (which is EOF condition)\n",
    "    if n is None:\n",
    "        break\n",
    "    elif d1 is None and d2 is None:\n",
    "        num += 1\n",
    "        continue\n",
    "    elif d2 is None:\n",
    "        d = d1\n",
    "    else:\n",
    "        d = d2\n",
    "        \n",
    "    d = d.lower().strip(' \\n')\n",
    "    \n",
    "    # update information\n",
    "    meta_names.append(n)\n",
    "    meta_dx1.append(d)\n",
    "    \n",
    "    # move the pivot row\n",
    "    num += 1\n",
    "\n",
    "    \n",
    "meta_file = os.path.join(os.path.join(output_path, 'new_DB_list.xlsx'))\n",
    "wb = load_workbook(meta_file, data_only=True)\n",
    "ws = wb['metadata']\n",
    "\n",
    "num = 2\n",
    "while True:\n",
    "    # field 1: EDF filename\n",
    "    n = ws.cell(row=num, column=1).value\n",
    "    \n",
    "    # field 2: dx_1\n",
    "    if n in meta_names:\n",
    "        d = meta_dx1[meta_names.index(n)]\n",
    "        ws.cell(row=num, column=2).value = d\n",
    "   \n",
    "    # check whether the row is empty (which is EOF condition)\n",
    "    if n is None:\n",
    "        break\n",
    "\n",
    "    # move the pivot row\n",
    "    num += 1\n",
    "    \n",
    "wb.save(os.path.join(output_path, 'new_DB_list.xlsx'))\n",
    "print('new_DB_list.xlsx is updated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## `210420_many-to-many_Diagnosis_YY정리.xlsx` 반영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_DB_list.xlsx is updated.\n"
     ]
    }
   ],
   "source": [
    "meta_file = os.path.join(inform_path, r'210420_many-to-many_Diagnosis_YY정리.xlsx')\n",
    "ws = load_workbook(meta_file, data_only=True)['many-to-many']\n",
    "\n",
    "meta_names = []\n",
    "meta_dx1 = []\n",
    "\n",
    "num = 2\n",
    "while True:\n",
    "    # field 1: EDF filename\n",
    "    n = ws.cell(row=num, column=1).value\n",
    "    \n",
    "    # field 4: dx_1\n",
    "    d = ws.cell(row=num, column=4).value\n",
    "    \n",
    "    # check whether the row is empty (which is EOF condition)\n",
    "    if n is None:\n",
    "        break\n",
    "    elif d is None:\n",
    "        num += 1\n",
    "        continue\n",
    "        \n",
    "    d = d.lower().strip(' \\n')\n",
    "    \n",
    "    # update information\n",
    "    meta_names.append(n)\n",
    "    meta_dx1.append(d)\n",
    "    \n",
    "    # move the pivot row\n",
    "    num += 1\n",
    "\n",
    "    \n",
    "meta_file = os.path.join(output_path, 'new_DB_list.xlsx')\n",
    "wb = load_workbook(meta_file, data_only=True)\n",
    "ws = wb['metadata']\n",
    "\n",
    "num = 2\n",
    "while True:\n",
    "    # field 1: EDF filename\n",
    "    n = ws.cell(row=num, column=1).value\n",
    "    \n",
    "    # field 2: dx_1\n",
    "    if n in meta_names:\n",
    "        d = meta_dx1[meta_names.index(n)]\n",
    "        ws.cell(row=num, column=2).value = d\n",
    "   \n",
    "    # check whether the row is empty (which is EOF condition)\n",
    "    if n is None:\n",
    "        break\n",
    "\n",
    "    # move the pivot row\n",
    "    num += 1\n",
    "    \n",
    "wb.save(os.path.join(output_path, 'new_DB_list.xlsx'))\n",
    "print('new_DB_list.xlsx is updated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "279px",
    "width": "378px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "356px",
    "left": "1090px",
    "top": "213px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
