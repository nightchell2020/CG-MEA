{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 1D CNN\n",
    "\n",
    "1D Convolution을 기본 구성 요소로 하는 EEG classifier를 학습해보는 노트북.\n",
    "\n",
    "- Three-way SoftMax classifier of normal, non-vascular MCI, and non-vascular dementia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----\n",
    "\n",
    "## 환경 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import datetime\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "from itertools import cycle\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import wandb\n",
    "\n",
    "# custom package\n",
    "from utils.eeg_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook name\n",
    "def get_notebook_name():\n",
    "    import ipynbname\n",
    "    return ipynbname.name()\n",
    "nb_fname = get_notebook_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other settings\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # cleaner text\n",
    "\n",
    "plt.style.use('default') \n",
    "# ['Solarize_Light2', '_classic_test_patch', 'bmh', 'classic', 'dark_background', 'fast', \n",
    "#  'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn', 'seaborn-bright', 'seaborn-colorblind', \n",
    "#  'seaborn-dark', 'seaborn-dark-palette', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', \n",
    "#  'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', \n",
    "#  'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'tableau-colorblind10']\n",
    "\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams[\"font.family\"] = 'NanumGothic' # for Hangul in Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.9.0\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 78,\n",
      " 'birth': '1940-06-02',\n",
      " 'dx1': 'mci_rf',\n",
      " 'edfname': '00001809_261018',\n",
      " 'events': [[0, 'Start Recording'],\n",
      "            [0, 'New Montage - Montage 002'],\n",
      "            [36396, 'Eyes Open'],\n",
      "            [72518, 'Eyes Closed'],\n",
      "            [73862, 'Eyes Open'],\n",
      "            [75248, 'Eyes Closed'],\n",
      "            [76728, 'swallowing'],\n",
      "            [77978, 'Eyes Open'],\n",
      "            [79406, 'Eyes Closed'],\n",
      "            [79996, 'Photic On - 3.0 Hz'],\n",
      "            [80288, 'Eyes Open'],\n",
      "            [81296, 'Eyes Closed'],\n",
      "            [82054, 'Photic Off'],\n",
      "            [84070, 'Photic On - 6.0 Hz'],\n",
      "            [84488, 'Eyes Open'],\n",
      "            [85538, 'Eyes Closed'],\n",
      "            [86086, 'Photic Off'],\n",
      "            [88144, 'Photic On - 9.0 Hz'],\n",
      "            [90160, 'Photic Off'],\n",
      "            [91458, 'Eyes Open'],\n",
      "            [92218, 'Photic On - 12.0 Hz'],\n",
      "            [92762, 'Eyes Closed'],\n",
      "            [94198, 'Photic Off'],\n",
      "            [94742, 'Eyes Open'],\n",
      "            [95708, 'Eyes Closed'],\n",
      "            [96256, 'Photic On - 15.0 Hz'],\n",
      "            [98272, 'Photic Off'],\n",
      "            [100330, 'Photic On - 18.0 Hz'],\n",
      "            [102346, 'Photic Off'],\n",
      "            [102596, 'Eyes Open'],\n",
      "            [103856, 'Eyes Closed'],\n",
      "            [104361, 'Photic On - 21.0 Hz'],\n",
      "            [106420, 'Photic Off'],\n",
      "            [106880, 'Eyes Open'],\n",
      "            [107804, 'Eyes Closed'],\n",
      "            [108435, 'Photic On - 24.0 Hz'],\n",
      "            [110452, 'Photic Off'],\n",
      "            [111080, 'Eyes Open'],\n",
      "            [112004, 'Eyes Closed'],\n",
      "            [112509, 'Photic On - 27.0 Hz'],\n",
      "            [114528, 'Photic Off'],\n",
      "            [114864, 'Eyes Open'],\n",
      "            [116124, 'Eyes Closed'],\n",
      "            [116544, 'Photic On - 30.0 Hz'],\n",
      "            [118602, 'Photic Off'],\n",
      "            [126672, 'artifact'],\n",
      "            [134030, 'Move'],\n",
      "            [135584, 'Eyes Open'],\n",
      "            [136668, 'Eyes Closed'],\n",
      "            [139818, 'Eyes Open'],\n",
      "            [141414, 'Eyes Closed'],\n",
      "            [145000, 'Paused']],\n",
      " 'label': ['mci', 'mci_amnestic', 'mci_amnestic_rf'],\n",
      " 'record': '2018-10-26T15:46:26',\n",
      " 'serial': '00001'}\n"
     ]
    }
   ],
   "source": [
    "# Data file path\n",
    "data_path = r'dataset/02_Curated_Data/'\n",
    "meta_path = os.path.join(data_path, 'metadata_debug.json')\n",
    "\n",
    "with open(meta_path, 'r') as json_file:\n",
    "    metadata = json.load(json_file)\n",
    "\n",
    "pprint.pprint(metadata[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Data Filtering by Diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Vascular Dementia, Non-Vascular MCI, Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_label_to_type: ['Normal', 'Non-vascular MCI', 'Non-vascular dementia']\n"
     ]
    }
   ],
   "source": [
    "diagnosis_filter = [\n",
    "    # Normal\n",
    "    {'type': 'Normal',\n",
    "     'include': ['normal'], \n",
    "     'exclude': []},\n",
    "    # Non-vascular MCI\n",
    "    {'type': 'Non-vascular MCI',\n",
    "     'include': ['mci'], \n",
    "     'exclude': ['mci_vascular']},\n",
    "    # Non-vascular dementia\n",
    "    {'type': 'Non-vascular dementia',\n",
    "     'include': ['dementia'], \n",
    "     'exclude': ['vd']},\n",
    "]\n",
    "\n",
    "def generate_class_label(label):\n",
    "    for c, f in enumerate(diagnosis_filter):\n",
    "        inc = set(f['include']) & set(label) == set(f['include'])\n",
    "        # inc = len(set(f['include']) & set(label)) > 0        \n",
    "        exc = len(set(f['exclude']) & set(label)) == 0\n",
    "        if  inc and exc:\n",
    "            return (c, f['type'])\n",
    "    return (-1, 'The others')\n",
    "\n",
    "class_label_to_type = [d_f['type'] for d_f in diagnosis_filter]\n",
    "print('class_label_to_type:', class_label_to_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- There are 463 data belonging to Normal\n",
      "- There are 347 data belonging to Non-vascular MCI\n",
      "- There are 229 data belonging to Non-vascular dementia\n"
     ]
    }
   ],
   "source": [
    "splitted_metadata = [[] for i in diagnosis_filter]\n",
    "\n",
    "for m in metadata:\n",
    "    c, n = generate_class_label(m['label'])\n",
    "    if c >= 0:\n",
    "        m['class_type'] = n\n",
    "        m['class_label'] = c\n",
    "        splitted_metadata[c].append(m)\n",
    "        \n",
    "for i, split in enumerate(splitted_metadata):\n",
    "    if len(split) == 0:\n",
    "        print(f'(Warning) Split group {i} has no data.')\n",
    "    else:\n",
    "        print(f'- There are {len(split):} data belonging to {split[0][\"class_type\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Configure the Train, Validation, and Test Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the filtered dataset and shuffle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size\t\t: 831\n",
      "Validation data size\t: 104\n",
      "Test data size\t\t: 104\n",
      "\n",
      " --- Recheck --- \n",
      "\n",
      "Train data label distribution\t: [370 278 183] 831\n",
      "Val data label distribution\t: [46 35 23] 104\n",
      "Test data label distribution\t: [47 34 23] 104\n"
     ]
    }
   ],
   "source": [
    "# random seed\n",
    "random.seed(0)\n",
    "\n",
    "# Train : Val : Test = 8 : 1 : 1\n",
    "ratio1 = 0.8\n",
    "ratio2 = 0.1\n",
    "\n",
    "metadata_train = []\n",
    "metadata_val = []\n",
    "metadata_test = []\n",
    "\n",
    "for split in splitted_metadata:\n",
    "    random.shuffle(split)\n",
    "    \n",
    "    n1 = round(len(split) * ratio1)\n",
    "    n2 = n1 + round(len(split) * ratio2)\n",
    "\n",
    "    metadata_train.extend(split[:n1])\n",
    "    metadata_val.extend(split[n1:n2])\n",
    "    metadata_test.extend(split[n2:])\n",
    "\n",
    "random.shuffle(metadata_train)\n",
    "random.shuffle(metadata_val)\n",
    "random.shuffle(metadata_test)\n",
    "\n",
    "print('Train data size\\t\\t:', len(metadata_train))\n",
    "print('Validation data size\\t:', len(metadata_val))\n",
    "print('Test data size\\t\\t:', len(metadata_test))\n",
    "\n",
    "print('\\n', '--- Recheck ---', '\\n')\n",
    "train_class_nums = np.zeros((len(class_label_to_type)), dtype=np.int32)\n",
    "for m in metadata_train:\n",
    "    train_class_nums[m['class_label']] += 1\n",
    "\n",
    "val_class_nums = np.zeros((len(class_label_to_type)), dtype=np.int32)\n",
    "for m in metadata_val:\n",
    "    val_class_nums[m['class_label']] += 1\n",
    "\n",
    "test_class_nums = np.zeros((len(class_label_to_type)), dtype=np.int32)\n",
    "for m in metadata_test:\n",
    "    test_class_nums[m['class_label']] += 1\n",
    "\n",
    "print('Train data label distribution\\t:', train_class_nums, train_class_nums.sum())\n",
    "print('Val data label distribution\\t:', val_class_nums, val_class_nums.sum())\n",
    "print('Test data label distribution\\t:', test_class_nums, test_class_nums.sum())\n",
    "\n",
    "# random seed\n",
    "random.seed()\n",
    "\n",
    "# print([m['serial']  for m in metadata_train[:15]])\n",
    "# print([m['serial']  for m in metadata_val[:15]])\n",
    "# print([m['serial']  for m in metadata_test[:15]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrap the splitted data using PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age mean and standard deviation:\n",
      "69.92779783393502 9.817569889945597\n"
     ]
    }
   ],
   "source": [
    "ages = []\n",
    "for m in metadata_train:\n",
    "    ages.append(m['age'])\n",
    "\n",
    "ages = np.array(ages)\n",
    "age_mean = np.mean(ages)\n",
    "age_std = np.std(ages)\n",
    "\n",
    "print('Age mean and standard deviation:')\n",
    "print(age_mean, age_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2000])\n",
      "{'signal': tensor([[ 0.7583,  0.7835,  0.4607,  ..., -0.0212,  0.2512, -0.2997],\n",
      "        [ 0.1433, -0.7037, -0.4211,  ...,  0.0729,  0.3907,  0.3185],\n",
      "        [ 3.3368,  4.2569,  3.8936,  ...,  0.7546,  0.9782,  0.3295],\n",
      "        ...,\n",
      "        [ 0.4901,  0.2351,  0.4855,  ..., -0.1136,  0.6410,  0.6906],\n",
      "        [-1.3538, -1.1217, -0.9359,  ...,  0.7194,  0.6806,  0.0356],\n",
      "        [-0.0848, -0.5146, -0.3416,  ..., -0.0712, -0.2681, -1.0080]]), 'age': tensor(-1.2149), 'class_label': tensor(0), 'metadata': {'serial': '01012', 'edfname': '01212635_270515', 'birth': '1956-06-01', 'record': '2015-05-27T09:37:24', 'age': 58, 'dx1': 'cb_normal', 'label': ['normal', 'cb_normal'], 'events': [[0, 'Start Recording'], [0, 'New Montage - Montage 002'], [400, 'Eyes Open'], [7918, 'Eyes Closed'], [14091, 'Eyes Open'], [18208, 'Eyes Closed'], [24256, 'Eyes Open'], [30724, 'Eyes Closed'], [36562, 'Eyes Open'], [42190, 'Eyes Closed'], [48910, 'Eyes Open'], [55126, 'Eyes Closed'], [60417, 'Eyes Open'], [66004, 'Eyes Closed'], [71968, 'Eyes Open'], [78310, 'Eyes Closed'], [84442, 'Eyes Open'], [90070, 'Eyes Closed'], [96076, 'Eyes Open'], [102082, 'Eyes Closed'], [108844, 'Eyes Open'], [113674, 'Eyes Closed'], [120000, 'Paused']], 'class_type': 'Normal', 'class_label': 0}}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "torch.Size([20, 2000])\n",
      "{'signal': tensor([[ 0.4748,  0.4531,  0.4531,  ...,  0.9737,  0.9520,  0.9086],\n",
      "        [ 0.0457,  0.2407,  0.3870,  ...,  1.2647,  1.1185,  1.0697],\n",
      "        [ 0.4488,  0.3595,  0.4488,  ...,  0.0023,  0.0023,  0.0023],\n",
      "        ...,\n",
      "        [ 0.9243,  0.9243,  0.7398,  ...,  0.0017,  0.0017, -0.0905],\n",
      "        [-0.1749, -0.1749, -0.1749,  ..., -0.7116, -0.5327, -0.3538],\n",
      "        [ 0.4888,  0.4356,  0.4888,  ..., -0.0106, -0.1062, -0.0850]]), 'age': tensor(0.7204), 'class_label': tensor(1), 'metadata': {'serial': '00700', 'edfname': '00985401_011117', 'birth': '1940-09-09', 'record': '2017-11-01T14:20:48', 'age': 77, 'dx1': 'mci amnestic', 'label': ['mci', 'mci_amnestic'], 'events': [[0, 'Start Recording'], [0, 'New Montage - Montage 002'], [1705, 'Eyes Open'], [5402, 'Eyes Closed'], [13046, 'Eyes Open'], [17666, 'Eyes Closed'], [30308, 'Eyes Closed'], [36272, 'Eyes Open'], [41774, 'Eyes Closed'], [48958, 'Eyes Open'], [55510, 'Eyes Closed'], [61641, 'Eyes Open'], [66766, 'Eyes Closed'], [72730, 'Eyes Open'], [78988, 'Eyes Closed'], [87770, 'Eyes Open'], [90542, 'Eyes Closed'], [97096, 'Eyes Open'], [102178, 'Eyes Closed'], [110872, 'Eyes Open'], [113728, 'Eyes Closed'], [122052, 'Photic On - 3.0 Hz'], [122428, 'Eyes Open'], [123309, 'Eyes Closed'], [124068, 'Photic Off'], [126126, 'Photic On - 6.0 Hz'], [128142, 'Photic Off'], [130158, 'Photic On - 9.0 Hz'], [132216, 'Photic Off'], [132718, 'Eyes Open'], [133600, 'Eyes Closed'], [134232, 'Photic On - 12.0 Hz'], [136248, 'Photic Off'], [138306, 'Photic On - 15.0 Hz'], [140322, 'Photic Off'], [142380, 'Photic On - 18.0 Hz'], [142630, 'Eyes Open'], [143302, 'Eyes Closed'], [144396, 'Photic Off'], [146412, 'Photic On - 21.0 Hz'], [148428, 'Photic Off'], [150486, 'Photic On - 24.0 Hz'], [152502, 'Photic Off'], [152710, 'Eyes Open'], [153550, 'Eyes Closed'], [154560, 'Photic On - 27.0 Hz'], [156576, 'Photic Off'], [158592, 'Photic On - 30.0 Hz'], [160608, 'Photic Off'], [160942, 'Eyes Open'], [161698, 'Eyes Closed'], [169132, 'Eyes Open'], [170098, 'Eyes Closed'], [173600, 'Paused']], 'class_type': 'Non-vascular MCI', 'class_label': 1}}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "torch.Size([20, 2000])\n",
      "{'signal': tensor([[ 1.9246e-02, -2.4139e-02, -6.7523e-02,  ..., -5.0137e-01,\n",
      "         -4.7968e-01, -5.0137e-01],\n",
      "        [-2.9564e-01, -3.4440e-01, -4.4193e-01,  ..., -3.9317e-01,\n",
      "         -2.4688e-01, -1.9812e-01],\n",
      "        [-6.2293e-01, -5.3362e-01, -3.5499e-01,  ...,  9.1565e-02,\n",
      "          2.2528e-03,  2.2528e-03],\n",
      "        ...,\n",
      "        [-4.5952e-01, -3.6727e-01, -2.7502e-01,  ..., -3.6727e-01,\n",
      "         -3.6727e-01, -1.8276e-01],\n",
      "        [-1.0694e+00, -8.9051e-01, -7.1160e-01,  ...,  1.8292e-01,\n",
      "          9.3466e-02,  9.3466e-02],\n",
      "        [-1.9120e-01,  3.8794e-05,  3.0815e-01,  ...,  4.1440e-01,\n",
      "          3.9315e-01,  4.4627e-01]]), 'age': tensor(1.0259), 'class_label': tensor(0), 'metadata': {'serial': '00299', 'edfname': '00671212_160819', 'birth': '1938-08-17', 'record': '2019-08-16T10:57:03', 'age': 80, 'dx1': 'smi', 'label': ['normal', 'smi'], 'events': [[0, 'Start Recording'], [0, 'New Montage - Montage 005'], [1773, 'Eyes Closed'], [6000, 'Cz check'], [7612, 'Eyes Open'], [12912, 'Eyes Closed'], [18078, 'Eyes Open'], [23958, 'Eyes Closed'], [29288, 'Eyes Open'], [35934, 'Eyes Closed'], [41856, 'Eyes Open'], [47862, 'Eyes Closed'], [54460, 'Eyes Open'], [59962, 'Eyes Closed'], [66178, 'Eyes Open'], [71008, 'Eyes Closed'], [73948, 'Photic On - 3.0 Hz'], [74158, 'Eyes Open'], [75166, 'Eyes Closed'], [75964, 'Photic Off'], [77980, 'Photic On - 6.0 Hz'], [78358, 'Eyes Open'], [79282, 'Eyes Closed'], [80038, 'Photic Off'], [82054, 'Photic On - 9.0 Hz'], [84070, 'Photic Off'], [86128, 'Photic On - 12.0 Hz'], [87640, 'Eyes Open'], [88144, 'Photic Off'], [88396, 'Eyes Closed'], [90202, 'Photic On - 15.0 Hz'], [92218, 'Photic Off'], [92722, 'Eyes Open'], [93772, 'Eyes Closed'], [94234, 'Photic On - 18.0 Hz'], [96250, 'Photic Off'], [98308, 'Photic On - 21.0 Hz'], [100324, 'Photic Off'], [102382, 'Photic On - 24.0 Hz'], [104398, 'Photic Off'], [106414, 'Photic On - 27.0 Hz'], [108430, 'Photic Off'], [110488, 'Photic On - 30.0 Hz'], [111580, 'Eyes Open'], [111790, 'Photic Off'], [112420, 'Eyes Closed'], [113200, 'Paused']], 'class_type': 'Normal', 'class_label': 0}}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "torch.Size([20, 2000])\n",
      "{'signal': tensor([[-1.6077, -1.6511, -1.6945,  ...,  0.9520,  0.8653,  0.8219],\n",
      "        [-0.7833, -0.7345, -0.7833,  ..., -0.0518, -0.1494, -0.2956],\n",
      "        [ 0.8061,  1.0740,  1.2526,  ..., -0.5336, -0.4443, -0.4443],\n",
      "        ...,\n",
      "        [ 0.0940,  0.0940,  0.0017,  ..., -0.5518, -0.4595, -0.3673],\n",
      "        [ 0.7196,  0.6302,  0.7196,  ..., -0.4432, -0.4432, -0.3538],\n",
      "        [-0.1381, -0.1275, -0.1487,  ...,  0.5525,  0.5100,  0.4463]]), 'age': tensor(1.0259), 'class_label': tensor(0), 'metadata': {'serial': '00299', 'edfname': '00671212_160819', 'birth': '1938-08-17', 'record': '2019-08-16T10:57:03', 'age': 80, 'dx1': 'smi', 'label': ['normal', 'smi'], 'events': [[0, 'Start Recording'], [0, 'New Montage - Montage 005'], [1773, 'Eyes Closed'], [6000, 'Cz check'], [7612, 'Eyes Open'], [12912, 'Eyes Closed'], [18078, 'Eyes Open'], [23958, 'Eyes Closed'], [29288, 'Eyes Open'], [35934, 'Eyes Closed'], [41856, 'Eyes Open'], [47862, 'Eyes Closed'], [54460, 'Eyes Open'], [59962, 'Eyes Closed'], [66178, 'Eyes Open'], [71008, 'Eyes Closed'], [73948, 'Photic On - 3.0 Hz'], [74158, 'Eyes Open'], [75166, 'Eyes Closed'], [75964, 'Photic Off'], [77980, 'Photic On - 6.0 Hz'], [78358, 'Eyes Open'], [79282, 'Eyes Closed'], [80038, 'Photic Off'], [82054, 'Photic On - 9.0 Hz'], [84070, 'Photic Off'], [86128, 'Photic On - 12.0 Hz'], [87640, 'Eyes Open'], [88144, 'Photic Off'], [88396, 'Eyes Closed'], [90202, 'Photic On - 15.0 Hz'], [92218, 'Photic Off'], [92722, 'Eyes Open'], [93772, 'Eyes Closed'], [94234, 'Photic On - 18.0 Hz'], [96250, 'Photic Off'], [98308, 'Photic On - 21.0 Hz'], [100324, 'Photic Off'], [102382, 'Photic On - 24.0 Hz'], [104398, 'Photic Off'], [106414, 'Photic On - 27.0 Hz'], [108430, 'Photic Off'], [110488, 'Photic On - 30.0 Hz'], [111580, 'Eyes Open'], [111790, 'Photic Off'], [112420, 'Eyes Closed'], [113200, 'Paused']], 'class_type': 'Normal', 'class_label': 0}}\n"
     ]
    }
   ],
   "source": [
    "crop_length = 200 * 10 # 10 seconds\n",
    "awgn_mean = 0.0\n",
    "awgn_std = 3e-1\n",
    "\n",
    "# composed = transforms.Compose([EEGRandomCrop(crop_length=crop_length)])\n",
    "# train_dataset = EEGDataset(data_path, metadata_train, composed)\n",
    "\n",
    "# signal_means = []\n",
    "# signal_stds = []\n",
    "\n",
    "# for i in range(10):\n",
    "#     for d in train_dataset:\n",
    "#         signal_means.append(d['signal'].mean(axis=1, keepdims=True))\n",
    "#         signal_stds.append(d['signal'].std(axis=1, keepdims=True))\n",
    "        \n",
    "# signal_means = np.mean(np.array(signal_means), axis=0)\n",
    "# signal_stds = np.mean(np.array(signal_stds), axis=0)\n",
    "\n",
    "# print('Mean and standard deviation for signal:')\n",
    "# print(signal_means, '\\n\\n', signal_stds)\n",
    "\n",
    "signal_means = np.array([[ 0.1127599 ], [ 0.06298441], [-0.02522413], [ 0.00508518], \n",
    "                         [ 0.12026667], [-0.19987741], [-0.00516898], [ 0.00239212], \n",
    "                         [-0.02861219], [-0.02973673], [-0.02515898], [-0.00060568], \n",
    "                         [ 0.04921601], [-0.00562142], [-0.04888308], [-0.0438447 ], \n",
    "                         [ 0.07532331], [-0.01890181], [-0.044876  ], [-0.00365138], [-0.01564376]])\n",
    "signal_stds = np.array([[46.09896  ], [20.50783  ], [11.196733 ], [11.236944 ], [15.070532 ], \n",
    "                        [47.664406 ], [19.32747  ], [10.106162 ], [11.314243 ], [15.065008 ],\n",
    "                        [20.478817 ], [13.86243  ], [13.2378435], [21.554531 ], [16.875841 ],\n",
    "                        [13.989367 ], [19.789454 ], [10.839711 ], [11.179158 ], [94.12114  ], [65.64865  ]])\n",
    "\n",
    "composed_train = transforms.Compose([EEGNormalizeAge(mean=age_mean, std=age_std),\n",
    "                                     EEGRandomCrop(crop_length=crop_length),\n",
    "                                     EEGNormalizeMeanStd(mean=signal_means, std=signal_stds),\n",
    "                                     EEGDropPhoticChannel(),\n",
    "                                     EEGAddGaussianNoise(mean=awgn_mean, std=awgn_std),\n",
    "                                     EEGToTensor()])\n",
    "\n",
    "composed_test = transforms.Compose([EEGNormalizeAge(mean=age_mean, std=age_std),\n",
    "                                    EEGRandomCrop(crop_length=crop_length),\n",
    "                                    EEGNormalizeMeanStd(mean=signal_means, std=signal_stds),\n",
    "                                    EEGDropPhoticChannel(),\n",
    "                                    EEGToTensor()])\n",
    "\n",
    "longer_composed_test = transforms.Compose([EEGNormalizeAge(mean=age_mean, std=age_std),\n",
    "                                           EEGRandomCrop(crop_length=crop_length * 10),\n",
    "                                           EEGNormalizeMeanStd(mean=signal_means, std=signal_stds),\n",
    "                                           EEGDropPhoticChannel(),EEGToTensor()])\n",
    "\n",
    "train_dataset = EEGDataset(data_path, metadata_train, composed_train)\n",
    "val_dataset = EEGDataset(data_path, metadata_val, composed_test)\n",
    "test_dataset = EEGDataset(data_path, metadata_test, composed_test)\n",
    "longer_test_dataset = EEGDataset(data_path, metadata_test, composed_test)\n",
    "\n",
    "print(train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "\n",
    "print(val_dataset[0]['signal'].shape)\n",
    "print(val_dataset[0])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "\n",
    "print(test_dataset[0]['signal'].shape)\n",
    "print(test_dataset[0])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "\n",
    "print(longer_test_dataset[0]['signal'].shape)\n",
    "print(longer_test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loader test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current PyTorch device: cuda\n",
      "0 torch.Size([32, 20, 2000]) torch.Size([32]) torch.Size([32]) 32\n",
      "1 torch.Size([32, 20, 2000]) torch.Size([32]) torch.Size([32]) 32\n",
      "2 torch.Size([32, 20, 2000]) torch.Size([32]) torch.Size([32]) 32\n",
      "3 torch.Size([32, 20, 2000]) torch.Size([32]) torch.Size([32]) 32\n",
      "4 torch.Size([32, 20, 2000]) torch.Size([32]) torch.Size([32]) 32\n"
     ]
    }
   ],
   "source": [
    "print('Current PyTorch device:', device)\n",
    "if device.type == 'cuda':\n",
    "    num_workers = 0 # A number other than 0 causes an error\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=32, \n",
    "                          shuffle=True, \n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers, \n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    sample_batched['signal'].to(device)\n",
    "    sample_batched['age'].to(device)\n",
    "    sample_batched['class_label'].to(device)\n",
    "    \n",
    "    print(i_batch, \n",
    "          sample_batched['signal'].shape, \n",
    "          sample_batched['age'].shape, \n",
    "          sample_batched['class_label'].shape, \n",
    "          len(sample_batched['metadata']))\n",
    "    \n",
    "    if i_batch > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train, validation, test dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=32, \n",
    "                          shuffle=True, \n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers, \n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                        batch_size=32, \n",
    "                        shuffle=False, \n",
    "                        drop_last=False,\n",
    "                        num_workers=num_workers, \n",
    "                        pin_memory=pin_memory,\n",
    "                        collate_fn=eeg_collate_fn)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         batch_size=32, \n",
    "                         shuffle=False, \n",
    "                         drop_last=False,\n",
    "                         num_workers=num_workers, \n",
    "                         pin_memory=pin_memory,\n",
    "                         collate_fn=eeg_collate_fn)\n",
    "\n",
    "longer_test_loader = DataLoader(test_dataset, \n",
    "                         batch_size=16, \n",
    "                         shuffle=False, \n",
    "                         drop_last=False,\n",
    "                         num_workers=num_workers, \n",
    "                         pin_memory=pin_memory,\n",
    "                         collate_fn=eeg_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Define 1D CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def print_final_shape(model):\n",
    "    x = torch.zeros_like(sample_batched['signal']).to(device)\n",
    "    model(x, age=sample_batched['age'].to(device), print_shape=True)\n",
    "\n",
    "\n",
    "def visualize_network_tensorboard(model, name):\n",
    "    # default `log_dir` is \"runs\" - we'll be more specific here\n",
    "    writer = SummaryWriter('runs/' + nb_fname + '_' + name)\n",
    "\n",
    "    for batch_i, sample_batched in enumerate(train_loader):\n",
    "        # pull up the batch data\n",
    "        x = sample_batched['signal'].to(device)\n",
    "        age = sample_batched['age'].to(device)\n",
    "        target = sample_batched['class_label'].to(device)\n",
    "\n",
    "        # apply model on whole batch directly on device\n",
    "        writer.add_graph(model, (x, age))\n",
    "        output = model(x, age, print_shape=True)\n",
    "        break\n",
    "        \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D Tiny CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyCNN(nn.Module):\n",
    "    def __init__(self, n_input=20, n_output=3, stride=7, n_channel=64, \n",
    "                 use_age=True, final_pool='max'):\n",
    "        super().__init__()\n",
    "        \n",
    "        if final_pool not in {'average', 'max'}:\n",
    "            raise ValueError(\"final_pool must be set to one of ['average', 'max']\")\n",
    "        \n",
    "        self.use_age = use_age\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=35, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=7)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        \n",
    "        if final_pool == 'average':\n",
    "            self.final_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        elif final_pool == 'max':\n",
    "            self.final_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        if self.use_age:        \n",
    "            self.fc1 = nn.Linear(n_channel + 1, n_channel)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(n_channel, n_channel)\n",
    "            \n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.bnfc1 = nn.BatchNorm1d(n_channel)\n",
    "        self.fc2 = nn.Linear(n_channel, n_output)\n",
    "        \n",
    "    def reset_weights(self):\n",
    "        for m in self.modules():\n",
    "            if hasattr(m, 'reset_parameters'):\n",
    "                m.reset_parameters()\n",
    "\n",
    "    def forward(self, x, age, print_shape=False):\n",
    "        N = x.shape[0]\n",
    "        \n",
    "        # conv-bn-relu-pool \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        if print_shape:\n",
    "            print('Shape right before squeezing:', x.shape)\n",
    "\n",
    "        x = self.final_pool(x).squeeze()\n",
    "        if N == 1: x = x.reshape((1, -1))\n",
    "        if self.use_age:\n",
    "            x = torch.cat((x, age.reshape(-1, 1)), dim=1)\n",
    "\n",
    "        # fc-bn-dropout-relu-fc\n",
    "        x = self.fc1(x)\n",
    "        x = self.bnfc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "        # return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_TinyCNN():\n",
    "    return TinyCNN(n_input=train_dataset[0]['signal'].shape[0], \n",
    "                   n_output=3, use_age=True, final_pool='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyCNN(\n",
      "  (conv1): Conv1d(20, 64, kernel_size=(35,), stride=(7,))\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (final_pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc1): Linear(in_features=65, out_features=64, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (bnfc1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "\n",
      "The Number of parameters of the model: 78,403\n",
      "\n",
      "Shape right before squeezing: torch.Size([32, 64, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IPIS-Minjae\\anaconda3\\envs\\EEG_Project\\lib\\site-packages\\torch\\nn\\functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "model = generate_TinyCNN()\n",
    "model = model.to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print()\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-CNN')\n",
    "\n",
    "# number of parameters\n",
    "n = count_parameters(model)\n",
    "print(f'The Number of parameters of the model: {n:,}')\n",
    "print()\n",
    "\n",
    "# calculate the last shape right before squeezing\n",
    "print_final_shape(model)\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M5-like model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class M5(nn.Module):\n",
    "    def __init__(self, in_channels=20, base_channels=256, \n",
    "                 out_dims=3, use_age=True, final_pool='max'):\n",
    "        super().__init__()\n",
    "        \n",
    "        if final_pool not in {'average', 'max'}:\n",
    "            raise ValueError(\"final_pool must be set to one of ['average', 'max']\")\n",
    "        \n",
    "        self.use_age = use_age\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels, base_channels, kernel_size=41, stride=2)\n",
    "        self.bn1 = nn.BatchNorm1d(base_channels)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(base_channels, base_channels, kernel_size=11)\n",
    "        self.bn2 = nn.BatchNorm1d(base_channels)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(base_channels, 2 * base_channels, kernel_size=11)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * base_channels)\n",
    "        self.pool3 = nn.MaxPool1d(3)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(2 * base_channels, 2 * base_channels, kernel_size=11)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * base_channels)\n",
    "        self.pool4 = nn.MaxPool1d(3)\n",
    "        \n",
    "        self.conv5 = nn.Conv1d(2 * base_channels, 2 * base_channels, kernel_size=11)\n",
    "        self.bn5 = nn.BatchNorm1d(2 * base_channels)\n",
    "        self.pool5 = nn.MaxPool1d(2)\n",
    "        \n",
    "        if final_pool == 'average':\n",
    "            self.final_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        elif final_pool == 'max':\n",
    "            self.final_pool = nn.AdaptiveMaxPool1d(1)\n",
    "    \n",
    "        if self.use_age:        \n",
    "            self.fc1 = nn.Linear(2 * base_channels + 1, 2 * base_channels)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(2 * base_channels, 2 * base_channels)\n",
    "            \n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.bnfc1 = nn.BatchNorm1d(2 * base_channels)\n",
    "        self.fc2 = nn.Linear(2 * base_channels, out_dims)\n",
    "        \n",
    "    def reset_weights(self):\n",
    "        for m in self.modules():\n",
    "            if hasattr(m, 'reset_parameters'):\n",
    "                m.reset_parameters()\n",
    "\n",
    "    def forward(self, x, age, print_shape=False):\n",
    "        N = x.shape[0]\n",
    "        \n",
    "        # conv-bn-relu-pool \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(self.bn5(x))\n",
    "        x = self.pool5(x)\n",
    "\n",
    "        if N == 1: x = x.reshape((1, -1))\n",
    "        if print_shape:\n",
    "            print('Shape right before squeezing:', x.shape)\n",
    "    \n",
    "        x = self.final_pool(x).squeeze()\n",
    "        if self.use_age:\n",
    "            x = torch.cat((x, age.reshape(-1, 1)), dim=1)\n",
    "\n",
    "        # fc-bn-dropout-relu-fc\n",
    "        x = self.fc1(x)\n",
    "        x = self.bnfc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "        # return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_M5():\n",
    "    return M5(in_channels=train_dataset[0]['signal'].shape[0], \n",
    "              out_dims=3, use_age=True, final_pool='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M5(\n",
      "  (conv1): Conv1d(20, 256, kernel_size=(41,), stride=(2,))\n",
      "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(256, 256, kernel_size=(11,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(256, 512, kernel_size=(11,), stride=(1,))\n",
      "  (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv1d(512, 512, kernel_size=(11,), stride=(1,))\n",
      "  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool4): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv5): Conv1d(512, 512, kernel_size=(11,), stride=(1,))\n",
      "  (bn5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (final_pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc1): Linear(in_features=513, out_features=512, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (bnfc1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=512, out_features=3, bias=True)\n",
      ")\n",
      "\n",
      "The Number of parameters of the model: 8,411,651\n",
      "\n",
      "Shape right before squeezing: torch.Size([32, 512, 6])\n"
     ]
    }
   ],
   "source": [
    "model = generate_M5()\n",
    "model = model.to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print()\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, 'M5')\n",
    "\n",
    "# number of parameters\n",
    "n = count_parameters(model)\n",
    "print(f'The Number of parameters of the model: {n:,}')\n",
    "print()\n",
    "\n",
    "# calculate the last shape right before squeezing\n",
    "print_final_shape(model)\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M5-like model without the usage of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_M5_no_age():\n",
    "    return M5(in_channels=train_dataset[0]['signal'].shape[0], \n",
    "              out_dims=3, use_age=False, final_pool='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M5(\n",
      "  (conv1): Conv1d(20, 256, kernel_size=(41,), stride=(2,))\n",
      "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(256, 256, kernel_size=(11,), stride=(1,))\n",
      "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv1d(256, 512, kernel_size=(11,), stride=(1,))\n",
      "  (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv1d(512, 512, kernel_size=(11,), stride=(1,))\n",
      "  (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool4): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv5): Conv1d(512, 512, kernel_size=(11,), stride=(1,))\n",
      "  (bn5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (final_pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (bnfc1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=512, out_features=3, bias=True)\n",
      ")\n",
      "\n",
      "The Number of parameters of the model: 8,411,139\n",
      "\n",
      "Shape right before squeezing: torch.Size([32, 512, 6])\n"
     ]
    }
   ],
   "source": [
    "model = generate_M5_no_age()\n",
    "model = model.to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print()\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, 'M5-no-age')\n",
    "\n",
    "# number of parameters\n",
    "n = count_parameters(model)\n",
    "print(f'The Number of parameters of the model: {n:,}')\n",
    "print()\n",
    "\n",
    "# calculate the last shape right before squeezing\n",
    "print_final_shape(model)\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicResBlock(nn.Module):\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(self, c_in, c_out, kernel_size, stride, groups=1) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=c_in, out_channels=c_out, \n",
    "                               kernel_size=kernel_size, stride=stride, \n",
    "                               padding=kernel_size//2, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(c_out)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=c_out, out_channels=c_out, groups=groups,\n",
    "                               kernel_size=kernel_size, stride=1, \n",
    "                               padding=kernel_size//2, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(c_out)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.downsample = None\n",
    "        if stride != 1 or c_in != c_out:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=c_in, out_channels=c_out, \n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(c_out)\n",
    "            )\n",
    "                    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "        x = self.relu(x + identity)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleneckBlock(nn.Module):\n",
    "    expansion: int = 4\n",
    "        \n",
    "    def __init__(self, c_in, c_out, kernel_size, stride, groups=1) -> None:\n",
    "        super().__init__()\n",
    "        width = c_out        \n",
    "        self.conv1 = nn.Conv1d(in_channels=c_in, out_channels=width,\n",
    "                               kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(width)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=width, out_channels=width, groups=groups,\n",
    "                               kernel_size=kernel_size, stride=stride, \n",
    "                               padding=kernel_size//2, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(width)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=width, out_channels=c_out*self.expansion, \n",
    "                               kernel_size=1, stride=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm1d(c_out*self.expansion)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.downsample = None\n",
    "        if stride != 1 or c_in != c_out*self.expansion:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=c_in, out_channels=c_out*self.expansion, \n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(c_out*self.expansion)\n",
    "            )\n",
    "                    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "            \n",
    "        x = self.relu(x + identity)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, \n",
    "                 block: Type[Union[BasicResBlock, BottleneckBlock]], \n",
    "                 conv_layers: List[int],\n",
    "                 fc_stages: int,\n",
    "                 in_channels=20,\n",
    "                 out_dims=3,\n",
    "                 starting_channels=64,\n",
    "                 groups=1,\n",
    "                 kernel_size=9, \n",
    "                 use_age=True, \n",
    "                 final_pool='max') -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        if final_pool not in {'average', 'max'}:\n",
    "            raise ValueError(\"final_pool must be set to one of ['average', 'max']\")        \n",
    "\n",
    "        self.current_channels = starting_channels\n",
    "        self.use_age = use_age\n",
    "        self.groups = groups\n",
    "        \n",
    "        self.input_stage = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=in_channels, out_channels=starting_channels, \n",
    "                      kernel_size=kernel_size*3, stride=2,\n",
    "                      padding=(kernel_size*3)//2, bias=False),\n",
    "            nn.BatchNorm1d(starting_channels), \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.conv_stage1 = self._make_conv_layer(block, conv_layers[0], starting_channels, kernel_size, stride=3)\n",
    "        self.conv_stage2 = self._make_conv_layer(block, conv_layers[1], starting_channels*2, kernel_size, stride=3)\n",
    "        self.conv_stage3 = self._make_conv_layer(block, conv_layers[2], starting_channels*4, kernel_size, stride=3)\n",
    "        self.conv_stage4 = self._make_conv_layer(block, conv_layers[3], starting_channels*8, kernel_size, stride=3)\n",
    "        \n",
    "        if final_pool == 'average':\n",
    "            self.final_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        elif final_pool == 'max':\n",
    "            self.final_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        fc_stage = []        \n",
    "        if self.use_age:\n",
    "            self.current_channels = self.current_channels + 1\n",
    "        \n",
    "        for l in range(fc_stages):\n",
    "            layer = nn.Sequential(nn.Linear(self.current_channels, self.current_channels // 2, bias=False),\n",
    "                                  nn.Dropout(p=0.1),\n",
    "                                  nn.BatchNorm1d(self.current_channels // 2), \n",
    "                                  nn.ReLU())\n",
    "            self.current_channels = self.current_channels // 2\n",
    "            fc_stage.append(layer)\n",
    "        fc_stage.append(nn.Linear(self.current_channels, out_dims))\n",
    "        self.fc_stage = nn.Sequential(*fc_stage)\n",
    "        \n",
    "    def reset_weights(self):\n",
    "        for m in self.modules():\n",
    "            if hasattr(m, 'reset_parameters'):\n",
    "                m.reset_parameters()\n",
    "        \n",
    "    def _make_conv_layer(self, block: Type[Union[BasicResBlock, BottleneckBlock]], \n",
    "                         n_block: int, c_out: int, kernel_size: int, stride: int = 1) -> nn.Sequential:\n",
    "        layers = []\n",
    "        c_in = self.current_channels\n",
    "        layers.append(block(c_in, c_out, kernel_size, groups=self.groups, stride=1))\n",
    "\n",
    "        c_in = c_out * block.expansion\n",
    "        self.current_channels = c_in\n",
    "        for _ in range(1, n_block):\n",
    "            layers.append(block(c_in, c_out, kernel_size, groups=self.groups, stride=1))\n",
    "            \n",
    "        layers.append(nn.MaxPool1d(kernel_size=stride))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, age, print_shape=False):\n",
    "        N = x.shape[0]\n",
    "        \n",
    "        x = self.input_stage(x)\n",
    "        \n",
    "        x = self.conv_stage1(x)\n",
    "        x = self.conv_stage2(x)\n",
    "        x = self.conv_stage3(x)\n",
    "        x = self.conv_stage4(x)\n",
    "\n",
    "        if print_shape:\n",
    "            print('Shape right before squeezing:', x.shape)\n",
    "                \n",
    "        x = self.final_pool(x).squeeze()\n",
    "        if N == 1: x = x.reshape((1, -1))\n",
    "        if self.use_age:\n",
    "            x = torch.cat((x, age.reshape(-1, 1)), dim=1)\n",
    "        x = self.fc_stage(x)\n",
    "        \n",
    "        return x\n",
    "        # return F.log_softmax(x, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ResNet():\n",
    "    return ResNet(block=BottleneckBlock, \n",
    "                  conv_layers=[2, 2, 2, 2], \n",
    "                  fc_stages=3, \n",
    "                  in_channels=train_dataset[0]['signal'].shape[0], \n",
    "                  out_dims=3, \n",
    "                  starting_channels=64,\n",
    "                  kernel_size=9, \n",
    "                  use_age=True, \n",
    "                  final_pool='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (input_stage): Sequential(\n",
      "    (0): Conv1d(20, 64, kernel_size=(27,), stride=(2,), padding=(13,), bias=False)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (conv_stage1): Sequential(\n",
      "    (0): BottleneckBlock(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock(\n",
      "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage2): Sequential(\n",
      "    (0): BottleneckBlock(\n",
      "      (conv1): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage3): Sequential(\n",
      "    (0): BottleneckBlock(\n",
      "      (conv1): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage4): Sequential(\n",
      "    (0): BottleneckBlock(\n",
      "      (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock(\n",
      "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (final_pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc_stage): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=2049, out_features=1024, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=256, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (3): Linear(in_features=256, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "The Number of parameters of the model: 16,729,219\n",
      "\n",
      "Shape right before squeezing: torch.Size([32, 2048, 12])\n"
     ]
    }
   ],
   "source": [
    "model = generate_ResNet()\n",
    "model = model.to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print()\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-ResNet')\n",
    "\n",
    "# number of parameters\n",
    "n = count_parameters(model)\n",
    "print(f'The Number of parameters of the model: {n:,}')\n",
    "print()\n",
    "\n",
    "# calculate the last shape right before squeezing\n",
    "print_final_shape(model)\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D CNN: ResNet-like model without the usage of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ResNet_no_age():\n",
    "    return ResNet(block=BottleneckBlock, \n",
    "                  conv_layers=[2, 2, 2, 2], \n",
    "                  fc_stages=3, \n",
    "                  in_channels=train_dataset[0]['signal'].shape[0], \n",
    "                  out_dims=3, \n",
    "                  starting_channels=64,\n",
    "                  kernel_size=9, \n",
    "                  use_age=False, \n",
    "                  final_pool='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (input_stage): Sequential(\n",
      "    (0): Conv1d(20, 64, kernel_size=(27,), stride=(2,), padding=(13,), bias=False)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (conv_stage1): Sequential(\n",
      "    (0): BottleneckBlock(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock(\n",
      "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage2): Sequential(\n",
      "    (0): BottleneckBlock(\n",
      "      (conv1): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage3): Sequential(\n",
      "    (0): BottleneckBlock(\n",
      "      (conv1): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage4): Sequential(\n",
      "    (0): BottleneckBlock(\n",
      "      (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock(\n",
      "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (final_pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc_stage): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=256, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (3): Linear(in_features=256, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "The Number of parameters of the model: 16,728,195\n",
      "\n",
      "Shape right before squeezing: torch.Size([32, 2048, 12])\n"
     ]
    }
   ],
   "source": [
    "model = generate_ResNet_no_age()\n",
    "model = model.to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print()\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-ResNet-no-age')\n",
    "\n",
    "# number of parameters\n",
    "n = count_parameters(model)\n",
    "print(f'The Number of parameters of the model: {n:,}')\n",
    "print()\n",
    "\n",
    "# calculate the last shape right before squeezing\n",
    "print_final_shape(model)\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D-ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ResNet50():\n",
    "    return ResNet(block=BottleneckBlock, \n",
    "                  conv_layers=[3, 4, 6, 3], \n",
    "                  fc_stages=3, \n",
    "                  in_channels=train_dataset[0]['signal'].shape[0], \n",
    "                  out_dims=3, \n",
    "                  starting_channels=64,\n",
    "                  kernel_size=9, \n",
    "                  use_age=True, \n",
    "                  final_pool='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (input_stage): Sequential(\n",
      "    (0): Conv1d(20, 64, kernel_size=(27,), stride=(2,), padding=(13,), bias=False)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (conv_stage1): Sequential(\n",
      "    (0): BottleneckBlock(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock(\n",
      "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): BottleneckBlock(\n",
      "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage2): Sequential(\n",
      "    (0): BottleneckBlock(\n",
      "      (conv1): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): BottleneckBlock(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): BottleneckBlock(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage3): Sequential(\n",
      "    (0): BottleneckBlock(\n",
      "      (conv1): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): BottleneckBlock(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): BottleneckBlock(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): BottleneckBlock(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): BottleneckBlock(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage4): Sequential(\n",
      "    (0): BottleneckBlock(\n",
      "      (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock(\n",
      "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): BottleneckBlock(\n",
      "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (final_pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc_stage): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=2049, out_features=1024, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=256, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (3): Linear(in_features=256, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "The Number of parameters of the model: 26,291,075\n",
      "\n",
      "Shape right before squeezing: torch.Size([32, 2048, 12])\n"
     ]
    }
   ],
   "source": [
    "model = generate_ResNet50()\n",
    "model = model.to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print()\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-ResNet')\n",
    "\n",
    "# number of parameters\n",
    "n = count_parameters(model)\n",
    "print(f'The Number of parameters of the model: {n:,}')\n",
    "print()\n",
    "\n",
    "# calculate the last shape right before squeezing\n",
    "print_final_shape(model)\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D Tiny ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_TinyResNet():\n",
    "    return ResNet(block=BasicResBlock, \n",
    "                  conv_layers=[1, 1, 1, 1], \n",
    "                  fc_stages=3, \n",
    "                  in_channels=train_dataset[0]['signal'].shape[0], \n",
    "                  out_dims=3, \n",
    "                  starting_channels=64,\n",
    "                  kernel_size=9, \n",
    "                  use_age=True, \n",
    "                  final_pool='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (input_stage): Sequential(\n",
      "    (0): Conv1d(20, 64, kernel_size=(27,), stride=(2,), padding=(13,), bias=False)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (conv_stage1): Sequential(\n",
      "    (0): BasicResBlock(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage2): Sequential(\n",
      "    (0): BasicResBlock(\n",
      "      (conv1): Conv1d(64, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage3): Sequential(\n",
      "    (0): BasicResBlock(\n",
      "      (conv1): Conv1d(128, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage4): Sequential(\n",
      "    (0): BasicResBlock(\n",
      "      (conv1): Conv1d(256, 512, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (final_pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc_stage): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=513, out_features=256, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=64, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (3): Linear(in_features=64, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "The Number of parameters of the model: 5,104,323\n",
      "\n",
      "Shape right before squeezing: torch.Size([32, 512, 12])\n"
     ]
    }
   ],
   "source": [
    "model = generate_TinyResNet()\n",
    "model = model.to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print()\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Tiny-ResNet')\n",
    "\n",
    "# number of parameters\n",
    "n = count_parameters(model)\n",
    "print(f'The Number of parameters of the model: {n:,}')\n",
    "print()\n",
    "\n",
    "# calculate the last shape right before squeezing\n",
    "print_final_shape(model)\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D Multi-Dilated ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBottleneckBlock(nn.Module):\n",
    "    expansion: int = 4\n",
    "        \n",
    "    def __init__(self, c_in, c_out, kernel_size, stride, groups=1) -> None:\n",
    "        super().__init__()\n",
    "        width = c_out\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=c_in, out_channels=width, kernel_size=1, \n",
    "                                 dilation=1, stride=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(width)\n",
    "\n",
    "        self.conv2_1 = nn.Conv1d(in_channels=width, out_channels=width, groups=groups,\n",
    "                                 kernel_size=kernel_size, dilation=1, \n",
    "                                 stride=stride, padding=kernel_size//2, bias=False)\n",
    "        self.conv2_2 = nn.Conv1d(in_channels=width, out_channels=width, groups=groups,\n",
    "                                 kernel_size=kernel_size, dilation=2, \n",
    "                                 stride=stride, padding=(kernel_size//2)*2, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(width*2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(in_channels=width*2, out_channels=c_out*self.expansion, kernel_size=1, \n",
    "                                 dilation=1, stride=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm1d(c_out*self.expansion)\n",
    "                \n",
    "        self.downsample = None\n",
    "        if stride != 1 or c_in != c_out*self.expansion:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv1d(in_channels=c_in, out_channels=c_out*self.expansion, \n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(c_out*self.expansion)\n",
    "            )\n",
    "                    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        identity = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x1 = self.conv2_1(x)\n",
    "        x2 = self.conv2_2(x)\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "            \n",
    "        x = F.relu(x + identity)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Multi_Dilated_ResNet():\n",
    "    return ResNet(block=MultiBottleneckBlock, \n",
    "                  conv_layers=[3, 4, 6, 3], \n",
    "                  fc_stages=3, \n",
    "                  in_channels=train_dataset[0]['signal'].shape[0], \n",
    "                  out_dims=3, \n",
    "                  starting_channels=32,\n",
    "                  kernel_size=9, \n",
    "                  use_age=True, \n",
    "                  final_pool='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (input_stage): Sequential(\n",
      "    (0): Conv1d(20, 32, kernel_size=(27,), stride=(2,), padding=(13,), bias=False)\n",
      "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (conv_stage1): Sequential(\n",
      "    (0): MultiBottleneckBlock(\n",
      "      (conv1): Conv1d(32, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (conv2_2): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(32, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): MultiBottleneckBlock(\n",
      "      (conv1): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (conv2_2): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): MultiBottleneckBlock(\n",
      "      (conv1): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_1): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (conv2_2): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,), bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage2): Sequential(\n",
      "    (0): MultiBottleneckBlock(\n",
      "      (conv1): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_1): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (conv2_2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): MultiBottleneckBlock(\n",
      "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_1): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (conv2_2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): MultiBottleneckBlock(\n",
      "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_1): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (conv2_2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): MultiBottleneckBlock(\n",
      "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_1): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (conv2_2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,), bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage3): Sequential(\n",
      "    (0): MultiBottleneckBlock(\n",
      "      (conv1): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_1): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (conv2_2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): MultiBottleneckBlock(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_1): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (conv2_2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): MultiBottleneckBlock(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_1): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (conv2_2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): MultiBottleneckBlock(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_1): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (conv2_2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): MultiBottleneckBlock(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_1): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (conv2_2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): MultiBottleneckBlock(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_1): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (conv2_2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,), bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage4): Sequential(\n",
      "    (0): MultiBottleneckBlock(\n",
      "      (conv1): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_1): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (conv2_2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,), bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): MultiBottleneckBlock(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_1): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (conv2_2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,), bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): MultiBottleneckBlock(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2_1): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
      "      (conv2_2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(8,), dilation=(2,), bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (final_pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc_stage): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=1025, out_features=512, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=256, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (3): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "The Number of parameters of the model: 10,686,595\n",
      "\n",
      "Shape right before squeezing: torch.Size([32, 1024, 12])\n"
     ]
    }
   ],
   "source": [
    "model = generate_Multi_Dilated_ResNet()\n",
    "model = model.to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print()\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-Multi-Dilated-ResNet')\n",
    "\n",
    "# number of parameters\n",
    "n = count_parameters(model)\n",
    "print(f'The Number of parameters of the model: {n:,}')\n",
    "print()\n",
    "\n",
    "# calculate the last shape right before squeezing\n",
    "print_final_shape(model)\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNeXt-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ResNeXt_50():\n",
    "    return ResNet(block=BottleneckBlock, \n",
    "                  conv_layers=[3, 4, 7, 2], \n",
    "                  fc_stages=3, \n",
    "                  in_channels=train_dataset[0]['signal'].shape[0], \n",
    "                  out_dims=3, \n",
    "                  starting_channels=64,\n",
    "                  groups=32,\n",
    "                  kernel_size=9, \n",
    "                  use_age=True, \n",
    "                  final_pool='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (input_stage): Sequential(\n",
      "    (0): Conv1d(20, 64, kernel_size=(27,), stride=(2,), padding=(13,), bias=False)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (conv_stage1): Sequential(\n",
      "    (0): BottleneckBlock(\n",
      "      (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), groups=32, bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock(\n",
      "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), groups=32, bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): BottleneckBlock(\n",
      "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(64, 64, kernel_size=(9,), stride=(1,), padding=(4,), groups=32, bias=False)\n",
      "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage2): Sequential(\n",
      "    (0): BottleneckBlock(\n",
      "      (conv1): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), groups=32, bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), groups=32, bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): BottleneckBlock(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), groups=32, bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): BottleneckBlock(\n",
      "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(9,), stride=(1,), padding=(4,), groups=32, bias=False)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage3): Sequential(\n",
      "    (0): BottleneckBlock(\n",
      "      (conv1): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), groups=32, bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), groups=32, bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): BottleneckBlock(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), groups=32, bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): BottleneckBlock(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), groups=32, bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): BottleneckBlock(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), groups=32, bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): BottleneckBlock(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), groups=32, bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): BottleneckBlock(\n",
      "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(9,), stride=(1,), padding=(4,), groups=32, bias=False)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_stage4): Sequential(\n",
      "    (0): BottleneckBlock(\n",
      "      (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,), groups=32, bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BottleneckBlock(\n",
      "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv1d(512, 512, kernel_size=(9,), stride=(1,), padding=(4,), groups=32, bias=False)\n",
      "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (final_pool): AdaptiveMaxPool1d(output_size=1)\n",
      "  (fc_stage): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=2049, out_features=1024, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=1024, out_features=512, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=256, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (3): Linear(in_features=256, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "The Number of parameters of the model: 13,696,259\n",
      "\n",
      "Shape right before squeezing: torch.Size([32, 2048, 12])\n"
     ]
    }
   ],
   "source": [
    "model = generate_ResNeXt_50()\n",
    "model = model.to(device, dtype=torch.float32)\n",
    "print(model)\n",
    "print()\n",
    "\n",
    "# tensorboard visualization\n",
    "# visualize_network_tensorboard(model, '1D-ResNet')\n",
    "\n",
    "# number of parameters\n",
    "n = count_parameters(model)\n",
    "print(f'The Number of parameters of the model: {n:,}')\n",
    "print()\n",
    "\n",
    "# calculate the last shape right before squeezing\n",
    "print_final_shape(model)\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Some useful functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multistep(model, loader, optimizer, scheduler, config, steps):\n",
    "    model.train()\n",
    "        \n",
    "    i = 0\n",
    "    cumu_loss = 0\n",
    "    correct, total = (0, 0)\n",
    "    \n",
    "    while True:\n",
    "        for sample_batched in loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # load the mini-batched data\n",
    "            x = sample_batched['signal'].to(device)\n",
    "            age = sample_batched['age'].to(device)\n",
    "            y = sample_batched['class_label'].to(device)\n",
    "            \n",
    "            # forward pass\n",
    "            output = model(x, age)\n",
    "            \n",
    "            # loss function\n",
    "            if config['criterion'] == 'cross-entropy':\n",
    "                s = F.log_softmax(output, dim=1)\n",
    "                loss = F.nll_loss(s, y)\n",
    "            elif config['criterion'] == 'multi-bce':\n",
    "                y_oh = F.one_hot(y, num_classes=len(class_label_to_type))\n",
    "                s = torch.sigmoid(output)\n",
    "                loss = F.binary_cross_entropy_with_logits(output, y_oh)\n",
    "\n",
    "            # backward and update\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # train accuracy\n",
    "            pred = s.argmax(dim=-1)\n",
    "            correct += pred.squeeze().eq(y).sum().item()\n",
    "            total += pred.shape[0]\n",
    "            cumu_loss += loss.item()\n",
    "            \n",
    "            i += 1\n",
    "            if steps <= i: break\n",
    "        if steps <= i: break\n",
    "            \n",
    "    train_acc = 100.0 * correct / total\n",
    "    avg_loss = cumu_loss / steps\n",
    "    \n",
    "    return (avg_loss, train_acc)\n",
    "\n",
    "\n",
    "def train_mixup_multistep(model, loader, optimizer, scheduler, config, steps):\n",
    "    model.train()\n",
    "        \n",
    "    i = 0\n",
    "    cumu_loss = 0\n",
    "    correct, total = (0, 0)\n",
    "    \n",
    "    while True:\n",
    "        for sample_batched in loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # load and mixup the mini-batched data\n",
    "            x1 = sample_batched['signal'].to(device)\n",
    "            age1 = sample_batched['age'].to(device)\n",
    "            y1 = sample_batched['class_label'].to(device)\n",
    "\n",
    "            index = torch.randperm(x1.shape[0]).cuda()                \n",
    "            x2 = x1[index]\n",
    "            age2 = age1[index]\n",
    "            y2 = y1[index]\n",
    "            \n",
    "            mixup_alpha = config['mixup']\n",
    "            lam = np.random.beta(mixup_alpha, mixup_alpha)\n",
    "            x = lam * x1 + (1.0 - lam) * x2\n",
    "            age = lam * age1 + (1.0 - lam) * age2\n",
    "\n",
    "            # forward pass\n",
    "            output = model(x, age)\n",
    "            \n",
    "            # loss function\n",
    "            if config['criterion'] == 'cross-entropy':\n",
    "                s = F.log_softmax(output, dim=1)\n",
    "                loss1 = F.nll_loss(s, y1)\n",
    "                loss2 = F.nll_loss(s, y2)\n",
    "                loss = lam * loss1 + (1 - lam) * loss2\n",
    "            elif config['criterion'] == 'multi-bce':\n",
    "                y1_oh = F.one_hot(y1, num_classes=len(class_label_to_type))\n",
    "                y2_oh = F.one_hot(y2, num_classes=len(class_label_to_type))\n",
    "                y_oh = lam * y1_oh + (1.0 - lam) * y2_oh\n",
    "                s = torch.sigmoid(output)\n",
    "                loss = F.binary_cross_entropy_with_logits(output, y_oh)\n",
    "\n",
    "            # backward and update\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # train accuracy\n",
    "            pred = s.argmax(dim=-1)\n",
    "            correct1 = pred.squeeze().eq(y1).sum().item()\n",
    "            correct2 = pred.squeeze().eq(y2).sum().item()\n",
    "            correct += lam * correct1 + (1.0 - lam) * correct2\n",
    "            total += pred.shape[0]\n",
    "            cumu_loss += loss.item()\n",
    "            \n",
    "            i += 1\n",
    "            if steps <= i: break\n",
    "        if steps <= i: break\n",
    "            \n",
    "    train_acc = 100.0 * correct / total\n",
    "    avg_loss = cumu_loss / steps\n",
    "    \n",
    "    return (avg_loss, train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model, loader, config, repeat=1):\n",
    "    model.eval()\n",
    "    \n",
    "    # for test accuracy\n",
    "    correct, total = (0, 0) \n",
    "    \n",
    "    # for confusion matrix\n",
    "    C = len(class_label_to_type)\n",
    "    test_confusion = np.zeros((C, C), dtype=np.int32)\n",
    "    \n",
    "    # for test debug\n",
    "    test_debug = {data['metadata']['serial']: \n",
    "                  {'GT': data['class_label'].item(), \n",
    "                   'Acc': 0, \n",
    "                   'Pred': [0] * C} for data in loader.dataset}\n",
    "    \n",
    "    # for ROC curve\n",
    "    score = None\n",
    "    target = None\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for k in range(repeat):\n",
    "            for sample_batched in loader:\n",
    "                # pull up the data\n",
    "                x = sample_batched['signal'].to(device)\n",
    "                age = sample_batched['age'].to(device)\n",
    "                y = sample_batched['class_label'].to(device)\n",
    "\n",
    "                # apply model on whole batch directly on device\n",
    "                output = model(x, age)\n",
    "                \n",
    "                if config['criterion'] == 'cross-entropy':\n",
    "                    s = F.softmax(output, dim=1)\n",
    "                elif config['criterion'] == 'multi-bce':\n",
    "                    s = torch.sigmoid(output)\n",
    "                \n",
    "                # test accuracy\n",
    "                pred = s.argmax(dim=-1)\n",
    "                correct += pred.squeeze().eq(y).sum().item()\n",
    "                total += pred.shape[0]\n",
    "\n",
    "                if score is None:\n",
    "                    score = s.detach().cpu().numpy()\n",
    "                    target = y.detach().cpu().numpy()\n",
    "                else:\n",
    "                    score = np.concatenate((score, s.detach().cpu().numpy()), axis=0)\n",
    "                    target = np.concatenate((target, y.detach().cpu().numpy()), axis=0)\n",
    "\n",
    "                # confusion matrix\n",
    "                test_confusion += calculate_confusion_matrix(pred, y)\n",
    "\n",
    "                # test debug\n",
    "                for n in range(pred.shape[0]):\n",
    "                    serial = sample_batched['metadata'][n]['serial']\n",
    "                    test_debug[serial]['edfname'] = sample_batched['metadata'][n]['edfname']\n",
    "                    test_debug[serial]['Pred'][pred[n].item()] += 1\n",
    "                    acc = test_debug[serial]['Pred'][y[n].item()] / np.sum(test_debug[serial]['Pred']) * 100\n",
    "                    test_debug[serial]['Acc'] = f'{acc:>6.02f}%'\n",
    "        \n",
    "    test_accuracy = 100.0 * correct / total\n",
    "    return (test_accuracy, test_confusion, test_debug, score, target)\n",
    "\n",
    "\n",
    "def calculate_confusion_matrix(pred, target):\n",
    "    N = target.shape[0]\n",
    "    C = len(class_label_to_type)\n",
    "    confusion = np.zeros((C, C), dtype=np.int32)\n",
    "    \n",
    "    for i in range(N):\n",
    "        r = target[i]\n",
    "        c = pred[i]\n",
    "        confusion[r, c] += 1\n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_loss_plot(losses, lr_decay_step):\n",
    "    plt.style.use('default') # default, ggplot, fivethirtyeight, classic\n",
    "    fig = plt.figure(num=1, clear=True, figsize=(8.0, 3.0), constrained_layout=True)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    N = len(losses)\n",
    "    x = np.arange(1, N + 1)\n",
    "    ax.plot(x, losses)\n",
    "    \n",
    "    if type(lr_decay_step) is list:\n",
    "        ax.vlines(lr_decay_step, 0, 1, transform=ax.get_xaxis_transform(), \n",
    "                  colors='m', alpha=0.5, linestyle='solid')\n",
    "    else:\n",
    "        x2 = np.arange(lr_decay_step, N, lr_decay_step)\n",
    "        ax.vlines(x2, 0, 1, transform=ax.get_xaxis_transform(), \n",
    "                  colors='m', alpha=0.5, linestyle='solid')\n",
    "    # ax.vlines([1, N], 0, 1, transform=ax.get_xaxis_transform(), \n",
    "    #           colors='k', alpha=0.7, linestyle='solid')\n",
    "    \n",
    "    ax.set_xlim(left=0)\n",
    "    ax.set_title('Loss Plot')\n",
    "    ax.set_xlabel('Iteration')\n",
    "    ax.set_ylabel('Training Loss')\n",
    "    \n",
    "    plt.show()\n",
    "    fig.clear()\n",
    "    plt.close(fig)\n",
    "\n",
    "def draw_accuracy_history(train_acc_history, val_acc_history, history_interval, lr_decay_step):\n",
    "    plt.style.use('default') # default, ggplot, fivethirtyeight, classic\n",
    "    fig = plt.figure(num=1, clear=True, figsize=(8.0, 3.0), constrained_layout=True)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    N = len(train_acc_history) * history_interval\n",
    "    x = np.arange(history_interval, N + 1, history_interval)\n",
    "    ax.plot(x, train_acc_history, 'r-', label='Train accuracy')\n",
    "    ax.plot(x, val_acc_history, 'b-', label='Validation accuracy')\n",
    "    \n",
    "    if type(lr_decay_step) is list:\n",
    "        ax.vlines(lr_decay_step, 0, 1, transform=ax.get_xaxis_transform(), \n",
    "                  colors='m', alpha=0.5, linestyle='solid')\n",
    "    else:\n",
    "        x2 = np.arange(lr_decay_step, N + 1, lr_decay_step)\n",
    "        ax.vlines(x2, 0, 1, transform=ax.get_xaxis_transform(), \n",
    "                  colors='m', alpha=0.5, linestyle='solid')\n",
    "    # ax.vlines([history_interval, N], 0, 1, transform=ax.get_xaxis_transform(), \n",
    "    #           colors='k', alpha=0.7, linestyle='solid')\n",
    "    \n",
    "    ax.set_xlim(left=0)\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.set_title('Accuracy Plot during Training')\n",
    "    ax.set_xlabel('Iteration')\n",
    "    ax.set_ylabel('Accuracy (%)')\n",
    "    \n",
    "    plt.show()\n",
    "    fig.clear()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion(confusion):\n",
    "    C = len(class_label_to_type)\n",
    "    \n",
    "    plt.style.use('default') # default, ggplot, fivethirtyeight, classic\n",
    "    plt.rcParams['image.cmap'] = 'jet' # 'nipy_spectral'\n",
    "\n",
    "    fig = plt.figure(num=1, clear=True, figsize=(4.0, 4.0), constrained_layout=True)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    im = ax.imshow(confusion, alpha=0.8)\n",
    "\n",
    "    ax.set_xticks(np.arange(C))\n",
    "    ax.set_yticks(np.arange(C))\n",
    "    ax.set_xticklabels(class_label_to_type)\n",
    "    ax.set_yticklabels(class_label_to_type)\n",
    "    \n",
    "    for r in range(C):\n",
    "        for c in range(C):\n",
    "            text = ax.text(c, r, confusion[r, c],\n",
    "                           ha=\"center\", va=\"center\", color='k')\n",
    "    \n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.set_xlabel('Prediction')\n",
    "    ax.set_ylabel('Ground Truth')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    \n",
    "    # plt.show()\n",
    "    wandb.log({'Confusion Matrix (Image)': wandb.Image(plt)})\n",
    "    \n",
    "    fig.clear()\n",
    "    plt.close(fig)\n",
    "    \n",
    "\n",
    "def draw_roc_curve(score, target):\n",
    "    plt.style.use('default') # default, ggplot, fivethirtyeight, classic\n",
    "    \n",
    "    # Binarize the output\n",
    "    n_classes = len(class_label_to_type)\n",
    "    target = label_binarize(target, classes=np.arange(n_classes))\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(target[:, i], score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(target.ravel(), score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    # aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "    \n",
    "    # draw class-agnostic ROC curve\n",
    "    fig = plt.figure(num=1, clear=True, figsize=(8.5, 4.0), constrained_layout=True)\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    lw = 1.5\n",
    "    colors = cycle(['limegreen', 'mediumpurple', 'darkorange', \n",
    "                    'dodgerblue', 'lightcoral', 'goldenrod', \n",
    "                    'indigo', 'darkgreen', 'navy', 'brown'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        ax.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "                label='{0} (area = {1:0.2f})'\n",
    "                ''.format(class_label_to_type[i], roc_auc[i]))    \n",
    "    ax.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Class-Wise ROC Curves')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    # Plot class-aware ROC curves\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label='micro-average (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"micro\"]),\n",
    "             color='deeppink', linestyle='-', linewidth=lw)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "             label='macro-average (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"macro\"]),\n",
    "             color='navy', linestyle='-', linewidth=lw)\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Class-Agnostic ROC Curves')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    \n",
    "    # plt.show()\n",
    "    wandb.log({'ROC Curve': wandb.Image(plt)})\n",
    "    \n",
    "    fig.clear()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_search(model, min_log_lr, max_log_lr, trials, iters):\n",
    "    learning_rate_record = []\n",
    "    for t in tqdm(range(trials)):\n",
    "        log_lr = np.random.uniform(min_log_lr, max_log_lr)\n",
    "        lr = 10 ** log_lr\n",
    "        \n",
    "        model.reset_weights()\n",
    "        model.train()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-1)\n",
    "        correct, total = (0, 0)\n",
    "        \n",
    "        i = 1\n",
    "        while True:\n",
    "            for sample_batched in train_loader:\n",
    "                x = sample_batched['signal'].to(device)\n",
    "                age = sample_batched['age'].to(device)\n",
    "                y = sample_batched['class_label'].to(device)\n",
    "\n",
    "                output = model(x, age)\n",
    "                pred = F.log_softmax(output, dim=1)\n",
    "                loss = F.nll_loss(pred, y)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                pred = pred.argmax(dim=-1)\n",
    "                correct += pred.squeeze().eq(y).sum().item()\n",
    "                total += pred.shape[0]\n",
    "                \n",
    "                i += 1\n",
    "                if i >= iters:\n",
    "                    break\n",
    "            if i >= iters:\n",
    "                break\n",
    "        \n",
    "        train_accuracy = 100.0 * correct / total\n",
    "        \n",
    "        # Train accuracy for the final epoch is stored\n",
    "        learning_rate_record.append((log_lr, train_accuracy))\n",
    "    \n",
    "    return learning_rate_record\n",
    "\n",
    "\n",
    "def draw_learning_rate_record(learning_rate_record):\n",
    "    plt.style.use('default') # default, ggplot, fivethirtyeight, classic\n",
    "\n",
    "    fig = plt.figure(num=1, clear=True, constrained_layout=True) # figsize=(6.0, 6.0)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    \n",
    "    ax.set_title('Learning Rate Search')\n",
    "    ax.set_xlabel('Learning rate in log-scale')\n",
    "    ax.set_ylabel('Train accuracy')\n",
    "\n",
    "    ax.scatter(*max(learning_rate_record, key=lambda x: x[1]), \n",
    "               s=150, c='w', marker='o', edgecolors='limegreen')\n",
    "    \n",
    "    for log_lr, val_accuracy in learning_rate_record:\n",
    "        ax.scatter(log_lr, val_accuracy, c='r',\n",
    "                   alpha=0.5, edgecolors='none')\n",
    "        \n",
    "    plt.show()\n",
    "    fig.clear()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'M5', 'generator': <function generate_M5 at 0x0000016592DF9430>, 'lr_start': 0.001},\n",
      " {'name': '1D-ResNet-18', 'generator': <function generate_ResNet at 0x0000016592E063A0>, 'lr_start': 0.001},\n",
      " {'name': '1D-ResNeXt-50', 'generator': <function generate_ResNeXt_50 at 0x0000016592E2CF70>, 'lr_start': 0.001}]\n"
     ]
    }
   ],
   "source": [
    "model_pool = []\n",
    "\n",
    "# model_dict = {}\n",
    "# model_dict['name'] = '1D-Tiny-CNN'\n",
    "# model_dict['generator'] = generate_TinyCNN\n",
    "# model_dict['lr_start'] = None\n",
    "# model_pool.append(model_dict)\n",
    "\n",
    "model_dict = {}\n",
    "model_dict['name'] = 'M5'\n",
    "model_dict['generator'] = generate_M5\n",
    "model_dict['lr_start'] = 1e-3\n",
    "model_pool.append(model_dict)\n",
    "\n",
    "# model_dict = {}\n",
    "# model_dict['name'] = 'M5-no-age'\n",
    "# model_dict['generator'] = generate_M5_no_age\n",
    "# model_dict['lr_start'] = None\n",
    "# model_pool.append(model_dict)\n",
    "\n",
    "model_dict = {}\n",
    "model_dict['name'] = '1D-ResNet-18'\n",
    "model_dict['generator'] = generate_ResNet\n",
    "model_dict['lr_start'] = 1e-3\n",
    "model_pool.append(model_dict)\n",
    "\n",
    "# model_dict = {}\n",
    "# model_dict['name'] = '1D-ResNet-no-age'\n",
    "# model_dict['generator'] = generate_ResNet_no_age\n",
    "# model_dict['lr_start'] = None\n",
    "# model_pool.append(model_dict)\n",
    "\n",
    "# model_dict = {}\n",
    "# model_dict['name'] = '1D-ResNet-50'\n",
    "# model_dict['generator'] = generate_ResNet50\n",
    "# model_dict['lr_start'] = None\n",
    "# model_pool.append(model_dict)\n",
    "\n",
    "\n",
    "# model_dict = {}\n",
    "# model_dict['name'] = '1D-Tiny-ResNet'\n",
    "# model_dict['generator'] = generate_TinyResNet\n",
    "# model_dict['lr_start'] = None\n",
    "# model_pool.append(model_dict)\n",
    "\n",
    "# model_dict = {}\n",
    "# model_dict['name'] = '1D-Multi-Dilated-ResNet'\n",
    "# model_dict['generator'] = generate_Multi_Dilated_ResNet\n",
    "# model_dict['lr_start'] = None\n",
    "# model_pool.append(model_dict)\n",
    "\n",
    "model_dict = {}\n",
    "model_dict['name'] = '1D-ResNeXt-50'\n",
    "model_dict['generator'] = generate_ResNeXt_50\n",
    "model_dict['lr_start'] = 1e-3\n",
    "model_pool.append(model_dict)\n",
    "\n",
    "pprint.pp(model_pool, width=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M5: 1.00000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1D-ResNet-18: 1.00000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "1D-ResNeXt-50: 1.00000e-03\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[{'name': 'M5', 'generator': <function generate_M5 at 0x0000016592DF9430>, 'lr_start': 0.001},\n",
      " {'name': '1D-ResNet-18', 'generator': <function generate_ResNet at 0x0000016592E063A0>, 'lr_start': 0.001},\n",
      " {'name': '1D-ResNeXt-50', 'generator': <function generate_ResNeXt_50 at 0x0000016592E2CF70>, 'lr_start': 0.001}]\n"
     ]
    }
   ],
   "source": [
    "for model_dict in model_pool:\n",
    "    if model_dict['lr_start'] is None:\n",
    "        print(f'{model_dict[\"name\"]} LR searching..')\n",
    "        model = model_dict['generator']().to(device)\n",
    "        model.train()\n",
    "        \n",
    "        record = learning_rate_search(model, min_log_lr=-4.5, max_log_lr=-1.4, \n",
    "                                      trials=500, iters=30)\n",
    "        \n",
    "        draw_learning_rate_record(record)\n",
    "        best_log_lr = record[np.argmax(np.array([v for lr, v in record]))][0]\n",
    "        model_dict['lr_start'] = 10 ** best_log_lr\n",
    "        \n",
    "        print(f'best lr {model_dict[\"lr_start\"]:.5e} / log_lr {best_log_lr}')\n",
    "    else:\n",
    "        print(f'{model_dict[\"name\"]}: {model_dict[\"lr_start\"]:.5e}')\n",
    "        \n",
    "    print('-' * 100)\n",
    "        \n",
    "pprint.pp(model_pool, width=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0dbe302a2d437d8e33675b5af67199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************** M5 train starts ****************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis/runs/35r3gkvj\" target=\"_blank\">1D_001_wandb_10s_new_normal_wd1e-1_awgn3e-1_M5</a></strong> to <a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 24172... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.65MB of 0.65MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>▁▁</td></tr><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Accuracy (Longer)</td><td>▁</td></tr><tr><td>Train Accuracy</td><td>▁█</td></tr><tr><td>Validation Accuracy</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>0.0</td></tr><tr><td>Test Accuracy</td><td>51.73077</td></tr><tr><td>Test Accuracy (Longer)</td><td>52.37179</td></tr><tr><td>Train Accuracy</td><td>44.27666</td></tr><tr><td>Validation Accuracy</td><td>45.48077</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 2 media file(s), 2 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">1D_001_wandb_10s_new_normal_wd1e-1_awgn3e-1_M5</strong>: <a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis/runs/35r3gkvj\" target=\"_blank\">https://wandb.ai/ipis-mjkim/eeg-analysis/runs/35r3gkvj</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20211113_025040-35r3gkvj\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "**************************************** 1D-ResNet-18 train starts ****************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis/runs/3krqcyjy\" target=\"_blank\">1D_001_wandb_10s_new_normal_wd1e-1_awgn3e-1_1D-ResNet-18</a></strong> to <a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 21292... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.65MB of 0.65MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>▁▁</td></tr><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Accuracy (Longer)</td><td>▁</td></tr><tr><td>Train Accuracy</td><td>▁█</td></tr><tr><td>Validation Accuracy</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>0.0</td></tr><tr><td>Test Accuracy</td><td>45.19231</td></tr><tr><td>Test Accuracy (Longer)</td><td>45.19231</td></tr><tr><td>Train Accuracy</td><td>44.17223</td></tr><tr><td>Validation Accuracy</td><td>44.23077</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 2 media file(s), 2 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">1D_001_wandb_10s_new_normal_wd1e-1_awgn3e-1_1D-ResNet-18</strong>: <a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis/runs/3krqcyjy\" target=\"_blank\">https://wandb.ai/ipis-mjkim/eeg-analysis/runs/3krqcyjy</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20211113_025239-3krqcyjy\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "**************************************** 1D-ResNeXt-50 train starts ****************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis/runs/22m984ik\" target=\"_blank\">1D_001_wandb_10s_new_normal_wd1e-1_awgn3e-1_1D-ResNeXt-50</a></strong> to <a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 20740... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.66MB of 0.66MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>▁▁</td></tr><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Accuracy (Longer)</td><td>▁</td></tr><tr><td>Train Accuracy</td><td>▁█</td></tr><tr><td>Validation Accuracy</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>0.0</td></tr><tr><td>Test Accuracy</td><td>44.96795</td></tr><tr><td>Test Accuracy (Longer)</td><td>45.0641</td></tr><tr><td>Train Accuracy</td><td>45.33939</td></tr><tr><td>Validation Accuracy</td><td>44.42308</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 2 media file(s), 2 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">1D_001_wandb_10s_new_normal_wd1e-1_awgn3e-1_1D-ResNeXt-50</strong>: <a href=\"https://wandb.ai/ipis-mjkim/eeg-analysis/runs/22m984ik\" target=\"_blank\">https://wandb.ai/ipis-mjkim/eeg-analysis/runs/22m984ik</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20211113_025449-22m984ik\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "file_check = True\n",
    "save_model = True\n",
    "save_temporary = False\n",
    "draw_result = True\n",
    "\n",
    "# log path\n",
    "log_path = f'history_temp/{nb_fname}/'\n",
    "os.makedirs(log_path, exist_ok=True)\n",
    "\n",
    "# base configuration\n",
    "base_cfg = {}\n",
    "base_cfg['crop_length'] = crop_length\n",
    "base_cfg['input_norm'] = 'dataset' # 'datatset', datapoint', 'no'\n",
    "base_cfg['iterations'] = 100000\n",
    "base_cfg['history_interval'] = base_cfg['iterations'] // 500\n",
    "base_cfg['lr_decay_step'] = round(base_cfg['iterations'] * 0.8)\n",
    "base_cfg['weight_decay'] = 1e-2\n",
    "base_cfg['awgn'] = 5e-2\n",
    "base_cfg['mixup'] = 0.3\n",
    "base_cfg['criterion'] = 'multi-bce' # 'cross-entropy', 'multi-bce'\n",
    "\n",
    "tr_ms = train_multistep if base_cfg.get('mixup', 0) < 1e-3 else train_mixup_multistep\n",
    "    \n",
    "# progress bar\n",
    "pbar = tqdm(total=len(model_pool) * base_cfg['iterations'])\n",
    "\n",
    "# train process on model_pool\n",
    "for model_dict in model_pool:\n",
    "    if file_check:\n",
    "        path = os.path.join(log_path, f'{model_dict[\"name\"]}-log')\n",
    "        if os.path.isfile(path):\n",
    "            log_dict = torch.load(path)\n",
    "            if draw_result:\n",
    "                draw_loss_plot(log_dict[\"losses\"], log_dict[\"lr_decay_step\"])\n",
    "                draw_accuracy_history(log_dict[\"train_acc_history\"], log_dict[\"val_acc_history\"], \n",
    "                                      log_dict[\"history_interval\"], log_dict[\"lr_decay_step\"])            \n",
    "            script = f'- train accuracy {log_dict[\"train_acc_history\"][-1]:.2f}%, '\\\n",
    "            f'best / last test accuracies {log_dict[\"best_test_accuracy\"]:.2f}% / {log_dict[\"last_test_accuracy\"]:.2f}% - file exists'\n",
    "            print('\\n' + script + '\\n')\n",
    "            pbar.update(base_cfg['iterations'])\n",
    "            continue\n",
    "    \n",
    "    print(f'{\"*\"*40} {model_dict[\"name\"]} train starts {\"*\"*40}')\n",
    "    \n",
    "    # load the model dict\n",
    "    model = model_dict['generator']().to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), \n",
    "                            lr=model_dict['lr_start'], \n",
    "                            weight_decay=base_cfg['weight_decay'])\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, \n",
    "                                          step_size=base_cfg['lr_decay_step'], \n",
    "                                          gamma=0.1)\n",
    "    \n",
    "    # wandb initialization\n",
    "    config = {}\n",
    "    config.update(base_cfg)\n",
    "    config['model'] = model_dict['name']\n",
    "    config['num_params'] = count_parameters(model)\n",
    "    config['LR'] = model_dict['lr_start']\n",
    "    \n",
    "    wandb_run = wandb.init(project=\"eeg-analysis\", \n",
    "                           entity=\"ipis-mjkim\", \n",
    "                           reinit=True,\n",
    "                           save_code=True, \n",
    "                           name=nb_fname[9:] + '_' + model_dict[\"name\"], \n",
    "                           config=config)\n",
    "\n",
    "    with wandb_run:\n",
    "        # train and validation routine\n",
    "        best_val_acc = 0\n",
    "        for i in range(0, wandb.config.iterations, wandb.config.history_interval):\n",
    "            # train 'history_interval' steps\n",
    "            loss, train_acc = tr_ms(model, train_loader, optimizer, scheduler, \n",
    "                                    wandb.config, wandb.config.history_interval)\n",
    "            \n",
    "            # validation\n",
    "            val_acc, _, _, _, _ = check_accuracy(model, val_loader, config, repeat=10)\n",
    "            \n",
    "            if best_val_acc < val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_model_state = deepcopy(model.state_dict())                \n",
    "                if save_model and save_temporary:\n",
    "                    path = os.path.join(log_path, f'{model_dict[\"name\"]}')\n",
    "                    torch.save(best_model_state, path)                    \n",
    "                \n",
    "            # log\n",
    "            wandb.log({'Loss': loss, \n",
    "                       'Train Accuracy': train_acc, \n",
    "                       'Validation Accuracy': val_acc}, step=i)\n",
    "            pbar.update(wandb.config.history_interval)\n",
    "\n",
    "        # calculate the test accuracies for best and last models\n",
    "        last_model_state = deepcopy(model.state_dict())\n",
    "        last_test_result = check_accuracy(model, test_loader, wandb.config, repeat=30)\n",
    "        last_test_acc = last_test_result[0]\n",
    "        \n",
    "        model.load_state_dict(best_model_state)\n",
    "        best_test_result = check_accuracy(model, test_loader, wandb.config, repeat=30)\n",
    "        best_test_acc = best_test_result[0]\n",
    " \n",
    "        if last_test_acc < best_test_acc:\n",
    "            model_state = best_model_state\n",
    "            test_result = best_test_result\n",
    "        else:\n",
    "            model_state = last_model_state\n",
    "            test_result = last_test_result\n",
    "            \n",
    "        model.load_state_dict(model_state)\n",
    "        test_acc, test_confusion, test_debug, score, target = test_result\n",
    "        \n",
    "        # calculate the test accuracies for final model on much longer sequence\n",
    "        last_test_result = check_accuracy(model, longer_test_loader, wandb.config, repeat=30)\n",
    "        longer_test_acc = last_test_result[0]\n",
    "        \n",
    "        # save the model\n",
    "        if save_model:\n",
    "            path = os.path.join(log_path, f'{model_dict[\"name\"]}')\n",
    "            torch.save(model_state, path)\n",
    "            \n",
    "        # leave the message\n",
    "        wandb.log({'Test Accuracy': test_acc,\n",
    "                   '(Best / Last) Test Accuracy': ('Best' if last_test_acc < best_test_acc else 'Last', \n",
    "                                                   round(best_test_acc, 2), round(last_test_acc, 2)),\n",
    "                   'Confusion Matrix (Array)': test_confusion,\n",
    "                   'Test Debug Table': test_debug,\n",
    "                   'Test Accuracy (Longer)': longer_test_acc})\n",
    "        \n",
    "        if draw_result:\n",
    "            draw_roc_curve(score, target)\n",
    "            draw_confusion(test_confusion)\n",
    "            \n",
    "    print('\\n' + '-' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
