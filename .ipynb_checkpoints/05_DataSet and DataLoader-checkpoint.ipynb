{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and DataLoader\n",
    "\n",
    "This notebook loads the `CAUEEG` dataset, tests some useful preprocessing, and makes up the PyTorch DataLoader instances for the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some packages\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# custom package\n",
    "from datasets.caueeg_dataset import *\n",
    "from datasets.caueeg_script import *\n",
    "from datasets.pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.11.0+cu113\n",
      "cuda is available.\n"
     ]
    }
   ],
   "source": [
    "print('PyTorch version:', torch.__version__)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available(): print('cuda is available.')\n",
    "else: print('cuda is unavailable.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data file path\n",
    "data_path = r'local/dataset/02_Curated_Data_220419/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Load the CAUEEG dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the whole CAUEEG data as a PyTorch dataset instance without considering the target task (no train/val/test sets and no class label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_name': 'CAUEEG dataset',\n",
      " 'signal_header': ['Fp1-AVG', 'F3-AVG', 'C3-AVG', 'P3-AVG', 'O1-AVG', 'Fp2-AVG', 'F4-AVG', 'C4-AVG', 'P4-AVG', 'O2-AVG', 'F7-AVG', 'T3-AVG', 'T5-AVG', 'F8-AVG', 'T4-AVG', 'T6-AVG', 'FZ-AVG', 'CZ-AVG', 'PZ-AVG', 'EKG', 'Photic']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 78,\n",
      " 'serial': '00001',\n",
      " 'signal': array([[  0., -11., -13., ...,   0.,   0.,   0.],\n",
      "       [ 29.,  33.,  34., ...,   0.,   0.,   0.],\n",
      "       [ -3.,  -6.,  -3., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ -4.,  -2.,   1., ...,   0.,   0.,   0.],\n",
      "       [112.,  67.,  76., ...,   0.,   0.,   0.],\n",
      "       [ -1.,  -1.,  -1., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 56,\n",
      " 'serial': '00002',\n",
      " 'signal': array([[  39.,   58.,   72., ...,    0.,    0.,    0.],\n",
      "       [   4.,   12.,   13., ...,    0.,    0.,    0.],\n",
      "       [   1.,   -2.,   -3., ...,    0.,    0.,    0.],\n",
      "       ...,\n",
      "       [   2.,    1.,    1., ...,    0.,    0.,    0.],\n",
      "       [ -22., -173., -175., ...,    0.,    0.,    0.],\n",
      "       [   2.,    0.,    0., ...,    0.,    0.,    0.]]),\n",
      " 'symptom': ['normal', 'smi']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         load_event=False, \n",
    "                                                         file_format='edf',\n",
    "                                                         transform=None)\n",
    "\n",
    "pprint.pprint(config_data, width=250)\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(full_eeg_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(full_eeg_dataset[1])\n",
    "print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the CAUEEG task1 datasets as the PyTorch dataset instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_label_to_name': ['Normal', 'MCI', 'Dementia'],\n",
      " 'class_name_to_label': {'Dementia': 2, 'MCI': 1, 'Normal': 0},\n",
      " 'task_description': 'Classification of [Normal], [MCI], and [Dementia] '\n",
      "                     'symptoms.',\n",
      " 'task_name': 'CAUEEG-task1 benchmark'}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 88,\n",
      " 'class_label': 2,\n",
      " 'class_name': 'Dementia',\n",
      " 'serial': '01379',\n",
      " 'signal': array([[ -1.,  -4., -35., ...,   0.,   0.,   0.],\n",
      "       [ 11.,  18., -31., ...,   0.,   0.,   0.],\n",
      "       [ 18.,  30.,  -7., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ 20.,  33., -12., ...,   0.,   0.,   0.],\n",
      "       [ 91., 138.,  23., ...,   0.,   0.,   0.],\n",
      "       [  0.,  -1.,  -1., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['dementia', 'ad', 'load']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 69,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00970',\n",
      " 'signal': array([[76., 35., 36., ...,  0.,  0.,  0.],\n",
      "       [21., 25., 30., ...,  0.,  0.,  0.],\n",
      "       [11., 14., 18., ...,  0.,  0.,  0.],\n",
      "       ...,\n",
      "       [-1.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [-4., 24., 27., ...,  0.,  0.,  0.],\n",
      "       [-1.,  1.,  3., ...,  0.,  0.,  0.]]),\n",
      " 'symptom': ['normal', 'cb_normal']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 70,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '01104',\n",
      " 'signal': array([[  14.,   25.,   26., ...,    0.,    0.,    0.],\n",
      "       [   7.,    7.,    6., ...,    0.,    0.,    0.],\n",
      "       [  -8.,  -11.,  -13., ...,    0.,    0.,    0.],\n",
      "       ...,\n",
      "       [ -10.,   -5.,   -5., ...,    0.,    0.,    0.],\n",
      "       [ -95., -106.,  -44., ...,    0.,    0.,    0.],\n",
      "       [  -1.,   -1.,   -1., ...,    0.,    0.,    0.]]),\n",
      " 'symptom': ['normal', 'cb_normal']}\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf', \n",
    "                                                                                  transform=None)\n",
    "pprint.pprint(config_data)\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(train_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(val_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the CAUEEG task2 datasets as the PyTorch dataset instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_label_to_name': ['Normal', 'Abnormal'],\n",
      " 'class_name_to_label': {'Abnormal': 1, 'Normal': 0},\n",
      " 'task_description': 'Classification of [Normal] and [Abnormal] symptoms',\n",
      " 'task_name': 'CAUEEG-task2 benchmark'}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 60,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00137',\n",
      " 'signal': array([[ 13.,  21.,  22., ...,   0.,   0.,   0.],\n",
      "       [  9.,   8.,   8., ...,   0.,   0.,   0.],\n",
      "       [  5.,   8.,   9., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ -5.,  -6.,  -3., ...,   0.,   0.,   0.],\n",
      "       [-62., -48., -36., ...,   0.,   0.,   0.],\n",
      "       [ -1.,  -1.,   0., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['normal', 'smi']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 72,\n",
      " 'class_label': 1,\n",
      " 'class_name': 'Abnormal',\n",
      " 'serial': '00709',\n",
      " 'signal': array([[-67., -55., -54., ...,   0.,   0.,   0.],\n",
      "       [-35., -29., -27., ...,   0.,   0.,   0.],\n",
      "       [-27., -22., -19., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [-37., -40., -33., ...,   0.,   0.,   0.],\n",
      "       [ 44.,  99., 104., ...,   0.,   0.,   0.],\n",
      "       [ -1.,   0.,   2., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['dementia', 'ad', 'load']}\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 72,\n",
      " 'class_label': 1,\n",
      " 'class_name': 'Abnormal',\n",
      " 'serial': '00942',\n",
      " 'signal': array([[ -9.,   1.,   3., ...,   0.,   0.,   0.],\n",
      "       [ -1.,   4.,  11., ...,   0.,   0.,   0.],\n",
      "       [ -2.,  -3.,  -1., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ -2.,  -4.,  -4., ...,   0.,   0.,   0.],\n",
      "       [-47.,  -4., -10., ...,   0.,   0.,   0.],\n",
      "       [  1.,   3.,   0., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['mci', 'mci_vascular']}\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf', \n",
    "                                                                                  transform=None)\n",
    "pprint.pprint(config_data)\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(train_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(val_dataset[0])\n",
    "print('\\n', '-' * 100, '\\n')\n",
    "\n",
    "pprint.pprint(test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 88,\n",
      " 'class_label': 2,\n",
      " 'class_name': 'Dementia',\n",
      " 'event': [[0, 'Start Recording'],\n",
      "           [0, 'New Montage - Montage 005'],\n",
      "           [36596, 'Eyes Open'],\n",
      "           [41382, 'Move'],\n",
      "           [41740, 'Move'],\n",
      "           [72212, 'Eyes Closed'],\n",
      "           [75866, 'Eyes Open'],\n",
      "           [76706, 'Eyes Closed'],\n",
      "           [78512, 'Eyes Open'],\n",
      "           [79352, 'Eyes Closed'],\n",
      "           [80446, 'Photic On - 3.0 Hz'],\n",
      "           [80738, 'Eyes Open'],\n",
      "           [81494, 'Eyes Closed'],\n",
      "           [82464, 'Photic Off'],\n",
      "           [84522, 'Photic On - 6.0 Hz'],\n",
      "           [84816, 'Eyes Open'],\n",
      "           [85530, 'Eyes Closed'],\n",
      "           [86538, 'Photic Off'],\n",
      "           [88554, 'Photic On - 9.0 Hz'],\n",
      "           [90570, 'Photic Off'],\n",
      "           [90780, 'Eyes Open'],\n",
      "           [91578, 'Eyes Closed'],\n",
      "           [92628, 'Photic On - 12.0 Hz'],\n",
      "           [94644, 'Photic Off'],\n",
      "           [96702, 'Photic On - 15.0 Hz'],\n",
      "           [98718, 'Photic Off'],\n",
      "           [100734, 'Photic On - 18.0 Hz'],\n",
      "           [102750, 'Photic Off'],\n",
      "           [104808, 'Photic On - 21.0 Hz'],\n",
      "           [105144, 'Eyes Open'],\n",
      "           [105983, 'Eyes Closed'],\n",
      "           [106824, 'Photic Off'],\n",
      "           [108882, 'Photic On - 24.0 Hz'],\n",
      "           [110898, 'Photic Off'],\n",
      "           [112914, 'Photic On - 27.0 Hz'],\n",
      "           [114930, 'Photic Off'],\n",
      "           [116444, 'Move'],\n",
      "           [116988, 'Photic On - 30.0 Hz'],\n",
      "           [119004, 'Photic Off'],\n",
      "           [119340, 'Eyes Open'],\n",
      "           [120264, 'Eyes Closed'],\n",
      "           [123044, 'Eyes Open'],\n",
      "           [123968, 'Eyes Closed'],\n",
      "           [129511, 'Eyes Open'],\n",
      "           [130478, 'Eyes Closed'],\n",
      "           [152870, 'Eyes Open'],\n",
      "           [153752, 'Eyes Closed'],\n",
      "           [168326, 'Eyes Open'],\n",
      "           [169250, 'Eyes Closed'],\n",
      "           [173000, 'Paused']],\n",
      " 'serial': '01379',\n",
      " 'signal': array([[ -1.,  -4., -35., ...,   0.,   0.,   0.],\n",
      "       [ 11.,  18., -31., ...,   0.,   0.,   0.],\n",
      "       [ 18.,  30.,  -7., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ 20.,  33., -12., ...,   0.,   0.,   0.],\n",
      "       [ 91., 138.,  23., ...,   0.,   0.,   0.],\n",
      "       [  0.,  -1.,  -1., ...,   0.,   0.,   0.]]),\n",
      " 'symptom': ['dementia', 'ad', 'load']}\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=True, \n",
    "                                                                                  file_format='edf', \n",
    "                                                                                  transform=None)\n",
    "pprint.pprint(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Format: `EDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'serial': '00137', 'age': 60, 'symptom': ['normal', 'smi'], 'class_name': 'Normal', 'class_label': 0, 'signal': array([[ 13.,  21.,  22., ...,   0.,   0.,   0.],\n",
      "       [  9.,   8.,   8., ...,   0.,   0.,   0.],\n",
      "       [  5.,   8.,   9., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [ -5.,  -6.,  -3., ...,   0.,   0.,   0.],\n",
      "       [-62., -48., -36., ...,   0.,   0.,   0.],\n",
      "       [ -1.,  -1.,   0., ...,   0.,   0.,   0.]])}\n",
      "{'serial': '00526', 'age': 73, 'symptom': ['dementia', 'ad', 'load'], 'class_name': 'Abnormal', 'class_label': 1, 'signal': array([[-21.,  -3.,   6., ...,   0.,   0.,   0.],\n",
      "       [ 13.,  10.,  11., ...,   0.,   0.,   0.],\n",
      "       [ -7., -10., -12., ...,   0.,   0.,   0.],\n",
      "       ...,\n",
      "       [  0.,   0.,  -1., ...,   0.,   0.,   0.],\n",
      "       [ 13.,  22.,  14., ...,   0.,   0.,   0.],\n",
      "       [  1.,   2.,   2., ...,   0.,   0.,   0.]])}\n",
      "CPU times: total: 234 ms\n",
      "Wall time: 251 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf', \n",
    "                                                                                  transform=None)\n",
    "\n",
    "print(train_dataset[0])\n",
    "print(train_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Format: `PyArrow Feather`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'serial': '00137', 'age': 60, 'symptom': ['normal', 'smi'], 'class_name': 'Normal', 'class_label': 0, 'signal': array([[ 13,  21,  22, ...,  32,  30,  27],\n",
      "       [  9,   8,   8, ...,  -4,  -3,  -4],\n",
      "       [  5,   8,   9, ...,  -4,  -6,  -9],\n",
      "       ...,\n",
      "       [ -5,  -6,  -3, ...,  16,  15,  13],\n",
      "       [-62, -48, -36, ..., -78, -77, -76],\n",
      "       [ -1,  -1,   0, ...,   0,   0,   0]])}\n",
      "{'serial': '00526', 'age': 73, 'symptom': ['dementia', 'ad', 'load'], 'class_name': 'Abnormal', 'class_label': 1, 'signal': array([[-21,  -3,   6, ...,  -7, -11, -10],\n",
      "       [ 13,  10,  11, ...,   5,   5,   7],\n",
      "       [ -7, -10, -12, ...,   2,   1,   1],\n",
      "       ...,\n",
      "       [  0,   0,  -1, ...,   3,   4,   3],\n",
      "       [ 13,  22,  14, ...,  -3,  -8,  -9],\n",
      "       [  1,   2,   2, ...,   0,   1,   1]])}\n",
      "CPU times: total: 359 ms\n",
      "Wall time: 244 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather', \n",
    "                                                                                  transform=None)\n",
    "\n",
    "print(train_dataset[0])\n",
    "print(train_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Format: `NumPy Memmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'serial': '00137', 'age': 60, 'symptom': ['normal', 'smi'], 'class_name': 'Normal', 'class_label': 0, 'signal': memmap([[ 13,  21,  22, ...,  32,  30,  27],\n",
      "        [  9,   8,   8, ...,  -4,  -3,  -4],\n",
      "        [  5,   8,   9, ...,  -4,  -6,  -9],\n",
      "        ...,\n",
      "        [ -5,  -6,  -3, ...,  16,  15,  13],\n",
      "        [-62, -48, -36, ..., -78, -77, -76],\n",
      "        [ -1,  -1,   0, ...,   0,   0,   0]])}\n",
      "{'serial': '00526', 'age': 73, 'symptom': ['dementia', 'ad', 'load'], 'class_name': 'Abnormal', 'class_label': 1, 'signal': memmap([[-21,  -3,   6, ...,  -7, -11, -10],\n",
      "        [ 13,  10,  11, ...,   5,   5,   7],\n",
      "        [ -7, -10, -12, ...,   2,   1,   1],\n",
      "        ...,\n",
      "        [  0,   0,  -1, ...,   3,   4,   3],\n",
      "        [ 13,  22,  14, ...,  -3,  -8,  -9],\n",
      "        [  1,   2,   2, ...,   0,   1,   1]])}\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap', \n",
    "                                                                                  transform=None)\n",
    "\n",
    "print(train_dataset[0])\n",
    "print(train_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PyTorch Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 60,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00137',\n",
      " 'signal': array([[  53,   56,   58, ...,   75,   72,   73],\n",
      "       [  -3,   -2,   -2, ...,   -1,   -3,   -4],\n",
      "       [ -21,  -23,  -22, ...,  -21,  -22,  -22],\n",
      "       ...,\n",
      "       [ -16,  -17,  -18, ...,  -16,  -17,  -18],\n",
      "       [ -39,  -36,  -32, ...,   52,   57,   57],\n",
      "       [ 411,  779,  751, ..., -128, -126, -124]]),\n",
      " 'symptom': ['normal', 'smi']}\n",
      "\n",
      ">>> signal shape: (21, 100)\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 60,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00137',\n",
      " 'signal': array([[  9,   8,   8, ...,  56,  56,  58],\n",
      "       [-11, -12, -10, ...,  -7,  -6,  -6],\n",
      "       [-16, -15, -14, ..., -24, -24, -22],\n",
      "       ...,\n",
      "       [ -7,  -6,  -5, ..., -26, -25, -24],\n",
      "       [-48, -55, -61, ...,  69,  63,  59],\n",
      "       [679, 422, -40, ..., 347, 342, 283]]),\n",
      " 'symptom': ['normal', 'smi']}\n",
      "\n",
      ">>> signal shape: (21, 100)\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = EegRandomCrop(crop_length=100)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path,\n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "for i in range(2):\n",
    "    d = train_dataset[0]\n",
    "    pprint.pprint(d)\n",
    "    print()\n",
    "    print('>>> signal shape:', d['signal'].shape)\n",
    "    print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Random crop with multiple cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 60,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00137',\n",
      " 'signal': [array([[  22,   20,   19, ...,   29,   27,   25],\n",
      "       [  -8,  -10,   -8, ...,   12,    8,    6],\n",
      "       [ -13,  -13,  -12, ...,    1,    1,    0],\n",
      "       ...,\n",
      "       [  -9,   -9,   -9, ...,  -15,   -6,    2],\n",
      "       [  -4,   -4,   -4, ..., -507, -754, -818],\n",
      "       [  -1,   -1,   -1, ...,    0,   -1,   -1]]),\n",
      "            array([[ -8,  -6,  -8, ...,   3,   2,   2],\n",
      "       [ -3,  -4,  -3, ...,  -3,  -4,  -1],\n",
      "       [  8,   5,   3, ...,  -1,  -1,   2],\n",
      "       ...,\n",
      "       [  6,  -1,  -6, ...,  10,  12,  13],\n",
      "       [ 33,  28,  24, ..., -34, -25, -17],\n",
      "       [  0,   0,   2, ...,  -3,  -1,   0]])],\n",
      " 'symptom': ['normal', 'smi']}\n",
      "\n",
      ">>> signal shape: [(21, 200), (21, 200)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 60,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'serial': '00137',\n",
      " 'signal': [array([[  1,  -5,  -8, ...,   3,   3,   2],\n",
      "       [ -4,  -9, -12, ...,   8,   8,   8],\n",
      "       [  1,  -1,  -4, ...,  -6,  -6,  -7],\n",
      "       ...,\n",
      "       [-15, -14, -13, ..., -16, -17, -16],\n",
      "       [  6,   4,   4, ...,  79,  93,  22],\n",
      "       [  0,   3,   3, ...,   0,   0,   0]]),\n",
      "            array([[   9,    2,   -3, ...,    5,    5,    5],\n",
      "       [  -9,  -12,  -14, ...,   -8,  -10,  -12],\n",
      "       [  -4,   -6,   -7, ...,    2,    0,   -1],\n",
      "       ...,\n",
      "       [ -12,  -10,   -8, ...,   -6,   -4,   -4],\n",
      "       [-579, -294,   56, ...,   77,   36,  -12],\n",
      "       [   0,    1,    1, ...,    0,    0,    0]])],\n",
      " 'symptom': ['normal', 'smi']}\n",
      "\n",
      ">>> signal shape: [(21, 200), (21, 200)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = EegRandomCrop(crop_length=200, multiple=2)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "for i in range(2):\n",
    "    d = train_dataset[0]\n",
    "    pprint.pprint(d)\n",
    "    print()\n",
    "    print('>>> signal shape:', [signal.shape for signal in d['signal']])\n",
    "    print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random crop with multiple cropping and latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 60,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'crop_timing': [168177, 156969, 101014],\n",
      " 'serial': '00137',\n",
      " 'signal': [array([[ 47,  45,  44, ...,  -4,  -2,  -1],\n",
      "       [ 21,  18,  14, ..., -12, -14, -14],\n",
      "       [ 30,  29,  23, ...,  -2,  -4,  -4],\n",
      "       ...,\n",
      "       [-21, -19, -17, ..., -12, -12, -14],\n",
      "       [-14, -16, -15, ..., -14, -13, -14],\n",
      "       [  0,  -1,  -1, ...,   0,   0,   0]]),\n",
      "            array([[  1,  -2,  -3, ...,  -4,  -4,  -3],\n",
      "       [-18, -18, -18, ...,  -6,  -6,  -6],\n",
      "       [-15, -16, -16, ..., -13,  -9,  -7],\n",
      "       ...,\n",
      "       [ -3,  -3,  -5, ...,   3,   0,  -1],\n",
      "       [ 13,  14,  13, ...,  57,  40,  19],\n",
      "       [ -1,  -1,  -1, ...,   0,   0,   0]]),\n",
      "            array([[  -11,   -11,    -9, ...,     9,     9,    10],\n",
      "       [  -12,    -8,    -5, ...,    -6,    -5,    -3],\n",
      "       [   -3,    -3,    -1, ...,     2,     3,     5],\n",
      "       ...,\n",
      "       [    8,     7,     7, ...,    -6,    -6,    -8],\n",
      "       [  -40,   -15,    12, ...,    -7,    -6,    -7],\n",
      "       [ -401, -1346,  -781, ...,  -334,   207,   547]])],\n",
      " 'symptom': ['normal', 'smi']}\n",
      "\n",
      ">>> signal shape: [(21, 300), (21, 300), (21, 300)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 60,\n",
      " 'class_label': 0,\n",
      " 'class_name': 'Normal',\n",
      " 'crop_timing': [84816, 61576, 151242],\n",
      " 'serial': '00137',\n",
      " 'signal': [array([[    4,     0,    -1, ...,  -146,  -143,  -144],\n",
      "       [    8,     6,     4, ...,    16,    15,    13],\n",
      "       [    3,     4,     6, ...,     3,     0,    -2],\n",
      "       ...,\n",
      "       [    7,     7,     8, ...,    -6,    -8,    -9],\n",
      "       [   73,    65,    59, ...,    37,    29,    19],\n",
      "       [  262,   210,   293, ..., -1701, -1267,  -480]]),\n",
      "            array([[-16, -13,  -9, ..., -11,  -6,  -5],\n",
      "       [ -5,  -5,  -6, ...,   3,   3,   2],\n",
      "       [  8,   6,   5, ...,   0,  -2,  -4],\n",
      "       ...,\n",
      "       [  5,   4,   3, ...,  -2,  -1,   0],\n",
      "       [ 58,  55,  53, ..., -40, -37, -31],\n",
      "       [  0,  -1,   0, ...,   0,   0,   0]]),\n",
      "            array([[  29,   30,   29, ...,  -35,  -36,  -37],\n",
      "       [  15,   16,   15, ...,    1,    1,    0],\n",
      "       [   3,    4,    4, ...,   -4,   -4,   -2],\n",
      "       ...,\n",
      "       [  19,   19,   19, ...,  -21,  -21,  -19],\n",
      "       [ -91,  -82,  -71, ..., -230,  140,  343],\n",
      "       [   0,    1,    1, ...,    0,    2,    2]])],\n",
      " 'symptom': ['normal', 'smi']}\n",
      "\n",
      ">>> signal shape: [(21, 300), (21, 300), (21, 300)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = EegRandomCrop(crop_length=300, multiple=3, latency=50000, return_timing=True)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "for i in range(2): \n",
    "    d = train_dataset[0]\n",
    "    pprint.pprint(d)\n",
    "    print()\n",
    "    print('>>> signal shape:', [signal.shape for signal in d['signal']])\n",
    "    print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Random crop with multiple cropping, latency, and max length limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 88,\n",
      " 'class_label': 2,\n",
      " 'class_name': 'Dementia',\n",
      " 'crop_timing': [50029, 50000, 50044],\n",
      " 'serial': '01379',\n",
      " 'signal': [array([[-26, -26, -27, ..., -69, -68, -66],\n",
      "       [-66, -64, -67, ..., -58, -58, -61],\n",
      "       [  5,   7,   1, ...,   9,   9,   4],\n",
      "       ...,\n",
      "       [  1,  -1,  -5, ...,   6,   5,  -1],\n",
      "       [ 22,  22,  14, ...,  19,  18,  10],\n",
      "       [ -1,   0,  -1, ...,  -1,  -1,   0]]),\n",
      "            array([[-28, -25, -24, ..., -70, -71, -66],\n",
      "       [-60, -63, -64, ..., -62, -63, -63],\n",
      "       [ -9, -13, -13, ...,   5,   8,   9],\n",
      "       ...,\n",
      "       [  1,  -4,  -5, ...,  11,  10,  10],\n",
      "       [-35, -33, -28, ...,  -5,  -6,   2],\n",
      "       [  0,  -1,   0, ...,  -1,  -1,  -1]]),\n",
      "            array([[-28, -27, -19, ..., -57, -55, -46],\n",
      "       [-75, -72, -64, ..., -52, -50, -48],\n",
      "       [-12, -12,  -8, ...,   5,   4,   5],\n",
      "       ...,\n",
      "       [ -2,  -3,  -3, ...,   1,   2,   5],\n",
      "       [  4,   2,   6, ...,   2,   0,   6],\n",
      "       [ -1,  -1,  -1, ...,   2,   0,  -1]])],\n",
      " 'symptom': ['dementia', 'ad', 'load']}\n",
      "\n",
      ">>> signal shape: [(21, 200), (21, 200), (21, 200)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n",
      "{'age': 88,\n",
      " 'class_label': 2,\n",
      " 'class_name': 'Dementia',\n",
      " 'crop_timing': [50036, 50085, 50045],\n",
      " 'serial': '01379',\n",
      " 'signal': [array([[-31, -33, -34, ..., -49, -47, -58],\n",
      "       [-69, -68, -72, ..., -61, -63, -53],\n",
      "       [ -8,  -6,  -6, ...,   7,   5,   3],\n",
      "       ...,\n",
      "       [  2,   4,   1, ...,   3,   2,   1],\n",
      "       [ 10,  10,   2, ...,   4,   2,  -2],\n",
      "       [ -1,  -1,  -1, ...,  -1,  -1,  -1]]),\n",
      "            array([[ 18,  16,  19, ..., -19, -18, -21],\n",
      "       [-67, -61, -61, ..., -21, -21, -30],\n",
      "       [ -8,  -5,  -5, ...,   7,   9,   5],\n",
      "       ...,\n",
      "       [-15, -10,  -9, ...,   3,   7,   7],\n",
      "       [-26, -17, -10, ...,  -5,   6,  10],\n",
      "       [ -1,  -1,   2, ...,   0,  -1,  -1]]),\n",
      "            array([[-27, -19, -14, ..., -55, -46, -44],\n",
      "       [-72, -64, -61, ..., -50, -48, -46],\n",
      "       [-12,  -8,  -5, ...,   4,   5,   4],\n",
      "       ...,\n",
      "       [ -3,  -3,  -4, ...,   2,   5,   3],\n",
      "       [  2,   6,   7, ...,   0,   6,   4],\n",
      "       [ -1,  -1,   0, ...,   0,  -1,  -1]])],\n",
      " 'symptom': ['dementia', 'ad', 'load']}\n",
      "\n",
      ">>> signal shape: [(21, 200), (21, 200), (21, 200)]\n",
      "\n",
      " ---------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200, \n",
    "                  length_limit=50300,\n",
    "                  multiple=3, \n",
    "                  latency=50000, \n",
    "                  return_timing=True)\n",
    "])\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "for i in range(2):\n",
    "    d = train_dataset[0]\n",
    "    pprint.pprint(d)\n",
    "    print()\n",
    "    print('>>> signal shape:', [signal.shape for signal in d['signal']])\n",
    "    print('\\n', '-' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Drop channel(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fp1-AVG', 'F3-AVG', 'C3-AVG', 'P3-AVG', 'O1-AVG', 'Fp2-AVG', 'F4-AVG', 'C4-AVG', 'P4-AVG', 'O2-AVG', 'F7-AVG', 'T3-AVG', 'T5-AVG', 'F8-AVG', 'T4-AVG', 'T6-AVG', 'FZ-AVG', 'CZ-AVG', 'PZ-AVG', 'EKG', 'Photic']\n",
      "channel_ekg:  19\n",
      "channel_photic:  20\n"
     ]
    }
   ],
   "source": [
    "anno_path = os.path.join(data_path, 'annotation.json')\n",
    "with open(anno_path, 'r') as json_file:\n",
    "    annotation = json.load(json_file)\n",
    "signal_headers = annotation['signal_header']\n",
    "del annotation\n",
    "print(signal_headers)\n",
    "\n",
    "channel_ekg = signal_headers.index('EKG')\n",
    "print('channel_ekg: ', channel_ekg)\n",
    "\n",
    "channel_photic = signal_headers.index('Photic')\n",
    "print('channel_photic: ', channel_photic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: (21, 173000)\n",
      "[[ -1  -4 -35 ... -20 -16 -11]\n",
      " [ 11  18 -31 ...  -1   3   6]\n",
      " [ 18  30  -7 ...  -4  -1   0]\n",
      " ...\n",
      " [ 20  33 -12 ...   2   4   4]\n",
      " [ 91 138  23 ...  13  16  21]\n",
      " [  0  -1  -1 ...   0   0   0]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "after: (20, 173000)\n",
      "[[ -1  -4 -35 ... -20 -16 -11]\n",
      " [ 11  18 -31 ...  -1   3   6]\n",
      " [ 18  30  -7 ...  -4  -1   0]\n",
      " ...\n",
      " [ 22  38   0 ... -13 -10 -10]\n",
      " [ 20  33 -12 ...   2   4   4]\n",
      " [  0  -1  -1 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather', \n",
    "                                                                                  transform=None)\n",
    "print('before:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather', \n",
    "                                                                                  transform=EegDropChannels(channel_ekg))\n",
    "print('after:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: (21, 173000)\n",
      "[[ -1  -4 -35 ... -20 -16 -11]\n",
      " [ 11  18 -31 ...  -1   3   6]\n",
      " [ 18  30  -7 ...  -4  -1   0]\n",
      " ...\n",
      " [ 20  33 -12 ...   2   4   4]\n",
      " [ 91 138  23 ...  13  16  21]\n",
      " [  0  -1  -1 ...   0   0   0]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "after: (20, 173000)\n",
      "[[ -1  -4 -35 ... -20 -16 -11]\n",
      " [ 11  18 -31 ...  -1   3   6]\n",
      " [ 18  30  -7 ...  -4  -1   0]\n",
      " ...\n",
      " [ 22  38   0 ... -13 -10 -10]\n",
      " [ 20  33 -12 ...   2   4   4]\n",
      " [ 91 138  23 ...  13  16  21]]\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=None)\n",
    "print('before:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=EegDropChannels(channel_photic))\n",
    "print('after:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: (21, 173000)\n",
      "[[ -1  -4 -35 ... -20 -16 -11]\n",
      " [ 11  18 -31 ...  -1   3   6]\n",
      " [ 18  30  -7 ...  -4  -1   0]\n",
      " ...\n",
      " [ 20  33 -12 ...   2   4   4]\n",
      " [ 91 138  23 ...  13  16  21]\n",
      " [  0  -1  -1 ...   0   0   0]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "after: (19, 173000)\n",
      "[[ -1  -4 -35 ... -20 -16 -11]\n",
      " [ 11  18 -31 ...  -1   3   6]\n",
      " [ 18  30  -7 ...  -4  -1   0]\n",
      " ...\n",
      " [ 13  20 -17 ...  -5   1   3]\n",
      " [ 22  38   0 ... -13 -10 -10]\n",
      " [ 20  33 -12 ...   2   4   4]]\n"
     ]
    }
   ],
   "source": [
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=None)\n",
    "print('before:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=EegDropChannels([channel_ekg, channel_photic]))\n",
    "print('after:', train_dataset[0]['signal'].shape)\n",
    "print(train_dataset[0]['signal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "{'age': 78,\n",
      " 'serial': '00001',\n",
      " 'signal': array([[  0, -11, -13, ...,  18,  21,  22],\n",
      "       [ 29,  33,  34, ...,  -7,  -4,  -4],\n",
      "       [ -3,  -6,  -3, ...,  -1,   1,   2],\n",
      "       ...,\n",
      "       [ -4,  -2,   1, ...,   0,  -1,  -1],\n",
      "       [112,  67,  76, ..., -13, -15, -11],\n",
      "       [ -1,  -1,  -1, ...,  -1,  -1,  -1]]),\n",
      " 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf']}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "After:\n",
      "{'age': tensor(78.),\n",
      " 'serial': '00001',\n",
      " 'signal': tensor([[  0., -11., -13.,  ...,  18.,  21.,  22.],\n",
      "        [ 29.,  33.,  34.,  ...,  -7.,  -4.,  -4.],\n",
      "        [ -3.,  -6.,  -3.,  ...,  -1.,   1.,   2.],\n",
      "        ...,\n",
      "        [ -4.,  -2.,   1.,  ...,   0.,  -1.,  -1.],\n",
      "        [112.,  67.,  76.,  ..., -13., -15., -11.],\n",
      "        [ -1.,  -1.,  -1.,  ...,  -1.,  -1.,  -1.]]),\n",
      " 'symptom': ['mci', 'mci_amnestic', 'mci_amnestic_rf']}\n"
     ]
    }
   ],
   "source": [
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         load_event=False, \n",
    "                                                         file_format='feather',\n",
    "                                                         transform=None)\n",
    "print('Before:')\n",
    "pprint.pprint(full_eeg_dataset[0])\n",
    "\n",
    "print()\n",
    "print('-' * 100)\n",
    "print()\n",
    "\n",
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         load_event=False, \n",
    "                                                         file_format='feather',\n",
    "                                                         transform=EegToTensor())\n",
    "print('After:')\n",
    "pprint.pprint(full_eeg_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compose the above all in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': tensor(88.),\n",
      " 'class_label': tensor(2),\n",
      " 'class_name': 'Dementia',\n",
      " 'serial': '01379',\n",
      " 'signal': [tensor([[ -20.,  -27.,  -31.,  ...,  -28.,  -29.,  -29.],\n",
      "        [ -11.,  -16.,  -17.,  ...,   23.,   24.,   26.],\n",
      "        [   3.,    6.,    6.,  ...,  -10.,   -6.,   -2.],\n",
      "        ...,\n",
      "        [  -2.,    1.,    2.,  ...,   12.,   11.,   14.],\n",
      "        [  -7.,   -7.,   -7.,  ...,   -1.,    1.,    2.],\n",
      "        [  61.,  -75., -281.,  ..., -510., -517., -368.]]),\n",
      "            tensor([[13., 15., 15.,  ..., 37., 38., 37.],\n",
      "        [ 6., 11., 12.,  ..., 26., 28., 31.],\n",
      "        [-1.,  2.,  2.,  ..., -4.,  1.,  4.],\n",
      "        ...,\n",
      "        [20., 22., 19.,  ..., -5.,  0.,  6.],\n",
      "        [ 8.,  7.,  2.,  ..., -7., -4., -6.],\n",
      "        [47., 52., 50.,  ..., 22., 36., 42.]]),\n",
      "            tensor([[-55., -54., -55.,  ..., -14., -12.,  -7.],\n",
      "        [ 51.,  50.,  47.,  ...,  14.,  18.,  25.],\n",
      "        [  2.,  -3., -10.,  ...,  -5.,  -2.,   1.],\n",
      "        ...,\n",
      "        [ 14.,  13.,   8.,  ...,   2.,   3.,   6.],\n",
      "        [  4.,   2.,  -1.,  ...,  10.,   7.,   6.],\n",
      "        [ 27.,  23.,  20.,  ..., 144., 152., 167.]]),\n",
      "            tensor([[ 39.,  38.,  43.,  ...,   7.,   7.,  11.],\n",
      "        [-24., -22., -16.,  ..., -16., -15., -12.],\n",
      "        [ 18.,  20.,  25.,  ...,  -1.,  -1.,  -2.],\n",
      "        ...,\n",
      "        [  7.,   9.,  12.,  ...,   4.,   1.,   1.],\n",
      "        [ 19.,  20.,  20.,  ...,   6.,   3.,   2.],\n",
      "        [ 14.,  14.,  20.,  ...,   4.,  -1.,   0.]])],\n",
      " 'symptom': ['dementia', 'ad', 'load']}\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*10,       # crop: 10s\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=4, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "pprint.pprint(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == 'cuda':\n",
    "    num_workers = 0  # A number other than 0 causes an error\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': tensor([70., 70., 79., 79., 83., 83., 67., 67.]),\n",
      " 'serial': ['00389',\n",
      "            '00389',\n",
      "            '00723',\n",
      "            '00723',\n",
      "            '01035',\n",
      "            '01035',\n",
      "            '00939',\n",
      "            '00939'],\n",
      " 'signal': tensor([[[ 13.,   7.,  14.,  ..., -10.,  24.,  45.],\n",
      "         [  9.,   4.,   6.,  ...,  15.,  16.,   6.],\n",
      "         [ -2.,  -6.,  -9.,  ...,   0.,  -1.,   2.],\n",
      "         ...,\n",
      "         [  2.,  -1.,  -3.,  ...,  -2.,  -5.,   0.],\n",
      "         [ -1.,  -1.,   0.,  ...,  -5., -11.,  -6.],\n",
      "         [-45., -45., -41.,  ...,  -6., -11., -15.]],\n",
      "\n",
      "        [[ -6., -12., -10.,  ..., -33., -35., -36.],\n",
      "         [  6.,   6.,   5.,  ..., -20., -20., -17.],\n",
      "         [  5.,   6.,   7.,  ...,   5.,  -2.,  -7.],\n",
      "         ...,\n",
      "         [  9.,  11.,  12.,  ...,  -3.,  -7.,  -7.],\n",
      "         [ 15.,  15.,  16.,  ...,  22.,  21.,  15.],\n",
      "         [-66., -72., -78.,  ...,  78.,  83.,  85.]],\n",
      "\n",
      "        [[-36., -31., -27.,  ...,  15.,  15.,  16.],\n",
      "         [-11., -11., -10.,  ...,  -3.,  -5.,  -5.],\n",
      "         [  2.,  -4.,  -5.,  ...,  -3.,  -4.,  -5.],\n",
      "         ...,\n",
      "         [  4.,   4.,   5.,  ...,  -7.,  -8.,  -9.],\n",
      "         [  4.,   4.,   5.,  ...,  -3.,  -2.,  -1.],\n",
      "         [ 43.,  48.,  47.,  ...,  24.,  17.,  27.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  3.,   8.,   8.,  ...,  25.,  20.,  20.],\n",
      "         [  3.,   5.,   6.,  ..., -19., -21., -20.],\n",
      "         [  3.,   2.,   4.,  ...,  -8., -11., -14.],\n",
      "         ...,\n",
      "         [  2.,  -1.,  -1.,  ...,   4.,   4.,   3.],\n",
      "         [ 29.,  27.,  27.,  ...,  -3.,  -4.,  -5.],\n",
      "         [279., 151.,  41.,  ..., -88., -77., -82.]],\n",
      "\n",
      "        [[ 57.,  58.,  55.,  ...,  11.,  15.,  20.],\n",
      "         [ 57.,  59.,  61.,  ..., -19., -15., -13.],\n",
      "         [ 19.,  22.,  25.,  ...,  -1.,   0.,  -2.],\n",
      "         ...,\n",
      "         [  0.,   2.,   5.,  ...,  -7.,  -8.,  -8.],\n",
      "         [-10.,  -8.,  -7.,  ..., -10., -11., -11.],\n",
      "         [ 32.,  27.,  24.,  ..., 126.,  87.,  92.]],\n",
      "\n",
      "        [[283., 276., 258.,  ..., -52., -52., -53.],\n",
      "         [ 36.,  35.,  33.,  ..., -17., -17., -18.],\n",
      "         [  4.,   8.,  11.,  ...,   5.,   5.,   5.],\n",
      "         ...,\n",
      "         [ -6.,  -4.,  -3.,  ...,  -1.,  -4.,  -7.],\n",
      "         [ -4.,  -4.,  -4.,  ...,   8.,   8.,   7.],\n",
      "         [ 68.,  69.,  84.,  ..., -51., -57., -25.]]]),\n",
      " 'symptom': [['mci', 'mci_amnestic'],\n",
      "             ['mci', 'mci_amnestic'],\n",
      "             ['dementia', 'vd', 'sivd'],\n",
      "             ['dementia', 'vd', 'sivd'],\n",
      "             ['dementia', 'ad', 'load'],\n",
      "             ['dementia', 'ad', 'load'],\n",
      "             ['normal', 'smi'],\n",
      "             ['normal', 'smi']]}\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*10,       # crop: 10s\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=2, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "\n",
    "config_data, full_eeg_dataset = load_caueeg_full_dataset(dataset_path=data_path, \n",
    "                                                         load_event=False, \n",
    "                                                         file_format='memmap',\n",
    "                                                         transform=transform)\n",
    "\n",
    "full_loader = DataLoader(full_eeg_dataset,\n",
    "                         batch_size=4,\n",
    "                         shuffle=True,\n",
    "                         drop_last=True,\n",
    "                         num_workers=num_workers,\n",
    "                         pin_memory=pin_memory,\n",
    "                         collate_fn=eeg_collate_fn)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(full_loader):\n",
    "    pprint.pprint(sample_batched)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': tensor([85., 85., 73., 73., 92., 92., 73., 73., 66., 66., 75., 75., 61., 61.,\n",
      "        84., 84.]),\n",
      " 'class_label': tensor([2, 2, 0, 0, 2, 2, 1, 1, 0, 0, 1, 1, 0, 0, 2, 2]),\n",
      " 'class_name': ['Dementia', 'Dementia', 'Normal', 'Normal', 'Dementia', 'Dementia', 'MCI', 'MCI', 'Normal', 'Normal', 'MCI', 'MCI', 'Normal', 'Normal', 'Dementia', 'Dementia'],\n",
      " 'serial': ['00630', '00630', '00903', '00903', '01128', '01128', '00091', '00091', '00704', '00704', '00811', '00811', '00767', '00767', '00039', '00039'],\n",
      " 'signal': tensor([[[-22., -25., -25.,  ...,  28.,  23.,  36.],\n",
      "         [-18., -17., -11.,  ...,  17.,  16.,  11.],\n",
      "         [  9.,  11.,  11.,  ...,   9.,   9.,  10.],\n",
      "         ...,\n",
      "         [ 14.,   9.,   5.,  ...,  -6.,  -6.,  -9.],\n",
      "         [ 14.,  13.,  14.,  ..., -11., -12., -12.],\n",
      "         [ -9.,  -2.,   4.,  ...,  12.,  12.,  19.]],\n",
      "\n",
      "        [[  2.,   3.,   6.,  ..., -13., -13., -14.],\n",
      "         [ 12.,  14.,  18.,  ..., -11., -12., -11.],\n",
      "         [  1.,   2.,   5.,  ...,   1.,   0.,   0.],\n",
      "         ...,\n",
      "         [  7.,   9.,  10.,  ..., -15., -13., -13.],\n",
      "         [-15., -10.,  -7.,  ...,  -5.,  -2.,  -2.],\n",
      "         [-73., -54., -31.,  ...,  24.,  91., 124.]],\n",
      "\n",
      "        [[ 14.,  13.,  12.,  ...,  10.,  10.,  10.],\n",
      "         [ 11.,   9.,  10.,  ...,   1.,   5.,   3.],\n",
      "         [  5.,   1.,  -1.,  ...,   9.,  12.,  12.],\n",
      "         ...,\n",
      "         [  4.,   1.,  -3.,  ...,  12.,  11.,   8.],\n",
      "         [  0.,  -1.,  -3.,  ...,   9.,   7.,   5.],\n",
      "         [ 31.,  29.,  26.,  ...,  -7.,  -7.,  -5.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-34., -35., -30.,  ...,  37.,  27.,  16.],\n",
      "         [-25., -21., -10.,  ..., -22., -25., -28.],\n",
      "         [ 10.,   2., -19.,  ...,   1.,  12.,   4.],\n",
      "         ...,\n",
      "         [  0.,  -3.,  -4.,  ...,   0.,   1.,   1.],\n",
      "         [ -4., -10., -14.,  ...,   5.,   6.,   5.],\n",
      "         [ 13.,  36., -26.,  ...,  38.,  10., -25.]],\n",
      "\n",
      "        [[  7.,  10.,  13.,  ...,   4.,   1.,   0.],\n",
      "         [  5.,   6.,   8.,  ...,  -3.,  -5.,  -4.],\n",
      "         [ 12.,  13.,  12.,  ...,  -2.,  -2.,  -1.],\n",
      "         ...,\n",
      "         [ -2.,  -3.,  -3.,  ...,   1.,   0.,   0.],\n",
      "         [-12., -13., -13.,  ...,  -5.,  -4.,  -4.],\n",
      "         [-55., -16.,  40.,  ...,  -2.,   1.,  47.]],\n",
      "\n",
      "        [[  0.,  -1.,  -3.,  ...,  -1.,  -2.,  -5.],\n",
      "         [ 10.,   4.,   2.,  ...,   2.,  -1.,  -1.],\n",
      "         [  1.,   0.,   0.,  ...,   4.,   4.,   4.],\n",
      "         ...,\n",
      "         [ -4.,  -4.,  -5.,  ...,  -6.,  -6.,  -6.],\n",
      "         [ -5.,  -5.,  -6.,  ...,  14.,  13.,  14.],\n",
      "         [105., 102.,  74.,  ...,  22.,   6.,  -8.]]]),\n",
      " 'symptom': [['dementia', 'ad', 'load'],\n",
      "             ['dementia', 'ad', 'load'],\n",
      "             ['normal', 'cb_normal'],\n",
      "             ['normal', 'cb_normal'],\n",
      "             ['dementia', 'ad', 'load'],\n",
      "             ['dementia', 'ad', 'load'],\n",
      "             ['mci', 'mci_amnestic', 'mci_amnestic_ef'],\n",
      "             ['mci', 'mci_amnestic', 'mci_amnestic_ef'],\n",
      "             ['normal', 'smi'],\n",
      "             ['normal', 'smi'],\n",
      "             ['mci', 'mci_non_amnestic'],\n",
      "             ['mci', 'mci_non_amnestic'],\n",
      "             ['normal', 'cb_normal'],\n",
      "             ['normal', 'cb_normal'],\n",
      "             ['dementia', 'ad', 'load'],\n",
      "             ['dementia', 'ad', 'load']]}\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*10,       # crop: 10s\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=2, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task1',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=8,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    pprint.pprint(sample_batched, width=250)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Preprocessing steps run by the PyTorch Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*10,       # crop: 10s\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=2, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=2,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To GPU device if it is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      ")\n",
      "- Before -\n",
      "{'age': tensor([73., 73., 76., 76.]),\n",
      " 'class_label': tensor([0, 0, 1, 1]),\n",
      " 'class_name': ['Normal', 'Normal', 'Abnormal', 'Abnormal'],\n",
      " 'serial': ['00086', '00086', '00218', '00218'],\n",
      " 'signal': tensor([[[ -4.,  -2.,  -2.,  ...,  10.,   7.,   4.],\n",
      "         [-15., -16., -17.,  ..., -33., -36., -38.],\n",
      "         [-18., -15., -13.,  ...,   7.,   1.,  -1.],\n",
      "         ...,\n",
      "         [-10., -12., -12.,  ..., -26., -27., -31.],\n",
      "         [  1.,   1.,   3.,  ...,   0.,   0.,  -2.],\n",
      "         [-24.,  44., -41.,  ..., -52., -17.,  45.]],\n",
      "\n",
      "        [[ -7.,  -9., -14.,  ...,  -5., -10., -13.],\n",
      "         [-12., -16., -20.,  ...,  -4.,  -7.,  -8.],\n",
      "         [ 12.,  12.,  13.,  ...,  -1.,  -2.,  -3.],\n",
      "         ...,\n",
      "         [  0.,  -6., -12.,  ...,  -3.,  -4.,  -4.],\n",
      "         [  9.,  11.,  11.,  ...,  -3.,  -1.,   0.],\n",
      "         [-40., -12.,  54.,  ..., -49.,  13.,   0.]],\n",
      "\n",
      "        [[  1.,  -2.,   1.,  ..., -37., -32., -43.],\n",
      "         [-38., -35., -33.,  ..., -16., -15., -11.],\n",
      "         [  1.,   0.,   3.,  ...,   8.,   5.,   6.],\n",
      "         ...,\n",
      "         [ -7.,  -6.,  -4.,  ...,   8.,   7.,   5.],\n",
      "         [ 10.,  11.,  11.,  ...,   8.,  11.,  11.],\n",
      "         [ 22., -15., -43.,  ...,  64., -12., -11.]],\n",
      "\n",
      "        [[-15., -11., -10.,  ..., -17., -17., -11.],\n",
      "         [  3.,   4.,   2.,  ...,   1.,  -1.,   0.],\n",
      "         [ -1.,  -3.,  -3.,  ...,   7.,   4.,   2.],\n",
      "         ...,\n",
      "         [  2.,   3.,   5.,  ...,  -1.,  -5.,  -9.],\n",
      "         [  1.,   1.,   1.,  ..., -17., -18., -21.],\n",
      "         [-25.,  56.,  23.,  ..., -58.,   6.,  30.]]]),\n",
      " 'symptom': [['normal', 'cb_normal'],\n",
      "             ['normal', 'cb_normal'],\n",
      "             ['mci', 'mci_vascular'],\n",
      "             ['mci', 'mci_vascular']]}\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "{'age': tensor([73., 73., 76., 76.], device='cuda:0'),\n",
      " 'class_label': tensor([0, 0, 1, 1], device='cuda:0'),\n",
      " 'class_name': ['Normal', 'Normal', 'Abnormal', 'Abnormal'],\n",
      " 'serial': ['00086', '00086', '00218', '00218'],\n",
      " 'signal': tensor([[[ -4.,  -2.,  -2.,  ...,  10.,   7.,   4.],\n",
      "         [-15., -16., -17.,  ..., -33., -36., -38.],\n",
      "         [-18., -15., -13.,  ...,   7.,   1.,  -1.],\n",
      "         ...,\n",
      "         [-10., -12., -12.,  ..., -26., -27., -31.],\n",
      "         [  1.,   1.,   3.,  ...,   0.,   0.,  -2.],\n",
      "         [-24.,  44., -41.,  ..., -52., -17.,  45.]],\n",
      "\n",
      "        [[ -7.,  -9., -14.,  ...,  -5., -10., -13.],\n",
      "         [-12., -16., -20.,  ...,  -4.,  -7.,  -8.],\n",
      "         [ 12.,  12.,  13.,  ...,  -1.,  -2.,  -3.],\n",
      "         ...,\n",
      "         [  0.,  -6., -12.,  ...,  -3.,  -4.,  -4.],\n",
      "         [  9.,  11.,  11.,  ...,  -3.,  -1.,   0.],\n",
      "         [-40., -12.,  54.,  ..., -49.,  13.,   0.]],\n",
      "\n",
      "        [[  1.,  -2.,   1.,  ..., -37., -32., -43.],\n",
      "         [-38., -35., -33.,  ..., -16., -15., -11.],\n",
      "         [  1.,   0.,   3.,  ...,   8.,   5.,   6.],\n",
      "         ...,\n",
      "         [ -7.,  -6.,  -4.,  ...,   8.,   7.,   5.],\n",
      "         [ 10.,  11.,  11.,  ...,   8.,  11.,  11.],\n",
      "         [ 22., -15., -43.,  ...,  64., -12., -11.]],\n",
      "\n",
      "        [[-15., -11., -10.,  ..., -17., -17., -11.],\n",
      "         [  3.,   4.,   2.,  ...,   1.,  -1.,   0.],\n",
      "         [ -1.,  -3.,  -3.,  ...,   7.,   4.,   2.],\n",
      "         ...,\n",
      "         [  2.,   3.,   5.,  ...,  -1.,  -5.,  -9.],\n",
      "         [  1.,   1.,   1.,  ..., -17., -18., -21.],\n",
      "         [-25.,  56.,  23.,  ..., -58.,   6.,  30.]]], device='cuda:0'),\n",
      " 'symptom': [['normal', 'cb_normal'],\n",
      "             ['normal', 'cb_normal'],\n",
      "             ['mci', 'mci_vascular'],\n",
      "             ['mci', 'mci_vascular']]}\n"
     ]
    }
   ],
   "source": [
    "print('device:', device)\n",
    "print()\n",
    "\n",
    "preprocess_train = transforms.Compose([EegToDevice(device=device)])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    pprint.pprint(sample_batched)\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    pprint.pprint(sample_batched)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization per signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizePerSignal(eps=1e-08)\n",
      ")\n",
      "- Before -\n",
      "Mean: tensor([[-3.4385, -6.0560, -0.6960, -0.1600,  0.4090, -4.8755, -1.3905, -1.3640,\n",
      "         -0.1860,  0.5235,  1.2925, -0.0290,  0.2905,  1.5840, -2.2205,  0.6550,\n",
      "          6.2580,  2.0415, -0.9345, -0.2405],\n",
      "        [ 2.4240,  3.6905, -0.5770, -0.3915, -0.2865, -2.7200, -0.5115,  0.8420,\n",
      "         -0.5460, -0.0955,  0.1885, -1.9045,  0.3300, -2.4885,  2.3225,  0.0200,\n",
      "          1.9420, -2.5160, -0.0480,  0.0365],\n",
      "        [ 2.0325,  1.3565, -0.5185, -0.2350, -0.2260,  1.4070,  2.4470, -1.9080,\n",
      "          0.5040,  0.5730, -0.4885,  0.6505,  1.3050, -3.2440, -1.8865,  1.0555,\n",
      "         -0.9300,  2.0435, -0.4770,  0.2650],\n",
      "        [-2.3570,  2.4550, -0.3360,  0.0635, -0.4625, -5.5255, -1.3445,  1.5420,\n",
      "          0.0700, -0.4360, -4.1820,  0.4955, -0.4190, -1.8970,  2.6785, -0.2130,\n",
      "          0.6095,  1.1950,  0.1090,  1.0620]])\n",
      "\n",
      "Std: tensor([[ 63.7045,  20.2194,  10.6914,   8.9998,  10.3299,  55.8929,  15.1064,\n",
      "           8.1612,   8.2922,  11.5281,  14.2208,   8.5956,   8.5024,  50.4837,\n",
      "          21.3904,  10.9111,  51.4776,   7.1610,   7.9652,  72.8450],\n",
      "        [ 82.2619,  22.7691,   9.2632,   9.7134,  13.9569,  78.2907,  15.6571,\n",
      "           8.2655,   8.5094,  14.3694,  21.1820,  11.8924,  12.4079,  38.6229,\n",
      "          38.8997,  11.2858,  37.4547,   8.0043,   7.7652,  74.8616],\n",
      "        [ 22.8800,   9.2341,   6.4502,   6.5270,   8.1772,  15.2308,   7.2665,\n",
      "           5.8904,   6.4349,   9.2261,  10.1212,   6.5196,   6.7522,  20.9067,\n",
      "           9.3469,   7.8732,   8.9910,  11.4050,   5.9218, 104.9655],\n",
      "        [ 51.7128,  25.2578,   7.9298,   8.2336,  10.3075,  81.4930,  15.2314,\n",
      "           7.5947,   7.9857,  11.6549,  19.3191,  10.9511,  10.2167,  12.8547,\n",
      "          16.3262,  10.6086,  20.3311,  10.1194,   7.1938, 105.1054]])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "Mean: tensor([[ 6.1989e-09, -1.9073e-09, -1.1921e-09, -2.1935e-08, -1.3351e-08,\n",
      "          6.4373e-09, -1.3828e-08,  5.2452e-09,  4.7684e-09, -4.7684e-09,\n",
      "          1.9073e-08,  1.7166e-08,  6.6757e-09,  6.6757e-09, -1.4305e-08,\n",
      "          1.3828e-08, -4.2915e-09, -4.1008e-08,  7.6294e-09,  1.1444e-08],\n",
      "        [ 1.5259e-08,  8.5831e-09, -1.0014e-08,  1.7166e-08,  1.1444e-08,\n",
      "          1.1444e-08, -1.9073e-09,  4.7684e-09, -1.8597e-08,  1.4305e-08,\n",
      "          7.6294e-09, -9.5367e-09,  3.8147e-09,  0.0000e+00,  9.5367e-09,\n",
      "          6.6757e-09, -1.5259e-08,  5.0545e-08,  1.1444e-08,  5.7220e-09],\n",
      "        [-3.8147e-09,  3.8147e-09, -7.6294e-09, -5.7220e-09, -1.7166e-08,\n",
      "          1.3351e-08, -1.9073e-08, -1.9073e-09, -3.8147e-09,  1.4305e-08,\n",
      "         -1.1444e-08, -3.8147e-09,  5.7220e-09, -2.1935e-08,  1.7166e-08,\n",
      "         -6.6757e-09,  7.6294e-09, -1.4305e-08,  1.3351e-08, -7.6294e-09],\n",
      "        [-1.9073e-09, -1.5259e-08,  1.5259e-08, -5.7220e-09, -7.6294e-09,\n",
      "         -5.7220e-09, -5.7220e-09,  1.5259e-08,  7.6294e-09,  5.7220e-09,\n",
      "         -2.8849e-08,  1.9073e-09,  1.9073e-09, -3.8147e-09, -4.0531e-08,\n",
      "          0.0000e+00, -1.3351e-08,  2.7657e-08, -7.6294e-09, -1.1444e-08]],\n",
      "       device='cuda:0')\n",
      "\n",
      "Std: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizePerSignal()\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal normalization using the specified mean and std values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and standard deviation for signal:\n",
      "tensor([[[ 0.2844],\n",
      "         [ 0.2253],\n",
      "         [-0.0821],\n",
      "         [ 0.0339],\n",
      "         [-0.0259],\n",
      "         [ 0.4161],\n",
      "         [ 0.1093],\n",
      "         [-0.0760],\n",
      "         [-0.1932],\n",
      "         [-0.1694],\n",
      "         [-0.0005],\n",
      "         [ 0.0662],\n",
      "         [-0.0377],\n",
      "         [ 0.1298],\n",
      "         [-0.2924],\n",
      "         [-0.1287],\n",
      "         [ 0.2746],\n",
      "         [ 0.0489],\n",
      "         [-0.0198],\n",
      "         [-0.0386]]])\n",
      "-\n",
      "tensor([[[44.3354],\n",
      "         [19.7560],\n",
      "         [11.2161],\n",
      "         [10.9679],\n",
      "         [15.1231],\n",
      "         [45.9360],\n",
      "         [19.8389],\n",
      "         [10.3051],\n",
      "         [11.4575],\n",
      "         [15.2745],\n",
      "         [20.2380],\n",
      "         [13.9408],\n",
      "         [12.9799],\n",
      "         [21.6595],\n",
      "         [17.7961],\n",
      "         [14.4634],\n",
      "         [19.4985],\n",
      "         [10.7546],\n",
      "         [10.9364],\n",
      "         [96.2515]]])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeMeanStd(mean=tensor([ 0.2844,  0.2253, -0.0821,  0.0339, -0.0259,  0.4161,  0.1093, -0.0760,\n",
      "          -0.1932, -0.1694, -0.0005,  0.0662, -0.0377,  0.1298, -0.2924, -0.1287,\n",
      "           0.2746,  0.0489, -0.0198, -0.0386]),std=tensor([44.3354, 19.7560, 11.2161, 10.9679, 15.1231, 45.9360, 19.8389, 10.3051,\n",
      "          11.4575, 15.2745, 20.2380, 13.9408, 12.9799, 21.6595, 17.7961, 14.4634,\n",
      "          19.4985, 10.7546, 10.9364, 96.2515]),eps=1e-08)\n",
      ")\n",
      "- Before -\n",
      "Mean: tensor([[ 0.5190, -0.9710, -0.6520,  0.1590,  1.4935,  0.6495, -0.7250, -0.4025,\n",
      "         -0.8475, -0.3585,  1.0275,  0.5075,  0.0245,  0.4180, -0.3190, -0.0850,\n",
      "          0.0745,  0.3545,  0.2705, -0.0995],\n",
      "        [ 0.3475,  0.3815,  0.9165,  0.5980, -1.3810, -0.6480, -0.3490,  0.3285,\n",
      "         -0.5155, -0.0300, -0.8800, -1.7450,  0.3405,  0.6630,  0.4005,  0.6405,\n",
      "          0.2175,  0.4950, -0.0565, -0.9085],\n",
      "        [ 2.4690, -0.1905, -3.4825,  1.0540, -4.4325,  8.0510,  6.3060, -1.4490,\n",
      "         -0.9130, -4.1945,  0.8620, -3.5585,  1.1490, 11.6050, -0.8125, -2.9150,\n",
      "         -0.1620,  2.3585, -1.2105,  0.1505],\n",
      "        [ 3.1500, -0.8735, -1.2950,  0.5830, -0.9960,  2.3935,  1.2750, -0.1425,\n",
      "         -0.2305, -0.8345,  2.0555,  0.9665, -0.4980, -0.7440, -0.0750, -1.2895,\n",
      "          3.9895, -1.2580, -0.6465,  0.1265]])\n",
      "\n",
      "Std: tensor([[ 14.2373,   6.0023,   4.7736,   5.7428,   8.6632,  17.1610,   6.2454,\n",
      "           4.1577,   5.5502,   8.0190,   8.8805,   6.0130,   6.5263,   9.1036,\n",
      "           6.0786,   7.6569,   5.6597,   6.0670,   5.4973, 160.4289],\n",
      "        [ 15.5557,   6.7506,   6.0464,   6.4521,  11.0630,  15.2482,   7.1171,\n",
      "           5.6148,   6.0500,  11.5415,   9.5467,  11.1362,   8.2609,   8.7358,\n",
      "           5.9394,   7.8299,   7.7240,   7.6559,   7.3550, 154.8697],\n",
      "        [ 25.0260,  16.7401,  11.8724,  14.0522,  25.3956,  30.7612,  19.1787,\n",
      "           9.7923,  12.2979,  14.8022,  35.6147,  17.2532,  26.2648,  20.1138,\n",
      "          14.5657,  24.2722,  16.1245,  13.3743,  12.5399,  78.0922],\n",
      "        [ 28.6815,  19.3381,  14.7029,  11.5243,  12.9919,  29.3782,  17.1712,\n",
      "          10.3133,  11.9227,  13.4263,  23.2461,  19.1608,  12.9777,  20.9889,\n",
      "          16.8546,  12.9039,  22.1776,  11.8289,  11.6947,  78.4288]])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "Mean: tensor([[ 0.0053, -0.0606, -0.0508,  0.0114,  0.1005,  0.0051, -0.0421, -0.0317,\n",
      "         -0.0571, -0.0124,  0.0508,  0.0317,  0.0048,  0.0133, -0.0015,  0.0030,\n",
      "         -0.0103,  0.0284,  0.0265, -0.0006],\n",
      "        [ 0.0014,  0.0079,  0.0890,  0.0514, -0.0896, -0.0232, -0.0231,  0.0393,\n",
      "         -0.0281,  0.0091, -0.0435, -0.1299,  0.0291,  0.0246,  0.0389,  0.0532,\n",
      "         -0.0029,  0.0415, -0.0034, -0.0090],\n",
      "        [ 0.0493, -0.0210, -0.3032,  0.0930, -0.2914,  0.1662,  0.3124, -0.1332,\n",
      "         -0.0628, -0.2635,  0.0426, -0.2600,  0.0914,  0.5298, -0.0292, -0.1926,\n",
      "         -0.0224,  0.2148, -0.1089,  0.0020],\n",
      "        [ 0.0646, -0.0556, -0.1081,  0.0501, -0.0641,  0.0430,  0.0588, -0.0065,\n",
      "         -0.0033, -0.0435,  0.1016,  0.0646, -0.0355, -0.0403,  0.0122, -0.0803,\n",
      "          0.1905, -0.1215, -0.0573,  0.0017]], device='cuda:0')\n",
      "\n",
      "Std: tensor([[0.3211, 0.3038, 0.4256, 0.5236, 0.5728, 0.3736, 0.3148, 0.4035, 0.4844,\n",
      "         0.5250, 0.4388, 0.4313, 0.5028, 0.4203, 0.3416, 0.5294, 0.2903, 0.5641,\n",
      "         0.5027, 1.6668],\n",
      "        [0.3509, 0.3417, 0.5391, 0.5883, 0.7315, 0.3319, 0.3587, 0.5449, 0.5280,\n",
      "         0.7556, 0.4717, 0.7988, 0.6364, 0.4033, 0.3337, 0.5414, 0.3961, 0.7119,\n",
      "         0.6725, 1.6090],\n",
      "        [0.5645, 0.8473, 1.0585, 1.2812, 1.6793, 0.6697, 0.9667, 0.9502, 1.0733,\n",
      "         0.9691, 1.7598, 1.2376, 2.0235, 0.9286, 0.8185, 1.6782, 0.8270, 1.2436,\n",
      "         1.1466, 0.8113],\n",
      "        [0.6469, 0.9788, 1.3109, 1.0507, 0.8591, 0.6395, 0.8655, 1.0008, 1.0406,\n",
      "         0.8790, 1.1486, 1.3744, 0.9998, 0.9690, 0.9471, 0.8922, 1.1374, 1.0999,\n",
      "         1.0693, 0.8148]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "signal_mean, signal_std = calculate_signal_statistics(train_loader, repeats=1, verbose=True)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age mean and standard deviation:\n",
      "tensor([70.6000]) tensor([6.2312])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6000]),std=tensor([6.2312]),eps=1e-08)\n",
      ")\n",
      "- Before -\n",
      "tensor([69., 69., 65., 65.])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "tensor([-0.2568, -0.2568, -0.8987, -0.8987], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "age_mean, age_std = calculate_age_statistics(train_loader, verbose=True)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    pprint.pprint(sample_batched['age'])\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    pprint.pprint(sample_batched['age'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short time Fourier transform (STFT or spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegSpectrogram(n_fft=200, complex_mode=as_real, stft_kwargs={})\n",
      ")\n",
      "- Before -\n",
      "torch.Size([4, 20, 2000])\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "torch.Size([4, 40, 101, 41])\n"
     ]
    }
   ],
   "source": [
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegSpectrogram(n_fft=200, complex_mode='as_real')\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    pprint.pprint(sample_batched['signal'].shape)\n",
    "\n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    preprocess_train(sample_batched)\n",
    "    \n",
    "    print('- After -')\n",
    "    pprint.pprint(sample_batched['signal'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal normalization after STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegSpectrogram(n_fft=200, complex_mode=as_real, stft_kwargs={})\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegNormalizeMeanStd(mean=tensor([[ 4.9821e+01,  1.4474e+00, -7.2085e-02,  ...,  9.7853e-02,\n",
      "            1.0077e-01,  9.0708e-02],\n",
      "          [ 9.2374e+00,  1.0931e-01,  1.5210e-01,  ...,  4.1250e-02,\n",
      "            4.1423e-02,  5.0705e-02],\n",
      "          [-1.6948e+00,  2.6213e-01, -1.0001e-01,  ...,  7.0841e-03,\n",
      "            7.5616e-03, -1.3990e-02],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  4.0039e-01,  2.2454e-01,  ..., -2.7715e-04,\n",
      "           -1.2458e-03, -1.4335e-08],\n",
      "          [ 0.0000e+00,  7.9169e-01,  4.4377e-01,  ...,  1.3421e-03,\n",
      "            2.7339e-03, -2.6603e-09],\n",
      "          [ 0.0000e+00, -1.8461e+00, -5.4384e-01,  ..., -8.0143e-04,\n",
      "           -1.3102e-03, -8.9033e-08]], device='cuda:0'),std=tensor([[7.4402e+03, 1.5207e+03, 8.0498e+02,  ..., 2.9127e+01, 2.9083e+01,\n",
      "           2.9303e+01],\n",
      "          [3.2419e+03, 5.8653e+02, 3.0239e+02,  ..., 1.3144e+01, 1.3098e+01,\n",
      "           1.3485e+01],\n",
      "          [1.7581e+03, 2.8439e+02, 1.5336e+02,  ..., 7.9609e+00, 7.9001e+00,\n",
      "           8.4914e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 4.4324e+02, 2.4112e+02,  ..., 2.7851e+00, 2.8783e+00,\n",
      "           3.2303e-06],\n",
      "          [0.0000e+00, 4.6529e+02, 2.5416e+02,  ..., 2.7922e+00, 2.8774e+00,\n",
      "           3.1318e-06],\n",
      "          [0.0000e+00, 2.0903e+03, 1.9913e+03,  ..., 3.6812e+00, 4.6927e+00,\n",
      "           6.0485e-05]], device='cuda:0'),eps=1e-08)\n",
      ")\n",
      "- Before -\n",
      "Mean: tensor([[[ 1.2676e+02, -9.3148e+01,  4.6670e+01,  ..., -1.3690e+00,\n",
      "          -1.4485e+00, -7.5610e-01],\n",
      "         [-3.6166e+02, -1.6275e+01,  1.4349e+01,  ..., -1.7796e+00,\n",
      "          -1.8479e+00, -9.7561e-01],\n",
      "         [-8.3878e+02, -1.9699e+01, -5.4679e+00,  ..., -1.2869e+00,\n",
      "          -1.1335e+00, -1.2683e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  6.8301e+01,  3.2035e+01,  ...,  7.7738e-02,\n",
      "           4.7251e-02,  2.8049e-07],\n",
      "         [ 0.0000e+00, -1.3718e+01, -1.1653e+00,  ..., -1.8449e-02,\n",
      "           1.2089e-02,  9.1285e-07],\n",
      "         [ 0.0000e+00,  3.4185e+01,  3.2944e+01,  ..., -1.8470e-01,\n",
      "          -3.2323e-01,  1.7098e-05]],\n",
      "\n",
      "        [[-8.8008e+03, -6.0487e+00,  2.1672e+01,  ...,  5.4672e+00,\n",
      "           5.3434e+00,  3.3902e+00],\n",
      "         [-2.2474e+03, -9.9607e-01, -7.2302e+00,  ...,  8.9537e-01,\n",
      "           7.8469e-01,  2.0000e+00],\n",
      "         [ 8.5393e+02,  2.2931e+00, -9.2245e-01,  ...,  7.5494e-01,\n",
      "           8.2081e-01,  1.4878e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  2.5103e+01,  5.0667e+00,  ..., -7.9485e-03,\n",
      "          -8.8520e-02,  1.3687e-07],\n",
      "         [ 0.0000e+00,  2.2362e+01,  1.0904e+01,  ..., -8.1228e-02,\n",
      "          -5.9500e-02,  2.7977e-07],\n",
      "         [ 0.0000e+00,  3.7300e+01, -1.7571e+00,  ...,  1.0565e-01,\n",
      "           1.4841e-01, -2.5754e-06]],\n",
      "\n",
      "        [[-2.3622e+02,  5.0128e+00,  7.0229e-01,  ...,  3.9324e-01,\n",
      "           3.3291e-01,  1.3415e+00],\n",
      "         [ 1.2700e+02,  2.8280e+00, -1.2023e+00,  ...,  1.8517e+00,\n",
      "           1.8144e+00,  1.7317e+00],\n",
      "         [-2.9717e+02, -1.5979e+00,  1.0653e+00,  ..., -2.8316e-01,\n",
      "          -3.5343e-01, -1.4146e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  6.1730e+01,  2.5282e+01,  ...,  1.2652e-01,\n",
      "           3.8683e-02,  1.3352e-07],\n",
      "         [ 0.0000e+00,  1.7805e+01,  7.5183e+00,  ..., -9.7737e-02,\n",
      "          -6.9562e-02,  6.4198e-07],\n",
      "         [ 0.0000e+00, -1.0599e+02, -5.4133e+01,  ...,  2.7103e-01,\n",
      "          -2.3830e+00,  8.0996e-06]],\n",
      "\n",
      "        [[-9.8510e+02, -2.5406e+01, -3.6311e+00,  ...,  2.9150e-01,\n",
      "           1.4211e-01,  2.1220e+00],\n",
      "         [-1.6922e+02,  9.9815e-01,  6.9410e+00,  ...,  7.4113e-01,\n",
      "           7.7671e-01,  3.4146e-01],\n",
      "         [ 2.6902e+02, -3.1134e+00, -2.4209e+00,  ..., -3.4131e-01,\n",
      "          -3.4495e-01, -3.4146e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -3.0471e+01, -1.2594e+01,  ...,  1.9834e-02,\n",
      "          -3.1685e-02,  7.3201e-07],\n",
      "         [ 0.0000e+00, -2.1517e+01, -7.0482e+00,  ..., -2.8984e-02,\n",
      "           9.0061e-02,  5.0137e-07],\n",
      "         [ 0.0000e+00, -7.5796e+01, -2.5505e+01,  ...,  6.4923e-02,\n",
      "           2.0095e-01,  5.2839e-06]]], device='cuda:0')\n",
      "\n",
      "Std: tensor([[[3.2613e+03, 1.6913e+03, 9.1139e+02,  ..., 2.2286e+01,\n",
      "          2.1919e+01, 2.3785e+01],\n",
      "         [1.5404e+03, 4.8212e+02, 2.9815e+02,  ..., 7.0795e+00,\n",
      "          7.3725e+00, 7.5614e+00],\n",
      "         [4.0278e+03, 7.0378e+02, 1.3946e+02,  ..., 1.5256e+01,\n",
      "          1.5031e+01, 1.3334e+01],\n",
      "         ...,\n",
      "         [0.0000e+00, 8.8945e+02, 3.5801e+02,  ..., 3.2611e+00,\n",
      "          3.3211e+00, 1.9572e-06],\n",
      "         [0.0000e+00, 3.8492e+02, 1.6394e+02,  ..., 2.4850e+00,\n",
      "          2.4759e+00, 1.4759e-06],\n",
      "         [0.0000e+00, 1.0874e+03, 1.2807e+03,  ..., 3.4351e+00,\n",
      "          2.5546e+00, 3.6780e-05]],\n",
      "\n",
      "        [[1.2250e+04, 2.5644e+03, 1.3105e+03,  ..., 3.6035e+01,\n",
      "          3.5991e+01, 3.6465e+01],\n",
      "         [3.0371e+03, 8.1296e+02, 4.1103e+02,  ..., 1.3281e+01,\n",
      "          1.3746e+01, 1.2526e+01],\n",
      "         [1.7979e+03, 3.3753e+02, 1.4476e+02,  ..., 8.2061e+00,\n",
      "          8.7268e+00, 7.5800e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 6.0200e+02, 3.1497e+02,  ..., 2.8168e+00,\n",
      "          2.7753e+00, 1.8474e-06],\n",
      "         [0.0000e+00, 5.2066e+02, 4.1996e+02,  ..., 2.8970e+00,\n",
      "          2.7620e+00, 1.4590e-06],\n",
      "         [0.0000e+00, 1.0993e+03, 1.1916e+03,  ..., 3.4030e+00,\n",
      "          3.1027e+00, 4.1760e-05]],\n",
      "\n",
      "        [[1.5743e+03, 2.2949e+02, 1.2751e+02,  ..., 7.7867e+00,\n",
      "          7.4719e+00, 8.7995e+00],\n",
      "         [2.4318e+03, 2.3321e+02, 1.4824e+02,  ..., 6.6779e+00,\n",
      "          6.7680e+00, 6.3798e+00],\n",
      "         [7.3402e+02, 1.0766e+02, 1.0785e+02,  ..., 4.5675e+00,\n",
      "          4.9502e+00, 5.1864e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 1.8992e+02, 1.1449e+02,  ..., 2.4404e+00,\n",
      "          3.0665e+00, 3.2888e-06],\n",
      "         [0.0000e+00, 1.5227e+02, 1.0817e+02,  ..., 2.8592e+00,\n",
      "          2.7142e+00, 1.8945e-06],\n",
      "         [0.0000e+00, 9.6504e+02, 1.4934e+03,  ..., 3.6052e+00,\n",
      "          1.5570e+01, 5.6055e-05]],\n",
      "\n",
      "        [[3.2874e+03, 1.1011e+03, 5.0148e+02,  ..., 1.4638e+01,\n",
      "          1.4654e+01, 1.4994e+01],\n",
      "         [1.4626e+03, 5.9049e+02, 2.2653e+02,  ..., 7.7239e+00,\n",
      "          7.1657e+00, 7.3096e+00],\n",
      "         [2.0155e+03, 4.1916e+02, 1.1880e+02,  ..., 6.9539e+00,\n",
      "          6.7849e+00, 9.7458e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 2.4734e+02, 1.4942e+02,  ..., 3.5838e+00,\n",
      "          2.3396e+00, 2.7880e-06],\n",
      "         [0.0000e+00, 2.1754e+02, 2.0175e+02,  ..., 3.0792e+00,\n",
      "          2.9262e+00, 2.6781e-06],\n",
      "         [0.0000e+00, 7.4624e+02, 1.6554e+03,  ..., 5.5162e+00,\n",
      "          3.9341e+00, 4.3483e-05]]], device='cuda:0')\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "- After -\n",
      "Mean: tensor([[[ 1.0340e-02, -6.2205e-02,  5.8066e-02,  ..., -5.0359e-02,\n",
      "          -5.3271e-02, -2.8898e-02],\n",
      "         [-1.1441e-01, -2.7934e-02,  4.6949e-02,  ..., -1.3853e-01,\n",
      "          -1.4425e-01, -7.6110e-02],\n",
      "         [-4.7613e-01, -7.0188e-02, -3.5002e-02,  ..., -1.6255e-01,\n",
      "          -1.4444e-01, -1.4771e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  1.5319e-01,  1.3193e-01,  ...,  2.8012e-02,\n",
      "           1.6849e-02,  9.0986e-02],\n",
      "         [ 0.0000e+00, -3.1185e-02, -6.3311e-03,  ..., -7.0879e-03,\n",
      "           3.2511e-03,  2.9140e-01],\n",
      "         [ 0.0000e+00,  1.7237e-02,  1.6817e-02,  ..., -4.9956e-02,\n",
      "          -6.8601e-02,  2.8411e-01]],\n",
      "\n",
      "        [[-1.1896e+00, -4.9294e-03,  2.7012e-02,  ...,  1.8434e-01,\n",
      "           1.8026e-01,  1.1260e-01],\n",
      "         [-6.9607e-01, -1.8846e-03, -2.4413e-02,  ...,  6.4984e-02,\n",
      "           5.6747e-02,  1.4456e-01],\n",
      "         [ 4.8667e-01,  7.1413e-03, -5.3628e-03,  ...,  9.3941e-02,\n",
      "           1.0294e-01,  1.7686e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  5.5731e-02,  2.0082e-02,  ..., -2.7544e-03,\n",
      "          -3.0321e-02,  4.6663e-02],\n",
      "         [ 0.0000e+00,  4.6359e-02,  4.1158e-02,  ..., -2.9572e-02,\n",
      "          -2.1629e-02,  8.9896e-02],\n",
      "         [ 0.0000e+00,  1.8727e-02, -6.0930e-04,  ...,  2.8919e-02,\n",
      "           3.1905e-02, -4.1100e-02]],\n",
      "\n",
      "        [[-3.8445e-02,  2.3446e-03,  9.6199e-04,  ...,  1.0141e-02,\n",
      "           7.9818e-03,  4.2683e-02],\n",
      "         [ 3.6325e-02,  4.6352e-03, -4.4789e-03,  ...,  1.3775e-01,\n",
      "           1.3536e-01,  1.2466e-01],\n",
      "         [-1.6807e-01, -6.5402e-03,  7.5985e-03,  ..., -3.6458e-02,\n",
      "          -4.5694e-02, -1.6495e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  1.3837e-01,  1.0392e-01,  ...,  4.5528e-02,\n",
      "           1.3873e-02,  4.5629e-02],\n",
      "         [ 0.0000e+00,  3.6565e-02,  2.7835e-02,  ..., -3.5484e-02,\n",
      "          -2.5126e-02,  2.0518e-01],\n",
      "         [ 0.0000e+00, -4.9822e-02, -2.6912e-02,  ...,  7.3844e-02,\n",
      "          -5.0754e-01,  1.3536e-01]],\n",
      "\n",
      "        [[-1.3910e-01, -1.7658e-02, -4.4212e-03,  ...,  6.6481e-03,\n",
      "           1.4216e-03,  6.9318e-02],\n",
      "         [-5.5047e-02,  1.5154e-03,  2.2451e-02,  ...,  5.3249e-02,\n",
      "           5.6137e-02,  2.1562e-02],\n",
      "         [ 1.5398e-01, -1.1869e-02, -1.5134e-02,  ..., -4.3764e-02,\n",
      "          -4.4622e-02, -3.8565e-02],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -6.9650e-02, -5.3164e-02,  ...,  7.2211e-03,\n",
      "          -1.0576e-02,  2.3033e-01],\n",
      "         [ 0.0000e+00, -4.7946e-02, -2.9478e-02,  ..., -1.0861e-02,\n",
      "           3.0350e-02,  1.6043e-01],\n",
      "         [ 0.0000e+00, -3.5378e-02, -1.2535e-02,  ...,  1.7854e-02,\n",
      "           4.3101e-02,  8.8815e-02]]], device='cuda:0')\n",
      "\n",
      "Std: tensor([[[0.4383, 1.1122, 1.1322,  ..., 0.7651, 0.7537, 0.8117],\n",
      "         [0.4752, 0.8220, 0.9860,  ..., 0.5386, 0.5629, 0.5607],\n",
      "         [2.2910, 2.4747, 0.9094,  ..., 1.9163, 1.9026, 1.5703],\n",
      "         ...,\n",
      "         [0.0000, 2.0067, 1.4848,  ..., 1.1709, 1.1538, 0.6040],\n",
      "         [0.0000, 0.8273, 0.6450,  ..., 0.8900, 0.8605, 0.4698],\n",
      "         [0.0000, 0.5202, 0.6431,  ..., 0.9331, 0.5444, 0.6080]],\n",
      "\n",
      "        [[1.6465, 1.6863, 1.6280,  ..., 1.2371, 1.2375, 1.2444],\n",
      "         [0.9368, 1.3860, 1.3593,  ..., 1.0104, 1.0495, 0.9289],\n",
      "         [1.0227, 1.1869, 0.9439,  ..., 1.0308, 1.1046, 0.8927],\n",
      "         ...,\n",
      "         [0.0000, 1.3582, 1.3063,  ..., 1.0114, 0.9642, 0.5701],\n",
      "         [0.0000, 1.1190, 1.6523,  ..., 1.0375, 0.9599, 0.4644],\n",
      "         [0.0000, 0.5259, 0.5984,  ..., 0.9244, 0.6612, 0.6903]],\n",
      "\n",
      "        [[0.2116, 0.1509, 0.1584,  ..., 0.2673, 0.2569, 0.3003],\n",
      "         [0.7501, 0.3976, 0.4902,  ..., 0.5081, 0.5167, 0.4731],\n",
      "         [0.4175, 0.3786, 0.7033,  ..., 0.5737, 0.6266, 0.6108],\n",
      "         ...,\n",
      "         [0.0000, 0.4285, 0.4748,  ..., 0.8762, 1.0654, 1.0150],\n",
      "         [0.0000, 0.3273, 0.4256,  ..., 1.0240, 0.9433, 0.6030],\n",
      "         [0.0000, 0.4617, 0.7500,  ..., 0.9793, 3.3180, 0.9266]],\n",
      "\n",
      "        [[0.4418, 0.7241, 0.6230,  ..., 0.5025, 0.5039, 0.5117],\n",
      "         [0.4512, 1.0067, 0.7491,  ..., 0.5877, 0.5471, 0.5421],\n",
      "         [1.1464, 1.4739, 0.7746,  ..., 0.8735, 0.8588, 1.1477],\n",
      "         ...,\n",
      "         [0.0000, 0.5580, 0.6197,  ..., 1.2868, 0.8128, 0.8604],\n",
      "         [0.0000, 0.4675, 0.7938,  ..., 1.1028, 1.0170, 0.8524],\n",
      "         [0.0000, 0.3570, 0.8313,  ..., 1.4985, 0.8383, 0.7188]]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegSpectrogram(n_fft=200, complex_mode='as_real')\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "\n",
    "signal_2d_mean, signal_2d_std = calculate_signal_statistics(train_loader, preprocess_train)\n",
    "\n",
    "preprocess_train2 = transforms.Compose([\n",
    "    EegNormalizeMeanStd(mean=signal_2d_mean, std=signal_2d_std)\n",
    "])\n",
    "preprocess_train2 = torch.nn.Sequential(*preprocess_train2.transforms).to(device)\n",
    "\n",
    "pprint.pprint(preprocess_train)\n",
    "pprint.pprint(preprocess_train2)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    print('- Before -')\n",
    "    preprocess_train(sample_batched)   \n",
    "    \n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "    \n",
    "    print()\n",
    "    print('-' * 100)\n",
    "    print()\n",
    "    \n",
    "    print('- After -')\n",
    "    preprocess_train2(sample_batched)\n",
    "    \n",
    "    print('Mean:', torch.mean(sample_batched['signal'], axis=-1))\n",
    "    print()\n",
    "    print('Std:', torch.std(sample_batched['signal'], axis=-1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Speed check without STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_length = 200 * 10\n",
    "multiple = 4\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `EDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=120000, multiple=4, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6000]),std=tensor([6.2312]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([ 0.2844,  0.2253, -0.0821,  0.0339, -0.0259,  0.4161,  0.1093, -0.0760,\n",
      "          -0.1932, -0.1694, -0.0005,  0.0662, -0.0377,  0.1298, -0.2924, -0.1287,\n",
      "           0.2746,  0.0489, -0.0198, -0.0386]),std=tensor([44.3354, 19.7560, 11.2161, 10.9679, 15.1231, 45.9360, 19.8389, 10.3051,\n",
      "          11.4575, 15.2745, 20.2380, 13.9408, 12.9799, 21.6595, 17.7961, 14.4634,\n",
      "          19.4985, 10.7546, 10.9364, 96.2515]),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 26min 59s\n",
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Feather`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=120000, multiple=4, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6000]),std=tensor([6.2312]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([ 0.2844,  0.2253, -0.0821,  0.0339, -0.0259,  0.4161,  0.1093, -0.0760,\n",
      "          -0.1932, -0.1694, -0.0005,  0.0662, -0.0377,  0.1298, -0.2924, -0.1287,\n",
      "           0.2746,  0.0489, -0.0198, -0.0386]),std=tensor([44.3354, 19.7560, 11.2161, 10.9679, 15.1231, 45.9360, 19.8389, 10.3051,\n",
      "          11.4575, 15.2745, 20.2380, 13.9408, 12.9799, 21.6595, 17.7961, 14.4634,\n",
      "          19.4985, 10.7546, 10.9364, 96.2515]),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 1min 11s\n",
      "Wall time: 4.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `memmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=2000, length_limit=120000, multiple=4, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6000]),std=tensor([6.2312]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([ 0.2844,  0.2253, -0.0821,  0.0339, -0.0259,  0.4161,  0.1093, -0.0760,\n",
      "          -0.1932, -0.1694, -0.0005,  0.0662, -0.0377,  0.1298, -0.2924, -0.1287,\n",
      "           0.2746,  0.0489, -0.0198, -0.0386]),std=tensor([44.3354, 19.7560, 11.2161, 10.9679, 15.1231, 45.9360, 19.8389, 10.3051,\n",
      "          11.4575, 15.2745, 20.2380, 13.9408, 12.9799, 21.6595, 17.7961, 14.4634,\n",
      "          19.4985, 10.7546, 10.9364, 96.2515]),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 17.8 s\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    " \n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `memmap` (Drop  Crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegRandomCrop(crop_length=2000, length_limit=120000, multiple=4, latency=2000, return_timing=False)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6000]),std=tensor([6.2312]),eps=1e-08)\n",
      "  (2): EegNormalizeMeanStd(mean=tensor([ 0.2844,  0.2253, -0.0821,  0.0339, -0.0259,  0.4161,  0.1093, -0.0760,\n",
      "          -0.1932, -0.1694, -0.0005,  0.0662, -0.0377,  0.1298, -0.2924, -0.1287,\n",
      "           0.2746,  0.0489, -0.0198, -0.0386]),std=tensor([44.3354, 19.7560, 11.2161, 10.9679, 15.1231, 45.9360, 19.8389, 10.3051,\n",
      "          11.4575, 15.2745, 20.2380, 13.9408, 12.9799, 21.6595, 17.7961, 14.4634,\n",
      "          19.4985, 10.7546, 10.9364, 96.2515]),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 1min 17s\n",
      "Wall time: 6.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    " \n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std)\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Speed check with STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence length: (3000) would become (78, 77) after the STFT with n_fft (155) and hop_length (39).\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crop_length = 300 * 10\n",
    "n_fft, hop_length, seq_len_2d = calculate_stft_params(seq_length=crop_length, verbose=True)\n",
    "multiple = 2\n",
    "batch_size = 128\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegSpectrogram(n_fft=n_fft, hop_length=hop_length, complex_mode='as_real')\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "signal_2d_mean, signal_2d_std = calculate_signal_statistics(train_loader, preprocess_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `EDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=3000, length_limit=120000, multiple=2, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6000]),std=tensor([6.2312]),eps=1e-08)\n",
      "  (2): EegSpectrogram(n_fft=155, complex_mode=as_real, stft_kwargs={'hop_length': 39})\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([[ 3.1320e+01,  3.4730e-01,  1.6575e-01,  ..., -3.2248e-02,\n",
      "           -3.3008e-02, -3.1671e-02],\n",
      "          [-1.2258e+01,  2.0957e-02,  7.7337e-02,  ..., -1.5162e-03,\n",
      "           -6.2796e-03, -5.6553e-03],\n",
      "          [-1.3421e-01,  1.5528e-02,  2.7589e-02,  ...,  4.3992e-04,\n",
      "           -1.0055e-03, -1.1822e-03],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  7.0140e-01,  3.1880e-01,  ..., -6.5730e-04,\n",
      "            1.5833e-03, -2.0423e-04],\n",
      "          [ 0.0000e+00,  2.2840e-01,  9.8081e-02,  ..., -1.5298e-03,\n",
      "            1.5692e-03, -6.6039e-05],\n",
      "          [ 0.0000e+00,  5.5736e-02,  8.6825e-02,  ..., -3.2863e-04,\n",
      "            5.7027e-04,  2.0031e-04]], device='cuda:0'),std=tensor([[6.0426e+03, 1.0585e+03, 5.3499e+02,  ..., 2.6778e+01, 2.6754e+01,\n",
      "           2.6766e+01],\n",
      "          [2.5743e+03, 3.9961e+02, 2.0767e+02,  ..., 1.1983e+01, 1.1946e+01,\n",
      "           1.1972e+01],\n",
      "          [1.3842e+03, 1.9016e+02, 1.1044e+02,  ..., 7.1543e+00, 7.1089e+00,\n",
      "           7.1490e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 3.0709e+02, 1.7470e+02,  ..., 2.5605e+00, 2.5958e+00,\n",
      "           2.6175e+00],\n",
      "          [0.0000e+00, 3.3320e+02, 1.8507e+02,  ..., 2.5655e+00, 2.5926e+00,\n",
      "           2.6129e+00],\n",
      "          [0.0000e+00, 1.9492e+03, 2.0880e+03,  ..., 5.6784e+00, 5.3058e+00,\n",
      "           4.5623e+00]], device='cuda:0'),eps=1e-08)\n",
      ")\n",
      "torch.Size([256, 40, 78, 77])\n",
      "CPU times: total: 27min 38s\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='edf',\n",
    "                                                                                  transform=transform)\n",
    " \n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegSpectrogram(n_fft=n_fft, hop_length=hop_length, complex_mode='as_real'),\n",
    "    EegNormalizeMeanStd(mean=signal_2d_mean, std=signal_2d_std),\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)\n",
    "    size = sample_batched['signal'].size()\n",
    "    \n",
    "print(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Feather`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=3000, length_limit=120000, multiple=2, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6000]),std=tensor([6.2312]),eps=1e-08)\n",
      "  (2): EegSpectrogram(n_fft=155, complex_mode=as_real, stft_kwargs={'hop_length': 39})\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([[ 3.1320e+01,  3.4730e-01,  1.6575e-01,  ..., -3.2248e-02,\n",
      "           -3.3008e-02, -3.1671e-02],\n",
      "          [-1.2258e+01,  2.0957e-02,  7.7337e-02,  ..., -1.5162e-03,\n",
      "           -6.2796e-03, -5.6553e-03],\n",
      "          [-1.3421e-01,  1.5528e-02,  2.7589e-02,  ...,  4.3992e-04,\n",
      "           -1.0055e-03, -1.1822e-03],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  7.0140e-01,  3.1880e-01,  ..., -6.5730e-04,\n",
      "            1.5833e-03, -2.0423e-04],\n",
      "          [ 0.0000e+00,  2.2840e-01,  9.8081e-02,  ..., -1.5298e-03,\n",
      "            1.5692e-03, -6.6039e-05],\n",
      "          [ 0.0000e+00,  5.5736e-02,  8.6825e-02,  ..., -3.2863e-04,\n",
      "            5.7027e-04,  2.0031e-04]], device='cuda:0'),std=tensor([[6.0426e+03, 1.0585e+03, 5.3499e+02,  ..., 2.6778e+01, 2.6754e+01,\n",
      "           2.6766e+01],\n",
      "          [2.5743e+03, 3.9961e+02, 2.0767e+02,  ..., 1.1983e+01, 1.1946e+01,\n",
      "           1.1972e+01],\n",
      "          [1.3842e+03, 1.9016e+02, 1.1044e+02,  ..., 7.1543e+00, 7.1089e+00,\n",
      "           7.1490e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 3.0709e+02, 1.7470e+02,  ..., 2.5605e+00, 2.5958e+00,\n",
      "           2.6175e+00],\n",
      "          [0.0000e+00, 3.3320e+02, 1.8507e+02,  ..., 2.5655e+00, 2.5926e+00,\n",
      "           2.6129e+00],\n",
      "          [0.0000e+00, 1.9492e+03, 2.0880e+03,  ..., 5.6784e+00, 5.3058e+00,\n",
      "           4.5623e+00]], device='cuda:0'),eps=1e-08)\n",
      ")\n",
      "torch.Size([256, 40, 78, 77])\n",
      "CPU times: total: 1min 12s\n",
      "Wall time: 4.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='feather',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegSpectrogram(n_fft=n_fft, hop_length=hop_length, complex_mode='as_real'),\n",
    "    EegNormalizeMeanStd(mean=signal_2d_mean, std=signal_2d_std),\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)\n",
    "    size = sample_batched['signal'].size()\n",
    "    \n",
    "print(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `memmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=3000, length_limit=120000, multiple=2, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeAge(mean=tensor([70.6000]),std=tensor([6.2312]),eps=1e-08)\n",
      "  (2): EegSpectrogram(n_fft=155, complex_mode=as_real, stft_kwargs={'hop_length': 39})\n",
      "  (3): EegNormalizeMeanStd(mean=tensor([[ 3.1320e+01,  3.4730e-01,  1.6575e-01,  ..., -3.2248e-02,\n",
      "           -3.3008e-02, -3.1671e-02],\n",
      "          [-1.2258e+01,  2.0957e-02,  7.7337e-02,  ..., -1.5162e-03,\n",
      "           -6.2796e-03, -5.6553e-03],\n",
      "          [-1.3421e-01,  1.5528e-02,  2.7589e-02,  ...,  4.3992e-04,\n",
      "           -1.0055e-03, -1.1822e-03],\n",
      "          ...,\n",
      "          [ 0.0000e+00,  7.0140e-01,  3.1880e-01,  ..., -6.5730e-04,\n",
      "            1.5833e-03, -2.0423e-04],\n",
      "          [ 0.0000e+00,  2.2840e-01,  9.8081e-02,  ..., -1.5298e-03,\n",
      "            1.5692e-03, -6.6039e-05],\n",
      "          [ 0.0000e+00,  5.5736e-02,  8.6825e-02,  ..., -3.2863e-04,\n",
      "            5.7027e-04,  2.0031e-04]], device='cuda:0'),std=tensor([[6.0426e+03, 1.0585e+03, 5.3499e+02,  ..., 2.6778e+01, 2.6754e+01,\n",
      "           2.6766e+01],\n",
      "          [2.5743e+03, 3.9961e+02, 2.0767e+02,  ..., 1.1983e+01, 1.1946e+01,\n",
      "           1.1972e+01],\n",
      "          [1.3842e+03, 1.9016e+02, 1.1044e+02,  ..., 7.1543e+00, 7.1089e+00,\n",
      "           7.1490e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 3.0709e+02, 1.7470e+02,  ..., 2.5605e+00, 2.5958e+00,\n",
      "           2.6175e+00],\n",
      "          [0.0000e+00, 3.3320e+02, 1.8507e+02,  ..., 2.5655e+00, 2.5926e+00,\n",
      "           2.6129e+00],\n",
      "          [0.0000e+00, 1.9492e+03, 2.0880e+03,  ..., 5.6784e+00, 5.3058e+00,\n",
      "           4.5623e+00]], device='cuda:0'),eps=1e-08)\n",
      ")\n",
      "torch.Size([256, 40, 78, 77])\n",
      "CPU times: total: 16.2 s\n",
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=crop_length,\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=multiple, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(transform)\n",
    "\n",
    "config_data, train_dataset, val_dataset, test_dataset = load_caueeg_task_datasets(dataset_path=data_path, \n",
    "                                                                                  task='task2',\n",
    "                                                                                  load_event=False, \n",
    "                                                                                  file_format='memmap',\n",
    "                                                                                  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=pin_memory,\n",
    "                          collate_fn=eeg_collate_fn)\n",
    "\n",
    "preprocess_train = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeAge(mean=age_mean, std=age_std), \n",
    "    EegSpectrogram(n_fft=n_fft, hop_length=hop_length, complex_mode='as_real'),\n",
    "    EegNormalizeMeanStd(mean=signal_2d_mean, std=signal_2d_std),\n",
    "])\n",
    "preprocess_train = torch.nn.Sequential(*preprocess_train.transforms).to(device)\n",
    "pprint.pprint(preprocess_train)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_train(sample_batched)\n",
    "    size = sample_batched['signal'].size()\n",
    "    \n",
    "print(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test on longer sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    EegRandomCrop(crop_length=12000, length_limit=120000, multiple=2, latency=2000, return_timing=False)\n",
      "    EegDropChannels(drop_index=20)\n",
      "    EegToTensor()\n",
      ")\n",
      "Sequential(\n",
      "  (0): EegToDevice(device=cuda)\n",
      "  (1): EegNormalizeMeanStd(mean=tensor([ 0.2844,  0.2253, -0.0821,  0.0339, -0.0259,  0.4161,  0.1093, -0.0760,\n",
      "          -0.1932, -0.1694, -0.0005,  0.0662, -0.0377,  0.1298, -0.2924, -0.1287,\n",
      "           0.2746,  0.0489, -0.0198, -0.0386]),std=tensor([44.3354, 19.7560, 11.2161, 10.9679, 15.1231, 45.9360, 19.8389, 10.3051,\n",
      "          11.4575, 15.2745, 20.2380, 13.9408, 12.9799, 21.6595, 17.7961, 14.4634,\n",
      "          19.4985, 10.7546, 10.9364, 96.2515]),eps=1e-08)\n",
      "  (2): EegNormalizeAge(mean=tensor([70.6000]),std=tensor([6.2312]),eps=1e-08)\n",
      ")\n",
      "CPU times: total: 12 s\n",
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "longer_transform = transforms.Compose([\n",
    "    EegRandomCrop(crop_length=200*10*6,     # crop: 1m\n",
    "                  length_limit=200*60*10,   # length: 10m\n",
    "                  multiple=2, \n",
    "                  latency=200*10),          # latency: 10s\n",
    "    EegDropChannels(channel_photic), \n",
    "    EegToTensor()\n",
    "])\n",
    "pprint.pprint(longer_transform)\n",
    "\n",
    "config_data, longer_test_dataset = load_caueeg_task_split(dataset_path=data_path, \n",
    "                                                          task='task2', \n",
    "                                                          split='test',\n",
    "                                                          load_event=False,\n",
    "                                                          file_format='feather', \n",
    "                                                          transform=longer_transform)\n",
    "\n",
    "longer_test_loader = DataLoader(longer_test_dataset,\n",
    "                                batch_size=32,\n",
    "                                shuffle=True,\n",
    "                                drop_last=False,\n",
    "                                num_workers=num_workers,\n",
    "                                pin_memory=pin_memory,\n",
    "                                collate_fn=eeg_collate_fn)\n",
    " \n",
    "preprocess_test = transforms.Compose([\n",
    "    EegToDevice(device=device), \n",
    "    EegNormalizeMeanStd(mean=signal_mean, std=signal_std),\n",
    "    EegNormalizeAge(mean=age_mean, std=age_std),\n",
    "])\n",
    "preprocess_test = torch.nn.Sequential(*preprocess_test.transforms).to(device)\n",
    "pprint.pprint(preprocess_test)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(train_loader):\n",
    "    preprocess_test(sample_batched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
